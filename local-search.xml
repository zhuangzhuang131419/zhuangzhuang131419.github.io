<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>《数据密集型应用系统设计》-读书笔记2</title>
    <link href="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/"/>
    <url>/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/</url>
    
    <content type="html"><![CDATA[<h1 id="第二部分：分布式数据系统"><a href="#第二部分：分布式数据系统" class="headerlink" title="第二部分：分布式数据系统"></a>第二部分：分布式数据系统</h1><ul><li>扩展性<ul><li>当数据量或者读写负载巨大，严重超出了单台机器的处理上限，需要将负载分散到多台机器上。</li></ul></li><li>容错和高可用性<ul><li>当单台机器出现故障，还希望应用系统可以继续工作，这是需要采用多台机器提供冗余。</li></ul></li><li>延迟考虑<ul><li>如果客户遍布世界各地，通常需要考虑在全球范围内部署服务，以方便用户就近访问最近数据中心所提供的服务。</li></ul></li></ul><h2 id="系统扩展能力"><a href="#系统扩展能力" class="headerlink" title="系统扩展能力"></a>系统扩展能力</h2><p>当负载增加需要更强的处理能力时，最简单的办法就是购买更强大的机器（垂直扩容）。</p><ul><li><strong>共享内存架构</strong><ul><li>所有这些组件的集合可看做一台大机器。</li><li>共享内存架构的问题在于，成本增长过快甚至超过了线性：两倍的CPU，两倍的内存，两倍的磁盘容量可能不能将成本控制在两倍。</li></ul></li><li><strong>共享磁盘架构</strong><ul><li>拥有多台服务器，每个服务器各自拥有独立的CPU和内存，然后将数据存储在可共享访问的磁盘阵列上。</li><li>服务器与磁盘阵列之间往往通过高速网络连接。</li></ul></li></ul><h2 id="无共享结构"><a href="#无共享结构" class="headerlink" title="无共享结构"></a>无共享结构</h2><p>与上面的垂直扩容相比较之下，无共享架构优点更加明显。</p><ul><li>运行数据库软件的机器或者虚拟机成为<strong>节点</strong>。</li><li>每个<strong>节点</strong>独立使用本地的CPU，内存和磁盘。</li><li>节点之间的多有协调通信等任务全部运行在传统网络之上且核心逻辑主要依靠软件来实现。</li></ul><h2 id="复制与分区"><a href="#复制与分区" class="headerlink" title="复制与分区"></a>复制与分区</h2><ul><li>复制<ul><li>在多个节点上保存相同数据的副本，每个副本具体的存储位置可能不尽相同。</li></ul></li><li>分区<ul><li>将一个大块头的数据库拆分成多个较小的子集即<strong>分区</strong>，不同的分区分配给不同的节点。</li></ul></li></ul><h1 id="第五章-数据复制"><a href="#第五章-数据复制" class="headerlink" title="第五章 数据复制"></a>第五章 数据复制</h1><h1 id="第六章-分区"><a href="#第六章-分区" class="headerlink" title="第六章 分区"></a>第六章 分区</h1><h1 id="第七章-事务"><a href="#第七章-事务" class="headerlink" title="第七章 事务"></a>第七章 事务</h1><blockquote><p>事务将应用程序的多个读、写操作捆绑在一起成为一个逻辑操作单元</p></blockquote><p>但是并非每个应用程序都需要事务机制，有时可以弱化事务处理或完全放弃事务（为了实现更高的性能或更高的可用性）。</p><h2 id="深入理解事务"><a href="#深入理解事务" class="headerlink" title="深入理解事务"></a>深入理解事务</h2><p>随着非关系（NoSQL）数据库开始兴起。它们的目标是通过提供新的数据模型，以及内置的复制和分区等手段来改进传统的关系模型。</p><h3 id="ACID的含义"><a href="#ACID的含义" class="headerlink" title="ACID的含义"></a>ACID的含义</h3><p>实际上，各家数据库所实现的ACID并不尽相同。</p><h4 id="原子性-Atomicity"><a href="#原子性-Atomicity" class="headerlink" title="原子性 Atomicity"></a>原子性 Atomicity</h4><p>有一个误区：</p><blockquote><p>ACID中的原子性并不关乎多个操作的并发性，它没有描述多个线程试图访问相同的数据会发生什么情况，这其实是隔离性所定义的。</p></blockquote><p>ACID原子性实际上描述的是：</p><p><strong>客户端发起一个包含多个写操作的请求时可能发生的情况。</strong></p><p>在完成一部分写入操作后，系统发生了故障</p><ul><li>进程崩溃</li><li>网络中断</li><li>磁盘变满</li><li>违反了某种完整性约束</li></ul><p>出现了上述故障而导致无法完成最终提交时，事务会终止，数据库回滚。</p><blockquote><p>ACID中原子性所定义的特征是：在出错时中止事务，并将部分完成的写入全部丢弃。</p></blockquote><h4 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性 Consistency"></a>一致性 Consistency</h4><p>一致性这个词目前有多种含义：</p><ul><li>第五章讨论副本一致性以及异步复制模型时，引出最终一致性问题。</li><li>一致性哈希则是某些系统用于动态分区再平衡的方法。</li><li>CAP理论中，一致性一词用来表示线性化。</li><li>ACID中，一致性主要指数据库处于应用程序所期待的“预期状态”。</li></ul><blockquote><p>如果某事物从一个有效的状态开始，并且事务中任何更新操作都没有违背约束，那么最后的结果依然符合有效状态。</p></blockquote><p>这种一致性本质要求应用层来维护状态一致，应用程序有责任正确的定义事务来保持一致性。</p><p>ACID中的一致性更多是应用层的属性。</p><h4 id="隔离性-Isolation"><a href="#隔离性-Isolation" class="headerlink" title="隔离性 Isolation"></a>隔离性 Isolation</h4><blockquote><p>意味着并发执行的多个事务相互隔离，它们不能互相交叉。</p></blockquote><ul><li>串行性隔离<ul><li>虽然实际上它们可能同时运行，但数据库系统要确保当事务提交时，其结果与串行执行完全相同。</li></ul></li><li>快照隔离<ul><li>提供了比串行化更弱的保证。</li></ul></li></ul><h4 id="持久性-Durability"><a href="#持久性-Durability" class="headerlink" title="持久性 Durability"></a>持久性 Durability</h4><blockquote><p>保证一旦事务提交成功，即使存在硬件故障或数据库崩溃，事务所写入的任何数据也不会消失。</p></blockquote><h3 id="单对象与多对象事务操作"><a href="#单对象与多对象事务操作" class="headerlink" title="单对象与多对象事务操作"></a>单对象与多对象事务操作</h3><p>多对象事务目的通常是为了在多个数据对象之间保持同步。</p><p>对于关系数据库，客户端通常与数据库服务器建立TCP网络连接，因而对于特定的某个连接，SQL语句BEGIN TRANSACTION和COMMIT之间的所有操作都属于同一个事物。</p><p>例：电子邮件应用</p><ul><li>其他用户看到要么是更新后的电子邮件和更新后的计数器，要么是两者都未更新，而不会是两者不一致。（隔离性）</li><li>如果事务执行过程中发生错误，导致邮箱和未读计数器二者不同步。则事务将被终止，且此前插入的电子邮件将被回滚。（原子性）</li></ul><h4 id="单对象写入"><a href="#单对象写入" class="headerlink" title="单对象写入"></a>单对象写入</h4><ul><li><p>存储引擎在单节点、单个对象层面上提供原子性和隔离性。</p><ul><li>出现宕机时，基于日志回复来实现原子性（第三章“可靠的B-Tree”）</li><li>对每个对象采用加锁的方式来实现隔离，确保每次只允许一个线程访问对象。</li></ul></li><li><p>某些数据库还提供了高级的原子操作</p><ul><li>原子自增操作</li><li>compare-and-set</li></ul></li></ul><blockquote><p>通常意义上的事务针对的是多个对象，将多个操作聚合为一个逻辑执行单元。</p></blockquote><h4 id="多对象事务的必要性"><a href="#多对象事务的必要性" class="headerlink" title="多对象事务的必要性"></a>多对象事务的必要性</h4><ul><li>对于关系型数据模型，表中的某行可能是另一个表中的外键。</li><li>对于文档数据模型，更新非规范化数据时，就需要一次更新多个文档。此时多对象食物就可以有效防止非规范化数据之间出现不同步。</li><li>对于带有二级索引的数据库，每次更改值时都需要同步更新索引。</li></ul><h4 id="处理错误与中止"><a href="#处理错误与中止" class="headerlink" title="处理错误与中止"></a>处理错误与中止</h4><blockquote><p>ACID数据库基于这样的一个理念：如果存在违反原子性、隔离性或持久性的风险，则完全放弃整个事务，而不是部分放弃。</p></blockquote><ul><li>如果事务实际已经执行成功，但返回给客户端的消息在网络传输时发生意外，那么重试就会导致重复执行，此时需要额外的应用级重复数据删除机制。</li><li>如果错误是由于系统超负荷所导致，则重试事务将使情况变得更槽。为此，可以设定一个重试次数上限，例如指数回退，同时要尝试解决系统过载本身的问题。</li><li>由临时性故障（例如死锁，隔离违例，网络闪断和节点切换等）所导致的错误需要重试。但出现永久性故障（例如违反约束），则重试毫无意义。</li><li>如果在数据库之外，事务还产生其他副作用，即使事务被终止，这些副作用可能已事实生效。可以采用两阶段提交。</li><li>如果客户端在重试过程中也发生失败，没有其他人继续负责重试，则那些待写入的数据可能会因此而丢失。</li></ul><h2 id="弱隔离级别"><a href="#弱隔离级别" class="headerlink" title="弱隔离级别"></a>弱隔离级别</h2><blockquote><p>可串行化隔离（serializable）意味着数据库保证事务的最终执行结果与串行执行结果相同</p></blockquote><p>但是往往可串行化隔离意味着性能方面的损失。需要我们在实际开发环境中进行选择。</p><h3 id="读-提交-Read-Committed"><a href="#读-提交-Read-Committed" class="headerlink" title="读-提交 Read Committed"></a>读-提交 Read Committed</h3><ol><li><p>读数据库时，只能看到已成功提交的数据。（防止脏读）</p></li><li><p>写数据库时，只会覆盖已成功提交的数据。（防止脏写）</p></li></ol><h4 id="防止脏读"><a href="#防止脏读" class="headerlink" title="防止脏读"></a>防止脏读</h4><blockquote><p>脏读：某个事务已经完成部分数据写入，但事务尚未提交（或终止），另一个事务可以看到尚未提交的数据。</p></blockquote><p>有以下需求时，需要防止脏读</p><ul><li><p>事务需要更新多个对象，脏读意味着另一个事物可能会看到部分更新，而非全部。</p></li><li><p>如果事务发生终止，则所有写入操作都需要回滚。如果发生了脏读，这意味着他可能会看到一些稍后被回滚的数据。</p></li></ul><h4 id="防止脏写"><a href="#防止脏写" class="headerlink" title="防止脏写"></a>防止脏写</h4><blockquote><p>脏写：覆盖先写尚未提交事务的写入。</p></blockquote><p>防止脏写可以避免：</p><ul><li><p>如果事务需要更新多个对象，脏写会带来非预期的错误结果。</p></li><li><p>但是脏读不能解决“更新丢失”的问题。</p></li></ul><h4 id="实现读-提交"><a href="#实现读-提交" class="headerlink" title="实现读-提交"></a>实现读-提交</h4><p>数据库通常采用<strong>行级锁</strong>来防止脏写/读：</p><p>当事务想修改/读取某个对象（例如行或文档）时，它必须首先获得该对象的锁；然后一直持有锁直到事务提交（终止）。这种锁是由处于读-提交模式（或更强隔离级别）数据库自动完成的。</p><p>但是读锁在实际中并不可行，因为运行时间较长的写事务会导致许多只读的事务等待太久。</p><p>因此大多数数据库采用了多版本的方法来防止脏读：对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。（在事务提交之前，所有其他读操作都读取旧值；仅当写事务提交之后，才会切换到读取新值）</p><h3 id="快照级别隔离与可重复读-Snapshot-Isolation-and-Repeatable-Read"><a href="#快照级别隔离与可重复读-Snapshot-Isolation-and-Repeatable-Read" class="headerlink" title="快照级别隔离与可重复读 Snapshot Isolation and Repeatable Read"></a>快照级别隔离与可重复读 Snapshot Isolation and Repeatable Read</h3><blockquote><p>不可重复读：在一个事务中，两次读取的值不一样。</p></blockquote><p>有些场景不允许这种不一致的情况发生：</p><ul><li>备份场景<ul><li>在备份的过程中，可以继续写入数据库，得到的镜像里可能包含部分旧版本数据和部分新版本数据。如果从这样的备份进行恢复，最终就导致了永久性的不一致。</li></ul></li><li>分析查询与完整性检查场景</li></ul><p>可以使用<strong>快照隔离级别</strong>来解决上述问题。</p><blockquote><p>每个事务都从数据库的一致性快照中读取，事务一开始所看到是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事物都只看到该特定时间点的旧数据，</p></blockquote><h4 id="实现快照级别隔离"><a href="#实现快照级别隔离" class="headerlink" title="实现快照级别隔离"></a>实现快照级别隔离</h4><p>快照级别隔离的实现通常采用写锁来防止脏写。但是，读取则不需要加锁。</p><blockquote><p>数据库是采用多版本并发控制（MultiVersion Concurrency Control, MVCC）来实现快照级别隔离。</p></blockquote><p>因为读-提交只需要保留对象的两个版本就足够了：一个已提交的旧版本和尚未提交的新版本。所以，支持快照级别隔离的存储引擎往往直接采用MVCC来实现读-提交隔离。</p><p>做法为：</p><ul><li>在读-提交级别下，对每一个不同的查询单独创建一个快照</li><li>在快照级别下，使用一个快照来运行整个事务</li></ul><h4 id="一致性快照的可见性规则"><a href="#一致性快照的可见性规则" class="headerlink" title="一致性快照的可见性规则"></a>一致性快照的可见性规则</h4><blockquote><p>当事务读数据库时，通过事务ID可以决定哪些对象可见，哪些不可见。</p></blockquote><p>当以下两个条件都成立，则该数据对象对事务可见：</p><ul><li>事务开始时刻，创建该对象的事务已经完成了提交。</li><li>对象没有被标记删除；或者即使标记了，但删除事务在当前事务开始时还没有完成提交。</li></ul><h4 id="索引与快照级别隔离"><a href="#索引与快照级别隔离" class="headerlink" title="索引与快照级别隔离"></a>索引与快照级别隔离</h4><p>这种多版本数据库如何支持索引呢？</p><ol><li>索引直接指向对象的所有版本，然后想办法过滤对当前事务不可见的那些版本。</li><li>采用追加/写时复制的技术。当需要更新时，不会修改现有的页面，而总是创建一个新的修改副本，拷贝必要的内容，然后让父结点，或者递归向上直到树的root结点都指向新创建的结点。<ul><li>每次写入事务都会创建一个新的B-Tree root，代表该时刻数据库的一致性快照。</li><li>这时候就没有必要根据事务ID再去过滤掉某些对象，每笔写入都会修改现有的B-Tree，因为之后的查询可以直接作用于特定快照B-Tree。</li></ul></li></ol><h3 id="防止更新丢失"><a href="#防止更新丢失" class="headerlink" title="防止更新丢失"></a>防止更新丢失</h3><p>当有两个事务在同样的数据对象上执行类似操作时，由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一个事务的修改值可能会丢失。</p><p>目前有以下集中解决方案：</p><h4 id="原子写操作"><a href="#原子写操作" class="headerlink" title="原子写操作"></a>原子写操作</h4><ul><li>原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前不会被其他事务读取。</li><li>另一种实现方式是强制所有的原子操作都在单线程上执行。</li></ul><h4 id="显示加锁"><a href="#显示加锁" class="headerlink" title="显示加锁"></a>显示加锁</h4><p>由应用程序显示锁定待更新的对象。</p><p>例如，考虑一个多人游戏，其中几个玩家可以同时移动同一个数字。只靠原子操作可能还不够，因为应用程序还需要确保玩家的移动还需要遵守其他游戏规则，这涉及一些应用层逻辑。</p><h4 id="自动监测更新丢失"><a href="#自动监测更新丢失" class="headerlink" title="自动监测更新丢失"></a>自动监测更新丢失</h4><p>原子操作和锁都是通过强制“读-修改-写回”操作序列串行执行来防止丢失更新。</p><p>也可以先让他们并发执行，但如果事务管理其检测到了更新丢失风险，则会终止当前事务，并强制回退到安全的“读-修改-写回”方式。</p><blockquote><p>MySQL/InnoDB的可重复读却并不支持检测更新丢失。</p></blockquote><h4 id="原子比较和设置"><a href="#原子比较和设置" class="headerlink" title="原子比较和设置"></a>原子比较和设置</h4><p>在有的不提供事务支持的数据库中，会支持原子“比较和设置”操作。（只有在上次读取的数据没有发生变化时才允许更新；如果已经发生更新，则回退到“读-修改-写回”方式。）</p><h4 id="冲突解决与复制"><a href="#冲突解决与复制" class="headerlink" title="冲突解决与复制"></a>冲突解决与复制</h4><p>由于多节点上的数据副本，不同的节点可能会并发修改数据，因此必须采取一些额外的措施来防止丢失更新。</p><p>对于多主节点或者无主节点的多副本数据库，由于支持多个并发写，且通常以异步方式来同步更新，所以会出现多个最新的数据副本。</p><p>多副本数据库通常支持多个并发写，然后保留多个冲突版本（互称为兄弟），之后由应用层逻辑或依靠特定的数据结构来解决、合并多版本。</p><p>将在第九章详细介绍。</p><h3 id="写倾斜和幻读"><a href="#写倾斜和幻读" class="headerlink" title="写倾斜和幻读"></a>写倾斜和幻读</h3><p>可以把写倾斜视为一种更广义的更新丢失问题。</p><blockquote><p>如果两个事务读取相同的一组对象，然后更新其中一部分：不同的事务可能更新不同的对象，则可能发生写倾斜；而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失。</p></blockquote><p>如果不能使用可串行化级别隔离，一个次优的选择是对事务依赖的行来显示的加锁。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">BEGIN</span> TRANSACTION;<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> doctors <span class="hljs-keyword">WHERE</span> on_call <span class="hljs-operator">=</span> <span class="hljs-literal">true</span> <span class="hljs-keyword">AND</span> shift_id <span class="hljs-operator">=</span> <span class="hljs-number">1234</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><span class="hljs-keyword">UPDATE</span> doctors <span class="hljs-keyword">SET</span> on_call <span class="hljs-operator">=</span> <span class="hljs-literal">false</span> <span class="hljs-keyword">WHERE</span> name <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;Alice&#x27;</span> <span class="hljs-keyword">AND</span> shift_id <span class="hljs-operator">=</span> <span class="hljs-number">1234</span>;<br><span class="hljs-keyword">COMMIT</span>;<br></code></pre></td></tr></table></figure><p>其中 <code>FOR UPDATE</code> 语句会通知数据库对返回的所有结果行自动加锁。</p><h4 id="为何会发生写倾斜"><a href="#为何会发生写倾斜" class="headerlink" title="为何会发生写倾斜"></a>为何会发生写倾斜</h4><ol><li>首先输入一些匹配条件，即采用SELECT查询所有满足条件的行。</li><li>根据查询的结果，应用层代码来决定下一步的操作。</li><li>如果应用程序决定继续执行，它将发起数据库写入（INSERT, UPDATE 或 DELETE）并提交事务。<strong>而这个写操作通常会改变步骤2做出的前提条件。</strong></li></ol><h4 id="实体化冲突"><a href="#实体化冲突" class="headerlink" title="实体化冲突"></a>实体化冲突</h4><p>并没有看懂书中的意思</p><h2 id="串行化"><a href="#串行化" class="headerlink" title="串行化"></a>串行化</h2><p>可串行化隔离是最强的隔离级别。它保证即使事务可能会并行执行，但最终的结果与每次一个个串行执行结果相同。</p><h4 id="采用存储过程封装事务"><a href="#采用存储过程封装事务" class="headerlink" title="采用存储过程封装事务"></a>采用存储过程封装事务</h4><blockquote><p>因为性能影响，采用单线程串行执行的系统往往不支持交互式的多语句事务。应用程序必须提交整个事务代码作为存储过程（stored procedure）打包发送到数据库。</p></blockquote><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E4%BA%A4%E4%BA%92%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B8%8E%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB.png" class="" title="交互式事务与存储过程的区别"><p>优点：</p><ul><li>存储过程与内存式数据储存使得单线程上执行所有事务变得可行。</li></ul><p>缺点：</p><ul><li>在数据库中运行代码难以管理：与应用服务器相比，调试更加困难，版本控制与部署复杂，测试不便，并且不容易和指标监控系统集成。</li><li>数据库通常比应用服务器要求更高的性能。数据库中一个设计不好的存储过程要比同样低效的应用服务器代码带来更大的麻烦。</li></ul><h4 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h4><p>对于那些高写入需求的应用程序，单线程事务处理很容易称为严重的瓶颈。为了扩展到多个CPU核和多节点，可以对数据进行分区。</p><p>但是，对于跨分区的事务，数据库必须在设计的所有分区之间协调事务。存储过程需要跨越所有分区加锁执行，以确保整个系统的可串行化。</p><p>跨分区的事物具有额外的协调开销，其性能比单分区内要慢得多。</p><h4 id="串行执行小结"><a href="#串行执行小结" class="headerlink" title="串行执行小结"></a>串行执行小结</h4><p>满足下面的条件，串行执行事务可以实现串行隔离：</p><ul><li>事务必须简短而高效，否则一个缓慢的事务会影响到所有其他事务的执行性能。</li><li>仅限于活动数据集完全可以加载到内存的场景。有些很少访问的数据可能会被移到磁盘，但万一单线程事务需要访问它，就会严重拖累性能。</li><li>写入吞吐量必须足够低，才能在单个CPU核上处理；否则就需要采用分区，最好没有跨分区事务。</li><li>跨分区事务虽然也支持，但是占比必须很小。</li></ul><h3 id="两阶段加锁-two-phase-locking"><a href="#两阶段加锁-two-phase-locking" class="headerlink" title="两阶段加锁 two-phase locking"></a>两阶段加锁 two-phase locking</h3><blockquote><p>两阶段加锁（2PL）听起来和两阶段提交（2PC）很相近，但并不是同一个东西。</p></blockquote><p>2PL不仅在并发写操作之间互斥，读取也会和修改产生互斥。这就是两阶段加锁和快照级别隔离（读写互不干扰）的区别。</p><p>因为2PL提供了串行化，所以它可以防止前面讨论的所有竞争条件，包括更新丢失和写倾斜。</p><h4 id="实现两阶段加锁"><a href="#实现两阶段加锁" class="headerlink" title="实现两阶段加锁"></a>实现两阶段加锁</h4><blockquote><p>目前，2PL已经用于MySQL 和 SQL Server 中的“可串行化隔离”，以及DB2中的“可重复读隔离”</p></blockquote><ul><li>如果事务要读取对象，必须先以共享模式获得锁。</li><li>如果事务要修改对象，必须以独占模式获取锁。</li><li>如果事务首先读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁。</li><li>事务获得锁之后，一直持有所直到事务结束（包括提交或中止）。</li></ul><p>数据库会自动检测事务之间死锁情况，并强制中止其中一个，稍后由应用层重试。</p><h4 id="两阶段加锁的性能"><a href="#两阶段加锁的性能" class="headerlink" title="两阶段加锁的性能"></a>两阶段加锁的性能</h4><blockquote><p>其事务吞吐量和查询响应时间相比于其他弱隔离级别下降非常多</p></blockquote><p>当一个事务还需要等待另一个事务时，那么最终的等待时间是没有上限的</p><p>如果事务由于死锁而被强行终止，应用层就必须从头重试。</p><h4 id="谓词锁-Predicate-locks"><a href="#谓词锁-Predicate-locks" class="headerlink" title="谓词锁 Predicate locks"></a>谓词锁 Predicate locks</h4><p>类似于之前描述的共享/独占锁，而区别在于，它并不属于某个特定的对象，而是作用于<strong>满足某些搜索条件</strong>的所有查询对象。</p><ul><li>事务A想要读取某些满足匹配条件的对象，它必须以共享模式获的查询条件的谓词锁。如果另一个事务B正持有任何一个匹配对象的互斥锁，那么A必须等到B释放锁之后才能继续执行查询。</li><li>如果事务A想要插入、更新或删除任何对象，则必须首先检查所有旧值和新值是否与现有的任何谓词锁匹配。如果事务B持有这样的谓词锁，那么A必须等到B完成提交后才能继续。</li></ul><p>谓词锁甚至可以保护数据库中那些尚不存在但可能马上会被插入的对象。将两阶段加锁与谓词锁结合使用，数据库可以防止所有形式的写倾斜以及其他竞争条件，隔离变的真正可串行化。</p><p>缺点：</p><p>谓词锁性能不佳，如果活动事务中存在许多锁，那么检测匹配这些锁就变得非常耗时。</p><h4 id="索引区间锁-next-key-locking"><a href="#索引区间锁-next-key-locking" class="headerlink" title="索引区间锁 next-key locking"></a>索引区间锁 next-key locking</h4><p>是一种简化的谓词锁，将其保护的对象扩大化。如果没有合适的索引可以施加区间锁，则数据库可以回退到对整个表施加共享锁。</p><h3 id="可串行化的快照隔离-Serializable-Snapshot-Isolation"><a href="#可串行化的快照隔离-Serializable-Snapshot-Isolation" class="headerlink" title="可串行化的快照隔离 Serializable Snapshot Isolation"></a>可串行化的快照隔离 Serializable Snapshot Isolation</h3><p>它提供了完整的可串行性保证，而性能相比于快照隔离损失很小。</p><h4 id="悲观与乐观的并发控制"><a href="#悲观与乐观的并发控制" class="headerlink" title="悲观与乐观的并发控制"></a>悲观与乐观的并发控制</h4><p>两阶段加锁是一种典型的悲观并发控制机制。相比之下，可串行化的快照隔离（Serializable Snapshot Isolation, SSI）则是一种乐观并发控制。</p><p>如果系统还有足够的性能提升空间，且如果事物之间的竞争不大，乐观并发控制会比悲观方式高效很多。</p><h4 id="基于过期的条件做决定"><a href="#基于过期的条件做决定" class="headerlink" title="基于过期的条件做决定"></a>基于过期的条件做决定</h4><p>安全起见，数据库假定对查询结果的任何变化都应使写事务失效。</p><p>数据库如何知道查询结果是否发生了改变呢？</p><ol><li>读取是否作用于一个过期的MVCC对象（读取之前已经有未提交的写入）</li><li>检查写入是否影响即将完成的读取</li></ol><h4 id="检测是否读取了过期的MVCC对象"><a href="#检测是否读取了过期的MVCC对象" class="headerlink" title="检测是否读取了过期的MVCC对象"></a>检测是否读取了过期的MVCC对象</h4><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E6%A3%80%E6%B5%8B%E4%BA%8B%E5%8A%A1%E6%98%AF%E5%90%A6%E4%BB%8EMVCC%E5%BF%AB%E7%85%A7%E4%B8%AD%E8%AF%BB%E5%8F%96%E4%BA%86%E6%97%A7%E5%80%BC.png" class="" title="检测事务是否从MVCC快照中读取了旧值"><p><strong>当事务提交时</strong>，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是则必须终止当前事务。</p><p>一定要等到提交是因为：</p><ul><li>如果事务43是个只读事务，就不需要中止。事务43读取数据库时，数据库还不知道事务是否稍后有任何写操作</li><li>有可能事务42发生了中止或者还处于未提交状态，不一定读的就是过期值。</li></ul><h4 id="检测写是否影响了之前的读"><a href="#检测写是否影响了之前的读" class="headerlink" title="检测写是否影响了之前的读"></a>检测写是否影响了之前的读</h4><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E6%A3%80%E6%B5%8B%E4%BA%8B%E5%8A%A1%E6%98%AF%E5%90%A6%E4%BF%AE%E6%94%B9%E4%BA%86%E5%8F%A6%E4%B8%80%E4%B8%AA%E4%BA%8B%E5%8A%A1%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C.png" class="" title="检测事务是否修改了另一个事务查询结果"><p>另一个事务尝试修改的时，首先检查索引，从而确定是否最近存在一些读目标数据的其他事物。</p><h4 id="可串行化快照隔离的性能"><a href="#可串行化快照隔离的性能" class="headerlink" title="可串行化快照隔离的性能"></a>可串行化快照隔离的性能</h4><p>与两阶段加锁相比，可串行化快照隔离的一大优点是事务不需要等待其他事务所持有的锁。</p><p>事务中止的比例会显著影响SSI的性能表现。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>脏读<ul><li>客户端读到了其他客户端尚未提交的写人。读-提交以及更强的隔离级别可以防止脏读。</li></ul></li><li>脏写<ul><li>客户端覆盖了另一个客户端尚未提交的写入。几乎所有的数据库实现都可以防止脏写。</li></ul></li><li>读倾斜（不可重复读）<ul><li>客户在不同的时间点看到了不同值。快照隔离是最用的防范手段，即事务总是在某个时间点的一致性快照中读取数据。通常采用多版本井发控制（ MVCC ）来实现快照隔离。</li></ul></li><li>更新丢失<ul><li>两个客户端同时执行读－修改－写入操作序列，出现了其中一个覆盖了另一个的写入，但又没有包含对方最新值的情况，最终导致了部分修改数据发生了丢失。快照隔离的一些实现可以自动防止这种异常，而另 一些则需要手动锁定查询结果 (SELECT FOR UPDATE ）。</li></ul></li><li>写倾斜<ul><li>事务首先查询数据，根据返回的结果而作出某些决定，然后修改数据库 。当事务提交时，支持决定的前提条件已不再成立。只有可串行化的隔离才能防止这种异常。</li></ul></li><li>幻读<ul><li>事务读取了某些符合查询条件的对象，同时另一个客户端执行写入，改变了先前的查询结果。快照隔离可以防止简单的幻读，但写倾斜情况则需要特殊处理，例如采用区间范围锁。</li></ul></li></ul><p>弱隔离级别可以防止上面的某些异常，只有可串行化的隔离可以防止所有这些问题。实现可串行化隔离有以下几种：</p><ul><li>严格串行执行事务<ul><li>如果每个事务的执行速度非常快，且单个CPU核可以满足事务的吞吐量要求，严格串行执行是一个非常简单有效的方案。</li></ul></li><li>两阶段加锁<ul><li>几十年来，这一直是实现可串行化的标准方式，但还是有很多系统出于性能原因而放弃使用它。</li></ul></li><li>可串行化的快照隔离<ul><li>一种最新的算法，可以避免前面方法的大部分缺点。它秉持乐观预期的原则， 允许多个事务并发执行而不互相阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，则某些事务会被中止。</li></ul></li></ul><h1 id="第八章：分布式系统的挑战"><a href="#第八章：分布式系统的挑战" class="headerlink" title="第八章：分布式系统的挑战"></a>第八章：分布式系统的挑战</h1><p>本章节对分布式系统可能出现的故障做了一个全面的总结。故障可能来自网络，时钟时序问题。</p><h2 id="不可靠的网络"><a href="#不可靠的网络" class="headerlink" title="不可靠的网络"></a>不可靠的网络</h2><p>处理网络的问题通常采用超时机制：在等待一段时间之后，如果仍然没有收到回复则选择放弃，并且认为响应不会到达。</p><h3 id="检测故障"><a href="#检测故障" class="headerlink" title="检测故障"></a>检测故障</h3><ul><li>负载均衡器需要避免向已失效的节点继续分发请求</li><li>对于主从复制的分布式数据库，如果主节点失败，需要将某个从节点提升为主节点。</li></ul><h3 id="超时与无限期的延迟"><a href="#超时与无限期的延迟" class="headerlink" title="超时与无限期的延迟"></a>超时与无限期的延迟</h3><p>没有一个标准的设置超时时间的值。</p><p>异步网络理论上的延迟无限大（即使尽力发送数据包，但数据包到达时间并没有上确界），多数服务端也无法保证在给定的某个时间内一定完成请求处理（参阅本章后面的“响应时间保证”）。如果超时设置太小，只需要一个短暂的网络延迟尖峰就会导致包超时进而将系统标记为失效。</p><h4 id="网络拥塞与排队"><a href="#网络拥塞与排队" class="headerlink" title="网络拥塞与排队"></a>网络拥塞与排队</h4><p>更好的做法是， 超时设置并不是一个不变的常量，而是持续测量响应时间及其变化（抖动），然后根据最新的响应时间分布来自动调整。</p><h3 id="同步与异步网络"><a href="#同步与异步网络" class="headerlink" title="同步与异步网络"></a>同步与异步网络</h3><h4 id="电路交换-vs-分组交换"><a href="#电路交换-vs-分组交换" class="headerlink" title="电路交换 vs. 分组交换"></a>电路交换 vs. 分组交换</h4><p>电路方式总是预留固定带宽，电路建立之后其他人无法使用；TCP连接的数据包则会尝试使用所有可用的网络带宽。</p><p>以太网和IP都是基于分组交换协议，这种协议注定受到排队的影响，从而导致网络延迟不确定， 在这些协议里完全没有电路的概念。</p><p>数据中心网络和互联网采用分组交换是因为无法事先确定带宽，只希望尽快完成。对于突发数据的传输，电路网络无法充分利用网络容量。相比之下，TCP动态调整传输速率则可以充分利用所有可用的网络容量。</p><h2 id="不可靠的时钟"><a href="#不可靠的时钟" class="headerlink" title="不可靠的时钟"></a>不可靠的时钟</h2><h3 id="单调时钟与墙上时钟"><a href="#单调时钟与墙上时钟" class="headerlink" title="单调时钟与墙上时钟"></a>单调时钟与墙上时钟</h3><h4 id="墙上时钟"><a href="#墙上时钟" class="headerlink" title="墙上时钟"></a>墙上时钟</h4><blockquote><p>墙上时钟根据某个日历返回当前的日期与时间。</p></blockquote><ul><li>Linux的clock_gettime</li><li>Java中的System.currentTimeMillis()</li></ul><p>墙上时钟可以与NTP同步。NTP（Network Time Protocol）是用来同步网络设备的时间协议。</p><h4 id="单调时钟"><a href="#单调时钟" class="headerlink" title="单调时钟"></a>单调时钟</h4><p>单调时钟更适合测量持续时间段（时间间隔）。可以在一个时间点读取单调时钟的值，完成某项工作，然后再次检查时钟。时钟值之间的差值即两次检查之间的时间间隔。</p><h3 id="时钟同步与准确性"><a href="#时钟同步与准确性" class="headerlink" title="时钟同步与准确性"></a>时钟同步与准确性</h3><p>单调时钟不需要同步，但是墙上时钟需要根据NTP服务器或其他外部时间源做必要的调整。</p><p>可能会出现一下的一些问题：</p><ul><li>计算机中的石英钟不够精确，存在漂移现象（运行速度会加快或减慢）</li><li>如果时钟与NTP服务器的时钟差别太大，可能会出现拒绝同步，或者本地时钟将被强制重置（时间突然倒退或突然跳跃的现象）。</li><li>可能会与NTP服务器链接失败，可能会很长一段时间没有留意到错误配置最终导致同步失败。</li><li>NTP同步会受限于当时的网络环境。</li><li>闰秒会产生一个59秒或者61秒的现象，可能会使一些对闰秒毫无防范的系统出现混乱。</li><li>在虚拟机中，由于硬件时钟也是被虚拟化的，这对需要精确计时的应用程序提出了额外的挑战。</li><li>运行在未完全可控的设备（移动设备或嵌入式设备）上，需要留意不能完全相信设备上的硬件时钟。</li></ul><h3 id="依赖同步的时钟"><a href="#依赖同步的时钟" class="headerlink" title="依赖同步的时钟"></a>依赖同步的时钟</h3><p>如果应用需要精确同步的时钟，最好仔细监控所有节点上的时钟偏差。如果某个节点的时钟漂移超出上限，应将其宣告为失效，并从集群中移除。</p><h4 id="时间戳与时间顺序"><a href="#时间戳与时间顺序" class="headerlink" title="时间戳与时间顺序"></a>时间戳与时间顺序</h4><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E8%B7%A8%E8%8A%82%E7%82%B9%E6%97%B6%E9%97%B4%E6%8E%92%E5%BA%8F.png" class="" title="跨节点时间排序"><p>客户端B的写入比客户端A写入要晚，但是B写入的时间戳却更早</p><p>这种冲突解决策略被称为最后写入获胜（Last Write Win, LWW），它的根本问题在于：</p><ul><li>数据库写入可能会奇怪地丢失：明明后续发生的写操作却没法覆盖另一个较早的值，原因是后者节点的时钟太快了。</li><li>LWW无法区分连续快速发生的连续写操作和并发写入（每个写操作都不依赖于其他写 ）</li><li>由于时钟精度的限制（例如毫秒级），两个节点可能各自独立产生了完全相同的时间戳。</li></ul><blockquote><p>我们很难利用NTP时钟同步来做到极高的精度来避免这种错误</p></blockquote><h4 id="时钟的置信区间"><a href="#时钟的置信区间" class="headerlink" title="时钟的置信区间"></a>时钟的置信区间</h4><blockquote><p>我们不应该将时钟读数视为一个精确的时间点，而更应该视为带有置信区间的时间范围。</p></blockquote><h4 id="全局快照的同步时钟"><a href="#全局快照的同步时钟" class="headerlink" title="全局快照的同步时钟"></a>全局快照的同步时钟</h4><p>常见的快照隔离实现中需要单调递增事务ID。如果写入发生在快照之后（即写入具有比快照更大的事务ID），那么该写入对于快照不可见。在单节点数据库上，一个简单的计数器足以生成事务ID。</p><p>但是，当数据库分布在多台机器上（可能跨越多个数据中心）时，由于需要复杂的协调以产生全局的、单调递增的事务ID（跨所有分区）。考虑到大量、频繁的小数据包，在分布式系统中创建事务ID通常会引入瓶颈。</p><h5 id="Google-Spanner"><a href="#Google-Spanner" class="headerlink" title="Google Spanner"></a>Google Spanner</h5><p>Google Spanner采用以下思路来实现跨数据中心的快照隔离。它根据TrueTime API返回的时钟置信区间，并基于以下观察结果：如果有两个置信区间，每个置信区间都包含最早和最新可能的时间戳（ <em>A</em>=[ <em>A<sub>earliest</sub> , A<sub>latest</sub></em> ] 和 <em>B</em> =[ <em>B<sub>earliest</sub> , B<sub>latest</sub></em> ] ），且这两个区间没有重叠（即 <em>A<sub>earliest</sub> &lt; A<sub>latest</sub></em> &lt; *B<sub>earliest</sub>* &lt; *B<sub>latest</sub>* ），那么可以断定<em>B</em>一定发生在<em>A</em>之后。只有发生了重叠，<em>A</em>和<em>B</em>发生顺序才无法明确。</p><p>为了确保事务时间戳反映因果关系， Spanner在提交读写事务之前故意等待置信区间的长度。这样做的目的是，确保所有读事务要足够晚才发生，避免与先前的事务的置信区间产生重叠。</p><h3 id="进程暂停"><a href="#进程暂停" class="headerlink" title="进程暂停"></a>进程暂停</h3><p>假设数据库每个分区只有一个主节点，只有主节点可以接受写入。那么其他节点该如何确信该主节点没有被宣告失效，可以安全地写入呢？</p><blockquote><p>一种思路是主节点从其他节点获得一个租约（lease），类似一个带有超时的锁。某一个时间只有一个节点可以拿到租约，某节点获得租约之后，在租约到期之前，它就是这段时间内的主节点。为了维持主节点的身份，节点必须在到期之前定期去更新租约 。如果 节点发生了故障， 则续约失败，这样另一个节点到期之后就可以接管。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>  request = getIncomingRequest();<br>  <br>  <span class="hljs-keyword">if</span> (lease.expiryTimeMillis - System.currentTimeMillis() &lt; <span class="hljs-number">10000</span>) &#123;<br>    lease = lease.renew();<br>  &#125;<br>  <br>  <span class="hljs-keyword">if</span> (lease.isValid()) &#123;<br>    process(request);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可能存在的问题：</p><ol><li>依赖于同步时钟：lease到期时间由另一台机器所设置，并和本地时钟进行比较。</li><li><code>System.currentTimeMillis()</code>与请求处理<code>process(request)</code>间隔时间不可预测。如果发生了线程暂停的情况，将会出现两个节点同时持有租期处理的情况。</li></ol><p>发生线程暂停的原因有很多：</p><ul><li>垃圾回收机制可能会导致所有正在运行的线程暂停几分钟。</li><li>在虚拟化的环境中，可能会暂停虚拟机然后继续。</li><li>用户关闭了笔记本电脑或休眠也有可能导致暂停。</li><li>当操作系统执行线程上下文切换时，或者虚拟机管理程序切换到另一个虚拟机时，正在运行的线程可能会在代码的任意位置被暂停。</li><li>应用程序执行同步磁盘操作，则线程可能暂停并等待磁盘I/O完成。</li><li>如果操作系统配置了基于磁盘的内存交换分区， 内存访问可能触发缺页中断， 进而需要从磁盘中加载内存页。</li></ul><blockquote><p>分布式系统中的一个节点必须假定，执行过程中的任何时刻都可能被暂停相当长一段时间。暂停期间，整个集群的其他部分都在照常运行，甚至会一直将暂停的节点宣告为故障节点。</p></blockquote><h4 id="响应时间保证"><a href="#响应时间保证" class="headerlink" title="响应时间保证"></a>响应时间保证</h4><blockquote><p>实时系统：软件有一个必须做出相应的上限。</p></blockquote><p>提供实时保证需要来自软件栈的多个层面支持：</p><ul><li>一个实时操作系统（real-time operating system, RTOS），保证进程在给定的间隔内完成CPU时间片的调度分配</li><li>库函数也必须考虑最坏的执行时间</li><li>动态内存分配很可能要受限或者完全被禁止</li></ul><p>对于大多数服务器端数据处理系统来说，实时性保证并不经济或者不合适。因此，现在这些运行在非实时环境下的系统就得承受如进程暂停、 时钟不稳定等困扰。</p><h5 id="调整垃圾回收的影响"><a href="#调整垃圾回收的影响" class="headerlink" title="调整垃圾回收的影响"></a>调整垃圾回收的影响</h5><ul><li>把GC暂停视为节点的一个计划内的临时离线，当节点启动垃圾回收时，通知其他节点来接管客户端的请求。</li><li>系统可以提前为前端应用发出预警，应用会等待当前请求完成，但停止向该节点发送新的请求，这样垃圾回收可以在无干扰的情况下更加高效运行。</li><li>只对短期对象执行垃圾回收，然后在其变成长期存活对象之前，采取定期重启的策略从而避免对长期存活对象执行全面回收。</li></ul><h2 id="知识，真相与谎言"><a href="#知识，真相与谎言" class="headerlink" title="知识，真相与谎言"></a>知识，真相与谎言</h2><h3 id="真相由多数决定"><a href="#真相由多数决定" class="headerlink" title="真相由多数决定"></a>真相由多数决定</h3><p>节点不能根据自己的信息来判断自身状态。由于节点可能随时会失效，可能会暂停-假死，甚至最终无法恢复，因此，分布式系统不能完全依赖与单个节点。</p><p>目前，许多分布式算法都依靠法定票数，即在节点之间进行投票。任何决策都需要来自多个节点的最小投票数，从而减少对特定节点的依赖。</p><h4 id="主节点和锁"><a href="#主节点和锁" class="headerlink" title="主节点和锁"></a>主节点和锁</h4><blockquote><p>在分布式系统实现时需要额外注意：即使某个节点自认为它是“唯一的那个”，但不一定获得了系统法定票数的同意！</p></blockquote><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E4%B8%8D%E6%AD%A3%E7%A1%AE%E5%AE%9E%E7%8E%B0.png" class="" title="分布式锁的不正确实现"><h4 id="Fencing令牌"><a href="#Fencing令牌" class="headerlink" title="Fencing令牌"></a>Fencing令牌</h4><p>我们假设每次锁服务在授予锁或租约时，还会同时返回一个fencing令牌，该令牌每授予一次就会递增。要求客户端每次向存储系统发送写请求时，都必须包含所持有的fencing令牌。</p><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E9%80%92%E5%A2%9Efencing%E4%BB%A4%E7%89%8C.png" class="" title="递增fencing令牌"><p>存储服务器由于记录了最近已经完成了更高令牌号，因此拒绝令牌号33的写请求。</p><h3 id="拜占庭故障-Byzantine-Faults"><a href="#拜占庭故障-Byzantine-Faults" class="headerlink" title="拜占庭故障 Byzantine Faults"></a>拜占庭故障 Byzantine Faults</h3><p>当节点故意发送错误的或者破坏性的响应，就被称为拜占庭故障。在这样不信任的环境中需要达成共识的问题也被称之为拜占庭将军问题。如果某个系统中即使发生部分节点故障，甚至不遵从协议，或者恶意攻击、干扰网络，但仍可继续正常运行，那么我们称之为拜占庭式容错系统。</p><p>解决拜占庭容错的系统协议异常复杂，而容错的嵌入式系统还依赖与硬件层面的支持。因为在绝大多数服务器端数据系统中，部署拜占庭容错解决方案基本不太可行。</p><h3 id="理论系统模型与现实"><a href="#理论系统模型与现实" class="headerlink" title="理论系统模型与现实"></a>理论系统模型与现实</h3><p>在计时方面，有常见的三种模型：</p><ul><li>同步模型<ul><li>同步模型假定有上届的网络延迟，有上届的进程暂停和由上届的时钟误差。</li></ul></li><li>部分同步模型<ul><li>部分同步意味着系统在大多数情况下像一个同步系统一样运行，但有时会超出网络延迟，进程暂停和时钟漂移的预期上届。</li></ul></li><li>异步模型<ul><li>在这个模型中，一个算法不会对时机作任何的假设，甚至里面根本没有时钟（也就没有超时机制）。</li></ul></li></ul><p>除了时机之外，我们还需要考虑节点失效。</p><ul><li>崩溃-终止模型<ul><li>算法假设一个节点只能以一种方式发生故障，即遭遇系统崩溃。这意味着节点可能在任何时候突然停止响应，且该结点以后永远消失，无法恢复。</li></ul></li><li>崩溃-恢复模型<ul><li>节点可能会在任何时候发生崩溃，且可能会在一段（未知的）时间之后得到恢复并再次响应。在崩溃－恢复模型中，节点上持久性存储（即非易失性存储）的数据会在崩溃之后得以保存，而内存中状态可能会丢失。</li></ul></li><li>拜占庭失效模型<ul><li>节点可能发生任何事情，包括试图作弊和欺骗其他节点。</li></ul></li></ul><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>分布式系统中可能发生的各种典型问题：</p><ul><li>当通过网络发送数据包时， 数据包可能会丢失或者延迟； 同样，回复也可能会丢失或延迟。所以如果没有收到回复，并不能确定消息是否发送成功。</li><li>节点的时钟可能会与其他节点存在明显的不同步（尽管尽最大努力设置了NTP服务器），时钟还可能会突然向前跳跃或者倒退 ，依靠精确的时钟存在一些风险，没有特别简单的办法来精确测量时钟的偏差范围。</li><li>进程可能在执行过程中的任意时候遭遇长度未知的暂停（ 一个重要的原因是垃圾回收），结果它被其他节点宣告为失效毫无所知。</li></ul><p>为了容错，需要先检测错误：</p><p>多数系统没有检测节点是否发生故障的准确机制，因此分布式算法更多依靠超时来确定远程节点是否仍然可用。</p><p>检测到错误之后：</p><p>信息从一个节点流动到另一个节点只能是通过不可靠的网络来发送。单个节点无法安全的做出任何决策，而是需要多个节点之间的共识协议，井争取达到位定票数。</p><p>虽然网络、时钟和进程的不可靠性不是不可避免的自然规律，但代价昂贵，且硬件资源利用率很低。除了安全关键场景，目前绝大多数都选择了低成本。</p><h1 id="第九章-一致性与共识"><a href="#第九章-一致性与共识" class="headerlink" title="第九章 一致性与共识"></a>第九章 一致性与共识</h1>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>读书笔记</tag>
      
      <tag>数据密集型应用系统设计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Elasticsearch 初步探索</title>
    <link href="/2021/01/25/Elasticsearch-%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/"/>
    <url>/2021/01/25/Elasticsearch-%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<p>前一段时间在听左耳朵耗子前辈的分享，开始决定渐渐解除对知乎和微信公众号的依赖，决定去向官网的英文文档以及一些paper靠拢。学习，仍然是一件很长的事情。</p><p>前一段时间在啃《数据密集型应用系统设计》，由于所学尚浅，其中有诸多不甚理解之处。在仁飞导师的建议下，决定先从es入手，再回头看这本堪称“圣经”的书。</p><h1 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h1><blockquote><p>定义：Elastic search is a highly scalable open-source full-text search and analytics engine. </p><p>作用：It allows you to store, search, and analyze big volumes of data quickly and  in near real time.</p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>Elasticsearch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/01/25/hello-world/"/>
    <url>/2021/01/25/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>LSM-Tree初探</title>
    <link href="/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/"/>
    <url>/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/</url>
    
    <content type="html"><![CDATA[<p>在阅读《数据密集型应用系统设计》的时候，接触到了LSM-Tree。觉得书中讲述的十分简略，没能深入理解这个存储结构。打算单独拎出来写一篇笔记。</p><h1 id="LSM-Tree背景"><a href="#LSM-Tree背景" class="headerlink" title="LSM-Tree背景"></a>LSM-Tree背景</h1><p>传统关系型数据库使用B-Tree或者一些变体作为存储结构，但这有一个缺点：有的数据逻辑上相离很近但是物理上相离甚远，这就会导致大量的<strong>磁盘随机读写</strong>。而随机读写比顺序读写要慢很多，为了提升IO性能，我们需要一种能将随机操作变为顺序操作的机制。这就有了LSM-Tree的诞生。LSM树能让我们进行顺序写磁盘，从而大幅提升写操作，作为代价的是牺牲了一些读性能。</p><h1 id="LSM-Tree原理"><a href="#LSM-Tree原理" class="headerlink" title="LSM-Tree原理"></a>LSM-Tree原理</h1><p>LSM-Tree实际上和Tree的关系不大，它是一种分层的存储结构。</p><h2 id="组件介绍"><a href="#组件介绍" class="headerlink" title="组件介绍"></a>组件介绍</h2><p>LSM-Tree由两个或更多的类Tree组成。我们暂时先讨论最简单的两个组件的情况</p><img src="/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/LSM-Tree%E4%B8%A4%E7%BB%84%E4%BB%B6.png" class="" title="LSM-Tree两组件"><p>LSM-Tree有两部分：</p><ul><li>一个较小的位于<strong>内存</strong>的组件，就是C0 Tree</li><li>一个较大的位于<strong>磁盘</strong>的组件，就是C1 Tree</li></ul><p>历史记录表的数据每生成一行新纪录流程如下：</p><ol><li><p>首先向顺序日至文件中写一条用于恢复这次插入行为的日志记录</p></li><li><p>该行数据的索引被插入到常驻内存的C0 Tree</p></li><li><p>会适时地将这些C0 Tree上的数据迁移到磁盘上的C1 Tree中</p></li><li><p>每个索引的搜索过程都是先C0后C1</p></li></ol><h2 id="组件合并"><a href="#组件合并" class="headerlink" title="组件合并"></a>组件合并</h2><h3 id="C0-合并到-C1"><a href="#C0-合并到-C1" class="headerlink" title="C0 合并到 C1"></a>C0 合并到 C1</h3><p>当C0 Tree上的插入数据达到一个指定阈值时，有一个持续循环的合并进程服务会删除C0 Tree上的一些连续segment段，将他们合并到磁盘中的C1 Tree。</p><img src="/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/C0%E5%90%88%E5%B9%B6%E8%87%B3C1.png" class="" title="C0合并至C1"><table><thead><tr><th></th><th>大小</th><th>描述</th><th>用途</th></tr></thead><tbody><tr><td>单页块</td><td>4KB</td><td>根节点；每个层级上的单页节点</td><td>单页节点被用在匹配索引查找中，以最小化缓存需求</td></tr><tr><td>多页块</td><td>256KB</td><td>根目录下的每个层级上的单页节点序列会被打包，然后一起放入连续的多页磁盘块中（囊括了根节点以下的节点），利于磁盘顺序访问</td><td>多页块IO，在滚动合并期间、大范围的范围搜索中被使用</td></tr></tbody></table><h3 id="Empty-Block和Filling-Block"><a href="#Empty-Block和Filling-Block" class="headerlink" title="Empty Block和Filling Block"></a>Empty Block和Filling Block</h3><blockquote><p>Empty Block: 在合并前，已缓存、且包含旧的C1 Tree节点的多页块。意味着它们会被清空、移除。</p><p>Filling Block: 新的叶节点被写入与旧的多页块不同的<strong>已缓存</strong>的多页块。意味着它们会被填满。</p></blockquote><ol><li>从C1中读取未合并叶子节点，放置在内存中的 <code>empty block</code> 中</li><li>从小到大找C0中的节点，与 <code>empty block</code> 进行合并排序，合并结果保存到<code>filling block</code>中，并将C0对应的节点删除。</li><li>不断执行第2步操作，合并排序结果不断填入 <code>filling block</code> 中，当其满了则将其追加到磁盘的新位置上，注意是追加而不是改变原来的节点。合并期间如故宫 <code>empty block</code> 使用完了则再从C1中读取未合并的叶子节点。</li><li>C0和C1所有叶子节点都按以上合并完成后即完成一次合并。</li></ol><p>具体插入例子可见：</p><p><a href="https://juejin.cn/post/6844903688075477000">看图轻松理解数据结构与算法系列（NoSQL存储-LSM树）</a></p><h2 id="LSM-Tree-索引查找"><a href="#LSM-Tree-索引查找" class="headerlink" title="LSM Tree 索引查找"></a>LSM Tree 索引查找</h2><h3 id="搜索原则"><a href="#搜索原则" class="headerlink" title="搜索原则"></a>搜索原则</h3><blockquote><p>C<sub>0</sub> Tree 是驻留在内存中的，而其他组件都在磁盘。这种情况下，每当C<sub>i-1</sub> 条目达到阈值时，每个 (C<sub>i-1</sub>, C<sub>i</sub>) 之间的异步滚动合并过程会从较小的组件中移动条目到较大的组件。</p></blockquote><img src="/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/LSM-Tree%E5%A4%9A%E7%BB%84%E4%BB%B6.png" class="" title="LSM-Tree多组件"><p>当一个需要立刻返回的精确匹配查询或是范围查询在LSM Tree的索引上执行时，会先在C<sub>0</sub>树执行搜索值，然后搜C<sub>1</sub>树。这暗含着少许额外的CPU开销(相对于B-Tree来说)，因为分别去两棵树目录进行搜索。</p><h2 id="LSM-Tree-删除、更新"><a href="#LSM-Tree-删除、更新" class="headerlink" title="LSM Tree 删除、更新"></a>LSM Tree 删除、更新</h2><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>删除操作为了能快速执行，主要是通过标记来实现，在内存中将要删除的记录标记一下，后面异步执行合并时将相应记录删除。</p><ul><li>比如要删除“U”，假设标为#的表示删除，则C0树的“U”节点变为“U(#)”</li><li>而如果C0树不存在的记录，则在C0树中生成一个节点，并标为#，查找时就能再内存中得知该记录已被删除，无需去磁盘找了。比如要删除“B”，那么没有必要去磁盘执行删除操作，直接在C0树中插入一个“B”节点，并标为#。</li></ul><h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>导致索引值更改的记录更新，这在任何类型的应用程序中都是不常见的。但如果我们将更新视为删除后紧跟着插入，则可以由LSM树以延迟方式处理此类更新。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://juejin.cn/post/6844903688075477000">看图轻松理解数据结构与算法系列（NoSQL存储-LSM树）</a></li><li><a href="https://my.oschina.net/u/4064459/blog/2999407">论文阅读-The Log-Structured Merge-Tree</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>《数据密集型应用系统设计》- 读书笔记1</title>
    <link href="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/"/>
    <url>/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/</url>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="第二章-数据模型与查询语言"><a href="#第二章-数据模型与查询语言" class="headerlink" title="第二章 数据模型与查询语言"></a>第二章 数据模型与查询语言</h1><h1 id="第三章-数据存储与检索"><a href="#第三章-数据存储与检索" class="headerlink" title="第三章 数据存储与检索"></a>第三章 数据存储与检索</h1><h2 id="数据库核心：数据结构"><a href="#数据库核心：数据结构" class="headerlink" title="数据库核心：数据结构"></a>数据库核心：数据结构</h2><p>适当的索引可以加速度取查询，但每个索引都会减慢写速度</p><h3 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h3><p>假设数据存储全部采用追加式文件组成。</p><blockquote><p>保存内存中的hash map, 把每个键一一映射到数据文件中特定的字节偏移量，这样就可以找到每个值的位置。</p></blockquote><p>Bitcask （Riak 中的默认存储引擎）就是采用哈希索引的。它非常适合每个键的值频繁更新的场景。</p><p>如何避免最终用尽磁盘空间？</p><blockquote><p>我们可以将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以在这些段上执行压缩，在日志中丢弃重复的键，并且只保留每个键最近的更新。</p></blockquote><h4 id="需要考虑的问题"><a href="#需要考虑的问题" class="headerlink" title="需要考虑的问题"></a>需要考虑的问题</h4><ul><li>文件格式<ul><li>csv 不是日志的最佳格式，应该使用二进制的格式，首先以字节为单位来记录字符串的长度，之后再跟上原始字符串。</li></ul></li><li>删除记录<ul><li>如果要删除一个键和它关联的记录，在数据文件中追加一个tag。合并日志的时候，一旦发现tag，则会丢弃这个已经删除键的值。</li></ul></li><li>崩溃恢复<ul><li>因为hash map是存在内存中的，数据库重新启动之后会丢失。Bitcask 通过将每个段的hash map的快照存储在磁盘上，可以更快的加载到内存中，以此加快恢复速度。</li></ul></li><li>部分写入的记录<ul><li>Bitcask 文件包括校验值，这样可以发现损坏部分并丢弃。</li></ul></li><li>并发控制<ul><li>因为写入以严格的先后顺序追加到日志中，通常的实现选择是只有一个写线程。数据文件段是追加的，并且是不可变的，所以他们可以被多个线程同时读取。</li></ul></li></ul><h4 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h4><ul><li>因为hash map 必须放在内存中，如果一旦有大量的键，就需要在磁盘维护hash map，这会导致整体的性能下降。</li><li>区间查询效率不高。</li></ul><h3 id="SSTables和LSM-Tree"><a href="#SSTables和LSM-Tree" class="headerlink" title="SSTables和LSM-Tree"></a>SSTables和LSM-Tree</h3><h4 id="SSTables"><a href="#SSTables" class="headerlink" title="SSTables"></a>SSTables</h4><blockquote><p>要求每个存储段的key-value对的顺序按键排序。要求每个键在合并的段文件中只能出现一次。</p></blockquote><blockquote><p>SSTable 是一个<strong>持久化的、有序的、不可变的</strong>映射表（map），其中的<strong>键和值都可以 是任意字节字符串</strong>。它提供了按 key 查询和对指定的 key range 进行遍历的操作。</p></blockquote><p>SSTable相比哈希索引，具有优点：</p><ul><li>合并段更加简单高效，即使文件大于可用内存</li><li>在文件中查找特定的键时，不再需要在内存中保存所有键的索引。仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的。</li></ul><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/SSTable%E5%8F%8A%E5%85%B6%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95.png" class="" title="SSTable及其内存中的索引"><h5 id="从SSTables到LSM-Tree"><a href="#从SSTables到LSM-Tree" class="headerlink" title="从SSTables到LSM-Tree"></a>从SSTables到LSM-Tree</h5><blockquote><p>基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎。</p></blockquote><p>LSM Tree的树节点可以分为两种，保存在内存中的称之为MemTable， 保存在磁盘上的称之为SSTable。</p><h5 id="构建和维护SSTables"><a href="#构建和维护SSTables" class="headerlink" title="构建和维护SSTables"></a>构建和维护SSTables</h5><ul><li>当写入时，将其添加到内存中的平衡树数据结构中。这个内存中的树有时被称为内存表。</li><li>当内存表大于某个阈值时，将其作为SSTable文件写入磁盘。由于树已经维护了按键排序的key-value对，写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当SSTable写磁盘的同时，写入可以继续添加到一个新的内存表实例。</li><li>处理读请求时，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件……</li><li>后台进程周期性的执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。</li></ul><p>LevelDB 和 RocksDB 使用的就是上面这段算法。</p><p>不同的策略会影响甚至决定SSTables压缩和合并时的具体顺序和时机。</p><ul><li>LevelDB和RocksDB使用分层压缩<ul><li>键的范围分裂成多个更小的SSTables，旧数据被移动到单独的“层级”。</li></ul></li><li>HBase使用大小分级<ul><li>较新的和较小的SSTables 被连续合并到较旧和较大的SSTables</li></ul></li><li>Cassandra则同时支持这两种压缩。</li></ul><p>LSM-Tree 的基本思想：</p><blockquote><p>保存在后台合并的一系列SSTable</p></blockquote><p><a href="https://zhuangzhuang131419.github.io/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/">LSM-Tree初探</a></p><h3 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B-Tree"></a>B-Tree</h3><p>B-Tree 已经比较熟悉它的基本原理了，这里讲一些新的收获。</p><blockquote><p>B-Tree 将数据库分解成固定大小的块或页，页是内部读/写的最小单元。每个页面都可以使用地址或位置进行标识，不过是指向磁盘地址，而不是内存。</p></blockquote><h4 id="B-Tree-可靠"><a href="#B-Tree-可靠" class="headerlink" title="B-Tree 可靠"></a>B-Tree 可靠</h4><ul><li><p>预写日志（write-ahead log, WAL）</p><ul><li>这是一个仅支持追加修改的文件，每个B-Tree的修改必须先更新 WAL 然后再修改树本身的页。当数据库在崩溃后需要恢复时，该日志用于将B-Tree恢复到最近一直的状态。</li></ul></li><li><p>原地更新页</p><ul><li>如果多个线程要同时访问B-Tree，则需要注意并发控制，否则线程可能会看到树处于不一致的状态。</li></ul></li></ul><h4 id="B-Tree-优化"><a href="#B-Tree-优化" class="headerlink" title="B-Tree 优化"></a>B-Tree 优化</h4><ul><li><p>一些数据库（LMDB）不使用覆盖页和维护WAL来进行崩溃恢复，而是使用写时复制方案。</p></li><li><p>保存键的缩略信息，而不是完整的键，这样可以节省页空间。</p></li><li><p>相邻叶子页可以按顺序保存在磁盘上。但是相比之下，LSM-Tree在合并过程中一次重写大量存储段，更容易让那个连续的键在磁盘上相互靠近。</p></li><li><p>添加额外的指针到树中。例如，每个叶子页面可能会向左和向右引用其同级的兄弟页。</p></li><li><p>B-Tree的变体如分形树，借鉴了一些日志结构的想法来减少磁盘寻道。</p></li></ul><h3 id="B-Tree-vs-LSM-Tree"><a href="#B-Tree-vs-LSM-Tree" class="headerlink" title="B-Tree vs. LSM-Tree"></a>B-Tree vs. LSM-Tree</h3><p>根据经验，LSM-Tree通常对于写入更快而读取较慢，因为必须在不同的压缩阶段检查多个不同的数据结构和SSTable。B-Tree被认为对于读取更快。</p><h4 id="LSM-Tree-的优点"><a href="#LSM-Tree-的优点" class="headerlink" title="LSM-Tree 的优点"></a>LSM-Tree 的优点</h4><ul><li><p>LSM-Tree 通常能够承受比 B-Tree 更高的写入吞吐量</p><ul><li>具有较低的写放大（在数据库内，由于一次数据库写入请求导致的多次磁盘写）</li><li>以顺序方式写入紧凑的SSTable，而不必重写树中的多个页。</li></ul></li><li><p>LSM-Tree 可以支持更好的压缩。</p><ul><li>由于碎片，B-Tree存储引擎使某些磁盘空间无法使用。</li></ul></li></ul><h4 id="LSM-Tree-的缺点"><a href="#LSM-Tree-的缺点" class="headerlink" title="LSM-Tree 的缺点"></a>LSM-Tree 的缺点</h4><ul><li>日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。<ul><li>由于磁盘的并发资源有限，所以当磁盘执行昂贵的压缩操作时，很容易发生读写请求等待的情况。</li></ul></li><li>磁盘的有限写入带宽需要在初始写入（记录并刷新内存表到磁盘）和后台运行的压缩线程之间所共享。<ul><li>数据量越大，压缩所需的磁盘带宽就越多。</li></ul></li></ul><h4 id="B-Tree-的优点"><a href="#B-Tree-的优点" class="headerlink" title="B-Tree 的优点"></a>B-Tree 的优点</h4><ul><li>每个键都恰好唯一对应于索引中的某个位置，而日志结构的存储引擎可能在不同的段中具有相同建的多个副本<ul><li>可以提供强大的事务语义</li></ul></li></ul><h3 id="其他索引结构"><a href="#其他索引结构" class="headerlink" title="其他索引结构"></a>其他索引结构</h3><h4 id="在索引中存储值"><a href="#在索引中存储值" class="headerlink" title="在索引中存储值"></a>在索引中存储值</h4><ul><li>聚集索引<ul><li>在索引中直接保存行数据</li><li>InnoDB</li></ul></li><li>非聚集索引<ul><li>仅存储索引中的数据的引用</li><li>MySQL</li></ul></li><li>覆盖索引<ul><li>包含列的索引，在索引中保存一些表的列值。</li></ul></li></ul><h5 id="多列索引"><a href="#多列索引" class="headerlink" title="多列索引"></a>多列索引</h5><p>如果需要同时查询表的多个列，就需要使用到多列索引。</p><ul><li><p>级联索引</p><ul><li>通过将一列追加到另一列，将几个字段简单地组合成一个键（索引的定义指定字段连接的顺序）。</li></ul></li><li><p>多维索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> restaurants <span class="hljs-keyword">where</span> latitude <span class="hljs-operator">&gt;</span> <span class="hljs-number">51</span> <span class="hljs-keyword">AND</span> latitude <span class="hljs-operator">&lt;</span> <span class="hljs-number">51.5</span> <span class="hljs-keyword">AND</span> longitude <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span> <span class="hljs-keyword">AND</span> longitude <span class="hljs-operator">&lt;</span> <span class="hljs-number">0.5</span> <br></code></pre></td></tr></table></figure><ul><li>B-Tree或LSM-Tree索引无法高效的应对这种查询。</li><li>更常见的是使用专门的空间索引 （R-Tree）</li></ul></li></ul><h4 id="全文搜索和模糊索引"><a href="#全文搜索和模糊索引" class="headerlink" title="全文搜索和模糊索引"></a>全文搜索和模糊索引</h4><p>全文搜索引擎通常支持对一个单词的所有同义词进行查询。</p><p>在Lucene中，内存中的索引是键中的字符序列的有限状态自动机，类似字典树。这个自动机可以转换成Levenshtein自动机，支持在给定编辑距离内高效地搜索单词。</p><p>这部分内容还有非常多深挖的细节，计划在第一遍读完本书后再做后续拓展。</p><h5 id="在内存中保存所有内容"><a href="#在内存中保存所有内容" class="headerlink" title="在内存中保存所有内容"></a>在内存中保存所有内容</h5><blockquote><p> 一些VoltDB、MemSQL和Oracle TimesTen的产品是具有关系模型的内存数据库。</p></blockquote><p>内存数据库的性能优势并不是因为它们不需要从磁盘读取。即使是基于磁盘的存储引擎，也可能永远不需要从磁盘读取，因为操作系统将最近使用的磁盘缓存在内存中。实际上，内存数据库可以更快，<strong>是因为它们避免使用写磁盘的格式对内存数据结构编码的开销</strong>。</p><p>内存数据库提供了基于磁盘索引难以实现的某些数据类型。例如，Redis为各种数据结构（如优先级队列和集合）都提供了类似数据库的访问接口。</p><h2 id="事务处理与分析处理"><a href="#事务处理与分析处理" class="headerlink" title="事务处理与分析处理"></a>事务处理与分析处理</h2><ul><li>在线事务处理（OLTP）<ul><li>根据用户的输入插入或更新记录。因为这些应用程序是交互式的。</li><li>OLTP要求高度可用，处理事务时延迟足够低。</li></ul></li><li>在线分析处理（OLAP）<ul><li>为了区分使用数据库与事务处理的模式。</li></ul></li></ul><p>现在的趋势是，放弃使用OLTP系统用于分析目的，而是在单独的数据库上运行分析。这个单独的数据库被称为<strong>数据仓库</strong>。</p><h3 id="数据仓库"><a href="#数据仓库" class="headerlink" title="数据仓库"></a>数据仓库</h3><blockquote><p>数据仓库就是面向主题的（Subject-Oriented ）、集成的（Integrated）、非易失的（Non-Volatile）和时变的（Time-Variant ）数据集合，用以支持管理决策 。</p></blockquote><p>现在国内最常用的是一款基于Hadoop的开源数据仓库 <strong>Hive</strong>，可以对存储在HDFS上的文件数据集进行查询和分析处理。</p><h4 id="数据仓库的特点"><a href="#数据仓库的特点" class="headerlink" title="数据仓库的特点"></a>数据仓库的特点</h4><ul><li>主题性<ul><li>数据仓库是围绕一个主题进行获取数据和分析数据，以此来满足数据分析的需求。</li></ul></li><li>集成性<ul><li>要整合成最终的数据集合，需要对数据进行抽取、清洗、转换的过程。</li></ul></li><li>稳定性<ul><li>数据仓库不允许对数据进行修改，只能进行查询和分析。</li></ul></li><li>及时性<ul><li>数据仓库一定要获取最新的数据，这样数据分析出来的结果才是有效的。</li></ul></li></ul><h4 id="数据仓库如何集成不同数据源"><a href="#数据仓库如何集成不同数据源" class="headerlink" title="数据仓库如何集成不同数据源"></a>数据仓库如何集成不同数据源</h4><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%92%8C%E7%AE%80%E5%8C%96%E7%9A%84ETL%E8%BF%87%E7%A8%8B.png" class="" title="数据仓库和简化的ETL过程"><p>将数据导入数据仓库的过程称为提取-转换-加载（Extract-Transform-Load, ETL）。</p><ul><li>Extract<ul><li>读取数据</li></ul></li><li>Transform<ul><li>把数据转换成需要的维度和格式，同时包含数据清洗，清洗掉一些噪音数据。</li></ul></li><li>Load<ul><li>把数据加载到目标仓库以供分析使用</li></ul></li></ul><p>使用单独的数据仓库而不是直接查询OLTP系统进行分析，很大的优势在于数据仓库可以针对分析访问模式进行优化。</p><h4 id="OLTP数据库和数据仓库之间的差异"><a href="#OLTP数据库和数据仓库之间的差异" class="headerlink" title="OLTP数据库和数据仓库之间的差异"></a>OLTP数据库和数据仓库之间的差异</h4><h3 id="星型与雪花型分析模式"><a href="#星型与雪花型分析模式" class="headerlink" title="星型与雪花型分析模式"></a>星型与雪花型分析模式</h3><h4 id="星型模式"><a href="#星型模式" class="headerlink" title="星型模式"></a>星型模式</h4><p>模式的中心是一个所谓的<strong>事实表</strong>。事实表的每一行表示在特定时间发生的事件。事实表中的列是属性，其他列可能会引用其他表的外键，称为<strong>维度表</strong>。</p><blockquote><p>由于事实表中的每一行都代表一个事件，维度通常代表事件的对象（who）、什么（what）、地点（where）、时间（when）、方法（how）以及原因（why）。</p></blockquote><p>事实表位于中间，被一系列维度表包围。</p><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F.png" class="" title="星型模式"><h4 id="雪花模式"><a href="#雪花模式" class="headerlink" title="雪花模式"></a>雪花模式</h4><p>维度进一步细分为子空间，每一行都可以再次引用品牌和类别作为外键，而不是将其作为字符串直接存储在表中。</p><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E9%9B%AA%E8%8A%B1%E5%9E%8B%E6%A8%A1%E5%BC%8F.png" class="" title="雪花型模式"><h2 id="列式储存"><a href="#列式储存" class="headerlink" title="列式储存"></a>列式储存</h2><p>我们将首先关注事实表的存储。</p><blockquote><p>面向行存储：来自表的一行所有值彼此相邻存储。</p><p>面向列存储：将每列中的所有值存储在一起。</p></blockquote><p>因为我们在查询的时候通常只会需要某几个字段，显然使用列存储是一个更为优化的办法。</p><h3 id="列压缩"><a href="#列压缩" class="headerlink" title="列压缩"></a>列压缩</h3><h4 id="位图编码"><a href="#位图编码" class="headerlink" title="位图编码"></a>位图编码</h4><p>现在可以使用n个不同值的列，并将其转换为n个单独的位图：一个位图对应每个不同的值，一个位对应一行。如果行具有该值，该位为1，否则为0。</p><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E5%8E%8B%E7%BC%A9%E7%9A%84%E4%BD%8D%E5%9B%BE%E7%B4%A2%E5%BC%95%E5%AD%98%E5%82%A8%E5%8D%95%E5%88%97.png" class="" title="压缩的位图索引存储单列"><h4 id="内存带宽和矢量化处理"><a href="#内存带宽和矢量化处理" class="headerlink" title="内存带宽和矢量化处理"></a>内存带宽和矢量化处理</h4><ul><li>内存带宽<ul><li>如何高效地将内存的带宽用于CPU缓存，避免分支错误预测和CPU指令处理流水线中的气泡，并利用现代CPU中的单指令多数据指令。</li></ul></li><li>矢量化处理<ul><li>列压缩使得列中更多的行可以加载到L1缓存。</li></ul></li></ul><h3 id="列存储中的排序"><a href="#列存储中的排序" class="headerlink" title="列存储中的排序"></a>列存储中的排序</h3><ul><li><p>可以基于常见查询的知识来选择要排序表的列。</p></li><li><p>排序可以帮忙进一步压缩列</p><ul><li>如果主排序列上没有很多不同的值，在排序后，会出现一个非常长的序列，其中相同的值在一行中重复多次。</li></ul></li></ul><h3 id="列存储的写操作"><a href="#列存储的写操作" class="headerlink" title="列存储的写操作"></a>列存储的写操作</h3><p>面向列的存储、压缩和排序都非常有助于加速读取查询，但是可以使用<strong>LSM-Tree</strong>。</p><blockquote><p>所有的写入首先进入内存存储区，将其添加到已排序的结构中，接着再准备写入磁盘。当累积了足够的写入时，它们将与磁盘上的列文件合并，并批量写入新文件。</p></blockquote><h2 id="聚合：数据立方体与物化视图"><a href="#聚合：数据立方体与物化视图" class="headerlink" title="聚合：数据立方体与物化视图"></a>聚合：数据立方体与物化视图</h2><p>如果许多不同查询使用相同的聚合，每次都处理原始数据将非常浪费</p><h3 id="物化视图"><a href="#物化视图" class="headerlink" title="物化视图"></a>物化视图</h3><blockquote><p>一个类似表的对象，其内容是一些查询的结果。</p></blockquote><p>当底层数据发生变化时，物化视图也需要随之更新，因为它是数据的非规范化副本。</p><h3 id="数据立方体"><a href="#数据立方体" class="headerlink" title="数据立方体"></a>数据立方体</h3><p>物化视图一种特殊情况。它是由不同维度分组的聚合网络。</p><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E6%95%B0%E6%8D%AE%E7%AB%8B%E6%96%B9%E4%BD%93.png" class="" title="数据立方体"><ul><li><p>优点</p><ul><li>某些查询会很快，因为已经被预先计算出来了。</li></ul></li><li><p>缺点</p><ul><li>缺乏像查原始数据那样的灵活性。</li></ul></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>存储引擎分为两大类：<strong>针对事务处理（OLTP）优化的结构</strong>和<strong>针对分析型（OLAP）的优化结构</strong>。</p><ul><li><p>OLTP</p><ul><li>OLTP通常面向用户，磁盘寻道时间往往是瓶颈。</li><li>有两个主要流派的存储引擎<ul><li>日志结构流派</li><li>原地更新流派</li></ul></li></ul></li><li><p>OLAP</p><ul><li>OLAP主要由业务分析师用，磁盘带宽通常是瓶颈，可以通过面向列的存储来解决。</li><li>当查询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的是非常紧凑地编码数据，以尽量减少磁盘读取的数据量。</li></ul></li></ul><h1 id="第四章-数据编码与演化"><a href="#第四章-数据编码与演化" class="headerlink" title="第四章 数据编码与演化"></a>第四章 数据编码与演化</h1><h2 id="数据编码格式"><a href="#数据编码格式" class="headerlink" title="数据编码格式"></a>数据编码格式</h2><ol><li>在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）。</li><li>将数据写入文件或通过网络发送时，必须将其编码为某种自包含的字节序列（例如JSON文档）。</li></ol><blockquote><p>从内存中的表示到字节序列的转化称为编码（序列化），相反的过程称为解码（反序列化）。</p></blockquote><h3 id="JSON、XML与二进制变体"><a href="#JSON、XML与二进制变体" class="headerlink" title="JSON、XML与二进制变体"></a>JSON、XML与二进制变体</h3><p>这些编码都有一定的缺点</p><ul><li>在XML和CSV中，无法区分数字和碰巧由数字组成的字符串。</li><li>JSON区分字符串和数字，但不区分整数和浮点数，并且不指定精度。</li><li>JSON和XML对Unicode字符串有很好的支持，但是它们不支持二进制字符串。</li><li>由于数据的正确解释取决于模式中的信息，因此不使用XML/JSON架构的应用程序可能不得不硬编码适当的编码/解码逻辑。</li><li>CSV没有任何模式，因此应用程序需要定义每行和每列的含义。</li></ul><h4 id="二进制编码"><a href="#二进制编码" class="headerlink" title="二进制编码"></a>二进制编码</h4><p>JSON不像XML那么冗长，但与二进制格式相比，两者仍然占用大量空间。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json">&#123;<br>  <span class="hljs-attr">&quot;userName&quot;</span>: <span class="hljs-string">&quot;Martin&quot;</span>,<br>  <span class="hljs-attr">&quot;favoriteNumber&quot;</span>: <span class="hljs-number">1337</span>,<br>  <span class="hljs-attr">&quot;interests&quot;</span>: [<span class="hljs-string">&quot;daydreaming&quot;</span>, <span class="hljs-string">&quot;hacking&quot;</span>]<br>&#125;<br></code></pre></td></tr></table></figure><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E7%A0%81.png" class="" title="二进制编码"><h3 id="Thrift与Protocol-Buffers"><a href="#Thrift与Protocol-Buffers" class="headerlink" title="Thrift与Protocol Buffers"></a>Thrift与Protocol Buffers</h3><p>接下来介绍的是模式（schemas）</p><h4 id="Thrift"><a href="#Thrift" class="headerlink" title="Thrift"></a>Thrift</h4><figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs thrift"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Person</span> </span>&#123;<br><span class="hljs-number">1</span>: <span class="hljs-keyword">required</span> <span class="hljs-built_in">string</span>       userName,<br><span class="hljs-number">2</span>: <span class="hljs-keyword">optional</span> <span class="hljs-built_in">i64</span>          favoriteNumber,<br><span class="hljs-number">3</span>: <span class="hljs-keyword">optional</span> list&lt;<span class="hljs-keyword">string</span>&gt; interests<br>&#125;<br></code></pre></td></tr></table></figure><p>Thrift有两种不同的二进制编码格式：BinaryProtocol和CompactProtocol</p><h5 id="BinaryProtocol"><a href="#BinaryProtocol" class="headerlink" title="BinaryProtocol"></a>BinaryProtocol</h5><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/BinaryProtocol.png" class="" title="BinaryProtocol"><p>最大的区别是没有字段名。相反，编码数据包含数字类型的字段标签。</p><h5 id="CompactProtocol"><a href="#CompactProtocol" class="headerlink" title="CompactProtocol"></a>CompactProtocol</h5><ul><li>将字段类型和标签号打包到单字节中，并使用可变长度整数来实现。</li><li>对数字1337，不使用全部8字节，而是使用两个字节进行编码。每个字节的最高位用来指示是否还有更多的字节。</li></ul><h4 id="Protocol-Buffers"><a href="#Protocol-Buffers" class="headerlink" title="Protocol Buffers"></a>Protocol Buffers</h4><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-class"><span class="hljs-keyword">message</span> <span class="hljs-title">Person</span> </span>&#123;<br><span class="hljs-keyword">required</span> <span class="hljs-built_in">string</span> user_name      = <span class="hljs-number">1</span>;<br><span class="hljs-keyword">optional</span> <span class="hljs-built_in">int64</span> favorite_number = <span class="hljs-number">2</span>;<br><span class="hljs-keyword">repeated</span> <span class="hljs-built_in">string</span> interests      = <span class="hljs-number">3</span>;<br>&#125;<br></code></pre></td></tr></table></figure><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/ProtocolBuffers.png" class="" title="ProtocolBuffers"><blockquote><p>在前面所示的模式中，每个字段被标记为required或optional，但这对字段如何编码没有任何影响。区别在于，如果字段设置了required，但字段未填充，则运行时检查将出现失败。</p></blockquote><h4 id="字段标签和模式演化"><a href="#字段标签和模式演化" class="headerlink" title="字段标签和模式演化"></a>字段标签和模式演化</h4><p>为了保持向后兼容性，在模式的初始部署之后添加的每个字段都必须是可选的或具有默认值。</p><p>为了保持向前兼容性，只能删除可选的字段（必填字段永远不能被删除）。</p><h4 id="数据类型和模式演化"><a href="#数据类型和模式演化" class="headerlink" title="数据类型和模式演化"></a>数据类型和模式演化</h4><p>Protocal Buffers 没有列表或数组数据类型，而是有字段的重复标记（repeated）。对于重复字段，表示同一个字段标签只是简单的多次出现在记录中。可以将可选（单值）字段更改为重复（多值）字段。</p><p>读取旧数据的新代码会看到一个包含零个或一个元素的列表。</p><p>读取新数据的旧代码只能看到列表的最后一个元素。</p><h3 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h3><p>TODO</p><h3 id="模式（schema）的优点"><a href="#模式（schema）的优点" class="headerlink" title="模式（schema）的优点"></a>模式（schema）的优点</h3><p>Protocal Buffers, Thrift和Avro都使用了模式来描述二进制编码格式。</p><ol><li>可以比各种“二进制JSON”变体更紧凑（可以省略编码数据中的变量名）。</li><li>模式是一种有价值的文档形式（而手动维护文档的成本是巨大的）。</li><li>可以向前兼容和向后兼容。</li><li>可以在编译时进行类型检查。</li></ol><h2 id="数据流模式"><a href="#数据流模式" class="headerlink" title="数据流模式"></a>数据流模式</h2><p>这里我们将探讨一些最常见的进程间数据流动的方式：</p><h3 id="基于数据库的数据流"><a href="#基于数据库的数据流" class="headerlink" title="基于数据库的数据流"></a>基于数据库的数据流</h3><blockquote><p>在数据库中，写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。</p></blockquote><p>由于可能存在新旧不同版本的进程对数据库进行编码或者解码，数据库需要向前或者向后兼容。</p><h4 id="归档存储"><a href="#归档存储" class="headerlink" title="归档存储"></a>归档存储</h4><p>数据传储通常使用最新的模式进行编码，即使源数据库中的原始编码包含了不同时代的各种模式版本。</p><h3 id="基于服务的数据流：REST和RPC"><a href="#基于服务的数据流：REST和RPC" class="headerlink" title="基于服务的数据流：REST和RPC"></a>基于服务的数据流：REST和RPC</h3><p>客户端和服务器。服务器通过网络公开API，客户端可以连接到服务器以向该API发出请求。服务器公开的API称为<strong>server</strong>。</p><ul><li>web浏览器<ul><li>发出GET请求来下载HTML, CSS, JavaScript, 图像</li><li>发出POST请求提交数据到服务器</li></ul></li><li>移动设备或桌面计算机上运行的本地应用程序<ul><li>服务器的响应通常是便于客户端应用程序进一步处理的编码数据（如JSON）</li></ul></li><li>服务器本身可以是另一项服务的客户端<ul><li>微服务体系架构<ul><li>通过使服务可独立部署和演化，让应用程序更易于更改和维护。</li></ul></li></ul></li></ul><h4 id="网络服务"><a href="#网络服务" class="headerlink" title="网络服务"></a>网络服务</h4><blockquote><p>当HTTP被用作与服务通信的底层协议时，它被称为Web服务。</p></blockquote><h5 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h5><p>REST不是一种协议，而是一个基于HTTP原则的设计理念。</p><ul><li>强调简单的数据格式</li><li>使用URL来标识资源</li><li>使用HTTP功能进行缓存控制、身份验证和内容类型协商。</li></ul><blockquote><p>根据REST原则所设计的API称为RESTful</p></blockquote><h5 id="SOAP"><a href="#SOAP" class="headerlink" title="SOAP"></a>SOAP</h5><p>基于XML的协议，用于发出网络API请求。</p><h4 id="远程过程调用（RPC）的问题"><a href="#远程过程调用（RPC）的问题" class="headerlink" title="远程过程调用（RPC）的问题"></a>远程过程调用（RPC）的问题</h4><ul><li>本地函数调用是可预测的，并且成功或失败仅取决于控制的参数。网络请求是不可预测的：请求或响应可能由于网络问题而丢失，或者远程计算机可能速度慢或不可用。</li><li>本地函数要么返回一个结果，要么抛出一个异常。网络请求有另一个可能：由于超时，它返回时可能没有结果。</li><li>重试失败的网络请求，可能会发生请求实际上已经完成，只是响应丢失的情况。需要在协议中建立重复数据消除（幂等性）机制</li><li>调用本地函数时，通常需要大致相同的时间来执行。网络请求比函数调用要慢得多，而且期延迟也有很大的变化。</li><li>调用本地函数时，可以高效地将引用传递给本地内存中的对象。当发出网络请求时，所有这些参数都需要被编码称可以通过网络发送的字节序列。</li><li>客户端和服务端可以用不同的编程语言来实现，所以RPC框架必须将数据类型从一种语言转换成另一语言。</li></ul><h4 id="RPC的发展方向"><a href="#RPC的发展方向" class="headerlink" title="RPC的发展方向"></a>RPC的发展方向</h4><p>REST似乎是公共API的主流风格。RPC框架主要侧重于同一组织内多项服务之间的请求，通常发生在统一数据中心内。</p><h4 id="RPC的数据编码和演化"><a href="#RPC的数据编码和演化" class="headerlink" title="RPC的数据编码和演化"></a>RPC的数据编码和演化</h4><blockquote><p>重要的是可以独立地更改和部署RPC客户端和服务器。</p></blockquote><p>可以假定所有的服务器都先更新，其次再是客户端。因此只需要在请求上具有向后兼容性，而在响应上具有向前兼容性即可</p><p>关于API版本管理暂时没有统一的方案</p><ul><li>对于RESTFUL API，常用的方法是在URL或HTTP Accept头中使用版本号。（目前我在字节实习所用的一种方式）</li><li>对于使用API密钥来表示特定客户端的服务，另一种选择是将客户端请求的API版本存储在服务器上，并允许通过单独的管理接口更新该本本选项。</li></ul><h3 id="基于消息传递的数据流"><a href="#基于消息传递的数据流" class="headerlink" title="基于消息传递的数据流"></a>基于消息传递的数据流</h3><p>RPC和数据库之间的异步消息传递系统。不是通过直接的网络连接发送消息，而是通过称为消息代理（消息队列，或面向消息的中间件）的中介发送的，该中介会暂存消息。</p><h4 id="消息代理"><a href="#消息代理" class="headerlink" title="消息代理"></a>消息代理</h4><p>优点：</p><ul><li>可以充当缓冲区，从而提高系统的可靠性。</li><li>可以自动将消息重新发送到崩溃的进程，防止消息丢失。</li><li>避免了发送方需要知道接收方的IP地址和端口号。</li><li>支持将一条消息发送给多个接收方。</li><li>在逻辑上将发送方与接收方分离。</li></ul><p>消息传递通信通常是单向的。</p><p>使用方式：</p><ol><li>一个进程向指定的队列或主题发送消息。</li><li>代理确保消息被传递给队列或主题的一个或多个消费者或订阅者。</li><li>在同一主题上可以有许多生产者和许多消费者。</li></ol><h4 id="分布式Actor框架"><a href="#分布式Actor框架" class="headerlink" title="分布式Actor框架"></a>分布式Actor框架</h4><p>每个Actor通常代表一个客户端或实体，它可能具有某些本地状态（不与其他任何Actor共享），并且它通过发送和接收异步消息与其他Actor通信。</p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。因此，在系统内流动的所有数据都以提供向后兼容性和向前兼容性的方式进行编码。</p><p>数据流的几种模型</p><ul><li>数据库，其中写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。</li><li>RPC和REST API，其中客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。</li><li>异步消息传递（使用消息代理或Actor），节点之间通过互相发送消息进行通信，消息由发送者编码并由接受者解码。</li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>读书笔记</tag>
      
      <tag>数据密集型应用系统设计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL实战-读书笔记</title>
    <link href="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>实习期间在导师的力荐下读到了这部极客网的 MySQL 课程，实在受益匪浅。初次速读，很多东西不能深刻的记在脑中，不能完全消化，先记录下来，日后再度翻阅。这份资料值得多次品味。</p><h1 id="18-为什么有的-SQL-语句逻辑相同，性能差异巨大"><a href="#18-为什么有的-SQL-语句逻辑相同，性能差异巨大" class="headerlink" title="18.为什么有的 SQL 语句逻辑相同，性能差异巨大"></a>18.为什么有的 SQL 语句逻辑相同，性能差异巨大</h1><h2 id="案例一："><a href="#案例一：" class="headerlink" title="案例一："></a>案例一：</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `tradelog` (<br>    `id`            <span class="hljs-type">int</span>(<span class="hljs-number">11</span>)     <span class="hljs-keyword">NOT</span>     <span class="hljs-keyword">NULL</span>,<br>    `tradeid`       <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    `operator`      <span class="hljs-type">int</span>(<span class="hljs-number">11</span>)     <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    `t_modified`    datetime    <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (`id`),<br>    KEY `tradeid` (`tradeid`),<br>    KEY `t_modified` (`t_modified`)<br>) ENGINE<span class="hljs-operator">=</span>InnoDB <span class="hljs-keyword">DEFAULT</span> CHARSET<span class="hljs-operator">=</span>utf8mb4;<br></code></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> <span class="hljs-keyword">month</span>(t_modified) <span class="hljs-operator">=</span> <span class="hljs-number">7</span>;  # 无法命中索引<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> <br>    (t_modified <span class="hljs-operator">&gt;=</span> <span class="hljs-string">&#x27;2016-7-1&#x27;</span> <span class="hljs-keyword">and</span> t_modified <span class="hljs-operator">&lt;</span> <span class="hljs-string">&#x27;2016-8-1&#x27;</span>) <span class="hljs-keyword">or</span><br>    (t_modified <span class="hljs-operator">&gt;=</span> <span class="hljs-string">&#x27;2017-7-1&#x27;</span> <span class="hljs-keyword">and</span> t_modified <span class="hljs-operator">&lt;</span> <span class="hljs-string">&#x27;2017-8-1&#x27;</span>) <span class="hljs-keyword">or</span> <br>    (t_modified <span class="hljs-operator">&gt;=</span> <span class="hljs-string">&#x27;2018-7-1&#x27;</span> <span class="hljs-keyword">and</span> t_modified <span class="hljs-operator">&lt;</span> <span class="hljs-string">&#x27;2018-8-1&#x27;</span>) ...     # 可以命中索引<br></code></pre></td></tr></table></figure><blockquote><p>如果对字段做了函数计算，就用不上索引了。</p><p>原因是：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。</p></blockquote><h2 id="案例二："><a href="#案例二：" class="headerlink" title="案例二："></a>案例二：</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"># tradeid 的类型是 <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>)<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> tradeid<span class="hljs-operator">=</span><span class="hljs-number">110717</span>;  # 无法命中索引<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> <span class="hljs-built_in">CAST</span>(tradidAS signed <span class="hljs-type">int</span>) <span class="hljs-operator">=</span> <span class="hljs-number">110717</span>;   # 等价于执行这条语句<br></code></pre></td></tr></table></figure><p><strong>MySQL 类型转换的规则是将字符串转换成数字。</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> &quot;10&quot; <span class="hljs-operator">&gt;</span> <span class="hljs-number">9</span> # 返回 <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"># id 的类型是 <span class="hljs-type">int</span><br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span>&quot;83126&quot;;  # 可以命中索引<br></code></pre></td></tr></table></figure><h2 id="案例三："><a href="#案例三：" class="headerlink" title="案例三："></a>案例三：</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `trade_detail` (<br>    `id`            <span class="hljs-type">int</span>(<span class="hljs-number">11</span>)     <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>    `tradeid`       <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    `trade_step`    <span class="hljs-type">int</span>(<span class="hljs-number">11</span>)     <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>, <span class="hljs-comment">/*操作步骤*/</span><br>    `step_info`     <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>, <span class="hljs-comment">/*步骤信息*/</span><br>    <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (`id`),<br>    KEY `tradeid` (`tradeid`)<br>) ENGINE<span class="hljs-operator">=</span>InnoDB <span class="hljs-keyword">DEFAULT</span> CHARSET<span class="hljs-operator">=</span>utf8;<br></code></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> d.<span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tradelog l, trade_detail d <span class="hljs-keyword">where</span> d.tradeid<span class="hljs-operator">=</span>l.tradeid <span class="hljs-keyword">and</span> l.id<span class="hljs-operator">=</span><span class="hljs-number">2</span>;<br># 优化器先在 tradelog 上查到 id<span class="hljs-operator">=</span><span class="hljs-number">2</span> 的行，使用了主键索引<br># 没有使用 trade_detail 上的 trade_id 进行了全表扫描<br></code></pre></td></tr></table></figure><blockquote><p>原因：因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4</p></blockquote><blockquote><p>字符集 utf8mb4 是 utf8 的超集，所以在作比较的时候，先把 utf8 转成 utf8mb4。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> trade_detail <span class="hljs-keyword">where</span> <span class="hljs-keyword">CONVERT</span>(traideid <span class="hljs-keyword">USING</span> utf8mb4)<span class="hljs-operator">=</span>$L2.tradeid.value; # 等价于执行这条语句<br></code></pre></td></tr></table></figure><p><strong>字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是导致对被驱动表做全表扫描的原因。</strong></p><ol><li>当使用left join时，左表是驱动表，右表是被驱动表 </li><li>当使用right join时，右表时驱动表，左表是驱动表</li><li>当使用join时，mysql会选择数据量比较小的表作为驱动表，大表作为被驱动表</li></ol><p>作为对比：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> l.operator <span class="hljs-keyword">from</span> tradelog l, trade_detail d <span class="hljs-keyword">where</span> d.tradeid<span class="hljs-operator">=</span>l.tradeid <span class="hljs-keyword">and</span> d.id<span class="hljs-operator">=</span><span class="hljs-number">4</span>; # 两次查找都可以命中索引<br><br><br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> operator <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> traideid <span class="hljs-operator">=</span><span class="hljs-keyword">CONVERT</span>($R4.tradeid.value <span class="hljs-keyword">USING</span> utf8mb4);<br># 与之前不同的是，这里的 <span class="hljs-keyword">CONVERT</span> 函数是加在参数里的<br><br></code></pre></td></tr></table></figure><h1 id="19-为什么我只查一行的语句，也执行这么慢"><a href="#19-为什么我只查一行的语句，也执行这么慢" class="headerlink" title="19 为什么我只查一行的语句，也执行这么慢"></a>19 为什么我只查一行的语句，也执行这么慢</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `t` (  <br>    `id`    <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>    `c`     <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (`id`)<br>) ENGINE<span class="hljs-operator">=</span>InnoDB;<br></code></pre></td></tr></table></figure><p>我们再往里插入十万条数据</p><h2 id="查询时间长时间不返回"><a href="#查询时间长时间不返回" class="headerlink" title="查询时间长时间不返回"></a>查询时间长时间不返回</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AD%89MDL%E9%94%81.png" class="" title="等MDL锁"><p>出现这个状态表示的是，现在有一个线程正在表上请求或者持有 MDL 写锁，把 <code>select</code> 语句 block 住了。</p><p>有一个 <code>flush table</code> 命令被别的语句 block 住了，然后又 block 住了我们的 <code>select</code> 语句。</p><h2 id="查询慢"><a href="#查询慢" class="headerlink" title="查询慢"></a>查询慢</h2><blockquote><p>坏查询不一定是慢查询</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">1</span>;                    # 慢<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">1</span> lock <span class="hljs-keyword">in</span> share mode; # 快<br></code></pre></td></tr></table></figure><p>带 lock in share mode 的 SQL 是当前读，因此会直接读到最后结果；而没有 share mode 的是一致读，要从最后的结果，依次执行 undo log，才能返回正确的结果。</p><h1 id="20-幻读是什么，幻读有什么问题"><a href="#20-幻读是什么，幻读有什么问题" class="headerlink" title="20 幻读是什么，幻读有什么问题"></a>20 幻读是什么，幻读有什么问题</h1><h2 id="幻读是什么"><a href="#幻读是什么" class="headerlink" title="幻读是什么"></a>幻读是什么</h2><blockquote><p><strong>幻读</strong>指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</p></blockquote><p>在可重读度隔离级别下，普通的查询时快照读，是不会看到别的事务插入数据的。因此幻读在当前读下才会出现。</p><h2 id="幻读有什么问题"><a href="#幻读有什么问题" class="headerlink" title="幻读有什么问题"></a>幻读有什么问题</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `t` (<br>    `id`    <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>    `c`     <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    `d`     <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (`id`),<br>    KEY `c` (`c`)<br>) ENGINE<span class="hljs-operator">=</span>InnoDB;<br><br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),(<span class="hljs-number">10</span>,<span class="hljs-number">10</span>,<span class="hljs-number">10</span>),(<span class="hljs-number">15</span>,<span class="hljs-number">15</span>,<span class="hljs-number">15</span>),(<span class="hljs-number">20</span>,<span class="hljs-number">20</span>,<span class="hljs-number">20</span>),(<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>);<br></code></pre></td></tr></table></figure><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select * from t where d=5 for update;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>update t set d=5 where id=0;</code> <br> <code>update t set c=5 where id=0;</code></td><td></td></tr><tr><td>T3</td><td><code>select * from t where d=5 for update;</code></td><td></td><td></td></tr><tr><td>T4</td><td></td><td></td><td><code>insert into t values(1, 1, 5);</code> <br> <code>update t set c=5 where id=1;</code></td></tr><tr><td>T5</td><td><code>select * from t where d=5 for update;</code></td><td></td><td></td></tr><tr><td>T6</td><td><code>commit;</code></td><td></td><td></td></tr></tbody></table><ol><li>语义上的问题<br>sessionA 在 T1 时刻声明 “我要将d=5的行锁住，不允许别的事务进行读写操作”。</li><li>数据不一致<br>会导致数据和日志在逻辑上的不一致<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d<span class="hljs-operator">=</span><span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">0</span>; <span class="hljs-comment">/*(0,0,5)*/</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> c<span class="hljs-operator">=</span><span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">0</span>; <span class="hljs-comment">/*(0,5,5)*/</span><br><br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">5</span>); <span class="hljs-comment">/*(1,1,5)*/</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> c<span class="hljs-operator">=</span><span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">1</span>; <span class="hljs-comment">/*(1,5,5)*/</span><br><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d<span class="hljs-operator">=</span><span class="hljs-number">100</span> <span class="hljs-keyword">where</span> d<span class="hljs-operator">=</span><span class="hljs-number">5</span>;<span class="hljs-comment">/*所有d=5的行,d改成100*/</span><br></code></pre></td></tr></table></figure>拿这个语句序列，无法克隆一个一模一样的库，会存在数据的不一致。</li></ol><h2 id="如何解决幻读"><a href="#如何解决幻读" class="headerlink" title="如何解决幻读"></a>如何解决幻读</h2><p>即使把所有的记录都加上锁，还是阻止不了新插入的记录。</p><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>InnoDB 引入新的锁，也就是间隙锁 (Gap Lock)。在一行行扫描的过程中，不仅将给行加上了行锁，还给两边的空隙，也加上了间隙锁，就可以确保无法再插入新的记录。</p><p>间隙锁和行锁合称 <strong>next-key lock</strong>。但是间隙锁的引入，可能会导致同样的语句锁住更大的范围</p><p>|   |  sessionA  | sessionB |<br>| - | - | - | - |<br>| T1 | <code>begin;</code> <br> <code>select * from t where id=9 for update;</code> | |<br>| T2 | | <code>begin;</code> <br> <code>select * from t where id=9 for update;</code> |<br>| T3 | | <code>insert into t values(9, 9, 9)</code> <br> (blocked)|<br>| T4 | <code>insert into t values(9, 9, 9);</code> <br> (ERROR: DEADLOCK)| |</p><p>上述情况出现的原因是 sessionA 被 sessionB 的间隙锁 block 了，同时 sessionB 也被 sessionA block 了。（因为间隙锁之间不会冲突）</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>如果把隔离级别设置为 Read Commit 就没有间隙锁了，但这时有需要解决数据与日志不一致的问题，需要把 binlog 格式设置为 row。</p><p>如果业务场景 Read Commit级别够用，即业务不需要可重复读的保证，考虑到读提交下操作数据的锁范围更小，这个选择是合理的。</p><h1 id="21-为什么我只改一行语句，锁这么多"><a href="#21-为什么我只改一行语句，锁这么多" class="headerlink" title="21 为什么我只改一行语句，锁这么多"></a>21 为什么我只改一行语句，锁这么多</h1><p>本篇还是在之前 20 的场景下</p><h2 id="两个原则，两个优化，一个bug"><a href="#两个原则，两个优化，一个bug" class="headerlink" title="两个原则，两个优化，一个bug"></a>两个原则，两个优化，一个bug</h2><ol><li>原则1：加锁的基本单位是 next-key lock。next-key lock 是前开后闭区间。</li><li>原则2：查找过程中访问到的对象才会加锁</li><li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li><li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li><li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止</li></ol><h2 id="案例一：等值查询间隙锁"><a href="#案例一：等值查询间隙锁" class="headerlink" title="案例一：等值查询间隙锁"></a>案例一：等值查询间隙锁</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>update t set d=d+1 where id=7;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>insert into t values(8, 8, 8);</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>update t set d=d+1 where id=10;</code> <br> (Query OK)</td></tr></tbody></table><p>根据<strong>优化2</strong>，next-key lock会退化为间隙锁，最终加锁的范围是(5, 10)，所以 sessionC 的修改是可以成功的。</p><h2 id="案例二：非唯一索引等值锁"><a href="#案例二：非唯一索引等值锁" class="headerlink" title="案例二：非唯一索引等值锁"></a>案例二：非唯一索引等值锁</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select id from t where c=5 lock in share mode;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>update t set d=d+1 where id=5;</code> <br> (Query OK)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>insert into t values(7, 7, 7);</code> <br> (blocked)</td></tr></tbody></table><ol><li>根据<strong>原则1</strong>，加锁单位是 next-key lock，因此会给(0, 5]加上 next-key lock。</li><li>因为c是普通索引，仅访问c=5这一条记录是不能马上停下来的，需要向右遍历，查到c=10才放弃。根据<strong>原则2</strong>，访问到的都要加锁，因此要给(5, 10]加next-key lock。</li><li>根据<strong>优化2</strong>，等值判断，向右遍历，最后一个值不满足c=5这个等值条件，退化成间隙锁(5, 10)</li><li>根据<strong>原则2</strong>，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，所以 sessionB 的 update 语句可以执行完成。但是 sessionC 要插入一个(7, 7, 7)的记录，就会被sessionA 的间隙锁锁住。</li></ol><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>锁是加在索引上的</li><li>如果要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入所有中不存在的字段。</li></ul><h2 id="案例三：主键索引范围锁"><a href="#案例三：主键索引范围锁" class="headerlink" title="案例三：主键索引范围锁"></a>案例三：主键索引范围锁</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select * from t where id&gt;=10 and id&lt;11 for update;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>insert into t values(8, 8, 8);</code> <br> (Query OK) <br> <code>insert into t values(13, 13, 13);</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>update t set d=d+1 where id=15;</code> <br> (blocked)</td></tr></tbody></table><ol><li>开始执行的时候，要找到一个id=10的行，next-key lock(5, 10]。根据<strong>优化一</strong>，主键id上的等值条件，退化成行锁，只加了id=10这一行的行锁。</li><li>范围查找就往后继续找，找到id=15这一行，需要next-key lock(10, 15]</li><li>sessionA 这时候锁的范围就是主键索引上，行锁id=10和next-key lock(10, 15]</li></ol><h2 id="案例四：非唯一索引范围锁"><a href="#案例四：非唯一索引范围锁" class="headerlink" title="案例四：非唯一索引范围锁"></a>案例四：非唯一索引范围锁</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select * from t where c&gt;=10 and c&lt;11 for update;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>insert into t values(8, 8, 8);</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>update t set d=d+1 where c=15;</code> <br> (blocked)</td></tr></tbody></table><ol><li>由于c是普通索引，不能退化成行锁，因此最终 sessionA 加的锁是，索引c上的(5, 10]和(10, 15]这两个next-key lock</li><li>InnoDB 要扫到c=15 才知道不需要继续往后找了。</li></ol><h2 id="案例五：唯一索引范围锁bug"><a href="#案例五：唯一索引范围锁bug" class="headerlink" title="案例五：唯一索引范围锁bug"></a>案例五：唯一索引范围锁bug</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select * from t where id&gt;10 and id&lt;=15 for update;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>update t set d=d+1 where id=20;</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>insert t values(16, 16, 16);</code> <br> (blocked)</td></tr></tbody></table><ol><li>根据<strong>原则1</strong>，应该是索引id上只加(10, 15]这个next-key lock，并且因为id是唯一键，所以循环判断到id=15这一行就应该停止了</li><li>但是根据<strong>一个bug</strong>，InnoDB 会往前扫描到第一个不满足条件的行 为止，因此索引id上的(15, 20]这个next-key lock也会被锁上。</li></ol><h2 id="案例六：非唯一索引上存在“等值”的例子"><a href="#案例六：非唯一索引上存在“等值”的例子" class="headerlink" title="案例六：非唯一索引上存在“等值”的例子"></a>案例六：非唯一索引上存在“等值”的例子</h2><p>先插入一条新纪录</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">30</span>, <span class="hljs-number">10</span>, <span class="hljs-number">30</span>);<br></code></pre></td></tr></table></figure><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>delete from t where c=10;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>insert into t values(12, 12, 12);</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>update t set d=d+1 where c=15;</code> <br> (Query OK)</td></tr></tbody></table><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/21-%E6%A1%88%E4%BE%8B%E5%85%AD.png" class="" title="21-案例六"><p>两个c=10的记录之间，也是有间隙的。</p><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/21-%E6%A1%88%E4%BE%8B%E5%85%AD%E5%8A%A0%E9%94%81%E7%A4%BA%E6%84%8F%E5%9B%BE.png" class="" title="21-案例六加锁示意图"><p>根据<strong>优化2</strong>，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10, id=10) 到 (c=15, id=15)的间隙锁。</p><h2 id="案例七：limit-语句加锁"><a href="#案例七：limit-语句加锁" class="headerlink" title="案例七：limit 语句加锁"></a>案例七：limit 语句加锁</h2><p>|   |  sessionA  | sessionB |<br>| - | - | - | - |<br>| T1 | <code>begin;</code> <br> <code>delete from t where c=10 limit 2;</code> | |<br>| T2 | | <code>insert into t values(12, 12, 12);</code> <br> (Query OK) |</p><p><code>delete</code> 语句明确加了 limit 2 的限制，因此在遍历到(c=10, id=30)这一行后，满足条件的语句就已经有两条，循环就结束了。</p><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/21-%E6%A1%88%E4%BE%8B%E4%B8%83%E5%8A%A0%E9%94%81%E7%A4%BA%E6%84%8F%E5%9B%BE.png" class="" title="21-案例七加锁示意图"><blockquote><p>在删除数据的时候尽量加limit</p></blockquote><h2 id="案例八：一个死锁的例子"><a href="#案例八：一个死锁的例子" class="headerlink" title="案例八：一个死锁的例子"></a>案例八：一个死锁的例子</h2><p>|   |  sessionA  | sessionB |<br>| - | - | - | - |<br>| T1 | <code>begin;</code> <br> <code>select id from t where c=10 lock in share mode;</code> | |<br>| T2 | | <code>update t set d=d+1 where c=10;</code> <br> (blocked) |<br>| T3 | <code>insert into t values(8, 8, 8)</code>| |<br>| T4 | | (ERROR: DEADLOCK) |</p><ol><li>sessionA 启动事务后执行查询语句加 lock in share mode，在索引c上加了next-key locks(5, 10]和间隙锁(10, 15)</li><li>sessionB 的update语句也要在索引c上加next-key lock(5, 10]，进入锁等待</li><li>然后sessionA 要再插入(8, 8, 8)这一行，被sessionB 的间隙锁锁住。由于出现了死锁，需要回滚。</li></ol><h2 id="案例九：desc导致的顺序差异"><a href="#案例九：desc导致的顺序差异" class="headerlink" title="案例九：desc导致的顺序差异"></a>案例九：desc导致的顺序差异</h2><p>|   |  sessionA  | sessionB |<br>| - | - | - | - |<br>| T1 | <code>begin;</code> <br> <code>select * from t where c&gt;=15 and c&lt;=20 order by c desc in share mode;</code> | |<br>| T2 | | <code>insert into t values(6, 6, 6);</code> <br> (blocked) |</p><ol><li>因为这里使用的是 <code>desc</code> 所以是从右往左扫描的。</li><li>根据<strong>优化2</strong>，先判断条件c&lt;=20，普通索引等值c=20，所以间隙锁(20, 25)</li><li>20 到 15，所以next-key locks(20, 15]</li><li>判断c&gt;=15，普通索引c=15，向左匹配到c=10这个记录，因为next-key locks是前开后闭的，所以只能是(5, 10]</li><li>最后的范围是 (5, 15)+[15, 20)+[20, 25)</li><li>c=20、c=15、c=10 都存在值， select *主键 id 加三个行锁。</li></ol><p>如果没有desc 锁的应该是(10, 15] + (15, 20] + (20, 25) 加上 15 20 主键id 两个行锁</p><h1 id="22-MySQL-有哪些“饮鸩止渴”提高性能的方法"><a href="#22-MySQL-有哪些“饮鸩止渴”提高性能的方法" class="headerlink" title="22 MySQL 有哪些“饮鸩止渴”提高性能的方法"></a>22 MySQL 有哪些“饮鸩止渴”提高性能的方法</h1><h2 id="短连接风暴"><a href="#短连接风暴" class="headerlink" title="短连接风暴"></a>短连接风暴</h2><ol><li>先处理掉那些占着连接但是不工作的线程</li></ol><ul><li>如果是连接数过多，你可以优先断开事务外空闲太久的连接。</li><li>如果这样还不够，可以考虑断开事务内空闲太久的连接。 </li></ul><blockquote><p>从数据库端断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的 handler 重试查询。这会导致从应用端看上去——“MySQL一直没恢复”。</p></blockquote><ol start="2"><li>减少连接过程的消耗</li></ol><p>如果现在数据库确认是被连接行为打挂了，那么可以让数据库跳过权限验证阶段。重启数据库，并使用 <code>-skip-grant-tables</code> 参数启动。但是这个方法风险极高。</p><h2 id="慢查询性能问题"><a href="#慢查询性能问题" class="headerlink" title="慢查询性能问题"></a>慢查询性能问题</h2><h3 id="索引没有设计好"><a href="#索引没有设计好" class="headerlink" title="索引没有设计好"></a>索引没有设计好</h3><p>通过紧急创建索引来解决</p><ol><li>在备库B上执行 <code>set sql_log_bin=off</code>, 也就是不写 binlog, 然后执行 <code>alter table</code> 语句加上索引</li><li>执行主备切换</li><li>这时候主库是B, 备库是A。在A上执行 <code>set sql_log_bin=off</code>, 然后执行 <code>alter table</code> 语句加上索引<h3 id="SQL-语句没有写好"><a href="#SQL-语句没有写好" class="headerlink" title="SQL 语句没有写好"></a>SQL 语句没有写好</h3>详见 <a href="">18 为什么这些SQL语句逻辑相同，性能却差异巨大</a><h3 id="MySQL-选错了索引"><a href="#MySQL-选错了索引" class="headerlink" title="MySQL 选错了索引"></a>MySQL 选错了索引</h3>详见 <a href="">10 MySQL 为什么有时候会选错索引</a><br>可以通过添加语句 <code>force index</code> </li></ol><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>那么我们如何尽量避免这类性能问题的发生呢？</p><ol><li>上线前，在测试环境，把慢查询日志（slow log）打开，并且把long_query_time设置成0，确保每个语句都会被记录入慢查询日志</li><li>在测试表里插入模拟线上的数据，做一遍回归测试</li><li>观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致。</li></ol><h2 id="QPS-突增问题"><a href="#QPS-突增问题" class="headerlink" title="QPS 突增问题"></a>QPS 突增问题</h2><p>有时候由于业务突然出现高峰，或者应用程序bug，导致某个语句的QPS突然暴涨，也可能导致MySQL压力过大，影响服务。</p><h1 id="23-MySQL-是怎么保证数据不丢的"><a href="#23-MySQL-是怎么保证数据不丢的" class="headerlink" title="23 MySQL 是怎么保证数据不丢的"></a>23 MySQL 是怎么保证数据不丢的</h1><h2 id="binlog-的写入机制"><a href="#binlog-的写入机制" class="headerlink" title="binlog 的写入机制"></a>binlog 的写入机制</h2><blockquote><p>事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p></blockquote><p>TODO</p><h1 id="24-MySQL-是怎么保证主备一致的？"><a href="#24-MySQL-是怎么保证主备一致的？" class="headerlink" title="24 MySQL 是怎么保证主备一致的？"></a>24 MySQL 是怎么保证主备一致的？</h1><h2 id="MySQL-主备的基本原理"><a href="#MySQL-主备的基本原理" class="headerlink" title="MySQL 主备的基本原理"></a>MySQL 主备的基本原理</h2><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/24-MySQL%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%B5%81%E7%A8%8B.png" class="" title="24-MySQL主备切换流"><p>这就是基本的主备切换流程。</p><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/24-%E4%B8%BB%E5%A4%87%E6%B5%81%E7%A8%8B%E5%9B%BE.png" class="" title="24-主备流程图"><ol><li>在备库B上通过 change master 命令，设置主库A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。</li><li>在备库B上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。</li><li>主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取 binlog，发给B。</li><li>备库B拿到 binlog 后，写到本地文件，称为中转日志(relay log)</li><li>sql_thread 读取中转日志，解析出日志里的命令，并执行。</li></ol><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://drive.google.com/drive/folders/168dQ754KYC9QFikDy6iTq0mKHWYJkz8p">MySQL实战45讲</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>极客</tag>
      
      <tag>读书笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL-索引</title>
    <link href="/2021/01/05/MySQL-%E7%B4%A2%E5%BC%95/"/>
    <url>/2021/01/05/MySQL-%E7%B4%A2%E5%BC%95/</url>
    
    <content type="html"><![CDATA[<p>B树和B+树的具体结构在此不做赘述。好不容易弄明白了索引的底层实现，结果被面试官问为什么要使用B+索引，用Hash不香嘛。下了面试一查，发现居然还有Hash索引，真是吃了没有文化的亏呀。防不胜防，在此补作一笔。</p><p>首先要明白索引(index)是在存储引擎层面实现的，而不是server层面</p><h1 id="什么是索引"><a href="#什么是索引" class="headerlink" title="什么是索引"></a>什么是索引</h1><p>索引（Index）是帮助数据库高效获取数据的数据结构。索引是在基于数据库表创建的，它包含一个表中某些列的值以及记录对应的地址，并且把这些值存储在一个数据结构中。最常见的就是使用哈希表、B+树作为索引。我们会为每一个字段去建索引。</p><h1 id="从数据结构角度分类"><a href="#从数据结构角度分类" class="headerlink" title="从数据结构角度分类"></a>从数据结构角度分类</h1><p>实际上，还有Fulltext索引和R-Tree索引，但是这里简略带过。</p><ul><li>InnoDB存储引擎：默认是B+Tree 索引</li><li>MyISAM存储引擎：默认是Fulltext 索引</li><li>Memory存储引擎：默认Hash 索引。（也是可以使用B+Tree索引的）</li></ul><h2 id="Hash索引"><a href="#Hash索引" class="headerlink" title="Hash索引"></a>Hash索引</h2><p>来，说说这个神奇的东西。Hash索引把数据以hash形式组织起来，因此当查找某一条记录的时候，速度非常快。但是因为hash结构，每个键只对应一个值，而且是散列的方式分布。<strong>所以它并不支持范围查找和排序等功能。</strong></p><ul><li>Hash 索引无法完成排序</li><li>不支持最左匹配原则</li><li>在有大量重复键值情况下，Hash 索引的效率也很低</li><li>不支持范围查询</li></ul><h2 id="B-Tree索引"><a href="#B-Tree索引" class="headerlink" title="B+Tree索引"></a>B+Tree索引</h2><p>相比Hash索引，B+Tree在查找单条记录的速度比不上Hash索引，但是因为更加适合排序等操作，所以更加受欢迎。(想起我跟面试官信誓旦旦的说B+Tree肯定查的快真是丢人😢)</p><ul><li>带顺序访问指针的B+Tree<ul><li>B+Tree所有的缩影数据都在叶子节点上，并且相比于B Tree增加了顺序访问指针，每个叶子结点都有指向相邻叶子节点的指针。</li><li>这样做是为了提高区间效率，例如查询key为从18到49的所有数据记录，当找到18后，只要顺着节点和指针顺序遍历就可以以此向访问到所有数据节点，极大提高了区间查询效率。</li></ul></li><li>大大减少磁盘I/O读取<ul><li>数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点需要一次I/O就可以完全载入。</li></ul></li></ul><h2 id="Full-Text全文索引"><a href="#Full-Text全文索引" class="headerlink" title="Full-Text全文索引"></a>Full-Text全文索引</h2><ul><li>可以用全文索引代替效率较低的LIKE模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。</li><li>同样适用B-Tree存放索引数据，但使用的是特定的算法，将字段数据分割后再进行索引，索引文件存储的是分割前的索引字符串集合，与分割后的索引信息，对应B-Tree结构的节点储存的是分割后的词信息以及它在分割前的索引字符串集合中的位置。</li></ul><h2 id="R-Tree空间索引"><a href="#R-Tree空间索引" class="headerlink" title="R-Tree空间索引"></a>R-Tree空间索引</h2><ul><li>空间索引是MyISAM的一种特殊索引类型，主要用于地理空间数据类型</li></ul><h1 id="从物理存储角度：聚簇索引与非聚簇索引"><a href="#从物理存储角度：聚簇索引与非聚簇索引" class="headerlink" title="从物理存储角度：聚簇索引与非聚簇索引"></a>从物理存储角度：聚簇索引与非聚簇索引</h1><p>B+Tree索引可以分为聚簇缩影和非聚簇索引，但本质还是使用B+Tree实现的，即高度是平衡的，叶子节点存放所有的数据<b>聚集索引与非聚集索引的区别是：叶节点是否存放一整行记录。非聚簇索引是叶子节点存储的是索引+索引对应的记录的数据，聚簇索引是叶子节点上的数据是主键与具体记录(数据内容)</b>每张表只能有一个聚簇索引。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://juejin.im/post/5cdd701ee51d453a36384939">https://juejin.im/post/5cdd701ee51d453a36384939</a></p><h1 id="从逻辑角度分类"><a href="#从逻辑角度分类" class="headerlink" title="从逻辑角度分类"></a>从逻辑角度分类</h1><ul><li><p>主键索引</p><ul><li>是一种特殊的唯一索引，不允许有空值。</li></ul></li><li><p>唯一索引</p><ul><li>与“普通索引”类似，不同的就是：索引列的值必须唯一，但允许有空值。</li></ul></li><li><p>普通索引</p><ul><li>最基本的索引，没有任何限制。</li></ul></li><li><p>全文索引</p><ul><li>仅可用于MyISAM和InnoDB，针对较大的数据，生成全文索引很耗时耗空间。</li></ul></li><li><p>倒排索引</p><ul><li><p>全文检索使用倒排索引来实现，倒排索引同B+树索引一样，也是一种数据结构，它在辅助表中存储了单词与单词自身在一个或多个文档中所在位置的映射，这通常利用关联数组实现。</p></li><li><p>倒排索引它需要将分词（word）存储在一个辅助表（Auxiliary Table）中，为了提高全文检索的并行性能，共有6张辅助表。辅助表中存储了单词和单词在各行记录中位置的映射关系。它分为两种：<b>倒排文件索引</b>，<b>详细倒排索引</b></p><ul><li>Inverted file index 倒排文件索引，表现为{单词，单词所在文档ID}</li><li>Full inverted index 详细倒排索引，表现为{单词，(单词所在文档ID, 文档中的位置)}</li></ul></li><li><p><a href="https://www.zhihu.com/question/23202010">倒排索引为什么叫倒排索引？</a></p></li></ul></li></ul><h2 id="组合索引"><a href="#组合索引" class="headerlink" title="组合索引"></a>组合索引</h2><p>为了更多的提高mysql效率可建立组合索引，遵循”最左前缀”原则。创建复合索引应该将最常用（频率）做限制条件的列放在最左边，一次递减。组合索引最左字段用in是可以用到索引的。</p><h2 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h2><p>覆盖索引只一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。如果一个索引包含(或覆盖)满足查询语句中字段与条件的数据就叫做覆盖索引。</p><h1 id="最左匹配原则"><a href="#最左匹配原则" class="headerlink" title="最左匹配原则"></a>最左匹配原则</h1><p>最左匹配原则就是指在联合索引中，如果你的 SQL 语句中用到了联合索引中的最左边的索引，那么这条 SQL 语句就可以利用这个联合索引去进行匹配。</p><blockquote><p>示例1 </p></blockquote><p>假设有索引(a,b,c)</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样可以利用到定义的索引（a,b,c）<br><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样可以利用到定义的索引（a,b,c）<br><br># 借助mysql查询优化器explain，explain会纠正<span class="hljs-keyword">sql</span>语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样可以利用到定义的索引（a,b,c）<br><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样也可以利用到定义的索引（a,b,c）<br><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样不可以利用到定义的索引（a,b,c）<br><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样不可以利用到定义的索引（a,b,c）<br><br># 当遇到范围查询(<span class="hljs-operator">&gt;</span>、<span class="hljs-operator">&lt;</span>、<span class="hljs-keyword">between</span>、<span class="hljs-keyword">like</span>)就会停止匹配<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b<span class="hljs-operator">&gt;</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样a,b可以用到（a,b,c），c不可以<br><br></code></pre></td></tr></table></figure><blockquote><p>示例2</p></blockquote><p>假设对列<code>col1</code>,<code>col2</code>,<code>col3</code>建立一个联合索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs SQL">KEY test_col1_col2_col3 <span class="hljs-keyword">on</span> test(col1,col2,col3)<br></code></pre></td></tr></table></figure><p>联合索引<code>test_col1_col2_col3</code>实际上建立了<code>(col1)</code>,<code>(col1,col2)</code>,<code>(col1,col2,col3)</code>三个索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> test <span class="hljs-keyword">WHERE</span> col1<span class="hljs-operator">=</span>“<span class="hljs-number">1</span>” <span class="hljs-keyword">AND</span> clo2<span class="hljs-operator">=</span>“<span class="hljs-number">2</span>” <span class="hljs-keyword">AND</span> clo4<span class="hljs-operator">=</span>“<span class="hljs-number">4</span>”<br></code></pre></td></tr></table></figure><p>上面这个查询语句执行时会依照最左前缀匹配的原则，检索时会使用索引<code>(col1,col2)</code>进行数据匹配</p><h2 id="最左匹配原则的原理"><a href="#最左匹配原则的原理" class="headerlink" title="最左匹配原则的原理"></a>最左匹配原则的原理</h2><p>因为构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树</p><blockquote><p>示例</p></blockquote><p>假如创建一个(a,b,c)的联合索引</p><p>该图就是一个形如(a,b,c)联合索引的 b+ 树，其中的非叶子节点存储的是第一个关键字的索引 a，而叶子节点存储的是三个关键字的数据。这里可以看出 a 是有序的，而 b，c 都是无序的。但是当在 a 相同的时候，b 是有序的，b 相同的时候，c 又是有序的。通过对联合索引的结构的了解，那么就可以很好的了解为什么最左匹配原则中如果遇到范围查询就会停止了。以 <code>select * from t where a=5 and b&gt;0 and c =1; </code>这样a,b可以用到（a,b,c），c不可以 为例子，当查询到 b 的值以后（这是一个范围值），c 是无序的。所以就不能根据联合索引来确定到低该取哪一行。</p><h1 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.cnblogs.com/aspirant/p/9214485.html">https://www.cnblogs.com/aspirant/p/9214485.html</a></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL-事务</title>
    <link href="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/"/>
    <url>/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="数据库ACID特性"><a href="#数据库ACID特性" class="headerlink" title="数据库ACID特性"></a>数据库ACID特性</h1><h2 id="原子性-Atomicity"><a href="#原子性-Atomicity" class="headerlink" title="原子性 Atomicity"></a>原子性 Atomicity</h2><p>一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部回滚失败。</p><h2 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性 Consistency"></a>一致性 Consistency</h2><p>数据库总是从一个一致性状态转换到另一个一致性状态。</p><h2 id="隔离性-Isolation"><a href="#隔离性-Isolation" class="headerlink" title="隔离性 Isolation"></a>隔离性 Isolation</h2><p>一个事务在做提交之前，对其他事物是不可见的。</p><h2 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h2><p>一旦事务提交，其所作的修改就会永久的保存在数据库中。</p><h1 id="MVCC-多版本并发控制"><a href="#MVCC-多版本并发控制" class="headerlink" title="MVCC 多版本并发控制"></a>MVCC 多版本并发控制</h1><p>我们在数据库表中看到的一行记录可能实际上有多个版本，每个版本的记录除了有数据本身外，还要有一个表示版本的字段 <code>row trx_id</code>，这个字段就是使其产生的事务id，记为 <code>transcation id</code>，在事务开始的时候向事务系统申请，按时间顺序递增。</p><img src="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/%E4%BA%8B%E5%8A%A1ID.png" class="" title="事务ID"><p>可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。</p><p><b>MVCC 的实现是通过保存数据在某个时间点的快照来实现的。</b>也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。</p><p>典型的MVCC实现方式，分为乐观（optimistic）并发控制和悲观（pressimistic）并发控制。下边通过 InnoDB的简化版行为来说明 MVCC 是如何工作的。</p><p>InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是真实的时间，而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。</p><ul><li>SELECT<ul><li>InnoDB会根据以下两个条件检查没行记录：<ul><li>a. InnoDB只会查找版本早于当前事务版本的数据行（也就是，行的系统版本小于或等于事务的系统版本号），<br>这样可以确保事务读取到的行，要么是事务开始前已经存在的，要么是事务自身插入或者修改过的。</li><li>b. 行的删除版本要么未定义，要么大于当前事务的版本号。这样可以确保事务读取到的行，在事务之前未被<br>删除。<br>只有符合上述两个条件的记录，才能被作为返回查询结果</li></ul></li></ul></li><li>INSERT<ul><li>InnoDB 为新插入的每一行保存当前系统版本号作为行版本号</li></ul></li><li>DELETE<ul><li>InnoDB 为删除的每一行保存当前系统版本号作为行删除标识</li></ul></li><li>UPDATE<ul><li>InnoDB 为插入一行新纪录，保存当前系统版本号作为版本号，同时保存当前系统版本号到原来的行作为行删除标识。</li></ul></li></ul><h1 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h1><h2 id="数据库事务隔离级别"><a href="#数据库事务隔离级别" class="headerlink" title="数据库事务隔离级别"></a>数据库事务隔离级别</h2><table><thead><tr><th></th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>Read Uncommitted</td><td>可能</td><td>可能</td><td>可能</td></tr><tr><td>Read Committed</td><td>不可能</td><td>可能</td><td>可能</td></tr><tr><td>Repeatable Read</td><td>不可能</td><td>不可能</td><td>可能</td></tr><tr><td>Serializable</td><td>不可能</td><td>不可能</td><td>不可能</td></tr></tbody></table><h3 id="脏读、不可重复读、幻读"><a href="#脏读、不可重复读、幻读" class="headerlink" title="脏读、不可重复读、幻读"></a>脏读、不可重复读、幻读</h3><ul><li><p>脏读</p><p>  脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。</p></li><li><p>不可重复读</p><p>  是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。（即不能读到相同的数据内容）</p><p>  例如，一个编辑人员两次读取同一文档，但在两次读取之间，作者重写了该文档。当编辑人员第二次读取文档时，文档已更改。原始读取不可重复。如果只有在作者全部完成编写后编辑人员才可以读取文档，则可以避免该问题。</p></li><li><p>幻读</p><p>  是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。</p><p>  例如，一个编辑人员更改作者提交的文档，但当生产部门将其更改内容合并到该文档的主复本时，发现作者已将未编辑的新材料添加到该文档中。如果在编辑人员和生产部门完成对原始文档的处理之前，任何人都不能将新材料添加到文档中，则可以避免该问题。</p></li></ul><h3 id="四种隔离级别的解读"><a href="#四种隔离级别的解读" class="headerlink" title="四种隔离级别的解读"></a>四种隔离级别的解读</h3><h4 id="Read-Uncommitted"><a href="#Read-Uncommitted" class="headerlink" title="Read Uncommitted"></a>Read Uncommitted</h4><p>最差的隔离级别，一个事务可以读到另一个事务没有commit时的数据</p><h4 id="Read-Committed"><a href="#Read-Committed" class="headerlink" title="Read Committed"></a>Read Committed</h4><p>当隔离级别设置为Read committed 时，一个事务虽然不能读未commit的数据，但是别的事务可以修改当前读过的数据，造成前后不一致。大多数数据库的默认级别就是Read committed，比如Sql Server , Oracle。</p><h4 id="Repeatable-Read"><a href="#Repeatable-Read" class="headerlink" title="Repeatable Read"></a>Repeatable Read</h4><p>虽然Repeatable read避免了不可重复读，但还有可能出现幻读 。</p><h4 id="Serializable"><a href="#Serializable" class="headerlink" title="Serializable"></a>Serializable</h4><p>Serializable 是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。</p><h2 id="快照-Snapshot"><a href="#快照-Snapshot" class="headerlink" title="快照 (Snapshot)"></a>快照 (Snapshot)</h2><p>快照又叫一致性视图，快照需要遵循以下规则：</p><ul><li>当前事务内的更新，可读</li><li>版本未提交，不可读</li><li>版本已提交，但是在快照创建后提交的，不可读</li><li>版本已提交，且是在快照创建前提交的，可读</li></ul><h3 id="快照读-vs-当前读"><a href="#快照读-vs-当前读" class="headerlink" title="快照读 vs. 当前读"></a>快照读 vs. 当前读</h3><ul><li>快照读<ul><li>读取的是记录数据的可见版本（可能是过期的数据），不用加锁</li></ul></li><li>当前读<ul><li>读取的是记录数据的最新版本，并且当前读返回的记录都会加上锁，保证其他事务不会再并发的修改这条记录</li></ul></li></ul><h2 id="隔离的实现"><a href="#隔离的实现" class="headerlink" title="隔离的实现"></a>隔离的实现</h2><h3 id="四种隔离级别的实现"><a href="#四种隔离级别的实现" class="headerlink" title="四种隔离级别的实现"></a>四种隔离级别的实现</h3><h4 id="读未提交-Read-Uncommitted"><a href="#读未提交-Read-Uncommitted" class="headerlink" title="读未提交 (Read Uncommitted)"></a>读未提交 (Read Uncommitted)</h4><p>这种隔离性是不加锁的。</p><h4 id="串行化"><a href="#串行化" class="headerlink" title="串行化"></a>串行化</h4><p>读的时候加共享锁(其他事务可以并发读)，但是不能写；写的时候加排他锁，其他事务不能并发写也不能并发读。</p><h4 id="读提交-Read-Committed"><a href="#读提交-Read-Committed" class="headerlink" title="读提交 (Read Committed)"></a>读提交 (Read Committed)</h4><p>而读提交则是每次执行语句的时候都重新生成一次快照。</p><h4 id="可重复读-Repeatable-Read"><a href="#可重复读-Repeatable-Read" class="headerlink" title="可重复读 (Repeatable Read)"></a>可重复读 (Repeatable Read)</h4><p>可重复读是在事务开始的时候生成一个当前事务全局性的快照。</p><h3 id="并发写问题"><a href="#并发写问题" class="headerlink" title="并发写问题"></a>并发写问题</h3><p>更新之前要先读取数据，这里用的是<strong>当前读</strong>，总是当前版本的数据，也就是多版本中最新一次提交的那版。</p><p>假设事务A要执行 update 操作，需要对所修改的行加行锁，这个行锁会在提交之后才释放。这时候事务B就没办法更新这行，直到事务A提交后释放行锁。</p><p>加锁过程要分有索引和无索引</p><ul><li>有索引<ul><li>MySQL 直接就在索引数中找到了这行数据，然后干净利落的加上行锁就可以了。</li></ul></li><li>无索引<ul><li>MySQL 会为这张表中<strong>所有行</strong>加行锁，在加上行锁后，MySQL 会进行一遍过滤，发现不满足的行就释放锁，最终只留下符合条件的行。</li></ul></li></ul><h3 id="解决幻读"><a href="#解决幻读" class="headerlink" title="解决幻读"></a>解决幻读</h3><blockquote><p>MySQL 如果使用 InnoDB 是可以在可重复读隔离级别下解决幻读问题。MyISAM 是不支持行级锁的，所以还会出现幻读的问题。</p></blockquote><p>MySQL 把行锁和间隙锁合并在一起，解决了并发写和幻读的问题，这个锁叫做 Next-Key 锁。</p><p>假设现在表中有两条记录，并且 age 字段已经添加了索引，两条记录 age 的值分别为 10 和 30。</p><img src="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/%E5%B9%BB%E8%AF%BB-1.png" class="" title="幻读-1"><p>此时，在数据库中会为索引维护一套 B+ 树，用来快速定位行记录。</p><img src="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/%E5%B9%BB%E8%AF%BB-2.png" class="" title="幻读-2"><p>如图所示，分成了3 个区间，(负无穷,10]、(10,30]、(30,正无穷]，在这3个区间是可以加间隙锁的。</p><p>之后，我用下面的两个事务演示一下加锁过程。</p><img src="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/%E5%B9%BB%E8%AF%BB-3.png" class="" title="幻读-3"><p>在事务A提交之前，事务B的插入操作只能等待，这就是间隙锁起得作用。当事务A执行<code>update user set name=&#39;风筝2号’ where age = 10;</code> 的时候，由于条件 where age = 10 ，数据库不仅在 age = 10 的行上添加了行锁，而且在这条记录的两边，也就是(负无穷,10]、(10,30]这两个区间加了间隙锁，从而导致事务B插入操作无法完成，只能等待事务A提交。不仅插入 age = 10 的记录需要等待事务A提交，age &lt; 10、10 &lt; age &lt; 30 的记录页无法完成，而大于等于30的记录则不受影响，这足以解决幻读问题了。</p><p>这是有索引的情况，如果 age 不是索引列，那么数据库会为整个表加上间隙锁。所以，如果是没有索引的话，不管 age 是否大于等于30，都要等待事务A提交才可以成功插入。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.cnblogs.com/fengzheng/p/12557762.html">一文讲清楚MySQL事务隔离级别和实现原理</a></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ZooKeeper初探</title>
    <link href="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/"/>
    <url>/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="ZooKeeper-是什么"><a href="#ZooKeeper-是什么" class="headerlink" title="ZooKeeper 是什么"></a>ZooKeeper 是什么</h1><blockquote><p>ZooKeeper 是一个分布式协调服务 (service for coordinating processes of distributed applications)</p></blockquote><ul><li>协调: 在一个并发的环境里，我们为了避免多个运行单元对共享数据同时进行修改，造成数据损坏的情况出现，我们就必须依赖像锁这样的协调机制.</li><li>我们在进程内还有各种各样的协调机制(一般我们称之为同步机制)。现在我们大概了解了什么是协调了，但是上面介绍的协调都是在进程内进行协调。在进程内进行协调我们可以使用语言，平台，操作系统等为我们提供的机制。</li><li>有两台机器A、B，A 对一个数据进行了一个操作，B是如何同步得到这个结果的，在分布式环境中，就需要一个分布式协调服务。</li><li>ZooKeeper = 文件系统 + 通知机制</li></ul><h1 id="ZooKeeper-可以干什么"><a href="#ZooKeeper-可以干什么" class="headerlink" title="ZooKeeper 可以干什么"></a>ZooKeeper 可以干什么</h1><p><code>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.</code></p><p>这句话描述了 ZooKeeper 可以进行: <code>配置管理</code>, <code>命名服务</code>, <code>分布式同步</code>, <code>集群管理</code>.</p><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><p>如果我们的配置很多，分布式系统中的服务器都需要这个配置。这时候，往往需要寻找一种集中管理配置的办法——我们在集群中的地方修改了配置，所有对这个配置感兴趣的都可以获得变更。</p><p>把公用的配置文件提取出来放在一个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会受到 ZooKeeper 的通知，然后从 ZooKeeper 获取新的配置应用信息。由于需要很高的可靠性，一般我们用一个集群来提供配置服务，但是用集群提升可靠性，如何保证及群众的一致性呢？</p><p>需要使用一种已经实现了一致性协议的服务。ZooKeeper 就是这种服务，它使用了 Zab 这种一致性协议来提供一致性。</p><h2 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h2><p>由于 IP 地址对人非常不友好，我们需要使用域名来访问。但是因为计算机不能识别域名，所以每台机器都有一份域名到 IP 地址的映射。如果域名对应的 IP 地址发生了变化怎么处理呢？</p><p>于是我们使用 DNS (Domain Name System) 。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。</p><p>Zookeeper的命名功能就是这么一个服务器。在集群中，相同的一个服务有很多个提供者，这些提供者启动时，提供者的相关信息（服务接口，地址，端口等）注册到 ZooKeeper 中，当消费者要消费某服务的时候，从 ZooKeeper 中获取该服务的所有提供者的信息目录，再根据 Dubbo 的负载均衡机制选择一个提供者。</p><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>可以利用 ZooKeeper 来协调多个分布式进程之间的活动。使用分布式锁，在某个时刻只让一个服务去干活，当这台服务出问题的时候锁释放，立即 fail over 到另外的服务。</p><p>这种机制也被称为 Leader Election</p><h2 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h2><p>集群中的机器要感知到其他节点的变化(有新的节点加入进来，或者有老的节点退出集群)</p><h1 id="ZooKeeper-的数据模型"><a href="#ZooKeeper-的数据模型" class="headerlink" title="ZooKeeper 的数据模型"></a>ZooKeeper 的数据模型</h1><p>很像数据结构当中的树，也很像文件系统的目录</p><img src="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/ZooKeeper%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" class="" title="ZooKeeper数据结构"><p>这种节点叫做<strong>Znode</strong>，<strong>Znode</strong>的引用方式是<strong>路径引用</strong>：</p><ul><li>/动物/仓鼠</li><li>/植物/荷花</li></ul><p>这样的层级结构，让每一个<strong>Znode</strong>节点拥有唯一的路径</p><h2 id="Znode"><a href="#Znode" class="headerlink" title="Znode"></a>Znode</h2><p>Znode 包含了数据、子节点引用、访问权限</p><ul><li>data<ul><li>Znode 存储的数据信息</li></ul></li><li>ACL<ul><li>记录 Znode 的访问权限，即哪些人哪些 IP 可以访问本节点</li></ul></li><li>stat<ul><li>包含 Znode 的各种元数据，比如事务ID，版本号，时间戳，大小等等</li></ul></li><li>child<ul><li>当前节点的子节点引用</li></ul></li></ul><p>一共有三种类型的Znode</p><ul><li>Regular<ul><li>这种 Znode 一旦创建，就永久存在，除非你删除了它</li></ul></li><li>Ephemeral<ul><li>如果 ZooKeeper 认为创建它的客户端挂了，他会删除这种类型的 Znode。</li><li>这种类型的 Znode 与客户端会话绑在一起，所以客户端会定时发送心跳给 ZooKeeper。</li></ul></li><li>Sequential<ul><li>当你想要以特定的名字创建一个文件，ZooKeeper 实际上创建的文件名是你指定的文件名再加上一个数字。</li><li>当有多个客户端同时创建 Sequential 文件时，ZooKeeper 会确保这里的数字是递增的。</li></ul></li></ul><p>ZooKeeper 是为读多写少的场景所设计，用于存储少量的状态和配置信息，每个节点的数据最大不能超过 1 MB</p><h1 id="ZooKeeper-基本操作和事件通知"><a href="#ZooKeeper-基本操作和事件通知" class="headerlink" title="ZooKeeper 基本操作和事件通知"></a>ZooKeeper 基本操作和事件通知</h1><ul><li><code>create(path, data, flag)</code> 创建节点<ul><li>flag 是表明 Znode 的类型的</li><li>如果得到了 yes 的返回，那么说明这个文件之前是不存在的</li><li>如果得到了 no 或者一个错误返回，那么说明这个文件之前就已经存在了</li></ul></li><li><code>delete(path, version)</code> 删除节点<ul><li>当且仅当 Znode 的当前版本号与传入的 version 相同，才执行操作。</li></ul></li><li><code>exist(path, watch)</code> 判断一个节点是否存在<ul><li>watch 可以监听对应文件的变化</li><li>判断文件是否存在和 watch 文件的变化在 ZooKeeper 中属于原子操作。</li></ul></li><li><code>getData(path, watch)</code> 获取一个节点的数据</li><li><code>setData(path, data, watch)</code> 设置一个节点的数据<ul><li>当且仅当文件的版本号与传入的 version 一致时，才会更新文件</li></ul></li><li><code>getChildren(watch)</code> 获取节点下的所有子节点</li></ul><p><strong>watch</strong> 是指注册在特定 Znode 上的触发器。当这个 Znode 发生改变，也就是调用了 <code>getData</code>, <code>setData</code>, <code>getChildren</code> 的时候，将会触发 Znode 上注册的对应事件，请求 <strong>watch</strong> 的客户端会接受到异步通知。</p><ol><li>客户端调用 <code>getData</code> 方法，watch 参数是 true。服务端接到请求，返回节点数据，并且在对应的哈希表里插入被 Watch 的 Znode 路径，以及 Watcher 列表。</li></ol><img src="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/watch%E7%9A%84%E5%85%B7%E4%BD%93%E4%BA%A4%E4%BA%92-1.png" class="" title="watch的具体交互-1"><ol start="2"><li>当被 Watch 的 Znode 已删除，服务端会查找哈希表，找到该 Znode 对应的所有 Watcher，异步通知客户端，并且删除哈希表中对应的 Key-Value。</li></ol><img src="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/watch%E7%9A%84%E5%85%B7%E4%BD%93%E4%BA%A4%E4%BA%92-2.png" class="" title="watch的具体交互-2"><h1 id="ZooKeeper-的一致性"><a href="#ZooKeeper-的一致性" class="headerlink" title="ZooKeeper 的一致性"></a>ZooKeeper 的一致性</h1><p>ZooKeeper 为了防止单机挂掉的情况，维护了一个集群。</p><img src="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/ZooKeeper%E9%9B%86%E7%BE%A4.png" class="" title="ZooKeeper集群"><ul><li>ZooKeeper Service 集群是一主多从结构</li><li>在更新数据时，首先更新到主节点(服务器, 不是 Znode)，再同步到从节点。</li><li>在读取数据时，直接读取任意从节点。</li></ul><h2 id="ZAB-协议"><a href="#ZAB-协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h2><p>ZAB (ZooKeeper Atomic Broadcast) 可以解决 ZooKeeper 集群崩溃恢复以及主从同步数据的问题。</p><ul><li>Looking: 选举状态</li><li>Following: 从节点所处的状态</li><li>Leading: 主节点所处的状态</li></ul><h2 id="最大ZXID"><a href="#最大ZXID" class="headerlink" title="最大ZXID"></a>最大ZXID</h2><p>最大 ZXID 也就是节点本地的最新事务编号，包含 epoch 和计数两部分。</p><ul><li>epoch 相当于 Raft 算法中的 term</li></ul><h3 id="恢复模式"><a href="#恢复模式" class="headerlink" title="恢复模式"></a>恢复模式</h3><p>加入 ZooKeeper 当前的主节点挂掉了，集群会进行崩溃恢复</p><ol><li>Leader Election</li></ol><ul><li>选举阶段，此时集群中的节点处于Looking状态。它们会各自向其他节点发起投票，投票当中包含自己的服务器ID和最新事务ID（ZXID）。</li><li>接下来，节点会用自身的ZXID和从其他节点接收到的ZXID做比较，如果发现别人家的ZXID比自己大，也就是数据比自己新，那么就重新发起投票，投票给目前已知最大的ZXID所属节点。</li><li>每次投票后，服务器都会统计投票数量，判断是否有某个节点得到半数以上的投票。如果存在这样的节点，该节点将会成为准Leader，状态变为Leading。其他节点的状态变为Following。</li></ul><ol start="2"><li>Discovery</li></ol><ul><li>发现阶段，用于在从节点中发现最新的ZXID和事务日志。(为什么还要寻找ZXID最大的呢)</li><li>这是为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。</li><li>所以这一阶段，Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。</li><li>各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。</li></ul><ol start="3"><li>Synchronization</li></ol><ul><li>同步阶段，把Leader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。</li></ul><p>自此，故障恢复正式完成。</p><h2 id="广播模式"><a href="#广播模式" class="headerlink" title="广播模式"></a>广播模式</h2><p>写入数据，涉及到 ZAB 协议的 Broadcast 阶段</p><ol><li>客户端发出写入数据请求给任意Follower。</li><li>Follower把写入数据请求转发给Leader。</li><li>Leader采用二阶段提交方式，先发送Propose广播给Follower。</li><li>Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader。</li><li>Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower。</li></ol><blockquote><p>Zab协议既不是强一致性，也不是弱一致性，而是处于两者之间的单调一致性。它依靠事务ID和版本号，保证了数据的更新和读取是有序的。</p></blockquote><h1 id="ZooKeeper-的应用"><a href="#ZooKeeper-的应用" class="headerlink" title="ZooKeeper 的应用"></a>ZooKeeper 的应用</h1><h2 id="分布式锁-1"><a href="#分布式锁-1" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>这是雅虎研究员设计Zookeeper的初衷。利用Zookeeper的临时顺序节点，可以轻松实现分布式锁。</p><h2 id="服务注册和发现"><a href="#服务注册和发现" class="headerlink" title="服务注册和发现"></a>服务注册和发现</h2><p>利用Znode和Watcher，可以实现分布式服务的注册和发现。最著名的应用就是阿里的分布式RPC框架Dubbo。</p><h2 id="共享配置和状态信息"><a href="#共享配置和状态信息" class="headerlink" title="共享配置和状态信息"></a>共享配置和状态信息</h2><p>Redis的分布式解决方案Codis，就利用了Zookeeper来存放数据路由表和 codis-proxy 节点的元信息。同时 codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://juejin.cn/post/6844903684610981895">ZooKeeper简介（浅入）</a></li><li><a href="http://www.360doc.com/content/18/0521/09/36490684_755631753.shtml">漫画：什么是ZooKeeper</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ray 新手常见错误</title>
    <link href="/2020/12/08/Ray-%E6%96%B0%E6%89%8B%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    <url>/2020/12/08/Ray-%E6%96%B0%E6%89%8B%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="Delay-ray-get"><a href="#Delay-ray-get" class="headerlink" title="Delay ray.get()"></a>Delay ray.get()</h1><p>调用 <code>get</code> 会产生一个副作用, 会阻塞 <code>driver</code> 程序去做别的操作，这样就会影响并行性.</p><p>首先看一个普通的例子:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">1</span>) <span class="hljs-comment"># Replace this with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br>start = time.time()<br>results = [do_some_work(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br>print(<span class="hljs-string">&quot;results = &quot;</span>, results)<br><br><br><span class="hljs-comment"># Output</span><br><span class="hljs-comment"># duration = 4.0149290561676025</span><br><span class="hljs-comment"># results =  [0, 1, 2, 3]</span><br></code></pre></td></tr></table></figure><p>现在当我们给这个函数加上 <code>remote</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>) <span class="hljs-comment"># Specify this system has 4 CPUs.</span><br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">1</span>) <span class="hljs-comment"># Replace this is with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br>start = time.time()<br>results = [do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br>print(<span class="hljs-string">&quot;results = &quot;</span>, results)<br><br><br><span class="hljs-comment"># Output</span><br><span class="hljs-comment"># duration = 0.0003619194030761719</span><br><span class="hljs-comment"># results =  [ObjectRef(df5a1a828c9685d3ffffffff0100000001000000), ObjectRef(cb230a572350ff44ffffffff0100000001000000), ObjectRef(7bbd90284b71e599ffffffff0100000001000000), ObjectRef(bd37d2621480fc7dffffffff0100000001000000)]</span><br></code></pre></td></tr></table></figure><p>但是这个 result 不是我们想要的, 我们调用 <code>ray.get()</code> 来获取结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Python">results = [ray.get(do_some_work.remote(x)) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br></code></pre></td></tr></table></figure><p>但是改成这样之后呢，输出就变成:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Python">duration = <span class="hljs-number">4.018050909042358</span><br>results =  [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br></code></pre></td></tr></table></figure><p>现在结果是对的, 但程序因此也退化成了串行. 原因也是显而易见的, 每次调用 <code>ray.get</code> 都会阻塞住程序.</p><p>修改的办法就是在调用完所有的 <code>task</code> 后再调用 <code>ray.get</code> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Python">results = ray.get([do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)])<br><br><span class="hljs-comment"># Output: </span><br><span class="hljs-comment"># duration = 1.0064549446105957</span><br><span class="hljs-comment"># results =  [0, 1, 2, 3]</span><br></code></pre></td></tr></table></figure><p>时刻保持警惕 <code>ray.get()</code> 是一个会阻塞的操作, 尽可能晚的去调用这个方法 <code>ray.get()</code></p><h1 id="Avoid-tiny-tasks"><a href="#Avoid-tiny-tasks" class="headerlink" title="Avoid tiny tasks"></a>Avoid tiny tasks</h1><p>避免出现执行时间过短的 <code>task</code>, 因为并行的结果可能适得其反.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tiny_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">0.0001</span>) <span class="hljs-comment"># Replace this with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br>start = time.time()<br>results = [tiny_work(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>)]<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 13.36544418334961</span><br></code></pre></td></tr></table></figure><p>这是一个符合逻辑的结果，当我们换成 <code>remote</code> 时</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tiny_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">0.0001</span>) <span class="hljs-comment"># Replace this is with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br>start = time.time()<br>result_ids = [tiny_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>)]<br>results = ray.get(result_ids)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 27.46447515487671</span><br></code></pre></td></tr></table></figure><p>结果非常的出乎意料, 因为我们并行的运行总时间反而增加了. 这是因为调用每一个 <code>task</code> 都会有一个小的开销(调度, 进程间通讯, 更新系统的状态), 由于 <code>task</code> 本身所需的时间太小, 那么这些额外的开销反而占据了大头.</p><p>修改的办法就是平摊这些开销</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tiny_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">0.0001</span>) <span class="hljs-comment"># replace this is with work you need to do</span><br>    <span class="hljs-keyword">return</span> x<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mega_work</span>(<span class="hljs-params">start, end</span>):</span><br>    <span class="hljs-keyword">return</span> [tiny_work(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start, end)]<br><br>start = time.time()<br>result_ids = []<br>[result_ids.append(mega_work.remote(x*<span class="hljs-number">1000</span>, (x+<span class="hljs-number">1</span>)*<span class="hljs-number">1000</span>)) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)]<br>results = ray.get(result_ids)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 3.2539820671081543</span><br></code></pre></td></tr></table></figure><p>经过测试, 运行一个空的 <code>task</code> 大概需要 0.5s, 这就说明我们的 <code>task</code> 需要一定的运行时间来摊平这个额外的开销.</p><h1 id="Avoid-passing-same-object-repeatedly-to-remote-tasks"><a href="#Avoid-passing-same-object-repeatedly-to-remote-tasks" class="headerlink" title="Avoid passing same object repeatedly to remote tasks"></a>Avoid passing same object repeatedly to remote tasks</h1><p>当我们给一个 remote function 传递一个大的对象时, Ray 调用 <code>ray.put()</code> 来把对象存在本地 object store 中. 这种操作可以显著的提升性能, 但是也会导致一些问题. 比如: 重复地传递相同的对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">no_work</span>(<span class="hljs-params">a</span>):</span><br>    <span class="hljs-keyword">return</span><br><br>start = time.time()<br>a = np.zeros((<span class="hljs-number">5000</span>, <span class="hljs-number">5000</span>))<br>result_ids = [no_work.remote(a) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br>results = ray.get(result_ids)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><span class="hljs-comment"># Output: </span><br><span class="hljs-comment"># duration = 1.0837509632110596</span><br></code></pre></td></tr></table></figure><p>这个时间对于一个仅仅进行了10个 <code>tasks</code> 显然偏大了. 造成这个情况的原因是每次我们调用 <code>no_work(a)</code>, Ray 就会会调用 <code>ray.put(a)</code> 就会导致复制一个非常大的数组导致时间的开销. </p><p>解决这个问题我们可以 显式地调用 <code>ray.put(a)</code> 然后把 obejct 的 ID 传递过去就可以避免复制</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">no_work</span>(<span class="hljs-params">a</span>):</span><br>    <span class="hljs-keyword">return</span><br><br>start = time.time()<br>a_id = ray.put(np.zeros((<span class="hljs-number">5000</span>, <span class="hljs-number">5000</span>)))<br>result_ids = [no_work.remote(a_id) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br>results = ray.get(result_ids)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><span class="hljs-comment"># Output: </span><br><span class="hljs-comment"># duration = 0.132796049118042</span><br></code></pre></td></tr></table></figure><h1 id="Pipeline-data-processing"><a href="#Pipeline-data-processing" class="headerlink" title="Pipeline data processing"></a>Pipeline data processing</h1><p>如果我们对一系列 <code>tasks</code> 使用 <code>ray.get()</code>. 我们就需要等到最后一个 <code>task</code> 完成, 当每一个 <code>task</code> 完成的时间相差很大的时候, 就会导致一些问题.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)) <span class="hljs-comment"># Replace this with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_results</span>(<span class="hljs-params">results</span>):</span><br>    <span class="hljs-built_in">sum</span> = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results:<br>        time.sleep(<span class="hljs-number">1</span>) <span class="hljs-comment"># Replace this with some processing code.</span><br>        <span class="hljs-built_in">sum</span> += x<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span><br><br>start = time.time()<br>data_list = ray.get([do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)])<br><span class="hljs-built_in">sum</span> = process_results(data_list)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start, <span class="hljs-string">&quot;\nresult = &quot;</span>, <span class="hljs-built_in">sum</span>)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 7.82636022567749</span><br><span class="hljs-comment"># result =  6</span><br><br></code></pre></td></tr></table></figure><p>总的时间由两部分组成(do_some_work + process_results), 由于需要等所有的 <code>task</code> 都完成(花费了将近4s)</p><p>解决这个问题我们可以对一系列 object ID调用 <code>ray.wait()</code>. 返回的参数(1) 就绪的 object ID. (2) 还未就绪的 object ID.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)) <span class="hljs-comment"># Replace this is with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_incremental</span>(<span class="hljs-params"><span class="hljs-built_in">sum</span>, result</span>):</span><br>    time.sleep(<span class="hljs-number">1</span>) <span class="hljs-comment"># Replace this with some processing code.</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span> + result<br><br>start = time.time()<br>result_ids = [do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br><span class="hljs-built_in">sum</span> = <span class="hljs-number">0</span><br><span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(result_ids):<br>    done_id, result_ids = ray.wait(result_ids)<br>    <span class="hljs-built_in">sum</span> = process_incremental(<span class="hljs-built_in">sum</span>, ray.get(done_id[<span class="hljs-number">0</span>]))<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start, <span class="hljs-string">&quot;\nresult = &quot;</span>, <span class="hljs-built_in">sum</span>)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 4.852453231811523</span><br><span class="hljs-comment"># result =  6</span><br></code></pre></td></tr></table></figure><img src="/2020/12/08/Ray-%E6%96%B0%E6%89%8B%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/PipelineDataProcessing.png" class="" title="PipelineDataProcessing">]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes介绍</title>
    <link href="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/"/>
    <url>/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="深入浅出地了解-Kubernetes"><a href="#深入浅出地了解-Kubernetes" class="headerlink" title="深入浅出地了解 Kubernetes"></a>深入浅出地了解 Kubernetes</h1><p>Kubernetes 是一个<strong>软件系统</strong>, 它允许你在其上很容易地部署和管理容器化的应用.</p><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/Kubernetes%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD.png" class="" title="Kubernetes的核心功能"><p>组件被部署在哪一个结点对于开发者和系统管理员来说都不用关心</p><h2 id="Kubernetes-集群架构"><a href="#Kubernetes-集群架构" class="headerlink" title="Kubernetes 集群架构"></a>Kubernetes 集群架构</h2><p>在硬件级别, 一个 Kubernetes 集群由很多节点组成, 这些节点被分成以下两种类型:</p><ul><li>主节点: 承载着 Kubernetes 控制和管理整个集群系统的控制面板<ul><li>控制面板<ul><li><em>Kubernetes</em> API 服务器, 你和其他控制面板组件都要和它通信</li><li><em>Scheculer</em> 它调度你的应用 (为应用的每个可部署组件分配一个工作节点)</li><li><em>Controller Manager</em> 它执行集群级别的功能, 如复制组件、持续跟踪工作节点、处理节点失败</li><li><em>etcd</em> 一个可靠的分布式数据存储, 它能持久化存储集群配置</li></ul></li><li>控制面板的组件持有并控制集群状态, 但是它们不运行你的应用程序, 是由工作节点完成的.</li></ul></li><li>工作结点: 它们运行用户实际部署的应用<ul><li>Docker, rtk 或其他的容器类型</li><li><em>Kubelet</em> 它与 API 服务器通信, 并管理它所在节点的容器</li><li><em>Kubernetes Service Proxy (kube-proxy)</em> 它负责组件之间的负载均衡网络流量</li></ul></li></ul><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/Kubernetes%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6.png" class="" title="Kubernetes集群组件"><h2 id="在-Kubernetes-中运行应用"><a href="#在-Kubernetes-中运行应用" class="headerlink" title="在 Kubernetes 中运行应用"></a>在 Kubernetes 中运行应用</h2><ol><li>首先需要将应用打包进一个或多个容器镜像</li><li>再将镜像推送到镜像仓库</li><li>然后将应用的描述发布到 Kubernetes API 服务器</li></ol><h3 id="描述信息怎样成为一个运行的容器"><a href="#描述信息怎样成为一个运行的容器" class="headerlink" title="描述信息怎样成为一个运行的容器"></a>描述信息怎样成为一个运行的容器</h3><ol><li>当 API 服务器处理应用的描述时, 调度器调度指定组的容器到可用的工作节点 (基于每组所需的计算资源以及调度时每个节点未分配的资源)</li><li>那些节点上的 Kubelet 指示容器运行时拉取所需的镜像并运行容器.</li></ol><h3 id="保持容器运行"><a href="#保持容器运行" class="headerlink" title="保持容器运行"></a>保持容器运行</h3><p>一旦应用程序运行起来, Kubernetes 就会不断地确认应用程序的部署状态始终与你提供的描述相匹配.</p><p>如果整个工作节点死亡或无法访问, Kubernetes 将为在故障节点上运行的所有容器选择新节点, 并在新选择的节点上运行它们.</p><h3 id="扩展副本数量"><a href="#扩展副本数量" class="headerlink" title="扩展副本数量"></a>扩展副本数量</h3><p>当应用程序运行的时候, 可以决定要增加或减少副本量, 而 Kubernetes 将分别增加附加的或停止多余的副本</p><h3 id="命中移动目标"><a href="#命中移动目标" class="headerlink" title="命中移动目标"></a>命中移动目标</h3><p>为了让客户能够轻松地找到提供特定服务的容器, 可以告诉 Kubernetes 哪些容器提供相同的服务. Kubernetes 将通过一个静态IP 地址暴露所有容器, 并将该地址暴露给集群中运行的所有应用程序. <em>kube-proxy</em> 将确保到服务的连接可跨提供服务的容器实现负载均衡.</p><h1 id="开始使用-Kubernetes-和-Docker"><a href="#开始使用-Kubernetes-和-Docker" class="headerlink" title="开始使用 Kubernetes 和 Docker"></a>开始使用 Kubernetes 和 Docker</h1><h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run busybox <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Hello World&quot;</span><br></code></pre></td></tr></table></figure><ol><li>Docker 首先会检查 busybox:latest 镜像是否已经存在于本机</li><li>如果没有, Docker 会从镜像中心拉取 busybox 镜像</li><li>Docker 在被隔离的容器里运行 <code>echo &quot;Hello World&quot;</code></li></ol><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/%E5%9F%BA%E4%BA%8EDockerfile%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F.png" class="" title="基于Dockerfile构建一个新的容器镜"><blockquote><p>镜像不是一个大的二进制块, 而是由多层组成的, 不同镜像可能会共享分层.</p></blockquote><h2 id="运行容器镜像"><a href="#运行容器镜像" class="headerlink" title="运行容器镜像"></a>运行容器镜像</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --name kubia-container -p 8080:8080 -d kubia<br><span class="hljs-comment"># 基于 kubia 镜像创建一个叫 kubia-container 的新容器. 这个容器与命令行分离 (-d), 意味着后台运行. 本机上的 8080 端口会被映射到容器内的 8080 端口 (-p 8080:8080), 所以可以通过 http://localhost:8080 来访问应用.</span><br></code></pre></td></tr></table></figure><ul><li>容器使用独立的 PID Linux 命名空间并且有着独立的系列号, 完全独立于进程树.</li><li>容器的文件系统也是独立的.</li></ul><h2 id="介绍-pod"><a href="#介绍-pod" class="headerlink" title="介绍 pod"></a>介绍 pod</h2><p>Kubernetes 不直接处理单个容器, 它使用多个共存容器的理念. 这组容器就叫做 <strong>pod</strong>.</p><blockquote><p>一个 pod 是一组紧密相关的容器, 他们总是运行在同一工作节点上, 以及同一个 Linux 命名空间中.</p></blockquote><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/%E5%AE%B9%E5%99%A8%E3%80%81pod%E5%8F%8A%E7%89%A9%E7%90%86%E5%B7%A5%E4%BD%9C%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.png" class="" title="容器、pod及物理工作节点之间的关系"><ul><li>每个 pod 就像一个独立的逻辑机器, 拥有自己的 IP, 主机名, 进程等, 运行一个独立的应用程序.</li><li>应用程序可以是单个进程, 运行在单个容器中, 也可以是一个主应用进程或者其他支持进程, 每个进程都在自己的容器中运行.</li><li>一个 pod 所有的容器都运行在同一逻辑机器上, 而其他 pod 中的容器, 即使运行在同一工作节点上, 也会出现在不同的节点上.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl run kubia --image=luksa/kubia --port=8080 --generator=run/v1<br><br><span class="hljs-comment"># 现在还处于创建容器的阶段</span><br>kubectl get pods<br><span class="hljs-comment"># NAME    READY   STATUS              RESTARTS   AGE</span><br><span class="hljs-comment"># kubia   0/1     ContainerCreating   0          14s</span><br><br><span class="hljs-comment"># 现在 pod 已变成运行状态</span><br>kubectl get pods<br><span class="hljs-comment"># NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="hljs-comment"># kubia   1/1     Running   0          90s</span><br></code></pre></td></tr></table></figure><p>上述幕后发生的事情</p><ol><li>构建镜像并将其推送到 Docker Hub (在本机上构建的镜像只能在本地机器上可用, 但是需要使它可以访问运行在工作节点上的 Docker 守护进程)</li><li>运行 <code>kubectl</code> 命令时, 它通过向 Kubernetes API 服务器发送一个 REST HTTP 请求, 在集群中创建一个新的 ReplicationController 对象.</li><li>ReplicationController 创建了一个新的 pod, 调度器将其调度到一个工作节点上.</li><li>Kubelet 看到 pod 被调度到节点上, 就告知 Docker 从镜像中心中拉取指定的镜像, 因为本地没有该镜像.</li><li>下载镜像后, Docker 创建并运行容器.</li></ol><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/%E5%9C%A8Kubernetes%E4%B8%AD%E8%BF%90%E8%A1%8C%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F.png" class="" title="在Kubernetes中运行容器镜像"><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li>《 Kubernetes in Action 中文版 》</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ray初步探索</title>
    <link href="/2020/12/02/Ray%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/"/>
    <url>/2020/12/02/Ray%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="Overview-of-Ray"><a href="#Overview-of-Ray" class="headerlink" title="Overview of Ray"></a>Overview of Ray</h1><h2 id="Why-Ray"><a href="#Why-Ray" class="headerlink" title="Why Ray ?"></a>Why Ray ?</h2><p>有很多教程解释了怎么去使用 Python 的 <code>multiprocessing module</code>. 但不幸的是, <code>multiprocessing module</code> 在解决现代应用的需求时有很大的局限性. 我们现在应用的需求有:</p><ul><li>在多台计算机上运行相同的代码</li><li>在不同服务器之间可以进程通信</li><li>可以轻松解决debug</li><li>有效地处理大型对象和数值数据</li></ul><blockquote><p>Ray是一个分布式执行引擎。同样的代码可以在一台机器上实现高效的多处理，也可以在集群是用于大型的计算。</p></blockquote><h2 id="Necessary-Concept"><a href="#Necessary-Concept" class="headerlink" title="Necessary Concept"></a>Necessary Concept</h2><p>传统的编程依赖两个核心的概念: <strong>function</strong> 和 <strong>classes</strong>. 但是当我们把我们的应用迁移到分布式系统的时候，这时候概念就变了. </p><blockquote><p>Ray takes the existing concepts of <strong>functions</strong> and <strong>classes</strong> and translates them to the distributed setting as <strong>tasks</strong> and <strong>actors</strong>.</p></blockquote><h3 id="From-Classes-to-Actors"><a href="#From-Classes-to-Actors" class="headerlink" title="From Classes to Actors"></a>From Classes to Actors</h3><p>如何理解 class 和 actor 之间的关系呢</p><p>Python 允许你用 <code>@ray.remote</code> 去修饰一个 class. 当这个 class 被实例化的时候, Ray 就会在集群中创建一个 <code>actor</code> 进程, 它拥有这个object 的副本. 在这个 <code>actor</code> 上的方法调用会转变成 <code>task</code> 在 <code>actor</code> 进程上运行并且可以访问和修改 <code>actor</code>的状态.</p><p>单个 <code>actor</code> 线性的执行函数 (每一个单独的函数都是原子的)</p><h2 id="Starting-Ray"><a href="#Starting-Ray" class="headerlink" title="Starting Ray"></a>Starting Ray</h2><p>调用<code>ray.init()</code> 启动所有 Ray 相关的进程.</p><ul><li>一些 <code>worker</code> 进程启动, 用来并行的处理 Python function (基本是一个 CPU 核一个<code>worker</code>)</li><li>一个 <code>scheduler</code> 进程启动, 用来分配 <code>tasks</code> 给 <code>workers</code>. <code>task</code> 是 Ray 用来分配任务的单位, 对应一个 function invocation 或者 method invocation.</li><li>创建一个 <code>shared-memory object store</code>, 用来在 <code>workers</code> 之间高效的共享对象 (而不是通过创造副本)</li><li>一个在内存中的数据库用来对元数据排序，元数据可以作为 machine failures 事件的返回</li></ul><h3 id="进程介绍"><a href="#进程介绍" class="headerlink" title="进程介绍"></a>进程介绍</h3><p>当我们使用Ray时，涉及到多个进程。</p><ul><li>多 <code>worker</code> 进程执行多个任务并将结果存储在对象存储中，每个 <code>worker</code> 都是一个独立的进程。<ul><li>为什么不是对应的 thread 是因为多线程在 Python 中由于 global interpreter lock 的影响有很大的限制. (即某一时刻, 只能有一个 thread 在运行)</li></ul></li><li>每个 <code>node</code> 上的对象存储都将<strong>不可变</strong>的对象存储存在共享内存 (shared memory) 中, 允许 <code>worker</code> 以少量的复制和并行化有效的共享同一 <code>node</code> 上的存储对象。</li><li>每个 <code>node</code> 上的本地调度将任务分配给同一 <code>node</code> 上的 <code>worker</code>. (一个<code>node</code> 上的本地调度把任务分配给本 <code>node</code> 上的 <code>worker</code>)</li><li>一个 <code>driver</code> 是用户控制 python 进程. 例如，如果用户正在运行脚本或者使用 python shell, 那么 <code>driver</code> 就是运行脚本或者 shell 的 python 进程。<code>driver</code> 和 <code>worker</code> 很相似，他们都可以提交任务给本地调度并从对象存储中获取对象，但是不同之处是本地调度不会将任务分配给 <code>driver</code> 执行。</li><li>Redis 服务器维护系统的大部分状态。</li></ul><p>Q: Ray 执行异步任务时，是怎样实现平行的</p><blockquote><p>A: Ray 集群中每个 <code>node</code> 共享本 <code>node</code> 本地存储, <code>node</code> 中 <code>worker</code> 并行运行, 集群间 <code>worker</code> 的并行</p></blockquote><p>Q: Ray 是怎么使用对象 ID 来表示不可变对象的远程对象的</p><blockquote><p>A: 任务执行前, 对象值已经存入存储对象中, 任务执行是通过对象 ID 调用存储对象的</p></blockquote><h2 id="不可变的远程-remote-对象"><a href="#不可变的远程-remote-对象" class="headerlink" title="不可变的远程 (remote) 对象"></a>不可变的远程 (remote) 对象</h2><ul><li>在 Ray 中, 我们可以在对象上创建和计算. 我们将这些对象称为远程对象, 并使用<strong>对象 ID</strong> 来引用它们.</li><li>远程对象是被存储在对象存储中的, 在集群中每个节点都有一个存储对象.</li><li>在集群设置中, 我们可能实际上不知道每个存储对象的位置.</li><li>由于远程对象是不可变的，那么他们的值在创建之后不能更改。这允许在多个对象存储中复制远程对象，而不需要同步副本</li></ul><h2 id="Put-Get"><a href="#Put-Get" class="headerlink" title="Put, Get"></a>Put, Get</h2><p>Ray 中的 <code>ray.get</code> 和 <code>ray.put</code> 是用作 Python 对象和对象 ID 之间的转换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Python">x = <span class="hljs-string">&quot;example&quot;</span><br><span class="hljs-comment"># 把一个 Python 对象复制到本地对象存储中(本地意味着同一节点). 一旦对象被存入存储对象后, 他的值就不能被改变了.</span><br>ray.put(x)  <span class="hljs-comment"># ObjectID(b49a32d72057bdcfc4dda35584b3d838aad89f5d)</span><br></code></pre></td></tr></table></figure><p>Ray的 <code>ray.put()</code> 返回的是一个对象 ID (其实就是一个引用), 可以被用来创建新的远程对象.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Python">x_id = ray.put(<span class="hljs-string">&quot;example&quot;</span>)<br><span class="hljs-comment"># 接受一个对象 ID, 并从相应的远程对象创建一个 Python 对象.</span><br>ray.get(x_id) <span class="hljs-comment"># &quot;example&quot;</span><br></code></pre></td></tr></table></figure><p>对于数组这样的对象, 我们可以使用内存的共享从而避免复制对象. 对于其他对象, 它将对象从对象存储中复制到 worker 进程的堆. 如果与对象 ID <code>x_id</code> 对应的远程(remote)对象与调用 <code>ray.get(x_id)</code> 的 <code>worker</code> 不在同一 <code>node</code> 上, 那么远程对象将首先从拥有它的对象存储区转移到需要他的对象存储区</p><blockquote><p>tips: function先后顺序，影响ray，例如b函数调用a函数，那么a不加修饰器，就必须放置b前面</p></blockquote><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://blog.csdn.net/weixin_43255962/article/details/88689665">Ray 入门指南(1) — Ray 分布式框架的介绍</a></li><li><a href="https://towardsdatascience.com/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8">Modern Parallel and Distributed Python: A Quick Tutorial on Ray</a></li></ul><h1 id="Using-Ray"><a href="#Using-Ray" class="headerlink" title="Using Ray"></a>Using Ray</h1><h2 id="Starting-Ray-1"><a href="#Starting-Ray-1" class="headerlink" title="Starting Ray"></a>Starting Ray</h2><ul><li>什么是 Ray runtime (内存管理)<ul><li>Ray programs are able to parallelize and distribute by leveraging an underlying Ray runtime.</li><li>The Ray runtime consists of multiple services/processes started in the background for communication, data transfer, scheduling, and more.</li><li>The Ray runtime can be started on a laptop, a single server, or multiple servers.</li></ul></li></ul><h2 id="Using-Actors"><a href="#Using-Actors" class="headerlink" title="Using Actors"></a>Using Actors</h2><p>一个 <code>actor</code> 实际上就是一个有状态的 <code>worker</code>. 当一个新的 actor 被实例化，那么一个新的 worker 就诞生了，同时这个 actor 的 method 就被安排在那个特定的 worker 上。 actor 可以访问并修改那个 worker 的状态. </p><ul><li>Worker 和 Actor 的区别<ul><li>“Ray worker” 就是一个 Python <code>进程</code></li><li>“Ray worker” 要么被用来运行多个 Ray task 或者开始时对应一个专门的 actor</li></ul></li></ul><blockquote><p>Task: 当 Ray 在一台机器上运行的时候，会自动开始几个 <code>Ray workers</code>. 他们被用来执行 <code>task</code> (类似一个进程池)</p></blockquote><blockquote><p>Actor: 一个 Ray Actor 也是一个 “Ray worker” 只不过是在 runtime 实例化的. 所有的 methods 都运行在同一个进程里，使用相同的资源. 与 <code>Task</code> 不同的是，运行 Ray Actor 的进程不会重复使用并且会在 Actor 被删除后终止.</p></blockquote><h2 id="AsyncIO-Concurrency-for-Actors"><a href="#AsyncIO-Concurrency-for-Actors" class="headerlink" title="AsyncIO / Concurrency for Actors"></a>AsyncIO / Concurrency for Actors</h2><p>Ray 提供了两种 concurrency 的办法 <code>async execution</code> 和 <code>threading</code>. Python 的 <code>Global Interpreter Lock (GIL)</code> 只允许在某一时刻运行一个thread, 那么我们就无法实现真正意义上的 parallelism. 一些常见的库，比如 Numpy, Cython, Tensorflow, PyTorch 在调用 C/C++ 函数的时候会释放 GIL. 但是<code>async execution</code> 和 <code>threading</code>无法绕开 GIL.</p><h3 id="AsyncIO-for-Actors"><a href="#AsyncIO-for-Actors" class="headerlink" title="AsyncIO for Actors"></a>AsyncIO for Actors</h3><ul><li><a href="https://juejin.cn/post/6844904088677662728">Python 中 async 与 await 的用法</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">import</span> asyncio<br>ray.init()<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AsyncActor</span>:</span><br>    <span class="hljs-comment"># multiple invocation of this method can be running in</span><br>    <span class="hljs-comment"># the event loop at the same time</span><br>    <span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run_concurrent</span>(<span class="hljs-params">self</span>):</span><br>        print(<span class="hljs-string">&quot;started&quot;</span>)<br>        <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">2</span>) <span class="hljs-comment"># concurrent workload here</span><br>        print(<span class="hljs-string">&quot;finished&quot;</span>)<br><br>actor = AsyncActor.remote()<br><br><span class="hljs-comment"># regular ray.get</span><br>ray.get([actor.run_concurrent.remote() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)])<br><br><span class="hljs-comment"># async ray.get</span><br><span class="hljs-keyword">await</span> actor.run_concurrent.remote()<br></code></pre></td></tr></table></figure><h3 id="Threaded-Actors"><a href="#Threaded-Actors" class="headerlink" title="Threaded Actors"></a>Threaded Actors</h3><p>有时候使用 asyncio 并不是一个理想的解决方案。比如你可能有一个method在进行大量的计算任务并阻塞了event loop, 且不能通过 <code>await</code> 去停止。这就对 Async Actor 的整体性能有影响，因为 Async Actor 在某一时刻只能执行一个任务并且依赖<code>await</code> 去进行上下文切换。</p><p>可以使用 <code>max_concurrency</code> Actor 来代替, 类似线程池。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ThreadedActor</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task_1</span>(<span class="hljs-params">self</span>):</span> print(<span class="hljs-string">&quot;I&#x27;m running in a thread!&quot;</span>)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task_2</span>(<span class="hljs-params">self</span>):</span> print(<span class="hljs-string">&quot;I&#x27;m running in another thread!&quot;</span>)<br><br>a = ThreadedActor.options(max_concurrency=<span class="hljs-number">2</span>).remote()<br>ray.get([a.task_1.remote(), a.task_2.remote()])<br></code></pre></td></tr></table></figure><p>每个 threaded actor 的 <code>Invocation</code> 都会在线程池中运行。线程池的大小是由 <code>max_concurrency</code> 控制的。</p><h2 id="GPU-Support"><a href="#GPU-Support" class="headerlink" title="GPU Support"></a>GPU Support</h2><h2 id="Serialization"><a href="#Serialization" class="headerlink" title="Serialization"></a>Serialization</h2><p>因为 Ray 进程不是内存空间共享的，数据在 <code>workers</code> 和 <code>nodes</code> 之间传输需要序列化和反序列化。Ray 使用 <code>Plasma object store</code> 高效的把对象传输给不同的 <code>nodes</code> 和 <code>processes</code>.</p><h3 id="Plasma-Object-Store"><a href="#Plasma-Object-Store" class="headerlink" title="Plasma Object Store"></a>Plasma Object Store</h3><p><strong>Plasma</strong> 是一个基于 Apache Arrow 开发的内对象存储。所有的对象在 <strong>Plasma object store</strong> 中都是不可变的并且保存在共享内存中。</p><p>每个 node 都有自己的 object store. 当数据存入 object store, 它不会自动的广播通知其他的 node. 数据一直保留在本地直到在别的 node 被别的 task 或者 actor 请求。</p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>Ray 使用 <code>Pickle protocol version 5</code> 作为序列化协议。</p><h2 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h2><p>Ray 当中的内存管理</p><img src="/2020/12/02/Ray%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/Ray%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86.png" class="" title="Ray内存管理"><p>我们把 Ray 的内存分成两个部分: <code>Ray system memory</code> 和 <code>Application memory</code>.</p><ul><li>Ray system memory (这部分的内存是 Ray 内部在使用)<ul><li>Redis<ul><li>存储在集群中的一系列 nodes 和 actors</li><li>存储这部分用到的内存很小</li></ul></li><li>Raylet<ul><li>C++ raylet 进程在每个 node 上运行所需要的空间</li><li>这部分不能够被控制，但是用到的内存空间也很小</li></ul></li></ul></li><li>Application memory (这部分内存是我们的应用在使用)<ul><li>Worker heap<ul><li>应用所使用的的内存 (e.g., in Python code or TensorFlow)</li><li>需要用应用的 <em>resident set size</em> 减去 <em>shared memory usage</em> 来衡量。</li></ul></li><li>Object store memory<ul><li>当应用通过 <code>ray.put</code> 创建对象并且返回的值来自 remote function</li></ul></li><li>Object store shared memory<ul><li>当应用通过 <code>ray.get</code> 读取对象</li><li>如果一个对象已经存在在一个 node 中, 这将不会导致额外的内存分配。这样可以使得一些比较大的对象在各个 actors 和 tasks 中共享的更有效率。</li></ul></li></ul></li></ul><h3 id="Raylet"><a href="#Raylet" class="headerlink" title="Raylet"></a>Raylet</h3><p>我们可以抽象一个相对简单的 Worker 和 GCS 的关系:</p><img src="/2020/12/02/Ray%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/Worker%E5%92%8CGCS%E5%85%B3%E7%B3%BB.png" class="" title="Worker和GCS关系"><p>Raylet 在中间的作用非常关键，包含了以下重要内容</p><ul><li>Node Manager<ul><li>基于 boost::asio 的异步通信模块，主要是通信的连接和消息处理管理</li></ul></li><li>Object Manager<ul><li>Object Store 的管理</li></ul></li><li>gcs_client 或者 gcs server<ul><li>gcs_client 是连接 GCS 客户端。如果设置 RAY_GCS_SERVICE_ENABLED 为 true 的话，这个 Server 就是作为 GCS 启动</li></ul></li></ul><h4 id="Raylet-的启动过程"><a href="#Raylet-的启动过程" class="headerlink" title="Raylet 的启动过程"></a>Raylet 的启动过程</h4><ol><li>Raylet 的初始化，这里包含有很多参数。包括 Node Manager 和 gcs client 的初始化</li><li>注册 GCS 准备接收消息。一旦有消息进来，就进入 Node Manager 的 ProcessClientMessage 过程。(TODO ProcessClientMessage的通信模型)</li></ol><h2 id="Placement-Groups-置放群组"><a href="#Placement-Groups-置放群组" class="headerlink" title="Placement Groups (置放群组)"></a>Placement Groups (置放群组)</h2><p><strong>Placement Groups</strong> 允许用户跨多个<code>nodes</code>原子性的保存一组资源.(i.e., gang scheduling). <strong>Placement Groups</strong> 可以被用不同的策略来调度打包 <code>Ray tasks</code> 和 <code>actors</code>.</p><blockquote><p>这里的原子性意味着如果有一个 bundle 不适合当前所在的 node, 那么整个 Placement Group 都不会被创建.</p></blockquote><p><strong>Placement Groups</strong> 有以下应用</p><ul><li>Gang Scheduling: </li><li>Maximizing data locality</li><li>Load balancing</li></ul><h3 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h3><ul><li><strong>bundle</strong> : 资源的集合<ul><li>一个 bundle 必须适合一个在集群中的 node</li><li>然后 Bundles 会根据 <code>placement group strategy</code> 在集群中跨 nodes 放置</li></ul></li><li><strong>placement group</strong> : bundle 的集合<ul><li>每一个 bundle 都被给予了一个在 placement group 的编号</li><li>然后 Bundles 会根据 <code>placement group strategy</code> 在集群中跨 nodes 放置</li><li>等 placement group 创建了后，<code>tasks</code> 和 <code>actors</code> 可以根据 placement group 或者个人 bundles 来调度。</li></ul></li></ul><h3 id="策略类型"><a href="#策略类型" class="headerlink" title="策略类型"></a>策略类型</h3><ul><li>STRICT_PACK<ul><li>All bundles must be placed into a single node on the cluster.</li></ul></li><li>PACK<ul><li>All provided bundles are packed onto a single node on a best-effort basis. If strict packing is not feasible (i.e., some bundles do not fit on the node), bundles can be placed onto other nodes nodes.</li></ul></li><li>STRICT_SPREAD<ul><li>Each bundle must be scheduled in a separate node.</li></ul></li><li>SPREAD<ul><li>Each bundle will be spread onto separate nodes on a best effort basis. If strict spreading is not feasible, bundles can be placed overlapping nodes.</li></ul></li></ul><h2 id="Advanced-Usage"><a href="#Advanced-Usage" class="headerlink" title="Advanced Usage"></a>Advanced Usage</h2><h3 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h3><ul><li><p>Inter-process synchronization using FileLock</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">from</span> filelock <span class="hljs-keyword">import</span> FileLock<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">write_to_file</span>(<span class="hljs-params">text</span>):</span><br>    <span class="hljs-comment"># Create a filelock object. Consider using an absolute path for the lock.</span><br>    <span class="hljs-keyword">with</span> FileLock(<span class="hljs-string">&quot;my_data.txt.lock&quot;</span>):<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;my_data.txt&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            f.write(text)<br><br>ray.init()<br>ray.get([write_to_file.remote(<span class="hljs-string">&quot;hi there!\n&quot;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)])<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;my_data.txt&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    print(f.read())<br><br><span class="hljs-comment">## Output is:</span><br><br><span class="hljs-comment"># hi there!</span><br><span class="hljs-comment"># hi there!</span><br><span class="hljs-comment"># hi there!</span><br></code></pre></td></tr></table></figure><p><a href="https://zhuanlan.zhihu.com/p/26487659">理解 Python 关键字 “with” 与上下文管理器</a></p></li><li><p>Multi-node synchronization using SignalActor</p></li></ul><blockquote><p>当你有多个 tasks 需要等待同一个条件的时候，你可以使用一个 <code>SingnalActor</code> 来调度。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># Also available via `from ray.test_utils import SignalActor`</span><br><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">import</span> asyncio<br><br><span class="hljs-meta">@ray.remote(<span class="hljs-params">num_cpus=<span class="hljs-number">0</span></span>)</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SignalActor</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        self.ready_event = asyncio.Event()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">send</span>(<span class="hljs-params">self, clear=<span class="hljs-literal">False</span></span>):</span><br>        self.ready_event.<span class="hljs-built_in">set</span>()<br>        <span class="hljs-keyword">if</span> clear:<br>            self.ready_event.clear()<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wait</span>(<span class="hljs-params">self, should_wait=<span class="hljs-literal">True</span></span>):</span><br>        <span class="hljs-keyword">if</span> should_wait:<br>            <span class="hljs-keyword">await</span> self.ready_event.wait()<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wait_and_go</span>(<span class="hljs-params">signal</span>):</span><br>    ray.get(signal.wait.remote())<br><br>    print(<span class="hljs-string">&quot;go!&quot;</span>)<br><br>ray.init()<br>signal = SignalActor.remote()<br>tasks = [wait_and_go.remote(signal) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br>print(<span class="hljs-string">&quot;ready...&quot;</span>)<br><span class="hljs-comment"># Tasks will all be waiting for the singals.</span><br>print(<span class="hljs-string">&quot;set..&quot;</span>)<br>ray.get(signal.send.remote())<br><br><span class="hljs-comment"># Tasks are unblocked.</span><br>ray.get(tasks)<br><br><span class="hljs-comment">##  Output is:</span><br><span class="hljs-comment"># ready...</span><br><span class="hljs-comment"># get set..</span><br><br><span class="hljs-comment"># (pid=77366) go!</span><br><span class="hljs-comment"># (pid=77372) go!</span><br><span class="hljs-comment"># (pid=77367) go!</span><br><span class="hljs-comment"># (pid=77358) go!</span><br></code></pre></td></tr></table></figure><ul><li>Message passing using Ray Queue<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">from</span> ray.util.queue <span class="hljs-keyword">import</span> Queue<br><br>ray.init()<br><span class="hljs-comment"># You can pass this object around to different tasks/actors</span><br>queue = Queue(maxsize=<span class="hljs-number">100</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">consumer</span>(<span class="hljs-params">queue</span>):</span><br>    next_item = queue.get(block=<span class="hljs-literal">True</span>)<br>    print(<span class="hljs-string">f&quot;got work <span class="hljs-subst">&#123;next_item&#125;</span>&quot;</span>)<br><br>consumers = [consumer.remote(queue) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]<br><br>[queue.put(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br></code></pre></td></tr></table></figure></li><li>Dynamic Remote Parameters</li></ul><h3 id="Dynamic-Custom-Resources"><a href="#Dynamic-Custom-Resources" class="headerlink" title="Dynamic Custom Resources"></a>Dynamic Custom Resources</h3><blockquote><p>我们可以动态的去调整资源的需求或者返回在运行时调用<code>.option</code> 返回 <code>ray.remote</code> 的值</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-meta">@ray.remote(<span class="hljs-params">num_cpus=<span class="hljs-number">4</span></span>)</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Counter</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        self.value = <span class="hljs-number">0</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">increment</span>(<span class="hljs-params">self</span>):</span><br>        self.value += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> self.value<br><br>a1 = Counter.options(num_cpus=<span class="hljs-number">1</span>, resources=&#123;<span class="hljs-string">&quot;Custom1&quot;</span>: <span class="hljs-number">1</span>&#125;).remote()<br>a2 = Counter.options(num_cpus=<span class="hljs-number">2</span>, resources=&#123;<span class="hljs-string">&quot;Custom2&quot;</span>: <span class="hljs-number">1</span>&#125;).remote()<br>a3 = Counter.options(num_cpus=<span class="hljs-number">3</span>, resources=&#123;<span class="hljs-string">&quot;Custom3&quot;</span>: <span class="hljs-number">1</span>&#125;).remote()<br></code></pre></td></tr></table></figure><h1 id="Ray-Cluster"><a href="#Ray-Cluster" class="headerlink" title="Ray Cluster"></a>Ray Cluster</h1><p>Ray 可以在单个机器上运行, 但是 Ray 真正的强大之处在于它可以在一个机器集群上运行.</p><h2 id="Distributed-Ray-Overview"><a href="#Distributed-Ray-Overview" class="headerlink" title="Distributed Ray Overview"></a>Distributed Ray Overview</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul><li><strong>Ray Nodes</strong>: 一个 Ray 集群包含一个 <code>head node</code> 和 一些 <code>worker nodes</code>. 首先运行的是 <code>head node</code>, 然后 <code>worker node</code> 会得到 <code>head node</code> 在集群中的地址. Ray 的集群可以自动扩容, 这意味着它可以根据当前的负载创建或者销毁实例.</li><li><strong>Ports</strong>: Ray 的进程通过 TCP 端口进行交流.</li><li><strong>Ray Cluster Launcher</strong>: 这是一个可以自动提供机器并且发布一个多节点的 Ray 集群的工具.</li></ul><h1 id="Ray-Serve"><a href="#Ray-Serve" class="headerlink" title="Ray Serve"></a>Ray Serve</h1><p>Ray Serve 是基于 Ray 构建的可伸缩模型服务库</p><h2 id="Ray-Serve-Scalable-and-Programmable-Serving"><a href="#Ray-Serve-Scalable-and-Programmable-Serving" class="headerlink" title="Ray Serve: Scalable and Programmable Serving"></a>Ray Serve: Scalable and Programmable Serving</h2><ul><li>框架不可知 (Framework Agnostic): 使用相同的工具包即可提供服务, 从使用 PyTorch 或 TensorFlow &amp; Keras 等框架构建的深度学习模型到 Scikit-Learn 模型或任意业务逻辑.</li><li>Python 优先 (Python First): 使用纯 Python 代码配置服务的模型 - 不再需要 YAML 或 JSON 配置.</li><li>面向性能 (Performance Oriented): 启用批处理, 流水线处理和 GPU 加速, 以提高模型的吞吐量.</li><li>本机组合 (Composition Native): 允许你将多个模型组合在一起以创建单个预测, 从而创建”模型管道”.</li><li>水平可扩展 (Horizontally Scalable): 服务可以随着你添加更多计算机而线性扩展.</li></ul><h2 id="Key-Concepts"><a href="#Key-Concepts" class="headerlink" title="Key Concepts"></a>Key Concepts</h2><h3 id="Backends"><a href="#Backends" class="headerlink" title="Backends"></a>Backends</h3><h3 id="Endpoints"><a href="#Endpoints" class="headerlink" title="Endpoints"></a>Endpoints</h3><h1 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://docs.ray.io/en/latest/index.html">官方文档</a></li><li><a href="https://zhuanlan.zhihu.com/p/111340572">Ray 分布式计算框架介绍</a></li><li><a href="https://www.jiqizhixin.com/articles/2020-09-11-11">取代Python多进程！高性能分布式执行框架 - Berkeley Ray</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Ray</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数仓：缓慢渐变维度</title>
    <link href="/2020/10/28/%E6%95%B0%E4%BB%93%EF%BC%9A%E7%BC%93%E6%85%A2%E6%B8%90%E5%8F%98%E7%BB%B4%E5%BA%A6/"/>
    <url>/2020/10/28/%E6%95%B0%E4%BB%93%EF%BC%9A%E7%BC%93%E6%85%A2%E6%B8%90%E5%8F%98%E7%BB%B4%E5%BA%A6/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>当业务数据库中的一些数据发生了更改，到底要不要将这些变化也反映到数据仓库中？在数据仓库中，那些数据应该随之变化，哪些可以不用变化？考虑到这些变化，在数据仓库中的维度表又应该如何设计以满足这些需要。</p><h1 id="Type-1-SCD"><a href="#Type-1-SCD" class="headerlink" title="Type 1 SCD"></a>Type 1 SCD</h1><blockquote><p>替换原始记录</p></blockquote><p>我们可以保持业务数据和数据仓库中的数据始终处于一致。</p><ul><li>优点：简单方便</li><li>缺点：无法追溯历史数据</li></ul><h1 id="Type-2-SCD"><a href="#Type-2-SCD" class="headerlink" title="Type 2 SCD"></a>Type 2 SCD</h1><blockquote><p>插入一条新的记录</p></blockquote><ul><li>优点：保留全部历史记录</li><li>缺点：使数据表记录飞涨，可能导致影响查询效率</li></ul><p>尽可能维护来自业务系统中的历史数据，能够真正捕获</p><h1 id="Type-3-SCD"><a href="#Type-3-SCD" class="headerlink" title="Type 3 SCD"></a>Type 3 SCD</h1><blockquote><p>更新原始表结构</p></blockquote><ul><li>优点：既可以反映历史记录，也可以避免成倍的数据增长</li><li>缺点：适用场景非常少，仅能反映部分历史记录。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>MapReduce: 在大型集群上简化数据处理</title>
    <link href="/2020/10/26/MapReduce-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E9%9B%86%E7%BE%A4%E4%B8%8A%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    <url>/2020/10/26/MapReduce-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E9%9B%86%E7%BE%A4%E4%B8%8A%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><blockquote><p>MapReduce 是一种编程模型，用于处理和生成大型数据集的实现。</p></blockquote><p>用户通过指定一个用来处理键值对 (key/value) 的 map 函数来生成一个中间键值对集合。然后，再指定一个 reduce 函数，它用来合并所有的具有相同中间 key 的中间 value.</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>虽然数据处理的逻辑简单，但是由于数据量巨大又需要在有限的时间内完成。计算任务也不得不分配给成百上千台机器去执行。如何并行化计算，分配数据以及处理故障的问题，所有的问题都纠缠在一起，这就需要大量的代码来对它们进行处理。</p><p>为了应对这种复杂性，我们设计了一种抽象。大多数计算计算都涉及到对输入中的每个逻辑记录进行 map 的操作，以便于计算出一个中间键值对的集合。然后，为了恰当的整合衍生数据，我们对共用相同键的所有值进行 reduce 操作。通过使用具备用户所指定的 map 和 reduce 操作的函数式模型，这使得我们能够轻松并行化大型计算。</p><h1 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h1><p>该计算任务将<strong>一个键值对集合</strong>作为输入，并生成一个键值对集合作为输出。<strong>MapReduce</strong> 这个库的用户将这种计算任务以两个函数进行表达，即 <strong>Map</strong> 和 <strong>Reduce</strong> 。</p><p>由用户所编写的 <strong>Map</strong> 函数接收输入，并生成一个中间键值对集合。<strong>MapReduce</strong> 这个库会将所有共用一个键的值组合在一起，并将它们传递给 <strong>Reduce</strong> 函数。</p><p><strong>Reduce</strong> 函数也是由用户编写。它接受一个中间键以及该键的值的集合作为输入。它会将这些值合并在一起，以此来生成一组更小的值的集合。</p><blockquote><p>key / value 集合 —<strong>Map</strong>—&gt; 中间 key / value 集合 —<strong>MapReduce</strong>—&gt; key / value1 / value2 /… —<strong>Reduce</strong>—&gt; key / value.zip</p></blockquote><p>通常每次调用 <strong>Reduce</strong> 函数所产生的值的结果只有0个或者1个。中间值通过一个迭代器来传递给用户所编写的 <strong>Reduce</strong> 函数。这使得我们可以处理这些因为数据量太大而无法存放在内存中的存储值的list列表了。</p><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h3 id="例1"><a href="#例1" class="headerlink" title="例1"></a>例1</h3><p>背景：我们要从大量文档中计算出每个单词的出现次数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * key: document name</span><br><span class="hljs-comment"> * value: document contents</span><br><span class="hljs-comment"> * 返回一个单词加上它出现的次数的键值对</span><br><span class="hljs-comment">**/</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">map</span><span class="hljs-params">(string key, string value)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (word w: value) &#123;<br>        EmitIntermediate(w, <span class="hljs-string">&quot;1&quot;</span>);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * key: a word</span><br><span class="hljs-comment"> * values: a list of counts</span><br><span class="hljs-comment"> * 将该单词的出现次数统计出来</span><br><span class="hljs-comment">**/</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(string key, Iterator values)</span> </span>&#123;<br>    <span class="hljs-keyword">int</span> result = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span> (v: values) &#123;<br>        result += ParseInt(v);<br>        Emit(AsString(result));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="分布式过滤器"><a href="#分布式过滤器" class="headerlink" title="分布式过滤器"></a>分布式过滤器</h3><p><strong>Map</strong> 函数会发出（emit）匹配某个规则的一行。<strong>Reduce</strong> 函数是一个恒等函数，即把中间数据复制到输出。</p><h3 id="计算URL的访问频率"><a href="#计算URL的访问频率" class="headerlink" title="计算URL的访问频率"></a>计算URL的访问频率</h3><p><strong>Map</strong> 函数用来处理网页请求的日志，并输出(URL,1)。<strong>Reduce</strong> 函数则用于将相同URL的值全部加起来，并输出(URL, 访问总次数)这样的键值对结果。</p><h3 id="倒转网络链接图"><a href="#倒转网络链接图" class="headerlink" title="倒转网络链接图"></a>倒转网络链接图</h3><p><strong>Map</strong>函数会在源页面中找到所有的目标URL，并输出&lt;target, source&gt;这样的键值对。<strong>Reduce</strong>函数会将给定的目标URL的所有链接组合成一个列表，输出&lt;target, list(source)&gt;这样的键值对。</p><h3 id="每台主机上的检索词频率"><a href="#每台主机上的检索词频率" class="headerlink" title="每台主机上的检索词频率"></a>每台主机上的检索词频率</h3><p>term（这里是指搜索系统里的某一项东西，这里指检索词）vector（这里指数组）将一个文档或者是一组文档中出现的最重要的单词概括为&lt;单词，频率&gt; 这样的键值对列表，对于每个输入文档，<strong>Map</strong> 函数会输出这样一对键值对&lt;hostname, term vector&gt;（其中hostname是从文档中的URL里提取出来的）。<strong>Reduce</strong> 函数接收给定主机的所有每一个文档的term vector。它会将这些term vector加在一起，并去除频率较低的term，然后输出一个最终键值对&lt;hostname, term vector&gt;。</p><h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><p><strong>Map</strong> 函数会对每个文档进行解析，并输出&lt;word, 文档ID&gt;这样的键值对序列。<strong>Reduce</strong> 函数所接受的输入是一个给定词的所有键值对，接着它会对所有文档ID进行排序，然后输出&lt;word, list(文档ID)&gt;。所有输出键值对的集合可以形成一个简单的倒排索引。我们能简单的计算出每个单词在文档中的位置。</p><h3 id="分布式排序"><a href="#分布式排序" class="headerlink" title="分布式排序"></a>分布式排序</h3><p><strong>Map</strong> 函数会从每条记录中提取出一个key，然后输出&lt;key, record&gt;这样的键值对。<strong>Reduce</strong> 函数对这些键值对不做任何修改，直接输出。这种计算任务依赖分区机制以及排序属性。</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="执行概述"><a href="#执行概述" class="headerlink" title="执行概述"></a>执行概述</h2><p>将传入 <strong>Map</strong> 函数的输入数据自动切分为 <strong>M</strong> 个数据片段的集合，这样就能将 <strong>Map</strong> 操作分布到多台机器上运行。使用分区函数将 <strong>Map</strong> 函数所生成的中间 <strong>key</strong> 值分成 <strong>R</strong> 个不同的分区，这样就可以将 <strong>Reduce</strong> 操作也分布到多台机器上并行处理。</p><img src="/2020/10/26/MapReduce-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E9%9B%86%E7%BE%A4%E4%B8%8A%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/MapReduce%E6%A1%86%E6%9E%B6.png" class="" title="MapReduce框架"><ul><li>用户程序中的 <code>MapReduce</code> 库会先将输入文件切分为 <code>M</code> 个片段，通常每个片段的大小在16MB到64MB之间（具体大小可以由用户通过可选参数来进行指定）。接着，它会在集群中启动许多个程序副本。</li><li>有一个程序副本是比较特殊的，那就是 <code>master</code> 。剩下的副本都是 <code>worker</code>，<code>master</code> 会对这些 <code>worker</code> 进行任务分配。这里有 <code>M</code> 个 <strong>Map</strong> 任务以及 <code>R</code> 个 <strong>Reduce</strong> 任务要进行分配。<code>master</code> 会给每个空闲的 <code>worker</code> 分配一个 <strong>map</strong> 任务或者一个 <strong>reduce</strong> 任务。</li><li>被分配了 <strong>map</strong> 任务的 <code>worker</code> 会读取相关的输入数据片段。它会从输入数据中解析出键值对，并将它们传入用户定义的 <code>Map</code> 函数中。Map函数所生成的中间键值对会被缓存在内存中。</li><li>每隔一段时间，被缓存的键值对会被写入到本地硬盘，并通过分区函数分到 <code>R</code> 个区域内。这些被缓存的键值对在本地磁盘的位置会被传回 <code>master</code>。<code>master</code> 负责将这些位置转发给执行 <code>reduce</code> 操作的 <code>worker</code>。</li><li>当 <code>master</code> 将这些位置告诉了某个执行 <code>reduce</code> 的 <code>worker</code> ，该 <code>worker</code> 就会使用 <code>RPC</code> 的方式去从保存了这些缓存数据的 <code>map worker</code> 的本地磁盘中读取数据。当一个 <code>reduce worker</code> 读取完了所有的中间数据后，它就会根据中间键进行排序，这样使得具有相同键值的数据可以聚合在一起。之所以需要排序是因为通常许多不同的key会映射到同一个 <code>reduce</code> 任务中。如果中间数据的数量太过庞大而无法放在内存中，那就需要使用外部排序。</li><li><code>reduce worker</code> 会对排序后的中间数据进行遍历。然后，对于遇到的每个唯一的中间键，<code>reduce worker</code> 会将该key和对应的中间value的集合传入用户所提供的 <code>Reduce</code> 函数中。<code>Reduce</code> 函数生成的输出会被追加到这个 <code>reduce</code> 分区的输出文件中。</li><li>当所有的 <code>map</code> 任务和 <code>reduce</code> 任务完成后，<code>master</code> 会唤醒用户程序。此时，用户程序会结束对 <code>MapReduce</code> 的调用。</li></ul><p>在成功完成任务后，<code>MapReduce</code> 的输出结果会存放在 <code>R</code> 个输出文件中（每个 <code>reduce</code> 任务都会生成对应的文件，文件名由用户指定）。一般情况下，用户无需将这些文件合并为一个文件。他们通常会将这些文件作为输入传入另一个 <code>MapReduce</code> 调用中。或者在另一个可以处理这些多个分割文件的分布式应用中使用。</p><h2 id="Master-的数据结构"><a href="#Master-的数据结构" class="headerlink" title="Master 的数据结构"></a>Master 的数据结构</h2><ul><li>保存了每个 <code>Map</code> 任务和每个 <code>Reduce</code> 任务的状态 (闲置，正在运行，以及完成)</li><li>非空闲任务 <code>worker</code> 机器的 <code>ID</code></li><li>保存由 <code>map</code> 任务所生成的中间文件区域的位置传播给 <code>reduce</code> 任务。对于每个完成的 <code>map</code> 任务，<code>master</code> 会保存由 <code>map</code> 任务所生成的 <code>R</code> 个中间文件区域的位置和大小。当 <code>map</code> 任务完成后，会对该位置和数据大小信息进行更新。这些信息会被逐渐递增地推送给那些正在运行的<code>Reduce</code>工作。</li></ul><h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><p>因为 <code>MapReduce</code> 库的设计旨在使用成百上千台机器来处理海量的数据，所以该库必须能很好地处理机器故障。</p><h3 id="Worker-故障"><a href="#Worker-故障" class="headerlink" title="Worker 故障"></a>Worker 故障</h3><p><code>master</code> 会周期 <code>ping</code> 下每个 <code>worker</code>. 如果在一定时间内无法收到来自某个 <code>worker</code> 的响应，那么 <code>master</code> 就会将该 <code>worker</code> 标记为 <code>failed</code>. 所有由该 <code>worker</code> 完成的 <code>Map</code> 任务都会被重设为初始的空闲 <code>idle</code> 状态。</p><h3 id="Master-故障"><a href="#Master-故障" class="headerlink" title="Master 故障"></a>Master 故障</h3><h2 id="地区性"><a href="#地区性" class="headerlink" title="地区性"></a>地区性</h2><h2 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h2><h2 id="备用任务"><a href="#备用任务" class="headerlink" title="备用任务"></a>备用任务</h2><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://mp.weixin.qq.com/s/sChCf07SxhTudxFIKd8pgA">https://mp.weixin.qq.com/s/sChCf07SxhTudxFIKd8pgA</a></p><p><a href="https://mp.weixin.qq.com/s/h43tPiycGrKf9089pML2tw">https://mp.weixin.qq.com/s/h43tPiycGrKf9089pML2tw</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Raft分布式一致性</title>
    <link href="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <url>/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>分布式系统</title>
    <link href="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    <url>/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<p>这篇学习笔记是针对 MIT 6.824 Distributed System. B站链接 <a href="https://www.bilibili.com/video/av91748150/">https://www.bilibili.com/video/av91748150/</a></p><h1 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h1><ul><li>核心是通过网络是一群计算机相互通信来完成一些连贯的任务</li><li>使用分布式系统的原因<ul><li>实现并行</li><li>容错</li><li>物理上的原因（两台计算机处于不同的地理位置）</li><li>考虑到安全性</li></ul></li><li>分布式系统的挑战<ul><li>部分故障</li><li>提升性能</li></ul></li></ul><h2 id="基础架构"><a href="#基础架构" class="headerlink" title="基础架构"></a>基础架构</h2><ul><li>存储 (最为关注)</li><li>通信</li><li>计算</li></ul><p>目标：能够从分布式存储和计算(computation)基础结构中发现一些可抽象的东西并设计为接口以简化使用</p><h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><h2 id="threads"><a href="#threads" class="headerlink" title="threads"></a>threads</h2><h2 id="concurrency"><a href="#concurrency" class="headerlink" title="concurrency"></a>concurrency</h2><h1 id="性能-Performance"><a href="#性能-Performance" class="headerlink" title="性能 Performance"></a>性能 Performance</h1><h2 id="可扩展性-scalability"><a href="#可扩展性-scalability" class="headerlink" title="可扩展性 scalability"></a>可扩展性 scalability</h2><p>使用两倍的计算机或资源就能使我获得两倍的性能或吞吐量</p><h1 id="容错-Fault-Tolerance"><a href="#容错-Fault-Tolerance" class="headerlink" title="容错 Fault Tolerance"></a>容错 Fault Tolerance</h1><h2 id="可用性-Availability"><a href="#可用性-Availability" class="headerlink" title="可用性 Availability"></a>可用性 Availability</h2><h2 id="可恢复性-Recoverability"><a href="#可恢复性-Recoverability" class="headerlink" title="可恢复性 Recoverability"></a>可恢复性 Recoverability</h2><h2 id="非易失性存储-Non-volatile-memory"><a href="#非易失性存储-Non-volatile-memory" class="headerlink" title="非易失性存储 Non-volatile memory"></a>非易失性存储 Non-volatile memory</h2><h2 id="复制-Replication"><a href="#复制-Replication" class="headerlink" title="复制 Replication"></a>复制 Replication</h2><p>目前流行的三种变更复制的算法: <code>单领导者</code>, <code>多领导者</code>, <code>无领导者</code></p><h3 id="领导者与追随者"><a href="#领导者与追随者" class="headerlink" title="领导者与追随者"></a>领导者与追随者</h3><p>存储数据库副本的每一个节点称为<strong>副本(replica)</strong>.</p><ul><li>基于领导者的复制 (leader-based replication)<ul><li>其中一个副本被指定为 leader. 当客户端要向数据库写入时, 他必须将请求发送给 leader, leader 会将新数据写入器本地存储.</li><li>其他副本被称为 followers. 每当 leader 将新数据写入本地存储时, 他也会将数据变更发送给所有的 followers, 这称为<strong>复制日志(replication log)</strong>. 每个 follower 从 leader 拉取日志, 并相应更新其本地数据库副本, 按照 leader 处理的相同顺序应用所有写入.</li><li>leader 是有读写操作的, 而 follower 只有读操作.</li></ul></li></ul><h4 id="同步复制与异步复制"><a href="#同步复制与异步复制" class="headerlink" title="同步复制与异步复制"></a>同步复制与异步复制</h4><p>复制的一个重要细节就是: 同步还是异步的.</p><blockquote><p><strong>半同步</strong>: 由于从库可能存在(崩溃, 网络故障)等一系列原因, 将所有从库都设置成同步是不切实际的. 实际上, 如果在数据库上启用同步复制, 这意味着通常只有一个 follower 是同步的, 而其他的都是异步的. 如果发现同步的 follower 变得不可用或是缓慢, 使一个异步的 follower 同步. 这样就可以保证至少有在两个节点上拥有最新的数据副本.</p></blockquote><h4 id="设置新从库"><a href="#设置新从库" class="headerlink" title="设置新从库"></a>设置新从库</h4><ol><li>在某个时刻获取主库的一致性快照, 而不必锁定整个数据库.</li><li>将快照复制到新的从库节点</li><li>从库连接到主库, 并拉取快照之后发生的所有数据变更. 这要求快照与主库复制日志中的位置精确关联.</li><li>当从库处理完快照之后积压的数据变更. 现在可以继续处理主库上的数据变化了.</li></ol><h4 id="处理节点宕机"><a href="#处理节点宕机" class="headerlink" title="处理节点宕机"></a>处理节点宕机</h4><ul><li>从库失效: 追赶恢复</li><li>主库失效: 故障切换<ul><li>其中一个从库需要被提升为新的主库, 需要重新配置客户端, 以将他们的写操作发送给新的主库, 其他从库需要开始拉取来自新主库的数据变更.</li></ul></li></ul><h4 id="复制日志的实现"><a href="#复制日志的实现" class="headerlink" title="复制日志的实现"></a>复制日志的实现</h4><ul><li>基于语句的复制<ul><li>任何调用非确定性函数的语句都会在每个副本上生成不同的值.例如 <code>NOW()</code>, <code>RAND()</code></li><li>如果语句使用了自增列, 则必须在每个副本上按照完全相同的顺序执行.</li><li>有副作用的语句可能会在每个副本上产生不同的副作用.</li></ul></li><li>传输预写式日志<ul><li>日志都是包含所有数据库写入的仅追加字节序列.</li></ul></li><li>逻辑日志复制<ul><li>以行的粒度描述对数据库表的写入<ul><li>对于插入的行，日志包含所有列的新值。</li><li>对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，但是如果表上没有主键，则需要记录所有列的旧值。</li><li>对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少所有已更改的列的新值）。</li></ul></li></ul></li></ul><h3 id="复制延迟的问题"><a href="#复制延迟的问题" class="headerlink" title="复制延迟的问题"></a>复制延迟的问题</h3><p>当应用程序从异步从库中读取数据的时候, 如果从库落后, 它可能会看到过时的消息. 但这种不一致只是一个暂时的状态 —— 如果停止写入数据库并等待一段时间, 从库最终会赶上主库并保持一致. 这种效应被称为 <strong>最终一致性 (eventually consistency)</strong></p><ul><li><p>读写一致性</p><ul><li>如果用户重新加载页面, 他们总会看到他们自己提交的任何更新。</li><li>读用户<strong>可能已经修改过</strong>的内容时, 强制都从主库读. (例如: 社交网络上的用户个人资料信息通常只能由用户本人编辑，而不能由其他人编辑. 因此一个简单的规则就是: 从主库读取用户自己的档案，在从库读取其他用户的档案)</li><li>如果应用中的大部分内容都被用户编辑了<ul><li>可以跟踪上次更新时间, 在上次更新后的一分钟内, 从主库读. </li><li>也可以监控从库的复制延迟, 防止向任意滞后超过一分钟的从库发起查询.</li></ul></li></ul></li><li><p>单调读</p><ul><li>用户首先从新副本读取, 然后从旧副本读取. 可能会发现前后读取不一致的情况</li><li>确保每个用户总是从同一个副本进行读取 (不同的用户可以从不同的副本读取)</li></ul></li><li><p>一致前缀读</p><ul><li>如果一系列写入按某个顺序发生, 那么任何人读取这些写入时, 也会看见它们以同样的顺序出现.</li><li>确保任何因果相关的写入都写入相同的分区.</li></ul></li></ul><h3 id="多主复制"><a href="#多主复制" class="headerlink" title="多主复制"></a>多主复制</h3><p>基于领导者的复制有一个主要的缺点：只有一个主库，而所有的写入都必须通过它。如果出于任何原因（例如和主库之间的网络连接中断）无法连接到主库, 就无法向数据库写入。</p><p>多领导者配置可以在每个数据中心都有主库, 每个数据中心内部使用常规的主从复制; 在数据中心之间, 每个数据中心的主库都会将其更改复制到其他数据中心的主库中.</p><h4 id="处理写入冲突"><a href="#处理写入冲突" class="headerlink" title="处理写入冲突"></a>处理写入冲突</h4><p>多领导者复制最大问题是可能发生写冲突, 这意味着需要解决冲突.</p><ul><li>避免冲突<ul><li>如果应用程序可以确保特定记录的所有写入都通过同一个 leader , 那么这个冲突就不会发生.</li></ul></li><li>收敛至一直的状态<ul><li>给每个写入一个唯一的 ID, 挑选最高 ID 的写入作为胜利者, 并丢弃其他写入. (LWW, last write wins)</li><li>以某种方式将这些值合并在一起.</li><li>在保留所有信息的显式数据结构中记录冲突, 并编写解决冲突的应用程序代码</li></ul></li></ul><h4 id="多主复制拓扑"><a href="#多主复制拓扑" class="headerlink" title="多主复制拓扑"></a>多主复制拓扑</h4><p>有两个以上的 leader, 各种不同的拓扑时可能的.</p><img src="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E9%A2%86%E5%AF%BC%E6%8B%93%E6%89%91.png" class="" title="多领导拓扑"><ul><li>循环和星型拓扑的问题是, 如果只有一个结点发生故障, 则可能会中断其他节点之间的复制消息流, 导致无法通信, 直到节点修复.</li><li>全能拓扑也可能有问题. 一些网络连接可能比其他网络连接更快, 一些消息可能先于它所依赖的消息.<ul><li>可以使用版本向量(version vector)来解决.</li></ul></li></ul><h3 id="无主复制"><a href="#无主复制" class="headerlink" title="无主复制"></a>无主复制</h3><p>客户端直接将写入发送到几个副本中. 在无领导配置中, 故障切换不存在, 为了解决这个问题, 当一个客户端从数据库中读取数据的时候, 它不仅仅发送他的请求到一个副本; 读请求也被并行的发送到多个节点. 客户可能会从不同的节点获得不同的响应。即来自一个节点的最新值和来自另一个节点的陈旧值。版本号用于确定哪个值更新.</p><ul><li>法定人数<ul><li>如果有 n 个副本, 每个写入必须由 w 个节点确认才能被认为是成功的, 并且我们必须至少为每一个读取查询 r 个节点. (w + r &gt; n) 即可以保证在读取的节点中一定能够读取到最新的值.</li></ul></li></ul><p>如果两个操作都互相感觉不到对方的存在, 就称这两个操作<strong>并发</strong>.</p><p>服务器可以通过查看版本号来确定两个操作是否并发的</p><ol><li>服务器为每个键保留一个版本号，每次写入键时都增加版本号，并将新版本号与写入的值一起存储.</li><li>当客户端读取键时，服务器将返回所有未覆盖的值以及最新的版本号。客户端在写入前必须读取.</li><li>客户端写入键时，必须包含之前读取的版本号，并且必须将之前读取的所有值合并在一起.</li><li>当服务器接收到具有特定版本号的写入时，它可以覆盖该版本号或更低版本的所有值, 但是它必须保持所有值更高版本号.</li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul><li><a href="https://vonng.gitbooks.io/ddia-cn/content/ch5.html">设计数据密集型应用-第五章</a></li></ul><h2 id="分区-Partition"><a href="#分区-Partition" class="headerlink" title="分区 Partition"></a>分区 Partition</h2><p>分区是一种有意将大型数据库分解成小型数据库的方式.</p><blockquote><p>tips: 上文中的<strong>分区(partition)</strong>,在MongoDB,Elasticsearch和Solr Cloud中被称为<strong>分片(shard)</strong>,在HBase中称之为<strong>区域(Region)**，Bigtable中则是</strong>表块(tablet)<strong>，Cassandra和Riak中是</strong>虚节点(vnode)<strong>, Couchbase中叫做</strong>虚桶(vBucket)**.但是分区(partition) 是约定俗成的叫法。</p></blockquote><h3 id="分区与复制"><a href="#分区与复制" class="headerlink" title="分区与复制"></a>分区与复制</h3><p>不均衡导致的高负载的分区被称为热点(hot spot). 解决这个问题可以采用一些的办法</p><ul><li>根据键的范围分区<ul><li>为每个分区指定一块连续的键范围 (分区边界可以由管理员手动选择, 也可以由数据库自动选择)</li><li>缺点<ul><li>某些特定的访问模式会导致热点. (e.g., 主键是时间戳的话)</li></ul></li></ul></li><li>根据键的散列分区<ul><li>一个好的 hash function 可以将偏斜的数据均匀分布.</li><li>Java 中的 Object.hashCode() 和 Ruby 的 Object#hash, 同一个键可能在不同的进程中有不同的哈希值.</li><li>一致性哈希 <strong>(Consistent Hashing)</strong> <ul><li><a href="http://www.zsythink.net/archives/1182">一致性哈希算法 consistent hashing</a></li></ul></li></ul></li><li>负载倾斜与消除热点<ul><li>如果一个主键被认为是非常火爆的, 可以在这个主键的开始或结尾添加一个随机数.</li><li>需要一些方法来跟踪哪些键需要被分割(否则对于吞吐量低的绝大多数主键来是不必要的开销)</li></ul></li></ul><h3 id="分片与次级索引"><a href="#分片与次级索引" class="headerlink" title="分片与次级索引"></a>分片与次级索引</h3><h4 id="按文档的次级索引"><a href="#按文档的次级索引" class="headerlink" title="按文档的次级索引"></a>按文档的次级索引</h4><img src="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E6%8C%89%E6%96%87%E6%A1%A3%E7%9A%84%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95.png" class="" title="按文档的二级索引"><p>每个分区完全独立: 每个分区维护自己的二级索引, 仅覆盖该分区中的文档. 所以也被称为<strong>本地索引(local index)</strong>.</p><p>缺点: 可能会使二级索引上的读取查询相当昂贵.</p><h4 id="基于关键词的次级索引"><a href="#基于关键词的次级索引" class="headerlink" title="基于关键词的次级索引"></a>基于关键词的次级索引</h4><img src="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E6%8C%89%E5%85%B3%E9%94%AE%E8%AF%8D%E7%9A%84%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95.png" class="" title="按关键词的二级索引"><p>构建一个覆盖所有分区的全局索引, 而不是给每个自己分区创建自己的本地索引.</p><p>缺点: 写入速度较慢且较为复杂, 因为写入单个文档现在可能会影响索引的多个分区</p><h3 id="分区再平衡"><a href="#分区再平衡" class="headerlink" title="分区再平衡"></a>分区再平衡</h3><p>再平衡一般需要满足:</p><ul><li>再平衡之后, 负载(数据存储, 读取和写入请求)应该在集群中的节点之间公平地共享.</li><li>再平衡发生时, 数据库应该继续接受读取和写入</li><li>节点之间只移动必须的数据, 以便快速再平衡, 并减少网络和磁盘 I/O 负载.</li></ul><h4 id="固定数量的分区"><a href="#固定数量的分区" class="headerlink" title="固定数量的分区"></a>固定数量的分区</h4><p>创建比节点更多的分区, 并为每个节点分配多个分区. 如果一个节点被添加到集群中, 新节点可以从当前每个节点中拿走一些分区, 直到分区再次公平分配. 如果从集群中删除一个节点, 就会把节点中的分区再分配回去.</p><img src="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%9B%BA%E5%AE%9A%E6%95%B0%E9%87%8F%E7%9A%84%E5%88%86%E5%8C%BA.png" class="" title="固定数量的分区"><p>缺点: 数据集的总大小难以估计, 难以选择正确的分区数.</p><h4 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h4><p>按键的范围进行分区的数据库会动态创建分区. 当分区增长到超过配置的大小时, 会被分成两个分区, 每个分区约占一般的数据. 相反的, 如果大量数据被删除并且分区缩小到某个阈值以下, 则可以将其与相邻分区合并.</p><h4 id="按节点比例分区"><a href="#按节点比例分区" class="headerlink" title="按节点比例分区"></a>按节点比例分区</h4><p>以上两种分区方式, 分区的数量都与节点的数量无关.</p><p>每个分区的大小与数据集大小成比例地增长, 而节点数量保持不变, 但是当增加节点数时, 分区将再次变小. 由于较大的数据量通常需要较大数量的节点进行存储, 因此这种方法也使每个分区的大小较为稳定.</p><h1 id="分布式系统的麻烦"><a href="#分布式系统的麻烦" class="headerlink" title="分布式系统的麻烦"></a>分布式系统的麻烦</h1><ul><li>无法访问的网络</li><li>时钟和时序问题</li></ul><h2 id="故障与部分失效"><a href="#故障与部分失效" class="headerlink" title="故障与部分失效"></a>故障与部分失效</h2><p>在分布式系统中, 尽管系统的其他部分工作正常, 单系统的某些部分可能会以某种不可预知的方式被破坏. <strong>(partial failure 部分失效)</strong></p><h3 id="不可靠的网络"><a href="#不可靠的网络" class="headerlink" title="不可靠的网络"></a>不可靠的网络</h3><h4 id="检测故障"><a href="#检测故障" class="headerlink" title="检测故障"></a>检测故障</h4><ul><li>负载平衡器需要停止向已死亡的节点转发请求</li><li>在单主复制功能的分布式数据库中, 如果主库失效, 则需要将从库之一升级为新主库.</li></ul><h1 id="一致性与共识-Consistency-and-Consensus"><a href="#一致性与共识-Consistency-and-Consensus" class="headerlink" title="一致性与共识 Consistency and Consensus"></a>一致性与共识 Consistency and Consensus</h1><p><strong>共识(consensus)</strong> : 就是让所有的节点对某件事达成共识.</p><h2 id="一致性保证"><a href="#一致性保证" class="headerlink" title="一致性保证"></a>一致性保证</h2><h3 id="线性一致性-强一致性"><a href="#线性一致性-强一致性" class="headerlink" title="线性一致性 = 强一致性"></a>线性一致性 = 强一致性</h3><p>让系统看起来好像只有一个数据副本, 而且所有的操作都是原子性的.</p><h4 id="区别-线性一致性-Linearizability-vs-可序列化-Serializability"><a href="#区别-线性一致性-Linearizability-vs-可序列化-Serializability" class="headerlink" title="区别 线性一致性(Linearizability) vs. 可序列化(Serializability)"></a>区别 线性一致性(Linearizability) vs. 可序列化(Serializability)</h4><ul><li>可序列化<ul><li>Serializability 是事务的隔离属性.</li><li>它确保事务的行为, 与它们按照<strong>某种</strong>顺序依次执行的结果相同. 这种执行顺序可以与事务实际执行的顺序不同.</li><li>保证即使事务可以并行执行, 最终的结果也是一样的, 就好像它们没有任何并发性, 连续挨个执行一样.</li></ul></li><li>线性一致性<ul><li>不会将操作组合成事务. 是在单个对象上面的单个操作保证</li></ul></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Linux中的IO</title>
    <link href="/2020/08/30/Linux%E4%B8%AD%E7%9A%84IO/"/>
    <url>/2020/08/30/Linux%E4%B8%AD%E7%9A%84IO/</url>
    
    <content type="html"><![CDATA[<p>基于面试的时候，碰到了很多与 Linux 有关的话题，对这方面一直了解不够深。本文讨论的背景是network IO。</p><h1 id="概念说明"><a href="#概念说明" class="headerlink" title="概念说明"></a>概念说明</h1><p>在讨论之前，我们先需要明确几个基本的概念</p><h2 id="用户空间和内核空间"><a href="#用户空间和内核空间" class="headerlink" title="用户空间和内核空间"></a>用户空间和内核空间</h2><p>对 32 位操作系统而言，它的寻址空间（虚拟地址空间，或叫线性地址空间）为 4G（2的32次方）。也就是说一个进程的最大地址空间为 4G。操作系统的核心是内核(kernel)，它独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证内核的安全，现在的操作系统一般都强制用户进程不能直接操作内核。具体的实现方式基本都是由操作系统将虚拟地址空间划分为两部分，一部分为内核空间，另一部分为用户空间。针对 Linux 操作系统而言，最高的 1G 字节(从虚拟地址 0xC0000000 到 0xFFFFFFFF)由内核使用，称为内核空间。而较低的 3G 字节(从虚拟地址 0x00000000 到 0xBFFFFFFF)由各个进程使用，称为用户空间。</p><p>每个进程的4G地址空间中，最高1G都是一样的，即内核空间，剩下3G归进程使用。最高1G的内核空间是被所有<b>进程</b>共享的。</p><img src="/2020/08/30/Linux%E4%B8%AD%E7%9A%84IO/%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E5%92%8C%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4.png" class="" title="用户空间和内核空间"><h3 id="为什么区分内核空间和用户空间"><a href="#为什么区分内核空间和用户空间" class="headerlink" title="为什么区分内核空间和用户空间"></a>为什么区分内核空间和用户空间</h3><ul><li>CPU将指令分为特权指令和非特权指令，因为有的指令是非常危险的，如果错用，将导致系统崩溃。</li><li>对于危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令</li></ul><h3 id="内核态和用户态"><a href="#内核态和用户态" class="headerlink" title="内核态和用户态"></a>内核态和用户态</h3><p>当进程运行在内核空间时就处于内核状态，而进程运行在用户空间时则处于用户态。</p><ul><li>在内核态下，进程运行在内核地址空间，此时CPU可以执行任何指令。运行的代码也不受限制，可以自由访问任何有效地址，也可以直接进行端口访问。</li><li>在用户态下，进程运行在用户地址空间中，被执行的代码要受到 CPU 的诸多检查，它们只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址，且只能对任务状态段(TSS)中 I/O 许可位图(I/O Permission Bitmap)中规定的可访问端口进行直接访问。</li></ul><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://www.cnblogs.com/sparkdev/p/8410350.html">https://www.cnblogs.com/sparkdev/p/8410350.html</a></p><h2 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h2><p>为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这就被称为进程切换。</p><p>从一个进程的运行转到另一个进程上进行，整个过程经历了以下的变化</p><ol><li>保存处理机上下文</li><li>更新PCB信息</li><li>把进程的PCB移入相应的队列，如就绪、在某事件阻塞队列。</li><li>选择另一个进程执行，并更新其PCB</li><li>更新内存管理的数据结构</li><li>恢复处理机上下文</li></ol><p>tips: PCB (Process Control Block) 为了描述控制进程的运行，系统中存放进程的管理和控制信息的数据结构。是进程实体的一部分，是操作系统中最重要的记录性数据结构。</p><h2 id="进程的阻塞"><a href="#进程的阻塞" class="headerlink" title="进程的阻塞"></a>进程的阻塞</h2><p>正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种<b>主动</b>行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。</p><h2 id="文件的描述符"><a href="#文件的描述符" class="headerlink" title="文件的描述符"></a>文件的描述符</h2><p>文件描述符(File Descriptor)是一个用于表述指向文件的引用的抽象化概念。实际上，他是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。</p><h2 id="缓存-I-O"><a href="#缓存-I-O" class="headerlink" title="缓存 I/O"></a>缓存 I/O</h2><p>缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。</p><h1 id="IO-模式"><a href="#IO-模式" class="headerlink" title="IO 模式"></a>IO 模式</h1><p>接下来我们详细介绍一下IO的几种模式，对于一次IO的访问，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p><ol><li>用户进程空间 &lt;–&gt; 内核空间</li><li>内核空间 &lt;–&gt; 设备空间</li></ol><ul><li>Linux 中进程无法直接操作I/O设备，其必须通过系统调用请求kernel来协助完成I/O动作</li><li>内核会为每个I/O设备维护一个缓冲区</li><li>对于一个输入操作来说，进程IO系统调用后，内核会先看缓冲区中有没有相应的缓存数据，没有的话再到设备中读取，因为设备IO一般速度较慢，需要等待；内核缓冲区有数据则直接复制到进程空间。<ul><li>等待网络数据到达网卡 -&gt; 读取到内核缓冲区，准备好数据</li><li>从内核缓冲区复制数据到进程空间</li></ul></li></ul><p>由于这两个阶段的存在，Linux系统产生下面五种网络模式的方案</p><h2 id="阻塞-I-O"><a href="#阻塞-I-O" class="headerlink" title="阻塞 I/O"></a>阻塞 I/O</h2><p>在 Linux 中，默认情况下所有的socket都使用的阻塞，一个典型的读流程是这样的：</p><p>进程发起IO系统调用后，进程被阻塞，转到内核空间处理，整个IO处理完毕后返回进程。操作成功则进程获取数据。</p><blockquote><p>blocking IO 的特点就是在 IO 执行的两个阶段都被 block 了</p></blockquote><ol><li><p>应用: 阻塞socket, Java BIO</p></li><li><p>特点</p><ul><li>进程阻塞不消耗CPU资源，及时响应每个操作</li><li>实现难度低，开发比较容易</li><li>适用并发量小的网络应用开发</li><li>不适用并发量大的应用: 因为一个请求IO会阻塞线程，得为每请求分配一个处理进程(线程)以及时响应，系统开销大。</li></ul></li></ol><h2 id="非阻塞-I-O"><a href="#非阻塞-I-O" class="headerlink" title="非阻塞 I/O"></a>非阻塞 I/O</h2><p>在Linux 中，可以通过设置 socket 使其变为 non-blocking. 当对一个 non-blocking socket执行读操作时，流程是这样的：</p><p>进程发起IO系统调用后，如果内核缓冲区没有数据，需要到IO设备中读取，进程返回一个错误而不会被阻塞。进程发起IO系统调用后，如果内核缓冲区有数据，内核就会把数据返回进程。</p><ol><li><p>应用: socket的非阻塞方式</p></li><li><p>特点</p><ul><li>进程轮询调用消耗CPU资源</li><li>实现难度低，开发应用相对阻塞IO模式较难</li></ul></li></ol><h2 id="I-O-多路复用"><a href="#I-O-多路复用" class="headerlink" title="I/O 多路复用"></a>I/O 多路复用</h2><p>这里就涉及到我们说的 <code>select</code>, <code>poll</code>, <code>epoll</code>. 他们都是IO多路复用机制，I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪(一般是读就绪或者写就绪)，能够通知程序进行相应的读写操作。但<code>select</code>, <code>poll</code>, <code>epoll</code>本质上都是同步IO, 因为它们都需要在读写时间就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间</p><p><strong>select</strong>/<strong>poll</strong>的好处在于单个process就可以同时处理多个网络连接的I/O. 它的原理</p><p>上面的图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (<code>select</code> 和 <code>recvfrom</code>)，而blocking IO只调用了一个system call (<code>recvfrom</code>)。但是，用select的优势在于它可以同时处理多个connection。</p><h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><ul><li>select 调用是内核级别的，<code>select</code>轮询相对非阻塞区别在于：<code>select</code> 可以等待多个socket, 能实现同时对多个 IO 端口进行监听，当其中任何一个socket的数据准备好了，就能返回进行可读，然后进程再进行<code>recvform</code>系统调用，将数据由内核拷贝到用户进程，这个过程是阻塞的。</li><li><code>select</code>或者<code>poll</code> 调用之后，会阻塞进程。与blocking IO阻塞的区别在于，此时的select不是等到socket数据全部到达再处理，而是有了一部分数据就会调用用户进程来处理。<code>select</code>的优势在于它可以同时处理多个connection</li></ul><h4 id="具体流程"><a href="#具体流程" class="headerlink" title="具体流程"></a>具体流程</h4><ol><li>当用户进程调用 select, 那么整个进程会被 block. </li><li>同时, kernel会监视所有select负责的socket, 当任何一个socket中的数据准备好了, select就会返回。</li><li>这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。</li></ol><p>在 I/O 编程中，当需要同时处理多个客户端接入请求时，可以利用多线程或者 I/O 多路复用技术进行处理。I/O 多路复用技术通过把多个 I/O 的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。</p><h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul><li>I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源。</li></ul><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">select</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout)</span></span>;<br></code></pre></td></tr></table></figure><p>一共 <code>select</code> 函数监视的文件描述符分3类，分别是<code>writefds</code>、<code>readfds</code>、和<code>exceptfds</code>。调用后<code>select</code>函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当<code>select</code>函数返回后，可以 通过遍历<code>fdset</code>，来找到就绪的描述符。</p><p>注册IO、阻塞扫描，监听的IO最大连接数不能多于FD_SIZE</p><h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><p>原理和select相似，没有数量限制，但IO数量大 扫描线性性能下降</p><h4 id="具体实现-1"><a href="#具体实现-1" class="headerlink" title="具体实现"></a>具体实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">poll</span> <span class="hljs-params">(struct pollfd *fds, <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span> nfds, <span class="hljs-keyword">int</span> timeout)</span></span>;<br></code></pre></td></tr></table></figure><p>不同于<code>select</code>使用三个位置来表示三个fdset的方式，<code>poll</code>使用一个pollfd的指针来实现。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">pollfd</span> &#123;</span><br>    <span class="hljs-keyword">int</span> fd;        <span class="hljs-comment">// file description</span><br>    <span class="hljs-keyword">short</span> events;  <span class="hljs-comment">// requested events to watch</span><br>    <span class="hljs-keyword">short</span> revents; <span class="hljs-comment">// returned events witnessed </span><br>&#125;<br></code></pre></td></tr></table></figure><p>pollfd结构包含了要监视的event和发生的event，不再使用<code>select</code> “参数-值” 传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和<code>select</code>函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。</p><h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>事件驱动不阻塞，mmap实现内核与用户空间的消息传递，数量很大</p><p>// TODO</p><h3 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://www.jianshu.com/p/486b0965c296">https://www.jianshu.com/p/486b0965c296</a></p><h2 id="信号驱动-I-O"><a href="#信号驱动-I-O" class="headerlink" title="信号驱动 I/O"></a>信号驱动 I/O</h2><p>这个目前并不常见</p><h2 id="异步-I-O"><a href="#异步-I-O" class="headerlink" title="异步 I/O"></a>异步 I/O</h2><p>相比于同步IO，异步IO 不是顺序执行。用户进程进行<code>aio_read</code>系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户进程就可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。</p><h1 id="参考文献-2"><a href="#参考文献-2" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://segmentfault.com/a/1190000003063859">https://segmentfault.com/a/1190000003063859</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>nginx那些事</title>
    <link href="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h1><p>在介绍什么是 nginx 之前，我们先了解两个概念</p><h2 id="web服务器"><a href="#web服务器" class="headerlink" title="web服务器"></a>web服务器</h2><blockquote><p>负责处理和响应用户请求，一般也称为http服务器，如 Apache, IIS, Nginx</p></blockquote><h2 id="应用服务器"><a href="#应用服务器" class="headerlink" title="应用服务器"></a>应用服务器</h2><blockquote><p>存放和运行系统程序的服务器，负责处理程序中的业务逻辑，如 Tomcat, Weblogic, Jboss</p></blockquote><p>总结一下, nginx 就是</p><ul><li>一种轻量级的 web 服务器</li><li>采用事件驱动的异步非阻塞处理方式框架</li><li>占用内存少，启动速度快，并发能力强</li></ul><h2 id="Nginx的四大应用"><a href="#Nginx的四大应用" class="headerlink" title="Nginx的四大应用"></a>Nginx的四大应用</h2><h3 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h3><img src="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB.png" class="" title="动静分离"><p>通过示意图，我们可以得出，<strong>动静分离</strong>其实就是 nginx 服务器将收到的请求分为<strong>动态请求</strong>和<strong>静态请求</strong></p><ul><li>静态请求直接从 nginx 服务器所设定的根目录路径去取对应的资源，动态请求转发给真实的后台去处理，即是应用服务器(Tomcat)</li><li>这样做不仅能给应用服务器减轻压力，将后台 api 接口服务化，还能将前后端代码分开并行开发和部署。</li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;  <br>        <span class="hljs-attribute">listen</span>       <span class="hljs-number">8080</span>;        <br>        <span class="hljs-attribute">server_name</span>  localhost;<br><br>        <span class="hljs-attribute">location</span> / &#123;<br>            <span class="hljs-attribute">root</span>   html; <span class="hljs-comment"># Nginx默认值</span><br>            <span class="hljs-attribute">index</span>  index.html index.htm;<br>        &#125;<br>        <br>        <span class="hljs-comment"># 静态化配置，所有静态请求都转发给 nginx 处理，存放目录为 my-project</span><br>        <span class="hljs-attribute">location</span> <span class="hljs-regexp">~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|ico|js|css)$</span> &#123;<br>            <span class="hljs-attribute">root</span> /usr/local/var/www/my-project; <span class="hljs-comment"># 静态请求所代理到的根目录</span><br>        &#125;<br>        <br>        <span class="hljs-comment"># 动态请求匹配到path为&#x27;node&#x27;的就转发到8002端口处理</span><br>        <span class="hljs-attribute">location</span> /node/ &#123;  <br>            <span class="hljs-attribute">proxy_pass</span> http://localhost:8002; <span class="hljs-comment"># 充当服务代理</span><br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>访问静态资源 nginx 服务器会返回 <code>my-project</code> 里面的文件</li><li>访问动态请求 nginx 服务器会将它从8002端口请求到的内容，原封不动的返回回去</li></ul><h3 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h3><h4 id="什么是反向代理"><a href="#什么是反向代理" class="headerlink" title="什么是反向代理"></a>什么是反向代理</h4><p>反向代理其实就类似你去找代购帮你买东西（浏览器或其他终端向nginx请求），你不用管他去哪里买，只要他帮你买到你想要的东西就行（浏览器或其他终端最终拿到了他想要的内容，但是具体从哪儿拿到的这个过程它并不知道）。</p><h4 id="反向代理的作用"><a href="#反向代理的作用" class="headerlink" title="反向代理的作用"></a>反向代理的作用</h4><ol><li>保障应用服务器的安全 (增加一层代理，可以屏蔽危险攻击，更方便的控制权限)</li><li>实现负载均衡</li><li>实现跨域</li></ol><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;  <br>        <span class="hljs-attribute">listen</span>       <span class="hljs-number">8080</span>;        <br>        <span class="hljs-attribute">server_name</span>  localhost;<br><br>        <span class="hljs-attribute">location</span> / &#123;<br>            <span class="hljs-attribute">root</span>   html; <span class="hljs-comment"># Nginx默认值</span><br>            <span class="hljs-attribute">index</span>  index.html index.htm;<br>        &#125;<br>        <br>        <span class="hljs-attribute">proxy_pass</span> http://localhost:8000; <span class="hljs-comment"># 反向代理配置，请求会被转发到8000端口</span><br>&#125;<br></code></pre></td></tr></table></figure><p>上面这个例子意思是向 nginx 请求 <code>localhost:8080</code> 跟请求 <code>http://localhost:8000</code> 是一样的效果</p><img src="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86.png" class="" title="反向代理"><p>nginx 就充当图中的 proxy. 当左边三个client在请求向 nginx 获取内容，是感受不到三个server的存在的</p><blockquote><p>proxy 就充当了三个server的反向代理</p></blockquote><ul><li>CDN 服务就是经典的反向代理</li><li>反向代理也是实现负载均衡的基础</li></ul><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>随着业务的不断增长和用户的增多，一台服务器已经无法满足系统的需求。这个时候就出现了服务器<strong>集群</strong>。</p><p>在服务器集群中, nginx 可以将接收到的客户端请求“均匀地”（严格讲并不一定均匀，可以通过设置权重）分配到这个集群中所有的服务器上。这个就叫做负载均衡。</p><img src="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.png" class="" title="负载均衡"><h4 id="负载均衡的作用"><a href="#负载均衡的作用" class="headerlink" title="负载均衡的作用"></a>负载均衡的作用</h4><ul><li>分摊服务器集群压力</li><li>保证客户端访问的稳定性</li></ul><p>nginx 自带<strong>健康检查</strong>功能，会定期轮询向集群里的所有服务器发送健康检查请求，来检查集群中是否有服务器处于异常状态。一旦发现某台服务器出现异常，那么在这以后代理进来的客户端请求都不会被发送到该服务器上，从而保证客户端访问的稳定性。</p><p>配置一个负载均衡</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-comment"># 负载均衡：设置domain</span><br><span class="hljs-attribute">upstream</span> domain &#123;<br>    <span class="hljs-attribute">server</span> localhost:<span class="hljs-number">8000</span>;<br>    <span class="hljs-attribute">server</span> localhost:<span class="hljs-number">8001</span>;<br>&#125;<br><span class="hljs-section">server</span> &#123;  <br>        <span class="hljs-attribute">listen</span>       <span class="hljs-number">8080</span>;        <br>        <span class="hljs-attribute">server_name</span>  localhost;<br><br>        <span class="hljs-attribute">location</span> / &#123;<br>            <span class="hljs-comment"># root   html; # Nginx默认值</span><br>            <span class="hljs-comment"># index  index.html index.htm;</span><br>            <br>            <span class="hljs-attribute">proxy_pass</span> http://domain; <span class="hljs-comment"># 负载均衡配置，请求会被平均分配到8000和8001端口</span><br>            <span class="hljs-attribute">proxy_set_header</span> Host $host:$server_port;<br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>8000和80001是我本地用 Node.js 起的两个服务，负载均衡成功后可以看到访问 <code>localhost:8080</code> 有时会访问到8000端口的页面，有时会访问到8001端口的页面。</p><h3 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h3><img src="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86.png" class="" title="正向代理"><p>正向代理跟反向道理正好相反。</p><blockquote><p>此时，proxy就充当了三个client的正向代理</p></blockquote><p>正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理。</p><p>科学上网vpn（俗称翻墙）其实就是一个正向代理工具。</p><p>该 vpn 会将想访问墙外服务器 server 的网页请求，代理到一个可以访问该网站的代理服务器 proxy 上。这个 proxy 把墙外服务器 server 上获取的网页内容，再转发给客户。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://juejin.im/entry/6844903464816869383">https://juejin.im/entry/6844903464816869383</a></p><p><a href="https://juejin.im/post/6844904129987526663">https://juejin.im/post/6844904129987526663</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Git的原理</title>
    <link href="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/"/>
    <url>/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>这篇文章主要是讲一讲git的底层实现原理，之前有了解过一点，现在作一个完整的梳理。</p><h1 id="Git-的信息是怎样被储存的"><a href="#Git-的信息是怎样被储存的" class="headerlink" title="Git 的信息是怎样被储存的"></a>Git 的信息是怎样被储存的</h1><p>首先我们初始化git, 可以发现新建了一个.git/目录，Git会将整个数据库储存在.git/目录下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git init<br>$ tree .git/objects<br>.git/objects<br>├── info<br>└── pack<br></code></pre></td></tr></table></figure><p>然后我们先创建两个文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ tree .git/objects<br>.git/objects<br>├── 58<br>│   └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c<br>├── c2<br>│   └── 00906efd24ec5e783bee7f23b5d7c941b0c12c<br>├── info<br>└── pack<br>$ <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;111&#x27;</span> &gt; a.txt<br>$ <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;222&#x27;</span> &gt; b.txt<br>$ git add *.txt<br></code></pre></td></tr></table></figure><p>可以看一个这个objects里面具体是什么</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ cat .git/objects/58/c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c<br>xKOR0a044K%<br></code></pre></td></tr></table></figure><p>这个乱码的出现其实是git把信息压缩成了二进制文件。但是不用担心，因为Git也提供了一个能够帮助你探索它的api <code>git cat-file [-t] [-p]</code>， -t可以查看object的类型，-p可以查看object储存的具体内容。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git cat-file -t 58c9<br>blob<br><br>$ git cat-file -p 58c9<br>111<br></code></pre></td></tr></table></figure><p>可以发现这个object是一个blob类型的节点，他的内容是111，也就是说这个object储存着a.txt文件的内容。这就引出了我们所说的第一个在git中数据存储的类型<strong>blob</strong></p><h2 id="Blob"><a href="#Blob" class="headerlink" title="Blob"></a>Blob</h2><p>它只储存的是一个文件的内容，不包括文件名等其他信息。然后将这些信息经过SHA1哈希算法得到对应的哈希值，这个哈希值就是这个文件在这个Git仓库中的唯一标识。即目前我们的Git 仓库是这样滴</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%861.png" class="" title="示意图"><p>我们继续探索, 我们新建了一个commit</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git commit -m <span class="hljs-string">&quot;[+] init&quot;</span><br>$ tree .git/objects<br>.git/objects<br>├── 4c<br>│   └── aaa1a9ae0b274fba9e3675f9ef071616e5b209<br>├── 58<br>│   └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c<br>├── ae<br>│   └── 202f2a6e3588115a05581d4dc12e082e3e97e4<br>├── c2<br>│   └── 00906efd24ec5e783bee7f23b5d7c941b0c12c<br>├── info<br>└── pack<br></code></pre></td></tr></table></figure><p>我们可以看到当我们commit了之后，又多了两个objects。使用cat-file看看具体的内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git cat-file -t 4caaa1<br>tree<br><br>$ git cat-file -p 4caaa1<br>100644 blob 58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6ca.txt<br>100644 blob c200906efd24ec5e783bee7f23b5d7c941b0c12cb.txt<br></code></pre></td></tr></table></figure><p>现在我们碰到了第二个数据类型<strong>tree</strong></p><h2 id="Tree"><a href="#Tree" class="headerlink" title="Tree"></a>Tree</h2><p>它将当前的目录结构打了一个快照。从它储存的内容来看可以发现它储存了一个目录结构（类似于文件夹），以及每一个文件（或者子文件夹）的权限、类型、对应的身份证（SHA1值）、以及文件名。现在我们的git仓库是这样的</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%862.png" class="" title="示意图"><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git cat-file -t ae20<br>commit<br><br>$ git cat-file -p ae20<br>tree 4caaa1a9ae0b274fba9e3675f9ef071616e5b209<br>author zhengchicheng.bob &lt;zhengchicheng.bob@bytedance.com&gt; 1598099521 +0800<br>committer zhengchicheng.bob &lt;zhengchicheng.bob@bytedance.com&gt; 1598099521 +0800<br><br>[+] init<br></code></pre></td></tr></table></figure><p>现在我们发现了第三种数据类型<strong>commit</strong></p><h2 id="Commit"><a href="#Commit" class="headerlink" title="Commit"></a>Commit</h2><p>它储存的是一个提交的信息，包括对应目录结构的快照tree的哈希值，上一个提交的哈希值（这里由于是第一个提交，所以没有父节点。在一个merge提交中还会出现多个父节点），提交的作者以及提交的具体时间，最后是该提交的信息。现在我们的数据库是这样的</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%863.png" class="" title="示意图"><p>那么目前为止，我们就已经知道了Git是如何去储存一个提交信息的了, 我们已经了解了Blob, Tree, Commit三个基本的数据类型。那么我们平时接触到的分支信息又存储在哪里呢</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ cat .git/HEAD<br>ref: refs/heads/master<br><br>$ cat .git/refs/heads/master<br>0c96bfc59d0f02317d002ebbf8318f46c7e47ab2<br></code></pre></td></tr></table></figure><p>在Git仓库中, HEAD、分支、普通的tag可以简单的理解成一个指针，指向对应commit的SHA1值。</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%864.png" class="" title="示意图"><blockquote><p>本质上Git是一个key-value的数据库加上默克尔树形成的无环图(DAG)</p></blockquote><p>tips: 默克尔树又叫哈希树，主要特点是:</p><ol><li>最下面的叶结点包含存储数据或其哈希值</li><li>非叶子结点都是他的两个孩子节点内容的哈希值<br>作用：</li><li>可以快速比较大量数据</li><li>快速定位修改</li></ol><h1 id="Git-的三个分区"><a href="#Git-的三个分区" class="headerlink" title="Git 的三个分区"></a>Git 的三个分区</h1><p>继续上面的例子，当前我们的仓库状态是这样的</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%864.png" class="" title="示意图"><h2 id="工作目录"><a href="#工作目录" class="headerlink" title="工作目录"></a>工作目录</h2><p>操作系统上的文件，所有代码开发编辑都在这上面完成。</p><h2 id="Index-索引区"><a href="#Index-索引区" class="headerlink" title="Index 索引区"></a>Index 索引区</h2><p>可以理解成一个暂存区域，这里面的代码会在下一次commit被提交到Git仓库</p><h2 id="Git-仓库"><a href="#Git-仓库" class="headerlink" title="Git 仓库"></a>Git 仓库</h2><p>由Git object记录着每一次提交的快照，以及链式结构记录的提交变更历史</p><p>图解Git<br><a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html">https://marklodato.github.io/visual-git-guide/index-zh-cn.html</a></p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.jiqizhixin.com/articles/2019-12-20">https://www.jiqizhixin.com/articles/2019-12-20</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Docker那些事</title>
    <link href="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="容器生态系统"><a href="#容器生态系统" class="headerlink" title="容器生态系统"></a>容器生态系统</h1><h2 id="容器核心技术"><a href="#容器核心技术" class="headerlink" title="容器核心技术"></a>容器核心技术</h2><p>容器核心技术指的是能够让 Container 在 host 上运行起来的技术</p><h3 id="容器规范"><a href="#容器规范" class="headerlink" title="容器规范"></a>容器规范</h3><blockquote><p>我们熟知的Docker只是容器的一种</p></blockquote><p>OCI 发布了以下两个规范</p><ul><li>runtime spec</li><li>image format spec<br>有了这两个规范，不同组织和厂商开发的容器能够在不同的runtime上运行</li></ul><h3 id="容器runtime"><a href="#容器runtime" class="headerlink" title="容器runtime"></a>容器runtime</h3><p>Java 程序 -&gt; 容器</p><p>JVM -&gt; runtime</p><p>JVM 为 Java 程序提供运行环境，同样的容器只有在runtime中才能运行</p><p>目前主流的三种容器runtime</p><ul><li>lxc<ul><li>Linux 上老牌的容器 runtime</li><li>Docker 最初也使用的 lxc</li></ul></li><li>runc<ul><li>是 Docker 开发的容器，也是 Docker 默认的runtime</li></ul></li><li>rkt<ul><li>是 CoreOS 开发的容器</li></ul></li></ul><h3 id="容器管理工具"><a href="#容器管理工具" class="headerlink" title="容器管理工具"></a>容器管理工具</h3><p>有了 runtime 之后，用户得有工具来管理容器，每种不同的runtime有自己不同的管理工具</p><ul><li>lxc<ul><li>lxd</li></ul></li><li>runc <ul><li>docker engine<ul><li>cli</li><li>deamon</li></ul></li><li>我们提到的 Docker 一般指的就是 docker engine</li></ul></li><li>rkt<ul><li>rkt cli</li></ul></li></ul><h3 id="容器定义工具"><a href="#容器定义工具" class="headerlink" title="容器定义工具"></a>容器定义工具</h3><p>允许用户自己定义容器的内容和属性，这样容器可以被保存、共享、重建。</p><ul><li>docker image<ul><li>runtime 依据 docker image 创建容器</li></ul></li><li>dockerfile<ul><li>包含若干命令的文本文件，可以通过这个创建出docker image</li></ul></li><li>ACI (App Container Image) </li></ul><h3 id="Registries"><a href="#Registries" class="headerlink" title="Registries"></a>Registries</h3><p>因为容器是通过模板 image 来创建的，需要有一个仓库来统一存放 image, 这个仓库就叫做 Registry</p><ul><li>Docker Registry<ul><li>企业通过 Docker Registry 来构建私有的 Registry</li></ul></li><li>Docker Hub</li><li>Quay.io</li></ul><h3 id="容器OS"><a href="#容器OS" class="headerlink" title="容器OS"></a>容器OS</h3><p>容器 OS 是专门运行容器的操作系统。与常规 OS 相比，容器 OS 通常体积更小，启动更快</p><h2 id="容器平台技术"><a href="#容器平台技术" class="headerlink" title="容器平台技术"></a>容器平台技术</h2><p>容器核心技术使得容器能够在单个 host 上运行，而容器平台技术能够让容器作为集群在分布式环境中运行。</p><p>部署在容器中的应用一般采用微服务架构，在这种架构下，应用被划分为不同的组件，并以服务的形式运行在<strong>各自</strong>的容器中。为了保证应用的高可用，每个组件都可能会运行多个相同的容器。这些容器会组成集群，集群中的容器会根据业务需要被动的创建、迁移和销毁。</p><h3 id="容器编排引擎"><a href="#容器编排引擎" class="headerlink" title="容器编排引擎"></a>容器编排引擎</h3><p>编排 (orchestration) 包括容器管理、调度、集群定义和服务发现。通过容器编排引擎，容器被有机组合成微服务应用。</p><p>以下三个是当前主流的容器编排引擎</p><ul><li>docker swarm<ul><li>Docker 开发的容器编排阵容</li></ul></li><li>kubernetes<ul><li>Google 开发的容器编排阵容</li></ul></li><li>mesos + marathon</li></ul><h3 id="容器管理平台"><a href="#容器管理平台" class="headerlink" title="容器管理平台"></a>容器管理平台</h3><p>容器管理平台是架构在容器编排引擎之上的一个更为通用的平台。</p><ul><li>Rancher</li><li>ContainerShip</li></ul><h3 id="基于容器的PaaS"><a href="#基于容器的PaaS" class="headerlink" title="基于容器的PaaS"></a>基于容器的PaaS</h3><p>基于容器的 PaaS 为微服务应用开发人员与公司提供了开发、部署和管理应用的平台</p><ul><li>Deis</li><li>Flynn</li><li>Dokku</li></ul><h2 id="容器支持技术"><a href="#容器支持技术" class="headerlink" title="容器支持技术"></a>容器支持技术</h2><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AE%B9%E5%99%A8%E6%94%AF%E6%8C%81%E6%8A%80%E6%9C%AF.png" class="" title="容器支持技术"><h3 id="容器网络"><a href="#容器网络" class="headerlink" title="容器网络"></a>容器网络</h3><p>容器的出现使网络拓扑变得更加动态和复杂。用户需要专门的解决方案来管理容器与容器，容器与其他实体之间的连通性和隔离性。</p><ul><li>docker network</li><li>flannel</li><li>weave</li><li>calico</li></ul><h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p>动态变化是微服务应用的一大特点。当负载增加时，集群会自动创建新的容器; 负载减小，多余的容器会被销毁。容器也会根据 host 的资源使用情况在不同的 host 中迁移，容器的 IP 和端口也会随之发生变化。那么就必须有一种机制可以让 client 能够知道如何访问容器提供的服务</p><ul><li>etcd</li><li>consul</li><li>zookeeper</li></ul><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul><li>docker ps/top/stats</li><li>docker stats API</li><li>sysdig</li><li>cAdvisor/Heapster</li><li>Weave Scope</li></ul><h3 id="数据管理"><a href="#数据管理" class="headerlink" title="数据管理"></a>数据管理</h3><ul><li>Rex-Ray</li></ul><h3 id="日志管理"><a href="#日志管理" class="headerlink" title="日志管理"></a>日志管理</h3><ul><li>docker logs<ul><li>是 Docker 原生的日志工具</li></ul></li><li>logsput</li></ul><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><ul><li>OpenSCAP</li></ul><h1 id="容器核心知识概述"><a href="#容器核心知识概述" class="headerlink" title="容器核心知识概述"></a>容器核心知识概述</h1><h2 id="什么是容器-Container"><a href="#什么是容器-Container" class="headerlink" title="什么是容器(Container)"></a>什么是容器(Container)</h2><p>容器是一种轻量级、可移植、自包含的软件打包<strong>技术</strong>, 使应用程序可以在几乎任何地方以相同的方式运行。</p><h3 id="容器与虚拟机"><a href="#容器与虚拟机" class="headerlink" title="容器与虚拟机"></a>容器与虚拟机</h3><ul><li>容器<ul><li>不会虚拟硬件层</li><li>用 namespace 和 cgroups 进行隔离<ul><li>namespace 使每个进程只看到它自己的系统视图 (文件, 进程, 网络接口, 主机名). 进程只能看到同一个命名空间下的资源。<ul><li>存在多种类型的多个命名空间. 所以一个进程属于每个类型的一个命名空间<ul><li>Mount (mnt)</li><li>ProcessID (pid)</li><li>Network (net)</li><li>Inter-process communication (ipd)</li><li>UTS</li><li>UserID (user)</li></ul></li><li>通过分派两个不同的 UTS 命名空间给一对进程, 能使他们看见不同的本地主机名</li><li>一个进程属于什么 Network 命名空间决定了运行在进程里的应用程序能看见什么网络接口.</li></ul></li><li>cgroups 限制了进程能使用的资源量(CPU, 内存, 网络带宽)<ul><li>cgroups 是一个 Linux 内核功能, 它被用来限制一个进程或者一组进程的资源使用</li></ul></li></ul></li><li>应用程序本身</li><li><strong>依赖</strong><ul><li>应用程序需要的库或其他软件容器在 Host 操作系统的用户空间中运行，与<strong>操作系统的其他进程隔离</strong></li><li>这一点显著区别于虚拟机</li></ul></li></ul></li><li>虚拟机<ul><li>在一个宿主的平台上又搭建出一个完全隔离的环境<ul><li>把 CPU, 内存, 硬盘, 网卡, 显卡, 声卡都虚拟化了</li><li>在一整套虚拟硬件的基础上，再搭建一个虚拟系统</li></ul></li><li>VMWare, KVM, Xen</li><li>为了运行应用，除了部署应用本身及其依赖，还得安装整个操作系统</li></ul></li></ul><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AE%B9%E5%99%A8%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA.png" class="" title="容器与虚拟机"><ol><li>每个虚拟机需要运行自己的一组系统进程, 这就产生了除组件进程消耗以外的额外计算资源损耗</li><li>一个容器仅仅是运行在宿主机上被隔离的单个进程, 仅消耗应用容器消耗的资源, 不会有其他进程的开销</li></ol><h2 id="为什么需要容器"><a href="#为什么需要容器" class="headerlink" title="为什么需要容器"></a>为什么需要容器</h2><blockquote><p>容器使软件具备了超强的可移植能力</p></blockquote><ul><li>一个应用包含多种服务，这些服务有自己所依赖的库和软件包</li><li>存在多种部署环境，服务在运行时可能需要动态迁移到不同的环境中</li></ul><p>Docker 将集装箱思想运用到软件打包上，为代码提供了一个基于容器的标准化运输系统。Docker 可以将任何应用极其依赖打包成一个轻量级、可移植、自包含的容器。容器可以运行在几乎所有的操作系统上。</p><p>只需要配置好标准的 runtime 环境，服务器就可以运行任何容器。容器消除了开发、测试、生产环境的不一致性。</p><h2 id="容器是怎么工作的"><a href="#容器是怎么工作的" class="headerlink" title="容器是怎么工作的"></a>容器是怎么工作的</h2><h3 id="Docker-架构"><a href="#Docker-架构" class="headerlink" title="Docker 架构"></a>Docker 架构</h3><p>Docker 的核心组件</p><ul><li>Docker 客户端: Client</li><li>Docker 服务端: Docker daemon</li><li>Docker 镜像: Image</li><li>Registry</li><li>Docker 容器: Container</li></ul><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/Docker%E6%9E%B6%E6%9E%84.png" class="" title="Docker架构"><ul><li>Docker 采用 Client/Server 架构。</li><li>客户端向服务端发送请求，服务端负责构建、运行和分发容器</li><li>客户端和服务端可以运行在同一个 Host 上，客户端也可以通过 socket 或 REST API 与远程的服务器通信</li></ul><h3 id="Docker-客户端"><a href="#Docker-客户端" class="headerlink" title="Docker 客户端"></a>Docker 客户端</h3><h3 id="Docker-服务端"><a href="#Docker-服务端" class="headerlink" title="Docker 服务端"></a>Docker 服务端</h3><h3 id="Docker-镜像"><a href="#Docker-镜像" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h3><p>可将 Docker 镜像看成只读模板，通过它可以创建 Docker 容器。</p><ul><li>从无到有创建镜像</li><li>下载并使用别人创建好的现成镜像</li><li>在现有镜像上创建新的镜像</li></ul><h3 id="Docker-容器"><a href="#Docker-容器" class="headerlink" title="Docker 容器"></a>Docker 容器</h3><p>Docker 容器就是 Docker 镜像运行的实例</p><h3 id="Registry"><a href="#Registry" class="headerlink" title="Registry"></a>Registry</h3><p>Registry 是存放 Docker 镜像的仓库，Registry 分私有和公有两种。</p><h1 id="Docker-镜像-1"><a href="#Docker-镜像-1" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h1><h2 id="镜像的内部结构"><a href="#镜像的内部结构" class="headerlink" title="镜像的内部结构"></a>镜像的内部结构</h2><h3 id="base-镜像"><a href="#base-镜像" class="headerlink" title="base 镜像"></a>base 镜像</h3><ul><li>不依赖其他镜像，从 scratch 构建</li><li>其他镜像可以以之为基础进行扩展</li><li>能称作 base 镜像的通常都是各种 Linux 发行版的 Docker 镜像<ul><li>Ubuntu</li><li>Debian</li><li>CentOS</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ docker pull centos<br>$ docker images centos<br>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE<br>centos              latest              0d120b6ccaa8        6 weeks ago         215MB<br></code></pre></td></tr></table></figure><h4 id="为什么-SIZE-这么小"><a href="#为什么-SIZE-这么小" class="headerlink" title="为什么 SIZE 这么小"></a>为什么 SIZE 这么小</h4><p>Linux 操作系统是由内核空间和用户空间构成的</p><ol><li>rootfs</li></ol><ul><li>rootfs (用户空间 文件系统)<ul><li>/dev</li><li>/proc</li><li>/bin</li><li>/etc</li><li>/usr</li><li>/tmp</li><li>…</li></ul></li><li>bootfs<ul><li>kernel (内核空间)</li></ul></li></ul><p>对于 base 镜像来说，底层直接用 host 的 kernel, 自己只需要提供 rootfs 就好了</p><ol start="2"><li><p>base 镜像提供的是最小安装的 Linux 发行版</p></li><li><p>支持多种 Linux OS</p></li></ol><h3 id="镜像的分层结构"><a href="#镜像的分层结构" class="headerlink" title="镜像的分层结构"></a>镜像的分层结构</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">FROM</span> debian<br><span class="hljs-keyword">RUN</span><span class="bash"> apt-get install emacs</span><br><span class="hljs-keyword">RUN</span><span class="bash"> apt-get install apache2</span><br><span class="hljs-keyword">CMD</span><span class="bash"> [<span class="hljs-string">&quot;/bin/bash&quot;</span>]</span><br></code></pre></td></tr></table></figure><ol><li>从 debian base 镜像上构建</li><li>安装 emacs 编辑器</li><li>安装 apache2</li><li>容器启动时运行 bash</li></ol><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/%E9%95%9C%E5%83%8F%E7%9A%84%E5%88%86%E5%B1%82%E7%BB%93%E6%9E%84.png" class="" title="镜像的分层结构"><h4 id="可写的容器层"><a href="#可写的容器层" class="headerlink" title="可写的容器层"></a>可写的容器层</h4><ul><li>当容器启动的时候，一个新的可写层被加载到镜像的顶端</li><li>通常被称为<strong>容器层</strong>，<strong>容器层</strong>下面的叫做<strong>镜像层</strong></li></ul><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/%E9%95%9C%E5%83%8F%E5%B1%82.png" class="" title="镜像层"><p>所有对容器的改动，无论添加、删除还是修改文件都只会发生在容器层中。只有容器层是可写的，容器层下面的镜像层是只读的。只有当需要修改时才复制出一份数据，这种特性被称之为 Copy-on-Write. 可见容器保存的是镜像变化的部分，不会对镜像本身进行修改。</p><h2 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h2><h3 id="docker-commit"><a href="#docker-commit" class="headerlink" title="docker commit"></a>docker commit</h3><ul><li>运行容器</li><li>修改容器</li><li>将容器保存为新的镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ docker run -it ubuntu<br>root@d4729bbdc9fb:/<span class="hljs-comment">#</span><br><span class="hljs-comment"># -it 参数的作用是已交互模式进入容器，并打开终端。d4729bbdc9fb 是容器内部 ID</span><br></code></pre></td></tr></table></figure><p>// todo 跳过</p><h2 id="分发镜像"><a href="#分发镜像" class="headerlink" title="分发镜像"></a>分发镜像</h2><ul><li>用相同的 Dockerfile 在其他 host 构建镜像</li><li>将镜像上传到公共 Registry (比如 Docker Hub) Host 直接下载使用</li><li>搭建私有的 Registry 供本地 Host 使用</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>《每天5分钟玩转Docker容器技术》</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>理解GoLang中的Context</title>
    <link href="/2020/08/05/%E7%90%86%E8%A7%A3GoLang%E4%B8%AD%E7%9A%84Context/"/>
    <url>/2020/08/05/%E7%90%86%E8%A7%A3GoLang%E4%B8%AD%E7%9A%84Context/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在实际的业务开发中，经常会有碰到一个在父协程中启动一个子协程的情况。一直没有弄明白这个子协程的关闭到底是否依赖与父协程，并且应该如何与父协程进行通信。今天在此补作一笔。</p><h1 id="子协程的退出问题"><a href="#子协程的退出问题" class="headerlink" title="子协程的退出问题"></a>子协程的退出问题</h1><p>先说结论，子协程是不会随着父协程的结束而结束，可以通过GoLang的MPG模型来理解，在此不做赘述。具体可以通过代码来发现</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    fmt.Println(<span class="hljs-string">&quot;main 函数 开始...&quot;</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;父 协程 开始...&quot;</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;子 协程 执行中...&quot;</span>)<br>timer := time.NewTimer(time.Second * <span class="hljs-number">2</span>)<br>&lt;-timer.C<br>&#125;<br>&#125;()<br>time.Sleep(time.Second*<span class="hljs-number">5</span>)<br>fmt.Println(<span class="hljs-string">&quot;父 协程 退出...&quot;</span>)<br>&#125;()<br>time.Sleep(time.Second*<span class="hljs-number">10</span>)<br>fmt.Println(<span class="hljs-string">&quot;main 函数 退出&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs erlang">main 函数 开始...<br>父 协程 开始...<br>子 协程 执行中...<br>子 协程 执行中...<br>子 协程 执行中...<br>父 协程 退出...<br>子 协程 执行中...<br>子 协程 执行中...<br></code></pre></td></tr></table></figure><p>可以得到结论</p><ul><li><code>main</code>函数退出，所有协程退出</li><li>协程无父子关系，在父协程开启新的协程，若父协程退出，不会影响子协程</li></ul><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>那么如何实现父协程与子协程的通信问题呢</p><h2 id="Context-上下文"><a href="#Context-上下文" class="headerlink" title="Context 上下文"></a>Context 上下文</h2><p>先看方式</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    fmt.Println(<span class="hljs-string">&quot;main 函数 开始...&quot;</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>ctx, cancel := context.WithCancel(context.Background())<br><span class="hljs-keyword">defer</span> cancel()<br>fmt.Println(<span class="hljs-string">&quot;父 协程 开始...&quot;</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-ctx.Done():<br>fmt.Println(<span class="hljs-string">&quot;子 协程 接受停止信号...&quot;</span>)<br><span class="hljs-keyword">return</span><br><span class="hljs-keyword">default</span>:<br>fmt.Println(<span class="hljs-string">&quot;子 协程 执行中...&quot;</span>)<br>timer := time.NewTimer(time.Second * <span class="hljs-number">2</span>)<br>&lt;-timer.C<br>&#125;<br>&#125;<br>&#125;<br>&#125;(ctx)<br>time.Sleep(time.Second*<span class="hljs-number">5</span>)<br>fmt.Println(<span class="hljs-string">&quot;父 协程 退出...&quot;</span>)<br>&#125;()<br>time.Sleep(time.Second*<span class="hljs-number">10</span>)<br>fmt.Println(<span class="hljs-string">&quot;main 函数 退出&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs erlang">main 函数 开始...<br>父 协程 开始...<br>子 协程 执行中...<br>子 协程 执行中...<br>子 协程 执行中...<br>父 协程 退出...<br>子 协程 接受停止信号...<br>main 函数 退出<br></code></pre></td></tr></table></figure><p>总算了我心头一事🐶，原来<code>context</code>是这么使用的。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Context <span class="hljs-keyword">interface</span> &#123;<br>Deadline() (deadline time.Time, ok <span class="hljs-keyword">bool</span>)<br>Done() &lt;-<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;<br>Err() error<br>Value(key <span class="hljs-keyword">interface</span>&#123;&#125;) <span class="hljs-keyword">interface</span>&#123;&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中，</p><ol><li><code>Deadline</code>: 返回<code>context.Context</code>被取消的时间</li><li><code>Done</code>: 返回一个Channel,这个Channel会在当前工作完成或者上下文被取消之后关闭, 多次调用<code>Done</code>会返回同一个Channel</li><li><code>Err</code>: 返回 <code>context.Context</code> 结束的原因，它只会在 <code>Done</code> 返回的 Channel 被关闭时才会返回非空的值</li><li><code>Value</code>: 从 <code>context.Context</code> 中获取键对应的值，对于同一个上下文来说，多次调用 <code>Value</code> 并传入相同的<code>Key</code> 会返回相同的结果，该方法可以用来传递请求特定的数据</li></ol><h3 id="Context-设计原理"><a href="#Context-设计原理" class="headerlink" title="Context 设计原理"></a>Context 设计原理</h3><p>见参考文献</p><h2 id="Channel-管道"><a href="#Channel-管道" class="headerlink" title="Channel 管道"></a>Channel 管道</h2><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/">https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/</a></p><p><a href="https://blog.csdn.net/cdq1358016946/article/details/106380790?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param">https://blog.csdn.net/cdq1358016946/article/details/106380790?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>RPC框架</title>
    <link href="/2020/07/23/RPC%E6%A1%86%E6%9E%B6/"/>
    <url>/2020/07/23/RPC%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="RPC-定义"><a href="#RPC-定义" class="headerlink" title="RPC 定义"></a>RPC 定义</h1><p>RPC是一种技术思想而非一种规范或协议，常见的RPC技术和框架有</p><ul><li>应用级的服务框架：阿里的Dubbo/Dubbox, Google的gRPC, Spring Boot/Spring Cloud</li><li>远程通信协议：RMI, Socket, SOAP(HTTP XML), REST(HTTP JSON)</li><li>通信框架：MINA和Netty</li></ul><p>RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。</p><h1 id="RPC-流程"><a href="#RPC-流程" class="headerlink" title="RPC 流程"></a>RPC 流程</h1><img src="/2020/07/23/RPC%E6%A1%86%E6%9E%B6/RPC%E6%A1%86%E6%9E%B6%E5%9B%BE.png" class="" title="RPC框架图"><ol><li>本地调用某个函数方法</li><li>本地机器的RPC框架把这个调用信息封装起来（调用的函数、入参等），序列化(json、xml等)后，通过网络传输发送给远程服务器。</li><li>远程服务器收到调用请求后，远程机器的RPC框架反序列化获得调用信息，并根据调用信息定位到实际要执行的方法，执行完这个方法后，序列化执行结果，通过网络传输把执行结果发送回本地机器。</li><li>本地机器的RPC框架反序列化出执行结果，函数return这个结果</li></ol><h1 id="GO-RPC-源码分析"><a href="#GO-RPC-源码分析" class="headerlink" title="GO RPC 源码分析"></a>GO RPC 源码分析</h1><h2 id="server端"><a href="#server端" class="headerlink" title="server端"></a>server端</h2><ul><li><p>server端首先进行方法注册，通过反射处理将方法取出后存到map中。</p></li><li><p>然后进行网络调用，主要是监听端口，读取数据包，解码请求，调用反射处理后的方法，将返回值编码，返回给客户端。</p><h3 id="方法注册"><a href="#方法注册" class="headerlink" title="方法注册"></a>方法注册</h3></li><li><p>Register</p></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Register publishes the receiver&#x27;s methods in the DefaultServer.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Register</span><span class="hljs-params">(rcvr <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">error</span></span> &#123; <span class="hljs-keyword">return</span> DefaultServer.Register(rcvr) &#125;<br><br><span class="hljs-comment">// RegisterName is like Register but uses the provided name for the type</span><br><span class="hljs-comment">// instead of the receiver&#x27;s concrete type.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">RegisterName</span><span class="hljs-params">(name <span class="hljs-keyword">string</span>, rcvr <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">error</span></span> &#123;<br><span class="hljs-keyword">return</span> DefaultServer.RegisterName(name, rcvr)<br>&#125;<br></code></pre></td></tr></table></figure><p>方法注册的入口函数有两个,分别为Register以及RegisterName,这里interface{}通常是带方法的对象.如果想要自定义方法的接收对象,则可以使用RegisterName.</p><ul><li>反射处理过程<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> methodType <span class="hljs-keyword">struct</span> &#123;<br>    sync.Mutex <span class="hljs-comment">// protects counters</span><br>    method     reflect.Method    <span class="hljs-comment">//反射后的函数</span><br>    ArgType    reflect.Type      <span class="hljs-comment">//请求参数的反射值</span><br>    ReplyType  reflect.Type      <span class="hljs-comment">//返回参数的反射值</span><br>    numCalls   <span class="hljs-keyword">uint</span>              <span class="hljs-comment">//调用次数</span><br>&#125;<br><br><br><span class="hljs-keyword">type</span> service <span class="hljs-keyword">struct</span> &#123;<br>    name   <span class="hljs-keyword">string</span>                 <span class="hljs-comment">// 服务名,这里通常为register时的对象名或自定义对象名</span><br>    rcvr   reflect.Value          <span class="hljs-comment">// 服务的接收者的反射值</span><br>    typ    reflect.Type           <span class="hljs-comment">// 接收者的类型</span><br>    method <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]*methodType <span class="hljs-comment">// 对象的所有方法的反射结果.</span><br>&#125;<br></code></pre></td></tr></table></figure>反射处理过程,其实就是将对象以及对象的方法,通过反射生成上面的结构,如注册<code>Arith.Multiply(xx,xx) error </code>这样的对象时,生成的结构为<code> map[&quot;Arith&quot;]service, service 中ethod为 map[&quot;Multiply&quot;]methodType</code>.</li></ul><h3 id="网络调用"><a href="#网络调用" class="headerlink" title="网络调用"></a>网络调用</h3><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://segmentfault.com/a/1190000013532622">https://segmentfault.com/a/1190000013532622</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>http和https的那些事</title>
    <link href="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><h2 id="HTTP-基本概念"><a href="#HTTP-基本概念" class="headerlink" title="HTTP 基本概念"></a>HTTP 基本概念</h2><p><b>HTTP（超文本传输协议，HyperText Transfer Protocol)</b>是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。是用于从WWW服务器传输超文本到本地浏览器的传输协议。默认使用80端口，HTTP客户端发起一个请求，建立一个到服务器指定端口（默认是80端口）的TCP连接，但是具体的通信不是在80端口。</p><p>我们可以把它拆成三个部分去理解</p><ul><li>超文本</li><li>传输</li><li>协议</li></ul><blockquote><p>协议</p></blockquote><p>HTTP 是一个用在计算机世界里的<strong>协议</strong>。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。</p><blockquote><p>传输 </p></blockquote><p>HTTP 协议是一个<strong>双向协议</strong></p><p>HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。</p><blockquote><p>超文本</p></blockquote><p>我们先来理解「文本」，在互联网早期的时候只是简单的字符文字，但现在「文本」的涵义已经可以扩展为图片、视频、压缩包等，在 HTTP 眼里这些都算作「文本」。</p><p>再来理解「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。</p><p>HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。</p><p>那么经过上面一系列分析，就可以给出比「超文本传输协议」这七个字更准确更有技术含量的答案：</p><blockquote><p>HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。</p></blockquote><p>HTTP协议和TCP协议是不冲突的，HTTP定义在七层协议中的应用层，TCP解决的是传输层的逻辑。HTTP使用TCP而不是UDP的原因在于（打开）一个网页必须传送很多数据，而TCP协议提供传输控制，按顺序组织数据，和错误纠正。所以<b>HTTP是一个基于TCP/IP通信协议来传递数据</b>。也要经过三次握手和四次挥手。</p><p><b>HTTP协议的瓶颈及其优化技巧都是基于TCP协议本身的特性。</b>如TCP建立连接时三次握手有1.5个RTT（round-trip time）的延迟，为了避免每次请求的都经历握手带来的延迟，应用层会选择不同策略的http长链接方案。(长连接和短连接会在下文中补充)又如TCP在建立连接的初期有慢启动（slow start）的特性，所以连接的重用总是比新建连接性能要好。</p><p>HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。HTTP/1.0是第一个在通讯中指定版本号的HTTP 协议版本，至今仍被广泛采用，特别是在代理服务器中。</p><p>HTTP/1.1是当前版本，持久连接被默认采用，并能很好地配合代理服务器工作，还支持以管道方式同时发送多个请求，以便降低线路负载，提高传输速度。HTTP／2.0在HTTP 1.x的基础上，大幅度的提高了web性能，减少了网络延迟。HTTP1.0和1.1在之后很长的一段时间内会一直并存，这是由于网络基础设施更新缓慢所决定的。</p><h3 id="常见的状态码"><a href="#常见的状态码" class="headerlink" title="常见的状态码"></a>常见的状态码</h3><h2 id="GET与POST"><a href="#GET与POST" class="headerlink" title="GET与POST"></a>GET与POST</h2><h2 id="HTTP-是无状态的"><a href="#HTTP-是无状态的" class="headerlink" title="HTTP 是无状态的"></a>HTTP 是无状态的</h2><p><a href="https://www.zhihu.com/question/23202402">https://www.zhihu.com/question/23202402</a></p><h2 id="HTTP-1-0"><a href="#HTTP-1-0" class="headerlink" title="HTTP 1.0"></a>HTTP 1.0</h2><p>HTTP 协议老的标准是HTTP/1.0，为了提高系统的效率，HTTP 1.0规定浏览器与服务器只保持<b>短暂的连接</b>，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。</p><p>但是，这也造成了一些性能上的缺陷，例如，一个包含有许多图像的网页文件中并没有包含真正的图像数据内容，而只是指明了这些图像的URL地址，当WEB浏览器访问这个网页文件时，浏览器首先要发出针对该网页文件的请求，当浏览器解析WEB服务器返回的该网页文档中的HTML内容时，发现其中的图像标签后，浏览器将根据标签中的src属性所指定的URL地址再次向服务器发出下载图像数据的请求。显然，访问一个包含有许多图像的网页文件的整个过程包含了多次请求和响应，每次请求和响应都需要建立一个单独的连接，每次连接只是传输一个文档和图像，上一次和下一次请求完全分离。即使图像文件都很小，但是客户端和服务器端每次建立和关闭连接却是一个相对比较费时的过程，并且会严重影响客户机和服务器的性能。当一个网页文件中包含JavaScript文件，CSS文件等内容时，也会出现类似上述的情况。</p><p>同时，带宽和延迟也是影响一个网络请求的重要因素。在网络基础建设已经使得带宽得到极大的提升的当下，大部分时候都是延迟在于响应速度。基于此会发现，http1.0被抱怨最多的就是<b>连接无法复用</b>，和<b>head of line blocking</b>这两个问题。理解这两个问题有一个十分重要的前提：客户端是依据域名来向服务器建立连接，一般PC端浏览器会针对单个域名的server同时建立6～8个连接，手机端的连接数则一般控制在4～6个。显然连接数并不是越多越好，资源开销和整体延迟都会随之增大。连接无法复用会导致每次请求都经历三次握手和慢启动。（多个连接的请求每次都要重新来）三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。head of line blocking会导致带宽无法被充分利用，以及后续健康请求被阻塞。</p><p>head of line blocking(holb)会导致健康的请求会被不健康的请求影响，而且这种体验的损耗受网络环境影响，出现随机且难以监控。为了解决holb带来的延迟，协议设计者设计了一种新的pipelining机制。pipelining只能适用于http1.1,而且由于使用苛刻，很多浏览器厂商并不支持。</p><p>tips: head of line blocking是队头阻塞，是指一列的第一个数据包（队头）受阻而导致整列数据报受阻。</p><h2 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP 1.1"></a>HTTP 1.1</h2><p>相较于HTTP1.0，HTTP1.1主要做了如下改动：</p><h3 id="长连接"><a href="#长连接" class="headerlink" title="长连接"></a>长连接</h3><ul><li>为了克服HTTP 1.0的这个缺陷，HTTP 1.1支持持久连接（HTTP/1.1的默认模式使用<strong>带流水线的持久连接</strong>），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。<ul><li>HTTP/1.1协议的持续连接有两种方式，即<strong>非流水线方式和流水线</strong>方式。非流水线方式的特点是，客户在收到前一个响应后才能发出下一个请求；流水线方式的特点是，客户在收到HTTP的响应报文之前就能接着发送新的请求报文。</li></ul></li><li>一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。</li><li>在 HTTP1.1 中默认开启 Connection： keep-alive，一定程度上弥补了 HTTP1.0 每次请求都要创建连接的缺点。</li></ul><h3 id="缓存处理"><a href="#缓存处理" class="headerlink" title="缓存处理"></a>缓存处理</h3><ul><li>在 HTTP1.0 中主要使用 header 里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。<h3 id="带宽优化及网络连接的使用"><a href="#带宽优化及网络连接的使用" class="headerlink" title="带宽优化及网络连接的使用"></a>带宽优化及网络连接的使用</h3></li><li>HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了range 头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</li></ul><h3 id="错误通知的管理"><a href="#错误通知的管理" class="headerlink" title="错误通知的管理"></a>错误通知的管理</h3><ul><li>在 HTTP1.1 中新增了24 个错误状态响应码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。</li></ul><h3 id="Host头处理"><a href="#Host头处理" class="headerlink" title="Host头处理"></a>Host头处理</h3><ul><li>在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个 IP 地址。HTTP1.1 的请求消息和响应消息都应支持 Host 头域，且请求消息中如果没有 Host 头域会报告一个错误（400 Bad Request）。</li><li>HTTP/1.0不支持文件断点续传，<code>RANGE:bytes</code>是HTTP/1.1新增内容，HTTP/1.0每次传送文件都是从文件头开始，即0字节处开始。<code>RANGE:bytes=XXXX</code>表示要求服务器从文件XXXX字节处开始传送，这就是我们平时所说的断点续传！</li><li>HTTP 1.1的持续连接，也需要增加新的请求头来帮助实现，例如，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。</li></ul><p>在http1.1，request和reponse头中都有可能出现一个connection的头，此header的含义是当client和server通信时对于长链接如何进行处理。<br>在http1.1中，client和server都是默认对方支持长链接的， 如果client使用http1.1协议，但又不希望使用长链接，则需要在header中指明connection的值为close；如果server方也不想支持长链接，则在response中也需要明确说明connection的值为close。不论request还是response的header中包含了值为close的connection，都表明当前正在使用的tcp链接在当天请求处理完毕后会被断掉。以后client再进行新的请求时就必须创建新的tcp链接了。</p><p>缺点：</p><ul><li>虽然HTTP1.1允许复用TCP连接，但是仍然没有解决队头阻塞的问题</li><li>HTTP1.x使用的都是<strong>明文</strong>传输，无法保证传输的安全性(后面会介绍使用HTTPS来增加传输的安全性)</li><li>HTTP1.x使用时，header里携带的内容过大，在一定程度上增加了传输的成本，并且每次请求 header 基本不怎么变化，尤其在移动端增加用户流量。</li><li><code>keep-alive</code>会给服务端带来巨大的性能压力，因为它在文件被请求后还保持了不必要的连接</li></ul><h2 id="SPDY-协议"><a href="#SPDY-协议" class="headerlink" title="SPDY 协议"></a>SPDY 协议</h2><p>SPDY 协议综合了HTTPS和HTTP两者于一体的传输协议</p><h3 id="降低延迟"><a href="#降低延迟" class="headerlink" title="降低延迟"></a>降低延迟</h3><ul><li><p>采用**多路复用(multiplexing)**。多路复用通过多个请求stream共享一个TCP连接的方式，解决了holb(head of line blocking)的问题，降低了延时同时提高了带宽的利用率。</p><h3 id="请求优先级"><a href="#请求优先级" class="headerlink" title="请求优先级"></a>请求优先级</h3></li><li><p>多路复用带来一个新的问题是，在连接共享的基础之上有可能会导致关键请求被阻塞。SPDY 允许给每个 request 设置优先级，这样重要的请求就会优先得到响应。比如浏览器加载首页，首页的 html 内容应该优先展示，之后才是各种静态资源文件，脚本文件等加载，这样可以保证用户能第一时间看到网页内容。</p><h3 id="header压缩"><a href="#header压缩" class="headerlink" title="header压缩"></a>header压缩</h3></li><li><p>前面提到 HTTP1.x 的 header 很多时候都是重复多余的。选择合适的压缩算法可以减小包的大小和数量。</p><h3 id="基于HTTPS的加密传输，大大提高了传输数据的可靠性"><a href="#基于HTTPS的加密传输，大大提高了传输数据的可靠性" class="headerlink" title="基于HTTPS的加密传输，大大提高了传输数据的可靠性"></a>基于HTTPS的加密传输，大大提高了传输数据的可靠性</h3><h3 id="服务端推送-server-push"><a href="#服务端推送-server-push" class="headerlink" title="服务端推送(server push)"></a>服务端推送(server push)</h3></li><li><p>采用了SPDY的网页</p><h3 id="SPDY构成图"><a href="#SPDY构成图" class="headerlink" title="SPDY构成图:"></a>SPDY构成图:</h3>  <img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/SPDY.png" class="" title="SPDY"></li></ul><h2 id="HTTP-2-0"><a href="#HTTP-2-0" class="headerlink" title="HTTP 2.0"></a>HTTP 2.0</h2><p>HTTP 2.0是SPDY的升级版，主要有以下两点区别：</p><ul><li>HTTP2.0 支持明文 HTTP 传输，而 SPDY 强制使用 HTTPS</li><li>HTTP2.0 消息头的压缩算法采用 HPACK，而非 SPDY 采用的 DEFLATE</li></ul><h3 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a>二进制分帧</h3><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><ul><li>连接(Connection)<ul><li>一个TCP连接包含多个stream</li></ul></li><li>流(Stream)<ul><li>流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）</li><li>在建立连接后，一次的请求与被响应，可以看作流</li><li>一个双向通讯数据流，包含一条或多条message</li></ul></li><li>消息(Message)<ul><li>是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧(frame)组成。</li></ul></li><li>帧(Frame)<ul><li>客户端与服务器通过交换帧来通信，帧是基于这个新协议通信的最小单位，以二进制压缩格式存放 HTTP1.x 中的内容。</li><li>每一帧都包含几个字段,<code>length</code>, <code>type</code>, <code>flags</code>等。</li></ul></li></ul><p>HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。 HTTP / 1 的请求和响应报文，都是由起始行，首部和实体正文（可选）组成，各部分之间以文本换行符分隔。HTTP 2.0将请求和响应数据分割为更小的帧，并且它们采用二进制编码。</p><ul><li><p>帧、流、消息的关系</p>  <img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E6%B5%81-%E6%B6%88%E6%81%AF-%E5%B8%A7.png" class="" title="流-消息-帧"></li></ul><h3 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h3><p>多路复用代替原来的序列和阻塞机制，所有的请求都是通过一个TCP连接并发的完成。同时也很好的解决了浏览器限制同一个域名下的请求数量的问题。</p><ul><li>同域名下所有的通信都是在单个连接上完成，同个域名只需要占用一个TCP连接，使用一个连接并行发送多个请求和响应。</li><li>单个连接可以承载任意数量的双向数据流，单个连接上可以并行交错的请求和响应，之间互不干扰。</li><li>数据流以消息的形式发送，而消息又有一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。每个请求都可以带一个31bits的优先值，0表示最高优先级，数值越大优先级越低。</li></ul><p><a href="https://juejin.im/post/5d70848df265da03d871de9c">https://juejin.im/post/5d70848df265da03d871de9c</a></p><p>HTTP 2.0 的多路复用其实是 HTTP 1.1 中长连接的升级版本。</p><p>在 HTTP 1.1 中，一次链接成功后，只要该链接还没断开，那么 client 端可以在这么一个链接中有序地发起多个请求，并以此获得每个请求对应的响应数据。它的缺点是，一次请求与响应的交互必须要等待前面的请求交互完成，否则后面的只能等待，这个就是<b>线头阻塞.</b> 下面举个例子：</p><blockquote><p>请求A 和 请求B。A 先被发起，此时 server 端接收到了 A 请求，正在处理。同时 B 请求也发过来了。但是 A 请求还没被返回，此时 B 请求只能等待。</p></blockquote><p>在 HTTP 2.0 中，一次链接成功后，只要链接还没断开，那么 client 端就可以在一个链接中并发地发起多个请求，每个请求及该请求的响应不需要等待其他的请求，某个请求任务耗时严重，不会影响到其它连接的正常执行。</p> <img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" class="" title="多路复用"><h3 id="首部压缩"><a href="#首部压缩" class="headerlink" title="首部压缩"></a>首部压缩</h3><p>HTTP1.x 的 header 带有大量信息，而且每次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的header大小，通讯双方各自cache一份header fields表，既<b>避免了重复 header 的传输</b>，<b>又减小了需要传输的大小</b>。</p><ul><li>HTTP 2.0 在客户端和服务端使用”首部表”来跟踪和存储之前发送的键 - 值对，不再重复发送header</li><li>首部表在HTTP 2.0 的连接存续期内始终存在，由客户端和服务器共同渐进地更新</li><li>每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值</li></ul><blockquote><p>示例：</p></blockquote> <img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E9%A6%96%E9%83%A8%E5%8E%8B%E7%BC%A9.png" class="" title="首部压缩"><h3 id="服务端推送"><a href="#服务端推送" class="headerlink" title="服务端推送"></a>服务端推送</h3><p>Server Push 即服务端能通过 push 的方式将客户端需要的内容预先推送过去，也叫 “cache push”. 服务器可以对一个客户端请求发送多个响应。服务器向客户端推送资源无需客户端明确地请求，服务端可以提前给客户端推送必要的资源，这样可以减少请求延迟时间，例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不是等到 HTML 解析到资源时发送请求。</p><p>tips: 所有推送的资源都遵守同源策略。 服务器必须遵循请求- 响应的循环，只能借着对请求的响应推送资源。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.jianshu.com/p/52d86558ca57">https://www.jianshu.com/p/52d86558ca57</a></p><p><a href="https://juejin.im/post/5d7082bcf265da03f233ed9b">https://juejin.im/post/5d7082bcf265da03f233ed9b</a></p><h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><h2 id="HTTPS-的加密方式"><a href="#HTTPS-的加密方式" class="headerlink" title="HTTPS 的加密方式"></a>HTTPS 的加密方式</h2><h3 id="加密方式"><a href="#加密方式" class="headerlink" title="加密方式"></a>加密方式</h3><ul><li>对称加密</li><li>非对称加密<h4 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h4></li></ul><img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png" class="" title="对称加密"><ul><li>定义<ul><li>需要对加密和解密使用相同密钥的加密算法。所谓对称，就是采用这种加密方法的双方使用方式用同样的密钥进行加密和解密。密钥是控制加密及解密过程的指令。算法是一组规则，规定如何进行加密和解密。</li></ul></li><li>算法实现<ul><li>可以参见<a href="https://juejin.im/post/5b48b0d7e51d4519962ea383">https://juejin.im/post/5b48b0d7e51d4519962ea383</a> 再次不作过多的叙述。</li></ul></li></ul><h4 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h4><p>由于使用对称加密的话，密钥是使用明文传输的，任然存在被截取的风险，这就是非对称加密的由来。</p><img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png" class="" title="非对称加密"><ul><li>定义<ul><li>非对称加密算法需要两个密钥：公开密钥（publickey:简称公钥）和私有密钥（privatekey:简称私钥）。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密。如果用公钥对数据进行加密，只有用对应的私钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。</li></ul></li></ul><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>由于非对称加密在加密的时候速度特别慢，比对称加密慢了上百倍。所以我们选用对称加密+非对称加密的形式。</p><h3 id="对称加密-非对称加密："><a href="#对称加密-非对称加密：" class="headerlink" title="对称加密+非对称加密："></a>对称加密+非对称加密：</h3><p>服务器用明文的方式给客户端发送自己的公钥，客户端收到公钥之后，会生成一把密钥(对称加密用的)，然后用服务器的公钥对这把密钥进行加密，之后再把密钥传输给服务器，服务器收到之后进行解密，最后服务器就可以安全着得到这把密钥了，而客户端也有同样一把密钥，他们就可以进行对称加密了。</p><h3 id="风险"><a href="#风险" class="headerlink" title="风险"></a>风险</h3><p>服务器以明文的方式给客户端传输公钥的时候，中间人截取了这把属于服务器的公钥，并且把中间人自己的公钥冒充服务器的公钥传输给了客户端。之后客户端就会用中间人的公钥来加密自己生成的密钥。然后把被加密的密钥传输给服务器，这个时候中间人又把密钥给截取了，中间人用自己的私钥对这把被加密的密钥进行解密，解密后中间人就可以获得这把密钥了。最后中间人再对这把密钥用刚才服务器的公钥进行加密，再发给服务器。</p><p>非对称加密之所以不安全，是因为客户端不知道这把公钥是不是属于服务器的。如何解决这个问题呢，就需要引入<strong>数字证书</strong>。</p><h2 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h2><ul><li>我们需要找到一个拥有公信力、大家都认可的认证中心(CA)。</li><li>服务器在给客户端传输公钥的过程中，会把公钥以及服务器的个人信息通过Hash算法生成<strong>信息摘要</strong>。</li><li>为了防止信息摘要被人调换，客户端还会用CA提供的私钥对信息摘要进行加密来形成<strong>数字签名</strong>。</li><li>把原来没Hash算法之前的个人信息以及公钥 和 数字签名合并在一起，形成<strong>数字证书</strong>。</li></ul><img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6_%E6%9C%8D%E5%8A%A1%E7%AB%AF.png" class="" title="数字证书_服务端"><ul><li>当数字证书拿到这份数字证书的时候，就会用CA提供的公钥来对数字证书里面的数字签名进行解密来得到信息摘要，然后对数字证书里服务器的公钥以及个人信息进行Hash得到另外一份信息摘要。最后把两份信息摘要进行对比，如果一样，则证明这个人是服务器。</li></ul><img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6_%E5%AE%A2%E6%88%B7%E7%AB%AF.png" class="" title="数字证书_客户端"><blockquote><p>客户端如何获得CA的公钥, 服务器又怎么会有CA的私钥</p></blockquote><p>其实，(有些)服务器一开始就向认证中心申请了这些证书了(有没有看过没有证书的网站在地址栏会被标出警告？)，而客户端是，也会内置这些证书。当客户端收到服务器传输过来的数据数字证书时，就会在内置的证书列表里，查看是否有解开该数字证书的公钥。</p><h3 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://segmentfault.com/a/1190000019687184">https://segmentfault.com/a/1190000019687184</a></p><p><a href="https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/30-zhang-tu-jie-http-chang-jian-mian-shi-ti">https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/30-zhang-tu-jie-http-chang-jian-mian-shi-ti</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>kite框架和gin框架</title>
    <link href="/2020/07/13/kite%E6%A1%86%E6%9E%B6%E5%92%8Cgin%E6%A1%86%E6%9E%B6/"/>
    <url>/2020/07/13/kite%E6%A1%86%E6%9E%B6%E5%92%8Cgin%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>字符编码</title>
    <link href="/2020/07/11/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/"/>
    <url>/2020/07/11/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>IO那些事</title>
    <link href="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<p>本来计划七月OKR了解一下经常面经中看到但是不很了解的“I/O多路复用”，发现自己在整理序列化，反序列化的时候连基本的I/O也没有整明白，于是搜集资料准备好好梳理一下</p><h1 id="为什么使用I-O"><a href="#为什么使用I-O" class="headerlink" title="为什么使用I/O"></a>为什么使用I/O</h1><ul><li>当我们的程序需要从硬盘，网络，或其他应用程序中读取或写入数据时候，数据传输量可能很大，而我们的内存或带宽有限，<strong>无法一次性读取获取写入大量数据</strong>。</li><li>而流（Stream）可以实现一点一点的逐步传输数据。</li><li>想想我们是怎样下载一个大文件的, 下载软件(例如x雷)并不会占用你内存很大的空间, 而只是在内存划分一个缓冲区, 一点一点地下载到自己的内存(缓冲区满了再写到硬盘)。</li></ul><h1 id="I-O在Java中的架构"><a href="#I-O在Java中的架构" class="headerlink" title="I/O在Java中的架构"></a>I/O在Java中的架构</h1><h2 id="I-O-的分类"><a href="#I-O-的分类" class="headerlink" title="I/O 的分类"></a>I/O 的分类</h2><h3 id="从流的方向划分"><a href="#从流的方向划分" class="headerlink" title="从流的方向划分"></a>从流的方向划分</h3><ul><li><p>输入流 (I)</p><ul><li>  <img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/Input.jpg" class="" title="Input"></li></ul></li><li><p>输出流 (O)</p><ul><li>  <img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/Output.jpg" class="" title="Output"><h3 id="从流的传输单位来分"><a href="#从流的传输单位来分" class="headerlink" title="从流的传输单位来分"></a>从流的传输单位来分</h3></li></ul></li><li><p>字节流 (8位字节)</p><ul><li>每次读取（写出）一个字节，当传输资源有中文时，就会出现乱码。</li><li>具体参见 为什么会乱码 // TODO</li></ul></li><li><p>字符流 (16位字节)</p><ul><li>每次读取（写出）两个字节，有中文时，使用流程就可以正确传输显示中文。<h2 id="Java中的分类"><a href="#Java中的分类" class="headerlink" title="Java中的分类"></a>Java中的分类</h2></li></ul></li><li><p>四大基本类型</p><table><thead><tr><th></th><th>输入流</th><th>输出流</th></tr></thead><tbody><tr><td>字节流</td><td>InputStream 字节输入流</td><td>OutputStream 字符输出流</td></tr><tr><td>字符流</td><td>Reader 字符输入流</td><td>Writer 字符输出流</td></tr></tbody></table></li><li><p>各自的子类都以父类作为自己的后缀，比如文件的字节输出流：FileOutputStream</p><h2 id="Java中的架构"><a href="#Java中的架构" class="headerlink" title="Java中的架构"></a>Java中的架构</h2></li><li><img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/JavaIO%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class="" title="JavaIO体系架构图"></li><li><p>流的选择</p><ul><li>选用输入流还是输出流，根据具体的使用场景判断，如果是写程序到别的地方，那么就使用输出流。反之就是输入流。</li><li>如果传输的数据有中文，那么选择字符流。</li><li>再根据额外需要的功能具体选择。<h2 id="Java底层实现"><a href="#Java底层实现" class="headerlink" title="Java底层实现"></a>Java底层实现</h2><h3 id="字节输入流-InputStream"><a href="#字节输入流-InputStream" class="headerlink" title="字节输入流 InputStream"></a>字节输入流 InputStream</h3></li></ul></li><li>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">InputStream</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Closeable</span> </span>&#123;<br><br>    <span class="hljs-comment">// Reads the next byte of data from the input stream.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-keyword">int</span> <span class="hljs-title">read</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException</span>;<br><br><br>    <span class="hljs-comment">// Closes this stream and releases any system resources associated with it.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;&#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">    Skips over and discards n bytes of data from this inputstream.</span><br><span class="hljs-comment">    <span class="hljs-doctag">@return</span>     the actual number of bytes skipped.</span><br><span class="hljs-comment">    */</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">skip</span><span class="hljs-params">(<span class="hljs-keyword">long</span> n)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-comment">// ...</span><br>    &#125;<br><br><br>    <span class="hljs-comment">// Returns an estimate of the number of bytes that can be read (or skipped over) from this input stream without blocking by the next invocation of a method for this input stream.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">available</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;###<br><br>    <span class="hljs-comment">// Marks the current position in this input stream</span><br>    <span class="hljs-comment">// 如果从标记处开始往后，已经获取或者跳过了readLimit个字节，那么这个标记失效，不允许再重新通过reset回到这个位置。</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-keyword">void</span> <span class="hljs-title">mark</span><span class="hljs-params">(<span class="hljs-keyword">int</span> readlimit)</span> </span>&#123;&#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reset</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> IOException(<span class="hljs-string">&quot;mark/reset not supported&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="ByteArrayInputStream"><a href="#ByteArrayInputStream" class="headerlink" title="ByteArrayInputStream"></a>ByteArrayInputStream</h4><p>字节数组输入流，该类的功能就是从字节数组 byte[] 中进行以字节为单位的读取，也就是将资源文件都以字节形式存入到该类中的字节数组中去，我们拿数据也是从这个字节数组中拿。</p><h4 id="PipedInputStream"><a href="#PipedInputStream" class="headerlink" title="PipedInputStream"></a>PipedInputStream</h4><p>管道字节输入流，它和 PipedOutputStream 一起使用，能实现多线程间的管道通信。</p><h4 id="FilterInputStream"><a href="#FilterInputStream" class="headerlink" title="FilterInputStream"></a>FilterInputStream</h4><p>装饰者模式中充当装饰者的角色，具体的装饰者都要继承它，所以在该类的子类下都是用来装饰别的流的，也就是处理类。</p><h4 id="BufferedInputStream"><a href="#BufferedInputStream" class="headerlink" title="BufferedInputStream"></a>BufferedInputStream</h4><p>缓冲流，对处理流进行装饰、增强，内部会有一个缓冲区，用来存放字节，每次都是将缓冲区存满然后发送，而不是一个字节或两个字节这样发送，效率更高。</p><h4 id="DataInputStream"><a href="#DataInputStream" class="headerlink" title="DataInputStream"></a>DataInputStream</h4><p>数据输入流，用来装饰其他输入流，它允许通过数据流来读写Java基本类型。</p><h4 id="FileInputStream"><a href="#FileInputStream" class="headerlink" title="FileInputStream"></a>FileInputStream</h4><p>文件输入流，通常用于对文件进行读取操作。</p><h4 id="File"><a href="#File" class="headerlink" title="File"></a>File</h4><p>对指定目录的文件进行操作。</p><h4 id="ObjectInputStream"><a href="#ObjectInputStream" class="headerlink" title="ObjectInputStream"></a>ObjectInputStream</h4><p>对象输入流，用来提供对“基本数据或对象”的持久存储。通俗点讲，就是能直接传输Java对象（序列化、反序列化用。</p><h3 id="字节输出流-OutputStream"><a href="#字节输出流-OutputStream" class="headerlink" title="字节输出流 OutputStream"></a>字节输出流 OutputStream</h3></li><li>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">OutputStream</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Closeable</span>, <span class="hljs-title">Flushable</span> </span>&#123;<br><br>    <span class="hljs-comment">// Writes the specified byte to this output stream.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-keyword">void</span> <span class="hljs-title">write</span><span class="hljs-params">(<span class="hljs-keyword">byte</span> b[])</span> <span class="hljs-keyword">throws</span> IOException</span>;<br><br>    <span class="hljs-comment">// Flushes this stream by writing any buffered output to the underlying stream.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">flush</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;&#125;<br><br>    <span class="hljs-comment">// Closes this stream and releases any system resources associated with it.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="缓冲区的作用"><a href="#缓冲区的作用" class="headerlink" title="缓冲区的作用"></a>缓冲区的作用</h4><p>为了<strong>加快数据传输速度</strong>，<strong>提高数据输出效率</strong>，又是输出数据流会在提交数据之前把所要输出的数据先暂时保存在内存缓冲区中，然后成批进行输出，每次传输过程都以某特定数据长度为单位进行传输，在这种方式下，数据的末尾一般都会有一部分数据由于数量不够一个批次，而存留在缓冲区里，调用 flush() 方法可以将这部分数据强制提交。</p></li></ul><h3 id="字符输入流-Reader"><a href="#字符输入流-Reader" class="headerlink" title="字符输入流 Reader"></a>字符输入流 Reader</h3><img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AD%97%E7%AC%A6%E8%BE%93%E5%85%A5%E6%B5%81.png" class="" title="字符输入流"><p>Reader 中各个类的用途和使用方法基本和InputStream 中的类使用一致。</p><h3 id="字符输出流-Writer"><a href="#字符输出流-Writer" class="headerlink" title="字符输出流 Writer"></a>字符输出流 Writer</h3><img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AD%97%E7%AC%A6%E8%BE%93%E5%87%BA%E6%B5%81.png" class="" title="字符输出流"><h2 id="字节流与字符流的区别"><a href="#字节流与字符流的区别" class="headerlink" title="字节流与字符流的区别"></a>字节流与字符流的区别</h2><ul><li>字节流操作的基本单元为字节；字符流操作的基本单元为Unicode码元。</li><li>字节流默认不使用缓冲区；字符流使用缓冲区。</li><li>字节流通常用于处理二进制数据，实际上它可以处理任意类型的数据，但它不支持直接写入或读取Unicode码元；字符流通常处理文本数据，它支持写入及读取Unicode码元。</li></ul><h2 id="字节流与字符流使用场景"><a href="#字节流与字符流使用场景" class="headerlink" title="字节流与字符流使用场景"></a>字节流与字符流使用场景</h2><ul><li>字节流：图像，视频，PPT, Word, 纯文本</li><li>字符流：纯文本类型（TXT), 不能处理图像视频等非文本类型的文件</li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://juejin.im/post/5d4ee73ae51d4561c94b0f9d">https://juejin.im/post/5d4ee73ae51d4561c94b0f9d</a><br><a href="https://zhuanlan.zhihu.com/p/109941007">https://zhuanlan.zhihu.com/p/109941007</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>序列化和反序列化</title>
    <link href="/2020/07/10/%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <url>/2020/07/10/%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<p>鉴于面试的时候被这个问题虐的实在太惨了，每次都只能说自己只是使用过，遂今天深挖一下这个底层的实现原理。</p><p>序列化与反序列化是一个标准，它是编程语言的一种共性，只是有些编程语言是内置的（如Java，PHP等），有些语言是通过第三方库来实现的（如C/C++）。</p><h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><ul><li>对象的持久化（将对象内容保存到数据库或文件中）</li><li>远程数据传输（将对象发送给其他计算机系统）</li></ul><h1 id="序列化协议的选择"><a href="#序列化协议的选择" class="headerlink" title="序列化协议的选择"></a>序列化协议的选择</h1><ul><li>通用性<ul><li>是否只能用于Java间序列化/反序列化，是否跨语言，跨平台</li></ul></li><li>性能<ul><li>空间开销：序列化后的数据一般用于存储或网络传输，其大小是很重要的一个参数</li><li>时间开销：解析的时间也影响了序列化协议的选择</li></ul></li><li>可扩展性<ul><li>系统升级不可避免，某一实体的属性变更，会不会导致反序列化异常</li></ul></li><li>易用性<ul><li>API使用是否复杂</li></ul></li></ul><h1 id="Java中的序列化与反序列化-（JDK-序列化）"><a href="#Java中的序列化与反序列化-（JDK-序列化）" class="headerlink" title="Java中的序列化与反序列化 （JDK 序列化）"></a>Java中的序列化与反序列化 （JDK 序列化）</h1><h2 id="实现Serializable接口的类"><a href="#实现Serializable接口的类" class="headerlink" title="实现Serializable接口的类"></a>实现Serializable接口的类</h2><p>jdk会自动帮我们序列化该类所有的信息，但如果用户定义了writeObject和readObject方法，那么在序列化和反序列化的时候会通过反射优先调用自定义的方法。默认情况会跳过transient修饰的对象。</p><h2 id="实现Externalizable接口的类"><a href="#实现Externalizable接口的类" class="headerlink" title="实现Externalizable接口的类"></a>实现Externalizable接口的类</h2><p>需要用户自定义序列化和反序列化的逻辑，分别重写writeExternal和readExternal方法。</p><h2 id="序列化具体步骤"><a href="#序列化具体步骤" class="headerlink" title="序列化具体步骤"></a>序列化具体步骤</h2><ol><li>创建一个对象输出流，它可以包装一个其它类型的目标输出流，如文件输出流：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Java">ObjectOutputStream oos = <span class="hljs-keyword">new</span> ObjectOutputStream(<span class="hljs-keyword">new</span> FileOutputStream(<span class="hljs-string">&quot;D:\object.out&quot;</span>));<br></code></pre></td></tr></table></figure><ol start="2"><li>通过对象输出流的writeObject()方法写对象：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Java">oos.writeObject(<span class="hljs-keyword">new</span> User(<span class="hljs-string">&quot;xuliugen&quot;</span>, <span class="hljs-string">&quot;123456&quot;</span>, <span class="hljs-string">&quot;male&quot;</span>));<br></code></pre></td></tr></table></figure><h2 id="反序列化的具体步骤"><a href="#反序列化的具体步骤" class="headerlink" title="反序列化的具体步骤"></a>反序列化的具体步骤</h2><ol><li>创建一个对象输入流，它可以包装一个其它类型输入流，如文件输入流：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Java">ObjectInputStream ois= <span class="hljs-keyword">new</span> ObjectInputStream(<span class="hljs-keyword">new</span> FileInputStream(<span class="hljs-string">&quot;object.out&quot;</span>));<br></code></pre></td></tr></table></figure><ol start="2"><li>通过对象输出流的readObject()方法读取对象：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Java">User user = (User) ois.readObject();<br></code></pre></td></tr></table></figure><h2 id="底层分析"><a href="#底层分析" class="headerlink" title="底层分析"></a>底层分析</h2><p>一般来说，在网上搜索序列化就是这些api的使用方法，但是我想去深挖一下这个<code>readObject</code>和<code>writeObject</code>的背后原理。隐隐感觉和反射有关。</p><h3 id="ObjectOutputStream的构造器"><a href="#ObjectOutputStream的构造器" class="headerlink" title="ObjectOutputStream的构造器"></a>ObjectOutputStream的构造器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/** if true, invoke writeObjectOverride() instead of writeObject() */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">boolean</span> enableOverride;<br><br><span class="hljs-comment">/** filter stream for handling block data conversion */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> BlockDataOutputStream bout;<br><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ObjectOutputStream</span><span class="hljs-params">(OutputStream out)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    verifySubclass();<br><br><br>    <span class="hljs-comment">// bout 是底层的字节数据容器</span><br>    bout = <span class="hljs-keyword">new</span> BlockDataOutputStream(out);<br>    handles = <span class="hljs-keyword">new</span> HandleTable(<span class="hljs-number">10</span>, (<span class="hljs-keyword">float</span>) <span class="hljs-number">3.00</span>);<br>    subs = <span class="hljs-keyword">new</span> ReplaceTable(<span class="hljs-number">10</span>, (<span class="hljs-keyword">float</span>) <span class="hljs-number">3.00</span>);<br><br>    enableOverride = <span class="hljs-keyword">false</span>;<br><br>    writeStreamHeader(); <span class="hljs-comment">// 写入文件头</span><br>    bout.setBlockDataMode(<span class="hljs-keyword">true</span>); <span class="hljs-comment">// flush数据</span><br>    <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>        debugInfoStack = <span class="hljs-keyword">new</span> DebugTraceInfoStack();<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        debugInfoStack = <span class="hljs-keyword">null</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>构造函数中首先会把bout绑定到底层的字节数据容器，然后调用<code>writeStreamHeader</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeStreamHeader</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    bout.writeShort(STREAM_MAGIC);<br>    bout.writeShort(STREAM_VERSION);<br>&#125;<br></code></pre></td></tr></table></figure><p>在writeStreamHeader()方法中首先会往底层字节容器中写入表示序列化的Magic Number以及版本号</p><h3 id="writeObject"><a href="#writeObject" class="headerlink" title="writeObject"></a>writeObject</h3><p>先贴上一段具体的实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">    Write the specified object to the ObjectOutputStream.   </span><br><span class="hljs-comment">*/</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeObject</span><span class="hljs-params">(Object obj)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    <span class="hljs-keyword">if</span> (enableOverride) &#123;<br>        writeObjectOverride(obj);<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-keyword">try</span> &#123;<br>        writeObject0(obj, <span class="hljs-keyword">false</span>);<br>    &#125; <span class="hljs-keyword">catch</span> (IOException ex) &#123;<br>        <span class="hljs-keyword">if</span> (depth == <span class="hljs-number">0</span>) &#123;<br>            writeFatalException(ex);<br>        &#125;<br>        <span class="hljs-keyword">throw</span> ex;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们可以发现这里直接走到了<code>writeObject0</code>函数，继续跟踪</p><h4 id="writeObject0"><a href="#writeObject0" class="headerlink" title="writeObject0"></a>writeObject0</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Underlying writeObject/writeUnshared implementation.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeObject0</span><span class="hljs-params">(Object obj, <span class="hljs-keyword">boolean</span> unshared)</span></span><br><span class="hljs-function">    <span class="hljs-keyword">throws</span> IOException</span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">boolean</span> oldMode = bout.setBlockDataMode(<span class="hljs-keyword">false</span>);<br>    depth++;<br>    <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-comment">// handle previously written and non-replaceable objects</span><br>        <span class="hljs-keyword">int</span> h;<br>        <span class="hljs-keyword">if</span> ((obj = subs.lookup(obj)) == <span class="hljs-keyword">null</span>) &#123;<br>            writeNull();<br>            <span class="hljs-keyword">return</span>;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!unshared &amp;&amp; (h = handles.lookup(obj)) != -<span class="hljs-number">1</span>) &#123;<br>            writeHandle(h);<br>            <span class="hljs-keyword">return</span>;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Class) &#123;<br>            writeClass((Class) obj, unshared);<br>            <span class="hljs-keyword">return</span>;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> ObjectStreamClass) &#123;<br>            writeClassDesc((ObjectStreamClass) obj, unshared);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br><br>        <span class="hljs-comment">// check for replacement object</span><br>        Object orig = obj;<br>        <span class="hljs-comment">// 获取对象的类型</span><br>        Class&lt;?&gt; cl = obj.getClass();<br>        ObjectStreamClass desc;<br>        <span class="hljs-keyword">for</span> (;;) &#123;<br>            <span class="hljs-comment">// REMIND: skip this check for strings/arrays?</span><br>            Class&lt;?&gt; repCl;<br>            desc = ObjectStreamClass.lookup(cl, <span class="hljs-keyword">true</span>);<br>            <span class="hljs-keyword">if</span> (!desc.hasWriteReplaceMethod() ||<br>                (obj = desc.invokeWriteReplace(obj)) == <span class="hljs-keyword">null</span> ||<br>                (repCl = obj.getClass()) == cl)<br>            &#123;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            cl = repCl;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (enableReplace) &#123;<br>            Object rep = replaceObject(obj);<br>            <span class="hljs-keyword">if</span> (rep != obj &amp;&amp; rep != <span class="hljs-keyword">null</span>) &#123;<br>                cl = rep.getClass();<br>                desc = ObjectStreamClass.lookup(cl, <span class="hljs-keyword">true</span>);<br>            &#125;<br>            obj = rep;<br>        &#125;<br><br>        <span class="hljs-comment">// if object replaced, run through original checks a second time</span><br>        <span class="hljs-keyword">if</span> (obj != orig) &#123;<br>            subs.assign(orig, obj);<br>            <span class="hljs-keyword">if</span> (obj == <span class="hljs-keyword">null</span>) &#123;<br>                writeNull();<br>                <span class="hljs-keyword">return</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!unshared &amp;&amp; (h = handles.lookup(obj)) != -<span class="hljs-number">1</span>) &#123;<br>                writeHandle(h);<br>                <span class="hljs-keyword">return</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Class) &#123;<br>                writeClass((Class) obj, unshared);<br>                <span class="hljs-keyword">return</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> ObjectStreamClass) &#123;<br>                writeClassDesc((ObjectStreamClass) obj, unshared);<br>                <span class="hljs-keyword">return</span>;<br>            &#125;<br>        &#125;<br><br><br>        <span class="hljs-comment">// remaining cases</span><br>        <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> String) &#123;<br>            writeString((String) obj, unshared);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cl.isArray()) &#123;<br>            writeArray(obj, desc, unshared);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Enum) &#123;<br>            writeEnum((Enum&lt;?&gt;) obj, desc, unshared);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Serializable) &#123;<br>            writeOrdinaryObject(obj, desc, unshared);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>                <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NotSerializableException(<br>                    cl.getName() + <span class="hljs-string">&quot;\n&quot;</span> + debugInfoStack.toString());<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NotSerializableException(cl.getName());<br>            &#125;<br>        &#125;<br>    &#125; <span class="hljs-keyword">finally</span> &#123;<br>        depth--;<br>        bout.setBlockDataMode(oldMode);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>看到了熟悉的反射，来分析一下这个<code>writeObject0</code>具体是怎么实现的</p><p>具体看到最后的部分</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Java"><br><span class="hljs-comment">// remaining cases</span><br><span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> String) &#123;<br>    writeString((String) obj, unshared);<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cl.isArray()) &#123;<br>    writeArray(obj, desc, unshared);<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Enum) &#123;<br>    writeEnum((Enum&lt;?&gt;) obj, desc, unshared);<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Serializable) &#123;<br>    writeOrdinaryObject(obj, desc, unshared);<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NotSerializableException(<br>            cl.getName() + <span class="hljs-string">&quot;\n&quot;</span> + debugInfoStack.toString());<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NotSerializableException(cl.getName());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这就告诉我们如果是简单的String, Array, Enum类型可以直接序列化，如果是通过实现<code>Serializable</code>接口的话，那么会继续往下调用<code>writeOrdinaryObject</code>, 这里具体的参数obj是我们要序列化的对象，desc是我们要序列化对象的class description</p><p>tips: 如果我们进到<code>Serializable</code>接口内部的时候会发现这是一个空的接口，实际上，它的作用只是在这里为我们做一个标识。</p><p>继续往下</p><h4 id="writeOrdinaryObject"><a href="#writeOrdinaryObject" class="headerlink" title="writeOrdinaryObject"></a>writeOrdinaryObject</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs Java"><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Writes representation of a &quot;ordinary&quot; (i.e., not a String, Class,</span><br><span class="hljs-comment"> * ObjectStreamClass, array, or enum constant) serializable object to the</span><br><span class="hljs-comment"> * stream.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeOrdinaryObject</span><span class="hljs-params">(Object obj, ObjectStreamClass desc, <span class="hljs-keyword">boolean</span> unshared)</span> <span class="hljs-keyword">throws</span> IOException</span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>        debugInfoStack.push(<br>            (depth == <span class="hljs-number">1</span> ? <span class="hljs-string">&quot;root &quot;</span> : <span class="hljs-string">&quot;&quot;</span>) + <span class="hljs-string">&quot;object (class \&quot;&quot;</span> +<br>            obj.getClass().getName() + <span class="hljs-string">&quot;\&quot;, &quot;</span> + obj.toString() + <span class="hljs-string">&quot;)&quot;</span>);<br>    &#125;<br>    <span class="hljs-keyword">try</span> &#123;<br>        desc.checkSerialize();<br><br>        <span class="hljs-comment">// 写入Object标志位</span><br>        bout.writeByte(TC_OBJECT);<br>        <span class="hljs-comment">// 写入类元数据</span><br>        writeClassDesc(desc, <span class="hljs-keyword">false</span>);<br>        handles.assign(unshared ? <span class="hljs-keyword">null</span> : obj);<br>        <span class="hljs-keyword">if</span> (desc.isExternalizable() &amp;&amp; !desc.isProxy()) &#123;<br>            writeExternalData((Externalizable) obj);  <span class="hljs-comment">// 写入被序列化的对象的实例数据</span><br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            writeSerialData(obj, desc);<br>        &#125;<br>    &#125; <span class="hljs-keyword">finally</span> &#123;<br>        <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>            debugInfoStack.pop();<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>在这个方法中首先会往底层字节容器中写入TC_OBJECT，表示这是一个新的Object</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">* new Object.</span><br><span class="hljs-comment">*/</span><br><span class="hljs-keyword">final</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">byte</span> TC_OBJECT =       (<span class="hljs-keyword">byte</span>)<span class="hljs-number">0x73</span>;<br></code></pre></td></tr></table></figure><p>接下来会调用writeClassDesc()方法写入被序列化对象的类的类元数据</p><h4 id="writeClassDesc"><a href="#writeClassDesc" class="headerlink" title="writeClassDesc"></a>writeClassDesc</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">// 写入被序列化对象的类的类元数据</span><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeClassDesc</span><span class="hljs-params">(ObjectStreamClass desc, <span class="hljs-keyword">boolean</span> unshared)</span> <span class="hljs-keyword">throws</span> IOException</span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">int</span> handle;<br>    <span class="hljs-keyword">if</span> (desc == <span class="hljs-keyword">null</span>) &#123;<br>        <span class="hljs-comment">// 如果desc为null</span><br>        writeNull();<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!unshared &amp;&amp; (handle = handles.lookup(desc)) != -<span class="hljs-number">1</span>) &#123;<br>        writeHandle(handle);<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (desc.isProxy()) &#123;<br>        writeProxyDesc(desc, unshared);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        writeNonProxyDesc(desc, unshared);<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h5 id="writeNull"><a href="#writeNull" class="headerlink" title="writeNull()"></a>writeNull()</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeNull</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    <span class="hljs-comment">// TC_NULL =         (byte)0x70;</span><br>    <span class="hljs-comment">// 表示对一个Object引用的描述的结束</span><br>    bout.writeByte(TC_NULL);<br>&#125;<br></code></pre></td></tr></table></figure><h5 id="writeProxyDesc"><a href="#writeProxyDesc" class="headerlink" title="writeProxyDesc"></a>writeProxyDesc</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs Java">    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeNonProxyDesc</span><span class="hljs-params">(ObjectStreamClass desc, <span class="hljs-keyword">boolean</span> unshared)</span> <span class="hljs-keyword">throws</span> IOException</span><br><span class="hljs-function">    </span>&#123;<br>        <span class="hljs-comment">// TC_CLASSDESC =    (byte)0x72;</span><br>        <span class="hljs-comment">// 表示一个新的Class描述符</span><br>        bout.writeByte(TC_CLASSDESC);<br>        handles.assign(unshared ? <span class="hljs-keyword">null</span> : desc);<br> <br>        <span class="hljs-keyword">if</span> (protocol == PROTOCOL_VERSION_1) &#123;<br>            <span class="hljs-comment">// do not invoke class descriptor write hook with old protocol</span><br>            desc.writeNonProxy(<span class="hljs-keyword">this</span>);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            writeClassDescriptor(desc);<br>        &#125;<br> <br>        Class cl = desc.forClass();<br>        bout.setBlockDataMode(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">if</span> (cl != <span class="hljs-keyword">null</span> &amp;&amp; isCustomSubclass()) &#123;<br>            ReflectUtil.checkPackageAccess(cl);<br>        &#125;<br>        annotateClass(cl);<br>        bout.setBlockDataMode(<span class="hljs-keyword">false</span>);<br>        bout.writeByte(TC_ENDBLOCKDATA);<br> <br>        writeClassDesc(desc.getSuperDesc(), <span class="hljs-keyword">false</span>);<br>&#125;<br><br></code></pre></td></tr></table></figure><p>在这个方法中首先会写入一个字节的TC_CLASSDESC，这个字节表示接下来的数据是一个新的Class描述符，接着会调用writeNonProxy()方法写入实际的类元信息，writeNonProxy()实现如下:</p><h5 id="writeNonProxy"><a href="#writeNonProxy" class="headerlink" title="writeNonProxy"></a>writeNonProxy</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">writeNonProxy</span><span class="hljs-params">(ObjectOutputStream out)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    out.writeUTF(name); <span class="hljs-comment">// 写入类的名字</span><br>    out.writeLong(getSerialVersionUID()); <span class="hljs-comment">// 写入类的序列号</span><br> <br>    <span class="hljs-keyword">byte</span> flags = <span class="hljs-number">0</span>;<br>    <span class="hljs-comment">// 获取类的标识</span><br>    <span class="hljs-keyword">if</span> (externalizable) &#123;<br>        flags |= ObjectStreamConstants.SC_EXTERNALIZABLE;<br>        <span class="hljs-keyword">int</span> protocol = out.getProtocolVersion();<br>        <span class="hljs-keyword">if</span> (protocol != ObjectStreamConstants.PROTOCOL_VERSION_1) &#123;<br>            flags |= ObjectStreamConstants.SC_BLOCK_DATA;<br>        &#125;<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (serializable) &#123;<br>        flags |= ObjectStreamConstants.SC_SERIALIZABLE;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (hasWriteObjectData) &#123;<br>        flags |= ObjectStreamConstants.SC_WRITE_METHOD;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (isEnum) &#123;<br>        flags |= ObjectStreamConstants.SC_ENUM;<br>    &#125;<br>    out.writeByte(flags); <span class="hljs-comment">// 写入类的flag</span><br> <br>    out.writeShort(fields.length); <span class="hljs-comment">// 写入对象的字段的个数</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; fields.length; i++) &#123;<br>        ObjectStreamField f = fields[i];<br>        out.writeByte(f.getTypeCode());<br>        out.writeUTF(f.getName());<br>        <span class="hljs-keyword">if</span> (!f.isPrimitive()) &#123;<br>            <span class="hljs-comment">// 如果不是原始类型，即是对象或者Interface</span><br>            <span class="hljs-comment">// 则会写入表示对象或者类的类型字符串</span><br>            out.writeTypeString(f.getTypeString());<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>jdk的缺点十分明显</p><ul><li>无法跨语言<ul><li>这一缺点几乎是致命伤害，对于跨进程的服务调用，通常都需要考虑到不同语言的相互调用时候的兼容性，而这一点对于jdk序列化操作来说却无法做到。这是因为jdk序列化操作时是使用了java语言内部的私有协议，在对其他语言进行反序列化的时候会有严重的阻碍。</li></ul></li><li>序列化之后的码流过大<ul><li>jdk进行序列化编码之后产生的字节数组过大，占用的存储内存空间也较高，这就导致了相应的流在网络传输的时候带宽占用较高，性能相比较为低下的情况。</li></ul></li></ul><h1 id="Kryo"><a href="#Kryo" class="headerlink" title="Kryo"></a>Kryo</h1><h1 id="Hessian"><a href="#Hessian" class="headerlink" title="Hessian"></a>Hessian</h1><p>Hessian的源码里面，核心主要还是com.caucho.hessian.io里面的代码，AbstractSerializer是Hessian里面的核心序列化类，当我们仔细查看源码的时候就会发现hessian提供了许多种序列化和反序列化的类进行不同类型数据的处理。（我使用的是hessian4.0，因此相应的类会多很多）</p><p>在SerializerFactory里面有getSerializer和getDefaultSerializer的函数，专门用于提取这些序列化和反序列化的工具类，这样可以避免在使用该工具类的时候又要重新实例化，这些工具类都会被存储到不同的ConcurrentHashMap里面去。</p><h1 id="Protobuf"><a href="#Protobuf" class="headerlink" title="Protobuf"></a>Protobuf</h1><h1 id="不同序列化框架的对比"><a href="#不同序列化框架的对比" class="headerlink" title="不同序列化框架的对比"></a>不同序列化框架的对比</h1><table><thead><tr><th></th><th>JDK</th><th>Hessian</th><th>Kryo</th><th>Xstream</th><th>Protobuf</th></tr></thead><tbody><tr><td>优点</td><td>使用方便<br>序列化包含的信息较多较全<br>安全性高</td><td>产生的码流小<br>支持跨语言</td><td>产生的码流小<br>速度快</td><td>对于被序列化对象的要求比较低<br>支持跨语言</td><td>产生的码流小<br>支持跨语言<br>速度快<br>灵活性高</td></tr><tr><td>缺点</td><td>产生的码流过大<br>网络传输占用带宽<br>消耗性能<br>不支持跨语言的序列化处理</td><td>性能比JDK序列化方式好<br>但是效率依旧不好</td><td>对于循环引用的情况需要将reference开启<br>开启之后性能会有所下降</td><td>序列化的耗时久<br>性能不高</td><td>需要进行环境安装和搭建</td></tr></tbody></table><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://juejin.im/post/6844903918879637518">https://juejin.im/post/6844903918879637518</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>进程间的通信</title>
    <link href="/2020/07/05/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1/"/>
    <url>/2020/07/05/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h1><p>管道，英文为pipe。这是一个我们在学习Linux命令行的时候就会引入的一个很重要的概念。它的发明人是道格拉斯.麦克罗伊，这位也是UNIX上早期shell的发明人。他在发明了shell之后，发现系统操作执行命令的时候，经常有需求要将一个程序的输出交给另一个程序进行处理，也因此，管道应运而生了。Golang中的Channel也是管道的思想。 </p><p>管道可以分为两类：匿名管道和命名管道。</p><p>常见的Linux命令 “|” 其实就是匿名管道，表示把一个进程的输出传输到另外一个进程，如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Happyjava&quot;</span> | awk -F <span class="hljs-string">&#x27;j&#x27;</span> <span class="hljs-string">&#x27;&#123;print $2&#125;&#x27;</span><br><span class="hljs-comment"># 输出 ava</span><br></code></pre></td></tr></table></figure><p>一个进程往管道输入数据，则会阻塞等待别的进程从管道读取数据。</p><h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><p>注意，此消息队列不是我们常用的MQ，如kafka，rabbitmq，rocketmq等。<br>消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。  每个数据块都被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。我们可以通过发送消息来避免命名管道的同步和阻塞问题。但是消息队列与命名管道一样，每个数据块都有一个最大长度的限制。<br>使用消息队列进行进程间通信，可能会收到数据块最大长度的限制约束等，这也是这种通信方式的缺点。如果频繁的发生进程间的通信行为，那么进程需要频繁地读取队列中的数据到内存，相当于间接地从一个进程拷贝到另一个进程，这需要花费时间。</p><h1 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h1><p>共享内存这个通信方式就可以很好着解决拷贝所消耗的时间了。系统加载一个进程的时候，分配给进程的内存并不是实际物理内存，而是虚拟内存空间。那么我们可以让两个进程各自拿出一块虚拟地址空间来，然后映射到相同的物理内存中，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了。</p><p>Golang中经典：不要通过共享内存来通信，而应该通过通信来共享内存。使用复制来减少锁的使用。</p><h1 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h1><p>共享内存最大的问题是什么？没错，就是多进程竞争内存的问题，就像类似于我们平时说的线程安全问题。如何解决这个问题？这个时候我们的信号量就上场了。<br>信号量的本质就是一个计数器，用来实现进程之间的互斥与同步。例如信号量的初始值是 1，然后 a 进程来访问内存1的时候，我们就把信号量的值设为 0，然后进程b 也要来访问内存1的时候，看到信号量的值为 0 就知道已经有进程在访问内存1了，这个时候进程 b 就会访问不了内存1。所以说，信号量也是进程之间的一种通信方式。</p><h1 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h1><p>这个就是我们一直在用的进程间的通信方式了，如我们的微信APP跟微信服务器通信，其实就是使用的Socket套接字进行通信的。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>面试那些事</title>
    <link href="/2020/07/03/%E9%9D%A2%E8%AF%95%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/07/03/%E9%9D%A2%E8%AF%95%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="字节跳动"><a href="#字节跳动" class="headerlink" title="字节跳动"></a>字节跳动</h1><h2 id="岗位：后端开发工程师-地点：杭州"><a href="#岗位：后端开发工程师-地点：杭州" class="headerlink" title="岗位：后端开发工程师 地点：杭州"></a>岗位：后端开发工程师 地点：杭州</h2><h3 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h3><ol><li>go里面线程，进程，协程的区别</li><li>完全二叉树与搜索二叉树的概念</li><li>Java中JVM 内存，垃圾回收机制。（面试官抠的比较细，要求讲到复制算法适用新生代，标记清楚算法适用年老代）</li><li>MySQL的索引原理</li><li>b树与b+树的区别</li><li>InnoDB 和 MyISAM的区别  (聚簇索引和非聚簇索引)</li><li>Redis的基本数据结构(string, hash, set, list zset)</li><li>讲一下跳表的原理（因为我前面提到了zset底层实现原理是skip list）</li><li>TCP/UDP 网络模型一共有几层</li><li>TCP和UDP的区别</li><li>从应用层到网络层各层的header都有什么不同的功能。（绝了，不知道咋讲。。说了存放地址和端口）</li><li>算法题<ul><li>通过给定的tree，判断是不是搜索二叉树和完全二叉树</li><li>tips:用中序遍历和广度优先法 </li></ul></li></ol><h3 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h3><ol><li>算法题<ul><li>给定一个随意的正整数数组，求最长的连续数字长度</li><li>eg. [3, 8, 9, 4, 6, 7] =&gt; 4 (6789)</li><li>刚开始用了桶排序，后面在面试官的提示下用map优化了一下</li></ul></li><li>Redis删除key的机制 （还问了一个很神奇的，为什么要删除 从来没想过这个问题）</li><li>Redis和MySQL存储数据的区别</li><li>Java中String为什么要声明成不可变的</li><li>如果自己设计一个不可变的类，有哪些步骤</li><li>说一个设计模式 （说了观察者模式）</li><li>为什么需要回调 （大概讲了因为一直监控耗费性能，但好像不是面试官特别想要的答案:-&lt;）</li><li>聊了一下之前在腾讯做过的项目</li></ol><h3 id="三面"><a href="#三面" class="headerlink" title="三面"></a>三面</h3><ol><li>算法题<ul><li>给定一个数组和一个数s，找到最短的子数组加起来的和超过s</li><li>用两个指针去遍历 讲了一遍思路 面试官让我开始写 写了十分钟还有bug 面试官让我先跳过了（真是想吐槽一下牛客的IDE）</li></ul></li><li>聊了一下暑假在字节做的项目<ul><li>总结了一篇新人文档</li><li>一个权限管理的平台 （封装了一些后端的接口）</li><li>一个对齐员工进度的表 （全栈）</li></ul></li></ol><p>主要还是在聊项目，没有考别的基础知识了</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总的来说，面试的时候还是有很多的不足，每次面试都是一次学习的过程。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis</title>
    <link href="/2020/07/03/Redis/"/>
    <url>/2020/07/03/Redis/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h1><ul><li>Redis 是 C 语言开发的一个开源的（遵从 BSD 协议）高性能键值对（key-value）的内存数据库，可以用作数据库、缓存、消息中间件等。</li><li>它是一种 NoSQL（not-only sql，泛指非关系型数据库）的数据库。（MySQL是一种关系型数据库）</li><li>性能优秀，数据在内存中，读写速度非常快，支持并发 10W QPS。</li><li>单进程单线程，是线程安全的，采用 IO 多路复用机制。</li><li>丰富的数据类型，支持字符串（strings）、散列（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等。</li><li>支持数据持久化。可以将内存中数据保存在磁盘中，重启时加载。</li><li>主从复制，哨兵，高可用。</li><li>可以用作分布式锁。</li><li>可以作为消息中间件使用，支持发布订阅。</li></ul><h1 id="Redis的五种数据类型"><a href="#Redis的五种数据类型" class="headerlink" title="Redis的五种数据类型"></a>Redis的五种数据类型</h1><h2 id="Redis-核心对象-redisObject"><a href="#Redis-核心对象-redisObject" class="headerlink" title="Redis 核心对象 (redisObject)"></a>Redis 核心对象 (redisObject)</h2><ul><li>数据类型 type<ul><li>string<ul><li>可以理解成与 Memcached一模一样的类型，一个 Key 对应一个 Value。Value 不仅是 String，也可以是数字。</li><li>String 类型是二进制安全的，意思是 Redis 的 String 类型可以包含任何数据，比如 jpg 图片或者序列化的对象。String 类型的值最大能存储 512M。</li></ul></li><li>hash<ul><li>Hash是一个键值（key-value）的集合。Redis 的 Hash 是一个 String 的 Key 和 Value 的映射表，Hash 特别适合存储对象。常用命令：hget，hset，hgetall 等。</li></ul></li><li>list<ul><li>List 列表是简单的字符串列表，按照插入顺序排序。可以添加一个元素到列表的头部（左边）或者尾部（右边） 常用命令：lpush、rpush、lpop、rpop、lrange（获取列表片段）等。</li><li>双向列表</li></ul></li><li>set<ul><li>集合是通过 hashtable 实现的。Set 中的元素是没有顺序的，而且是没有重复的。常用命令：sdd、spop、smembers、sunion 等。</li></ul></li><li>sorted list<ul><li>和 Set 相比，Sorted Set关联了一个 Double 类型权重的参数 Score，使得集合中的元素能够按照 Score 进行有序排列，Redis 正是通过分数来为集合中的成员进行从小到大的排序。</li><li>Redis Sorted Set 的内部使用 HashMap 和跳跃表（skipList）来保证数据的存储和有序，HashMap 里放的是成员到 Score 的映射。</li></ul></li></ul></li><li>编码方式 encoding<ul><li>raw </li><li>int</li><li>ht</li><li>zipmap</li><li>linkedlist</li><li>ziplist</li><li>intest</li></ul></li><li>数据指针</li><li>虚拟内存</li><li>其他</li></ul><p>使用<strong>一个</strong> redisObject 对象来表示<strong>所有</strong>的 key 和 value</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>type 表示一个 value 对象具体是何种数据类型，encoding 是不同数据类型在 Redis 内部的存储方式。</p><h1 id="Redis缓存"><a href="#Redis缓存" class="headerlink" title="Redis缓存"></a>Redis缓存</h1><p>//todo</p><h2 id="Redis雪崩"><a href="#Redis雪崩" class="headerlink" title="Redis雪崩"></a>Redis雪崩</h2><p><strong>举个栗子</strong>：如果首页所有 Key 的失效时间都是 12 小时，中午 12 点刷新的，我零点有个大促活动大量用户涌入，假设每秒 6000 个请求，本来缓存可以抗住每秒 5000 个请求，但是缓存中所有 Key 都失效了。</p><p><strong>解决方案</strong>：在批量往 Redis 存数据的时候，把每个 Key 的失效时间都加个随机值就好了，这样可以保证数据不会再同一时间大面积失效。</p><h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透是指缓存和数据库中都没有的数据，而用户（黑客）不断发起请求。</p><p><strong>举个栗子</strong>：我们数据库的 id 都是从 1 自增的，如果发起 id=-1 的数据或者 id 特别大不存在的数据，这样的不断攻击导致数据库压力很大，严重会击垮数据库。</p><p><strong>解决方案</strong></p><ul><li>缓存穿透我会在接口层增加校验，比如用户鉴权，参数做校验，不合法的校验直接 return，比如 id 做基础校验，id&lt;=0 直接拦截。</li><li><strong>布隆过滤器</strong><ul><li>快速剔除一些不在数据库的值</li><li>布隆过滤器是一个 bit 向量或者说 bit 数组，如果我们要映射一个值到布隆过滤器中，我们需要使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1。</li><li>如果查询的时候对应bit是 0，那么可以确定一定不在。但如果都是1，只能说明可能存在。</li><li><a href="https://zhuanlan.zhihu.com/p/43263751">https://zhuanlan.zhihu.com/p/43263751</a></li></ul></li></ul><h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>缓存击穿是指一个 Key 非常热点，在不停地扛着大量的请求，大并发集中对这一个点进行访问，当这个 Key 在失效的瞬间，持续的大并发直接落到了数据库上，就在这个 Key 的点上击穿了缓存。</p><p><strong>解决方案</strong>：设置热点数据永不过期，或者加上互斥锁就搞定了。</p><h1 id="Redis性能分析"><a href="#Redis性能分析" class="headerlink" title="Redis性能分析"></a>Redis性能分析</h1><p>Redis 是单进程单线程的模型，因为 Redis 完全是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。</p><h2 id="Redis速度快的原因分析"><a href="#Redis速度快的原因分析" class="headerlink" title="Redis速度快的原因分析"></a>Redis速度快的原因分析</h2><ul><li><p>Redis 完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度是 O(1)。</p></li><li><p>数据结构简单，对数据操作也简单。</p></li><li><p>采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的 CPU 切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗。</p></li><li><p>使用多路复用 IO 模型，非阻塞 IO。//todo</p></li></ul><h2 id="Redis-vs-Memcached"><a href="#Redis-vs-Memcached" class="headerlink" title="Redis vs. Memcached"></a>Redis vs. Memcached</h2><ul><li><p>存储方式上：Memcache 会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis 有部分数据存在硬盘上，这样能保证数据的持久性。</p></li><li><p>数据支持类型上：Memcache 对数据类型的支持简单，只支持简单的 key-value，，而 Redis 支持五种数据类型。</p></li><li><p>使用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。Redis 直接自己构建了 VM 机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</p></li><li><p>Value 的大小：Redis 可以达到 1GB，而 Memcache 只有 1MB。</p></li></ul><h2 id="Redis-淘汰策略"><a href="#Redis-淘汰策略" class="headerlink" title="Redis 淘汰策略"></a>Redis 淘汰策略</h2><table><thead><tr><th>策略</th><th>描述</th></tr></thead><tbody><tr><td>volatile-lru</td><td>从已设置过期时间的KV集中优先对最近最少使用的数据 (less recently usesd) 淘汰</td></tr><tr><td>volatile-ttl</td><td>从已设置过期时间的KV集中优先对剩余时间短的数据 (time to live) 淘汰</td></tr><tr><td>volatile-random</td><td>从已设置过期时间的KV集中随机淘汰</td></tr><tr><td>allKeys-lru</td><td>从所有KV集中优先对最近最少使用的数据 (less recently usesd) 淘汰</td></tr><tr><td>allKeys-random</td><td>从所有KV集中随机淘汰</td></tr><tr><td>noeviction</td><td>不淘汰，若超过最大内存，返回错误信息</td></tr></tbody></table><h1 id="Redis持久化机制"><a href="#Redis持久化机制" class="headerlink" title="Redis持久化机制"></a>Redis持久化机制</h1><p>Redis 为了保证效率，数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。当 Redis 重启的时候，它会优先使用 AOF 文件来还原数据集，因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。</p><h2 id="AOF-Append-Only-File"><a href="#AOF-Append-Only-File" class="headerlink" title="AOF (Append Only File)"></a>AOF (Append Only File)</h2><p>把所有的对 Redis 的服务器进行修改的<strong>命令</strong>都存到一个文件里，命令的集合。Redis 默认是快照 RDB 的持久化方式。</p><ul><li>工作方式<ul><li>使用 AOF 做持久化，每一个写命令都通过 write 函数追加到 appendonly.aof 中</li></ul></li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">appendfsync</span> <span class="hljs-literal">yes</span><br>appendfsync always     <span class="hljs-comment">#每次有数据修改发生时都会写入AOF文件。</span><br>appendfsync everysec   <span class="hljs-comment">#每秒钟同步一次，该策略为AOF的缺省策略。</span><br></code></pre></td></tr></table></figure><p>AOF 可以做到全程持久化，只需要在配置中开启 appendonly yes。这样 Redis 每执行一个修改数据的命令，都会把它添加到 AOF 文件中，当 Redis 重启时，将会读取 AOF 文件进行重放，恢复到 Redis 关闭前的最后时刻。</p><ul><li><p>优点</p><ul><li>让 Redis 变得非常耐久。可以设置不同的 Fsync 策略，AOF的默认策略是每秒钟 Fsync 一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。</li></ul></li><li><p>缺点</p><ul><li>对于相同的数据集来说，AOF 的文件体积通常要大于 RDB 文件的体积。根据所使用的 Fsync 策略，AOF 的速度可能会慢于 RDB。</li></ul></li></ul><h2 id="RDB-Redis-Database"><a href="#RDB-Redis-Database" class="headerlink" title="RDB (Redis Database)"></a>RDB (Redis Database)</h2><p>快照形式是直接把内存中的数据保存到一个 dump 的文件中，定时保存，保存策略。</p><ul><li>工作方式<ul><li> 当 Redis 需要做持久化时，Redis 会 fork 一个子进程，子进程将数据写到磁盘上一个临时 RDB 文件中。</li><li> 当子进程完成写临时文件后，将原来的 RDB 替换掉，这样的好处是可以 copy-on-write。</li></ul></li><li>优点<ul><li>这种文件非常适合用于备份：比如，你可以在最近的 24 小时内，每小时备份一次，并且在每个月的每一天也备份一个 RDB 文件。RDB 非常适合灾难恢复。</li></ul></li><li>缺点<ul><li>如果你需要尽量避免在服务器故障时丢失数据，那么RDB不合适你。 </li></ul></li></ul><p>如果你非常关心你的数据，但仍然可以承受数分钟内的数据丢失，那么可以额只使用 RDB 持久。AOF 将 Redis 执行的每一条命令追加到磁盘中，处理巨大的写入会降低Redis的性能，不知道你是否可以接受。数据库备份和灾难恢复：定时生成 RDB 快照非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度快。当然了，Redis 支持同时开启 RDB 和 AOF，系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。</p><h1 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h1><h2 id="整体步骤"><a href="#整体步骤" class="headerlink" title="整体步骤"></a>整体步骤</h2><ul><li>从节点执行 slaveof[masterIP][masterPort]，保存主节点信息。</li><li>从节点中的定时任务发现主节点信息，建立和主节点的 Socket 连接。</li><li>从节点发送 Ping 信号，主节点返回 Pong，两边能互相通信。</li><li>连接建立后，主节点将所有数据发送给从节点（数据同步）。</li><li>主节点把当前的数据同步给从节点后，便完成了复制的建立过程。接下来，主节点就会持续的把写命令发送给从节点，保证主从数据一致性。</li></ul><h2 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul><li>runId：每个 Redis 节点启动都会生成唯一的 uuid，每次 Redis 重启后，runId 都会发生变化。</li><li>offset：主节点和从节点都各自维护自己的主从复制偏移量 offset，当主节点有写入命令时，offset=offset+命令的字节长度。<br>从节点在收到主节点发送的命令后，也会增加自己的 offset，并把自己的 offset 发送给主节点。<br>这样，主节点同时保存自己的 offset 和从节点的 offset，<strong>通过对比 offset 来判断主从节点数据是否一致</strong>。</li><li>repl_backlog_size：保存在主节点上的一个固定长度的先进先出队列，默认大小是 1MB。</li></ul><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><ul><li>Redis 2.8 之前使用 sync[runId][offset] 同步命令，Redis 2.8 之后使用 psync[runId][offset] 命令。</li><li>两者不同在于，Sync 命令仅支持全量复制过程，Psync 支持全量和部分复制。</li></ul><h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><h3 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h3><pre><code class=" mermaid">graph RL;  从Redis-- 发送sync命令 --&gt;主Redis  主Redis-- 发送RDB文件 --&gt;从Redis  主Redis-- 发送缓冲获得所有写命令 --&gt;从Redis</code></pre><ul><li>复制过程：<ul><li>slave 服务启动，slave 会建立和 master 的连接，发送 sync 命令。</li><li>master 启动一个后台进程将数据库快照保存到 RDB 文件中<ul><li>注意：此时如果生成 RDB 文件过程中存在写数据操作会导致 RDB 文件和当前主 redis 数据不一致，所以此时 master 主进程会开始收集写命令并缓存起来。</li></ul></li><li>master 就发送 RDB 文件给 slave</li><li>slave 将文件保存到磁盘上，然后加载到内存恢复</li><li>master 把缓存的命令转发给 slave<ul><li>注意：后续 master 收到的写命令都会通过开始建立的连接发送给 slave。</li></ul></li><li>当 master 和 slave 的连接断开时 slave 可以自动重新建立连接。如果 master 同时收到多个 slave 发来的同步连接命令，只会启动一个进程来写数据库镜像，然后发送给所有 slave。</li></ul></li><li>问题</li></ul><h3 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h3><p>首次同步</p><pre><code class=" mermaid">graph RL;  从Redis-- 发送psync命令 --&gt;主Redis  主Redis-- 发送RDB文件 --&gt;从Redis  主Redis-- 发送缓冲获得所有写命令 --&gt;从Redis</code></pre><p>非首次同步</p><pre><code class=" mermaid">graph RL;  从Redis-- 发送psync命令 --&gt;主Redis  主Redis-- 发送部分非同步数据文件 --&gt;从Redis</code></pre><ul><li>复制过程<ul><li>从机连接主机后，会主动发起 PSYNC 命令，从机会提供 master 的 runid(机器标识，随机生成的一个串) 和 offset（数据偏移量，如果offset主从不一致则说明数据不同步）</li><li>主机验证 runid 和 offset 是否有效，runid 相当于主机身份验证码，用来验证从机上一次连接的主机<ul><li>如果 runid 验证未通过则，则进行全同步，如果验证通过则说明曾经同步过，根据 offset 同步部分数据。</li></ul></li></ul></li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.kancloud.cn/mayan0718/php/515287">https://www.kancloud.cn/mayan0718/php/515287</a></p><h1 id="Sentinel-哨兵机制"><a href="#Sentinel-哨兵机制" class="headerlink" title="Sentinel 哨兵机制"></a>Sentinel 哨兵机制</h1><h2 id="哨兵机制简介"><a href="#哨兵机制简介" class="headerlink" title="哨兵机制简介"></a>哨兵机制简介</h2><ul><li>Sentinel(哨兵) 进程是用于监控 Redis 集群中 Master 主服务器工作的状态</li><li>在 Master 主服务器发生故障的时候，可以实现 Master 和 Slave 服务器的切换，保证系统的高可用（High Availability）</li><li>Sentinel 本身没有主从之分，只有 Redis 服务节点有主从之分。</li></ul><h2 id="哨兵进程的作用"><a href="#哨兵进程的作用" class="headerlink" title="哨兵进程的作用"></a>哨兵进程的作用</h2><ul><li>监控(Monitoring)：哨兵(sentinel) 会不断地检查你的 Master 和 Slave 是否运作正常。</li><li>提醒(Notification)：当被监控的某个Redis节点出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知。（使用较少）</li><li>自动故障迁移(Automatic failover)：当一个 Master 不能正常工作时，哨兵(sentinel) 会开始一次自动故障迁移操作。具体操作如下：<ul><li>它会将失效 Master 的其中一个 Slave 升级为新的 Master, 并让失效 Master 的其他Slave 改为复制新的 Master。</li><li>当客户端试图连接失效的 Master 时，集群也会向客户端返回新 Master 的地址，使得集群可以使用现在的 Master 替换失效 Master。</li><li>Master 和 Slave 服务器切换后，Master 的 redis.conf、Slave 的 redis.conf 和sentinel.conf 的配置文件的内容都会发生相应的改变，即 Master 主服务器的 redis.conf 配置文件中会多一行 slaveof 的配置，sentinel.conf 的监控目标会随之调换。</li></ul></li></ul><h2 id="哨兵的工作方式"><a href="#哨兵的工作方式" class="headerlink" title="哨兵的工作方式"></a>哨兵的工作方式</h2><ul><li><p><strong>每个</strong> Sentinel（哨兵）进程以<strong>每秒钟一次</strong>的频率向整个集群中的<strong>Master主服务器，Slave 从服务器以及其他 Sentinel（哨兵）进程</strong>发送一个 PING 命令。</p></li><li><p>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为<strong>主观下线（SDOWN）</strong>。</p></li><li><p>如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态。</p></li><li><p>当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为<strong>客观下线（ODOWN）</strong>。</p></li><li><p>在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master 主服务器、Slave 从服务器发送 INFO 命令。</p></li><li><p>当 Master 主服务器被 Sentinel（哨兵）进程标记为<strong>客观下线（ODOWN）</strong>时，Sentinel（哨兵）进程向下线的 Master 主服务器的所有 Slave 从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。</p></li><li><p>若没有足够数量的 Sentinel（哨兵）进程同意 Master 主服务器下线， Master 主服务器的<strong>客观下线</strong>状态就会被移除。若 Master 主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master 主服务器的主观下线状态就会被移除。</p></li><li><img src="/2020/07/03/Redis/sentinel.jpg" class="" title="sentinel"></li></ul><h2 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/44474652">https://zhuanlan.zhihu.com/p/44474652</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>LeetCode那些事</title>
    <link href="/2020/06/29/LeetCode%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/06/29/LeetCode%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="Q146-LRU-Cache"><a href="#Q146-LRU-Cache" class="headerlink" title="Q146 LRU Cache"></a>Q146 LRU Cache</h1><p>Design and implement a data structure for Least Recently Used (LRU) cache. It should support the following operations: get and put.</p><p>get(key) - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.<br>put(key, value) - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.</p><p>The cache is initialized with a positive capacity.</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><h3 id="LinkedHashMap"><a href="#LinkedHashMap" class="headerlink" title="LinkedHashMap"></a>LinkedHashMap</h3><h4 id="LinkedHashMap-vs-HashMap"><a href="#LinkedHashMap-vs-HashMap" class="headerlink" title="LinkedHashMap vs. HashMap"></a>LinkedHashMap vs. HashMap</h4><p>大多数情况下，只要不涉及线程安全问题，Map基本都可以使用HashMap，不过HashMap有一个问题，就是迭代HashMap的顺序并不是HashMap放置的顺序，也就是无序。HashMap的这一缺点往往会带来困扰，因为有些场景，我们期待一个<strong>有序</strong>的Map.</p><ul><li><p>LinkedHashMap = LinkedList + HashMap</p></li><li><p>accessOrder   </p><ul><li>false： 基于插入顺序    </li><li>true：  基于访问顺序 </li></ul></li></ul><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://juejin.im/post/5a4b433b6fb9a0451705916f">https://juejin.im/post/5a4b433b6fb9a0451705916f</a></p><h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LRUCache</span> </span>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> capacity;<br>    <span class="hljs-keyword">private</span> LinkedHashMap&lt;Integer, Integer&gt; map;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">LRUCache</span><span class="hljs-params">(<span class="hljs-keyword">int</span> capacity)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.capacity = capacity;<br>        map = <span class="hljs-keyword">new</span> LinkedHashMap&lt;&gt;(capacity, <span class="hljs-number">1</span>, <span class="hljs-keyword">true</span>);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">get</span><span class="hljs-params">(<span class="hljs-keyword">int</span> key)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (!map.containsKey(key)) &#123;<br>            <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> map.get(key);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">put</span><span class="hljs-params">(<span class="hljs-keyword">int</span> key, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (!map.containsKey(key)) &#123;<br>            <span class="hljs-keyword">if</span> (map.size() &gt;= capacity) &#123;<br>                <span class="hljs-keyword">for</span> (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123;<br>                    map.remove(entry.getKey());<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>        map.put(key, value);<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL笔记</title>
    <link href="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="数据库三大范式"><a href="#数据库三大范式" class="headerlink" title="数据库三大范式"></a>数据库三大范式</h1><h2 id="第一范式"><a href="#第一范式" class="headerlink" title="第一范式"></a>第一范式</h2><p>每个列都不可以再拆分</p><h2 id="第二范式"><a href="#第二范式" class="headerlink" title="第二范式"></a>第二范式</h2><p>第一范式 + 非主键完全依赖于主键，而不能是依赖于主键的一部分</p><h2 id="第三范式"><a href="#第三范式" class="headerlink" title="第三范式"></a>第三范式</h2><p>第二范式 + 非主键列只依赖于主键，不依赖于其他非主键</p><p><a href="https://www.cnblogs.com/linjiqin/archive/2012/04/01/2428695.html">https://www.cnblogs.com/linjiqin/archive/2012/04/01/2428695.html</a></p><hr><h1 id="B树和B-树"><a href="#B树和B-树" class="headerlink" title="B树和B+树"></a>B树和B+树</h1><h2 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h2><p>我们知道，二叉树的查找的时间复杂度是O(logN)，其查找效率与深度有关，而普通的二叉树可能由于内部节点排列问题退化成链表，这样查找效率就会很低。因此平衡二叉树是更好的选择，因为它保持平衡，即通过旋转调整结构保持最小的深度。其查找的时间复杂度也是O(logN)。但实际上，数据库中索引的结构也并非AVL树或更优秀的红黑树，尽管它的查询的时间复杂度很低。</p><blockquote><p>为什么平衡二叉树不适合作为索引<br>不选择平衡二叉树的原因并不是因为O(logN)的时间复杂度不够好。</p></blockquote><p>索引是存在于索引文件中，是存在于磁盘中的。因为索引通常是很大的，因此无法一次将全部索引加载到内存当中，因此每次只能从磁盘中读取一个磁盘页的数据到内存中。而这个磁盘的读取的速度较内存中的读取速度而言是差了好几个级别。</p><p>注意，我们说的平衡二叉树结构，指的是逻辑结构上的平衡二叉树，其物理实现是数组。然后由于在逻辑结构上相近的节点在物理结构上可能会差很远。因此，每次读取的磁盘页的数据中有许多是用不上的。因此，查找过程中要进行许多次的磁盘读取操作。而适合作为索引的结构应该是尽可能少的执行磁盘IO操作，因为执行磁盘IO操作非常的耗时。因此，平衡二叉树并不适合作为索引结构。</p><h2 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h2><p>平衡二叉树没能充分利用磁盘预读功能，而B树是为了充分利用磁盘预读功能来而创建的一种数据结构，也就是说B树就是为了作为索引才被发明出来的的。</p><blockquote><p>局部性原理与磁盘预读：由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。</p></blockquote><blockquote><p>这样做的理论依据是计算机科学中著名的局部性原理：<br>当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。</p></blockquote><h2 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h2><blockquote><p>为什么B+树会比B树更加优秀</p></blockquote><p>B树：有序数组 + 平衡多叉树</p><p>B+树：有序数组链表 + 平衡多叉树</p><ul><li>B+树的关键字全部存放在叶子节点中，非叶子节点用来做索引，而叶子节点中有一个指针指向一下个叶子节点。做这个优化的目的是为了提高区间访问的性能。而正是这个特性决定了B+树更适合用来存储外部数据。</li><li>MySQL底层对B+Tree进行了进一步优化：在叶子节点中是双向链表，且在链表的头结点和尾节点也是循环指向的。</li><li>出于对IO性能的考虑，B-Tree的高度更高，IO更频繁。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存，只能逐一加载每一个磁盘页。</li></ul><blockquote><p>B+树还有一个最大的好处，方便扫库，B树必须用中序遍历的方法按序扫库，而B+树直接从叶子结点挨个扫一遍就完了，B+树支持range-query非常方便，而B树不支持。这是数据库选用B+树的最主要原因。比如要查 5-10之间的，B+树一把到5这个标记，再一把到10，然后串起来就行了，B树就非常麻烦。B树的好处，就是成功查询特别有利，因为树的高度总体要比B+树矮。不成功的情况下，B树也比B+树稍稍占一点点便宜。<br>B树比如你的例子中查，17的话，一把就得到结果了，有很多基于频率的搜索是选用B树，越频繁query的结点越往根上走，前提是需要对query做统计，而且要对key做一些变化。<br>另外B树也好B+树也好，根或者上面几层因为被反复query，所以这几块基本都在内存中，不会出现读磁盘IO，一般已启动的时候，就会主动换入内存。”</p></blockquote><img src="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/B+Tree.png" class="" title="B+Tree"><h3 id="B-Tree-的查找过程"><a href="#B-Tree-的查找过程" class="headerlink" title="B+Tree 的查找过程"></a>B+Tree 的查找过程</h3><p>如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。</p><h3 id="B-树的性质"><a href="#B-树的性质" class="headerlink" title="B+树的性质"></a>B+树的性质</h3><ul><li><p>索引字段要尽量的小<br>我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。</p></li><li><p>索引的最左匹配特性(即从左往右匹配)<br>当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。</p></li></ul><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p><a href="">MySQL-索引</a></p><h1 id="MySQL优化"><a href="#MySQL优化" class="headerlink" title="MySQL优化"></a>MySQL优化</h1><h2 id="MySQL逻辑架构"><a href="#MySQL逻辑架构" class="headerlink" title="MySQL逻辑架构"></a>MySQL逻辑架构</h2><img src="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/MySQL%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84.png" class="" title="MySQL逻辑架构"><p>MySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。</p><p>MySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。</p><p>最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。</p><h2 id="MySQL查询过程"><a href="#MySQL查询过程" class="headerlink" title="MySQL查询过程"></a>MySQL查询过程</h2><p>当我们向MySQL发送一个请求，MySQL内部具体流程</p><img src="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B.png" class="" title="MySQL查询过程"><h3 id="客户端-服务端通信协议"><a href="#客户端-服务端通信协议" class="headerlink" title="客户端/服务端通信协议"></a>客户端/服务端通信协议</h3><p>MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。</p><p>客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。</p><p>与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。</p><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。</p><p>MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。</p><p>如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。</p><p>既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：</p><ul><li>任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存</li><li>如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗</li></ul><p>基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：</p><ul><li>用多个小表代替一个大表，注意不要过度设计</li><li>批量插入代替循环单条插入</li><li>合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适</li><li>可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存</li></ul><p>最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。</p><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><ul><li>缓存是如何让使用内存的</li><li>如何控制内存的碎片化</li><li>事务对查询缓存有何影响</li></ul><h3 id="语法解析和预处理"><a href="#语法解析和预处理" class="headerlink" title="语法解析和预处理"></a>语法解析和预处理</h3><p>MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等。</p><h3 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h3><p>经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。</p><p>MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。</p><p>有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样（我们希望执行时间尽可能短，但MySQL值选择它认为成本小的，但成本小并不意味着执行时间短）等等。</p><p>MySQL的查询优化器是一个非常复杂的部件，它使用了非常多的优化策略来生成一个最优的执行计划：</p><ul><li>重新定义表的关联顺序（多张表关联查询时，并不一定按照SQL中指定的顺序进行，但有一些技巧可以指定关联顺序）</li><li>优化MIN()和MAX()函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值，具体原理见下文）</li><li>提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询）</li><li>优化排序（在老版本MySQL会使用两次传输排序，即先读取行指针和需要排序的字段在内存中对其排序，然后再根据排序结果去读取数据行，而新版本采用的是单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序。对于I/O密集型应用，效率会高很多）</li></ul><h3 id="查询执行引擎"><a href="#查询执行引擎" class="headerlink" title="查询执行引擎"></a>查询执行引擎</h3><p>在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为handler API。查询过程中的每一张表由一个handler实例表示。实际上，MySQL在查询优化阶段就为每一张表创建了一个handler实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。存储引擎接口提供了非常丰富的功能，但其底层仅有几十个接口，这些接口像搭积木一样完成了一次查询的大部分操作。</p><h3 id="返回结果给客户端"><a href="#返回结果给客户端" class="headerlink" title="返回结果给客户端"></a>返回结果给客户端</h3><p>查询执行的最后一个阶段就是将结果返回给客户端。即使查询不到数据，MySQL仍然会返回这个查询的相关信息，比如该查询影响到的行数以及执行时间等。</p><p>如果查询缓存被打开且这个查询可以被缓存，MySQL也会将结果存放到缓存中。</p><p>结果集返回客户端是一个增量且逐步返回的过程。有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>客户端向MySQL服务器发送一条查询请求</li><li>服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段</li><li>服务器进行SQL解析、预处理、再由优化器生成对应的执行计划</li><li>MySQL根据执行计划，调用存储引擎的API来执行查询</li><li>将结果返回给客户端，同时缓存查询结果</li></ol><h2 id="性能优化建议"><a href="#性能优化建议" class="headerlink" title="性能优化建议"></a>性能优化建议</h2><h3 id="Schema设计与数据类型优化"><a href="#Schema设计与数据类型优化" class="headerlink" title="Schema设计与数据类型优化"></a>Schema设计与数据类型优化</h3><p>选择数据类型只要遵循小而简单的原则就好，越小的数据类型通常会更快，占用更少的磁盘、内存，处理时需要的CPU周期也更少。越简单的数据类型在计算时需要更少的CPU周期，比如，整型就比字符操作代价低，因而会使用整型来存储ip地址，使用DATETIME来存储时间，而不是使用字符串。</p><ul><li>通常来说把可为NULL的列改为NOT NULL不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为NOT NULL。</li><li>对整数类型指定宽度，比如INT(11)，没有任何卵用。INT使用32位（4个字节）存储空间，那么它的表示范围已经确定，所以INT(1)和INT(20)对于存储和计算是相同的。</li><li>UNSIGNED表示不允许负值，大致可以使正数的上限提高一倍。比如TINYINT存储范围是-128 ~ 127，而UNSIGNED TINYINT存储的范围却是0 - 255。</li><li>通常来讲，没有太大的必要使用DECIMAL数据类型。即使是在需要存储财务数据时，仍然可以使用BIGINT。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用BIGINT存储。这样可以避免浮点数计算不准确和DECIMAL精确计算代价高的问题。</li><li>TIMESTAMP使用4个字节存储空间，DATETIME使用8个字节存储空间。因而，TIMESTAMP只能表示1970 - 2038年，比DATETIME表示的范围小得多，而且TIMESTAMP的值因时区不同而不同。</li><li>大多数情况下没有使用枚举类型的必要，其中一个缺点是枚举的字符串列表是固定的，添加和删除字符串（枚举选项）必须使用ALTER TABLE（如果只只是在列表末尾追加元素，不需要重建表）。</li><li>schema的列不要太多。原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高。</li><li>大表ALTER TABLE非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇技淫巧可以解决这个问题，有兴趣可自行查阅。</li></ul><h3 id="创建高性能索引"><a href="#创建高性能索引" class="headerlink" title="创建高性能索引"></a>创建高性能索引</h3><p>索引是提高MySQL查询性能的一个重要途径，但过多的索引可能会导致过高的磁盘使用率以及过高的内存占用，从而影响应用程序的整体性能。应当尽量避免事后才想起添加索引，因为事后可能需要监控大量的SQL才能定位到问题所在，而且添加索引的时间肯定是远大于初始添加索引所需要的时间，可见索引的添加也是非常有技术含量的。</p><h1 id="MySQL-事务"><a href="#MySQL-事务" class="headerlink" title="MySQL 事务"></a>MySQL 事务</h1><p><a href="https://zhuangzhuang131419.github.io/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/">MySQL 事务</a></p><h1 id="MySQL-锁🔐"><a href="#MySQL-锁🔐" class="headerlink" title="MySQL 锁🔐"></a>MySQL 锁🔐</h1><img src="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/%E9%94%81.png" class="" title="锁"><h2 id="从对数据操作分类"><a href="#从对数据操作分类" class="headerlink" title="从对数据操作分类"></a>从对数据操作分类</h2><h3 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h3><ul><li>读锁 = 共享锁: 针对同一份数据，多个读操作可以同时进行，不会互相影响。<h3 id="写锁"><a href="#写锁" class="headerlink" title="写锁"></a>写锁</h3></li><li>写锁 = 排他锁: 当前写操作没有完成前，会阻断其他写锁和读锁。</li></ul><h2 id="从对数据操作的粒度分类"><a href="#从对数据操作的粒度分类" class="headerlink" title="从对数据操作的粒度分类"></a>从对数据操作的粒度分类</h2><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><ul><li>开销小，加锁快</li><li>锁定粒度大，发生锁冲突的概率较高，并发度较低</li><li>不会出现死锁</li><li>MyISAM和Memory存储引擎采用的是表级锁</li></ul><h3 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h3><ul><li>开销大，加锁慢</li><li>锁定粒度小，发生锁冲突的概率最低，并发度较高</li><li>会出现死锁</li><li>InnoDB存储引擎既支持行级锁也支持表级锁，但默认情况是采用行级锁</li></ul><h3 id="页面锁"><a href="#页面锁" class="headerlink" title="页面锁"></a>页面锁</h3><ul><li>开销和加锁时间介于表锁和行锁之间</li><li>会出现死锁</li><li>锁定粒度界于表锁和行锁之间，并发度一般</li></ul><h2 id="MyISAM-表锁"><a href="#MyISAM-表锁" class="headerlink" title="MyISAM 表锁"></a>MyISAM 表锁</h2><p>MyISAM的表锁有两种模式</p><ul><li>表共享读锁(Table Read Lock): 不会阻塞其他用户对同一表的读请求，不会阻塞对同一表的写请求</li><li>表独占写锁(Table Write Lock): 会阻塞其他用户读同一表的读和写操作</li></ul><h2 id="InnoDB-行锁"><a href="#InnoDB-行锁" class="headerlink" title="InnoDB 行锁"></a>InnoDB 行锁</h2><ul><li>共享锁(S): 允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。</li><li>排他锁(X): 允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。</li><li>意向共享锁(IS): 事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。</li><li>意向排他锁(IX): 事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。</li></ul><h3 id="记录锁"><a href="#记录锁" class="headerlink" title="记录锁"></a>记录锁</h3><p>单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">WHERE</span> id <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br></code></pre></td></tr></table></figure><p>它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行</p><h3 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h3><p>当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”。</p><p>InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。</p><p>对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。</p><p><b>使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据</b></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">WHERE</span> id BETWEN <span class="hljs-number">1</span> <span class="hljs-keyword">AND</span> <span class="hljs-number">10</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span><br></code></pre></td></tr></table></figure><p>即所有在（1，10）区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。</p><h3 id="临键锁"><a href="#临键锁" class="headerlink" title="临键锁"></a>临键锁</h3><p>等于<b>记录锁</b>+<b>间隙锁</b> 它的封锁范围，既包含索引记录，又包含索引区间。(临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。</p><h3 id="特点分析"><a href="#特点分析" class="headerlink" title="特点分析"></a>特点分析</h3><p>InnoDB 这种行锁意味着: 只有通过索引条件检索数据，InnoDB才会使用行级锁，否则，InnoDB将使用表级锁</p><blockquote><p>假设有个表单products 里面有 id 和 name 两个栏位, id 是主键</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sql"># 明确指明主键，并且有这条记录 <span class="hljs-operator">=</span>》行锁<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id<span class="hljs-operator">=</span><span class="hljs-string">&#x27;3&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id<span class="hljs-operator">=</span><span class="hljs-string">&#x27;3&#x27;</span> <span class="hljs-keyword">and</span> type<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><br># 明确指明主键，但是没有这条记录 <span class="hljs-operator">=</span>》不加锁<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id<span class="hljs-operator">=</span><span class="hljs-string">&#x27;-1&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><br># 无主键 <span class="hljs-operator">=</span>》表锁<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> name<span class="hljs-operator">=</span><span class="hljs-string">&#x27;Mouse&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><br># 主键不明确 <span class="hljs-operator">=</span>》表锁<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id<span class="hljs-operator">&lt;&gt;</span><span class="hljs-string">&#x27;3&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id <span class="hljs-keyword">LIKE</span> <span class="hljs-string">&#x27;3&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><br></code></pre></td></tr></table></figure><h2 id="加锁机制"><a href="#加锁机制" class="headerlink" title="加锁机制"></a>加锁机制</h2><h3 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h3><p>乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。</p><h3 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h3><p>悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。</p><h3 id="两种锁机制的适用场景"><a href="#两种锁机制的适用场景" class="headerlink" title="两种锁机制的适用场景"></a>两种锁机制的适用场景</h3><ul><li>悲观锁比较适合写入操作比较频繁的场景，如果出现大量读取的操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。</li><li>乐观锁比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低系统的吞吐量。</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://dbaplus.cn/news-155-1531-1.html">https://dbaplus.cn/news-155-1531-1.html</a></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sftp服务器搭建</title>
    <link href="/2020/06/27/sftp%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"/>
    <url>/2020/06/27/sftp%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><h2 id="1-Linux管理员-root-修改和查看普通用户的密码"><a href="#1-Linux管理员-root-修改和查看普通用户的密码" class="headerlink" title="1. Linux管理员(root)修改和查看普通用户的密码"></a>1. Linux管理员(root)修改和查看普通用户的密码</h2><h3 id="root修改普通用户密码"><a href="#root修改普通用户密码" class="headerlink" title="root修改普通用户密码"></a>root修改普通用户密码</h3><p><code>-&gt; sudo passwd user_name</code></p><h3 id="root查看普通用户密码"><a href="#root查看普通用户密码" class="headerlink" title="root查看普通用户密码"></a>root查看普通用户密码</h3><p>密码是无法被查看的，即使是root也不行，因此普通用户要是遗忘了密码，可以参照上一步，让管理员使用root权限修改密码，然后再将新密码告知普通用户</p><h3 id="普通用户修改自己的密码"><a href="#普通用户修改自己的密码" class="headerlink" title="普通用户修改自己的密码"></a>普通用户修改自己的密码</h3><p><code>-&gt; passwd</code></p><h2 id="2-查看当前用户及用户组"><a href="#2-查看当前用户及用户组" class="headerlink" title="2. 查看当前用户及用户组"></a>2. 查看当前用户及用户组</h2><h3 id="可以查看所有用户的列表"><a href="#可以查看所有用户的列表" class="headerlink" title="可以查看所有用户的列表"></a>可以查看所有用户的列表</h3><p><code>-&gt; cat /etc/passwd</code></p><h3 id="可以查看当前活跃的用户列表"><a href="#可以查看当前活跃的用户列表" class="headerlink" title="可以查看当前活跃的用户列表"></a>可以查看当前活跃的用户列表</h3><p><code>-&gt; w</code></p><h3 id="查看用户组"><a href="#查看用户组" class="headerlink" title="查看用户组"></a>查看用户组</h3><p><code>-&gt; cat /etc/group</code></p><h3 id="查看当前登录用户名"><a href="#查看当前登录用户名" class="headerlink" title="查看当前登录用户名"></a>查看当前登录用户名</h3><p><code>-&gt; who am i</code></p><h3 id="查看用户属于哪一个用户组"><a href="#查看用户属于哪一个用户组" class="headerlink" title="查看用户属于哪一个用户组"></a>查看用户属于哪一个用户组</h3><p><code>-&gt; groups username</code></p><h1 id="开始搭建"><a href="#开始搭建" class="headerlink" title="开始搭建"></a>开始搭建</h1><p>需求：创建三个用户，其中一个为sftp管理员，其余两个分别为指定目录的访问用户。sftp管理员对其他用户的sftp根目录下的内容具有读写权限，限制其他用户只能访问其自己的根目录且仅有读权限；相关的sftp用户不能登录到Linux系统中。</p><h2 id="1-确认openssh的版本"><a href="#1-确认openssh的版本" class="headerlink" title="1. 确认openssh的版本"></a>1. 确认openssh的版本</h2><p><code>-&gt; ssh -V</code><br><img src="/Users/zhuangzhuang/Blog/source/images/sftp-ssh.png"></p><h2 id="2-切换到管理员-root"><a href="#2-切换到管理员-root" class="headerlink" title="2. 切换到管理员(root)"></a>2. 切换到管理员(root)</h2><blockquote><p>也可以不切换在下面的命令行前加<code>sudo</code></p></blockquote><p><code>-&gt; sudo -i</code></p><h2 id="3-创建sftp管理组及用户组"><a href="#3-创建sftp管理组及用户组" class="headerlink" title="3. 创建sftp管理组及用户组"></a>3. 创建sftp管理组及用户组</h2><blockquote><p>添加管理组 bytedance_admin</p></blockquote><p><code>-&gt; groupadd bytedance_admin </code></p><blockquote><p>添加用户组 bytedance</p></blockquote><p><code>-&gt; groupadd bytedance </code></p><h2 id="4-创建sftp管理用户及普通用户"><a href="#4-创建sftp管理用户及普通用户" class="headerlink" title="4. 创建sftp管理用户及普通用户"></a>4. 创建sftp管理用户及普通用户</h2><blockquote><p><code>/bin/false</code> 目的是不让用户登录 也可以使用<code>/bin/nologin</code></p></blockquote><p><code>-&gt; useradd -g bytedance -s /bin/false bob</code></p><p><code>-&gt; useradd -g bytedance -s /bin/false john</code></p><p><code>-&gt; useradd -g bytedance_admin -s /bin/false king</code></p><blockquote><p>为每一位用户设置密码</p></blockquote><p><code>-&gt; passwd king</code></p><p><code>-&gt; passwd bob</code></p><p><code>-&gt; passwd john</code></p><h2 id="5-分别创建对应用户的bytedance根目录并指定为其家目录"><a href="#5-分别创建对应用户的bytedance根目录并指定为其家目录" class="headerlink" title="5. 分别创建对应用户的bytedance根目录并指定为其家目录"></a>5. 分别创建对应用户的bytedance根目录并指定为其家目录</h2><p><code>-&gt; mkdir -pv /usr/bytedance/&#123;bob,john&#125;/share</code></p><h2 id="6-配置sshd-config文件"><a href="#6-配置sshd-config文件" class="headerlink" title="6. 配置sshd_config文件"></a>6. 配置sshd_config文件</h2><p><code>-&gt; vi /etc/ssh/sshd_config</code></p><p>找到如下这行，用#符号注释掉，大致在文件末尾处。 </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Subsystem sftp /usr/libexec/openssh/sftp-server</span><br><br><span class="hljs-string">Subsystem</span> <span class="hljs-string">sftp</span> <span class="hljs-string">internal-sftp</span>     <span class="hljs-comment">#这行指定使用sftp服务使用系统自带的internal-sftp</span><br><br><span class="hljs-string">Match</span> <span class="hljs-string">Group</span> <span class="hljs-string">bytedance</span>     <span class="hljs-comment">#这行用来匹配bytedance组的用户，如果要匹配多个组，多个组之间用逗号分割；</span><br><br><span class="hljs-string">ChrootDirectory</span> <span class="hljs-string">/usr/bytedance/%u</span>        <span class="hljs-comment">#用chroot将用户的根目录指定到%h，%h代表用户home目录，这样用户就只能在用户目录下活动。也可用%u，%u代表用户名。</span><br><br><span class="hljs-string">ForceCommand</span> <span class="hljs-string">internal-sftp</span>    <span class="hljs-comment">#指定sftp命令 </span><br><br><span class="hljs-string">AllowTcpForwarding</span> <span class="hljs-literal">no</span><br><br><span class="hljs-string">X11Forwarding</span> <span class="hljs-literal">no</span><br><br><span class="hljs-string">Match</span> <span class="hljs-string">User</span> <span class="hljs-string">bytedance_admin</span>        <span class="hljs-comment">#匹配用户了，多个用户名之间也是用逗号分割</span><br><br><span class="hljs-string">ChrootDirectory</span> <span class="hljs-string">/usr/bytedance</span><br><br><span class="hljs-string">ForceCommand</span> <span class="hljs-string">internal-sftp</span><br><br><span class="hljs-string">AllowTcpForwarding</span> <span class="hljs-literal">no</span><br><br><span class="hljs-string">X11Forwarding</span> <span class="hljs-literal">no</span><br><br></code></pre></td></tr></table></figure><h2 id="7-设置Chroot目录的权限"><a href="#7-设置Chroot目录的权限" class="headerlink" title="7. 设置Chroot目录的权限"></a>7. 设置Chroot目录的权限</h2><h3 id="chown和chmod-命令"><a href="#chown和chmod-命令" class="headerlink" title="chown和chmod 命令"></a>chown和chmod 命令</h3><blockquote><p>chmod修改的是文件的读、写、执行。</p><p>chown修改的是文件的用户或者组的权限。</p></blockquote><h3 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#修改普通用户的根目录属组</span><br><br>chown root:bytedance <span class="hljs-regexp">/usr/</span>bytedance/&#123;bob,john&#125;<br></code></pre></td></tr></table></figure><p><img src="/Users/zhuangzhuang/Blog/source/images/sftp-chown.png"></p><p>第一个root表示文件所有者 第二个bytedance表示文件所在的群组</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#修改普通用户的根目录权限</span><br>-&gt; chmod <span class="hljs-number">755</span> <span class="hljs-regexp">/usr/</span>bytedance/&#123;bob,john&#125;  <br><br><span class="hljs-comment">#修改管理员的根目录属组</span><br>-&gt; chown root:bytedance_admin <span class="hljs-regexp">/usr/</span>bytedance/<br><br><span class="hljs-comment">#修改管理员根目录的权限</span><br>-&gt; chmod <span class="hljs-number">755</span> <span class="hljs-regexp">/usr/</span>bytedance/<br><br><span class="hljs-comment">#修改各普通用户下的share目录的属主为管理员，属组为普通用户组</span><br>-&gt; chown king:bytedance <span class="hljs-regexp">/usr/</span>bytedance<span class="hljs-regexp">/&#123;bob,john&#125;/</span>share/ <br><br><span class="hljs-comment">#各share目录管理员的权限为读写，普通bytedance组仅有读权限，其他用户没有权限访问</span><br>-&gt; chmod <span class="hljs-number">750</span> <span class="hljs-regexp">/usr/</span>bytedance<span class="hljs-regexp">/&#123;bob,john&#125;/</span>share/<br><br></code></pre></td></tr></table></figure><p>chmod 后面的数字含义参考</p><p><a href="https://chmodcommand.com/">https://chmodcommand.com/</a></p><h2 id="8-关闭selinux"><a href="#8-关闭selinux" class="headerlink" title="8. 关闭selinux"></a>8. 关闭selinux</h2><p><code>-&gt; vim /etc/selinux/config</code></p><p><code>SELINUX=permissive</code></p><p><code>-&gt; setenforce 0</code></p><p>如果提示 <code>setenforce: command not found</code></p><p>解决方案:</p><ul><li><p><code>apt-get install selinux-utils</code></p></li><li><p>添加环境变量<br><code>/usr/sbin/setenforce</code></p></li></ul><h2 id="9-重启sshd服务"><a href="#9-重启sshd服务" class="headerlink" title="9. 重启sshd服务"></a>9. 重启sshd服务</h2><p><code>-&gt; service sshd restart</code></p><p>如果提示<br><code>Job for ssh.service failed because the control process exited with error codesee systemctl status ssh.service and journalctl -xe for details.</code><br>解决方案：</p><ul><li>按照提示<code>systemctl status ssh.service</code><ul><li><img src="/Users/zhuangzhuang/Blog/source/images/sftp-sshd.png"></li></ul></li><li><code>/usr/sbin/sshd -T</code><ul><li>根据具体情况分析</li><li><img src="/Users/zhuangzhuang/Blog/source/images/sftp-sshd02.png"></li><li>这里我的情况是把Match User写到了前面，导致后面的参数读取失败</li></ul></li></ul><p><strong>Tips:</strong><br>请务必解决上述问题，不然sshd重启出错将会导致之后本地无法通过ssh连接开发机</p><h2 id="10-验证sftp登录"><a href="#10-验证sftp登录" class="headerlink" title="10. 验证sftp登录"></a>10. 验证sftp登录</h2><figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs capnproto"><span class="hljs-comment">#管理员登录，能对share目录下的文件进行读写操作</span><br><br>-&gt; sftp king<span class="hljs-symbol">@127</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span><br><br>Connecting to <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>...<br>king<span class="hljs-symbol">@127</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span>&#x27;s password: <br><span class="hljs-comment">#输入之前的密码</span><br><br>sftp&gt; <br><br><span class="hljs-comment">#普通用户登录，对share目录下的文件只能进行读操作</span><br><br>-&gt; sftp bob<span class="hljs-symbol">@127</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span><br><br>bob<span class="hljs-symbol">@127</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span>&#x27;s password: <br><br>sftp&gt; ls<br>share<br><br></code></pre></td></tr></table></figure><p>验证登录出现<code>sftp&gt;</code> 基本就说明了sftp服务器搭建成功了，剩下需要注意的就是权限问题了。此时也可以通过相关的ftp client 如：FileZilla FTP Client 和xftp 来连接到对应的sftp服务器了。</p><h1 id="设置记录sftp服务器的登录及操作日志"><a href="#设置记录sftp服务器的登录及操作日志" class="headerlink" title="设置记录sftp服务器的登录及操作日志"></a>设置记录sftp服务器的登录及操作日志</h1><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.jianshu.com/p/6b588a712513">https://www.jianshu.com/p/6b588a712513</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
