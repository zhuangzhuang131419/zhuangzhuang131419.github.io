<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>《现代操作系统》-读书笔记</title>
    <link href="/2021/04/22/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/04/22/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h1><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><h3 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型"></a>进程模型</h3><blockquote><p>在进程模型中，计算机上所有可运行的软件，通常也包括操作系统，被组织成若干<strong>顺序进程</strong>，简称<strong>进程</strong>。</p></blockquote><ul><li><p>一个进程就是一个正在执行程序的实例，包括程序计数器、寄存器和变量当前值。</p></li><li><p>一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。</p></li></ul><h3 id="进程的创建"><a href="#进程的创建" class="headerlink" title="进程的创建"></a>进程的创建</h3><ul><li><p>4种主要事件会导致进程的创建</p><ul><li>系统初始化</li><li>正在运行的程序执行了创建进程的系统调用</li><li>用户请求创建一个新进程</li><li>一个批处理作业的初始化</li></ul></li><li><p>停留在后台处理诸如电子邮件、Web页面、新闻、打印之类活动的进程称为<strong>守护进程（daemon）</strong></p></li><li><p>在UNIX系统中，只有一个系统调用可以用来创建新进程：<code>fork</code></p><ul><li>进程创建之后，父进程和子进程有各自不同的地址空间。修改对其他进程是不可见的。</li><li>在UNIX中，子进程的初始地址空间是父进程的一个副本，不可写的内存区是共享的。或者，子进程共享父进程的所有内存，但这种情况下内存通过<strong>写时复制</strong>共享。</li><li><strong>可写的内存是不可以共享的</strong>。</li></ul></li></ul><h3 id="进程的终止"><a href="#进程的终止" class="headerlink" title="进程的终止"></a>进程的终止</h3><ul><li>以下条件会引起一个进程的终止：<ul><li>正常退出（自愿）</li><li>出错退出（自愿）</li><li>严重错误（非自愿）</li><li>被其他进程杀死（非自愿）</li></ul></li></ul><h3 id="进程的层次结构"><a href="#进程的层次结构" class="headerlink" title="进程的层次结构"></a>进程的层次结构</h3><ul><li>进程只有一个父进程。</li><li>在UNIX中，进程和它的所有子进程以及后裔共同组成一个进程组。</li></ul><h3 id="进程的状态"><a href="#进程的状态" class="headerlink" title="进程的状态"></a>进程的状态</h3><img src="/2021/04/22/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png" class="" title="进程的状态"><ul><li>进程的三种状态是：<ul><li>运行态：该时刻进程实际占用CPU</li><li>就绪态：可运行，但因为其他进程正在运行而暂时停止</li><li>阻塞态：除非某种外部事件发生，否则进程不能运行</li></ul></li></ul><h3 id="进程的实现"><a href="#进程的实现" class="headerlink" title="进程的实现"></a>进程的实现</h3><ul><li>操作系统维护着一张表格，即进程表。每个进程占用一个进程表项。</li><li>该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存非配状况、所打开文件的状态、账号和调度信息吗，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。</li><li>与每一I/O类关联的是一个称作<strong>中断向量</strong>的位置。<ul><li>中断向量包含中断服务程序的入口地址。</li><li>中断发生后操作系统最底层的工作步骤：<ol><li>中断硬件将程序计数器、程序状态字等压入堆栈</li><li>硬件从中断向量装入新的程序计数器</li><li>汇编语言过程保存寄存器值</li><li>汇编语言过程设置新的堆栈</li><li>C中断服务例程运行</li><li>调度程序决定下一个将运行的进程</li><li>C过程返回至汇编代码</li><li>汇编语言过程开始运行新的当前进程</li></ol></li></ul></li></ul><h3 id="多道程序设计模型"><a href="#多道程序设计模型" class="headerlink" title="多道程序设计模型"></a>多道程序设计模型</h3><h2 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h2><blockquote><p>在传统的操作系统中，每个进程有一个地址空间和一个控制线程。</p></blockquote><h3 id="线程的使用"><a href="#线程的使用" class="headerlink" title="线程的使用"></a>线程的使用</h3><ul><li>引入线程的原因<ul><li>需要一种并行实体拥有共享同一个地址空间和所有可用数据的能力</li><li>线程比进程更轻量级，所以它们比进程更容易创建和销毁。</li><li>如果存在大量的计算和大量的I/O处理，拥有多个线程允许活动彼此重叠进行，可以提升性能</li></ul></li><li>构造服务器的三种方法：<ul><li>多线程：并行性、阻塞系统调用</li><li>单线程进程：无并行性、阻塞系统调用</li><li>有限状态机：并行性、非阻塞系统调用、中断</li></ul></li></ul><h3 id="经典的线程模型"><a href="#经典的线程模型" class="headerlink" title="经典的线程模型"></a>经典的线程模型</h3><ul><li>各个线程都可以访问进程地址空间中的每一个内存地址。（线程之间是没有保护的）</li><li>每个进程中的内容<ul><li>地址空间</li><li>全局变量</li><li>打开文件</li><li>子进程</li><li>即将发生的定时器</li><li>信号与信号处理程序</li><li>账户能力</li></ul></li><li>每个线程中的内容<ul><li>程序计数器</li><li>寄存器</li><li>堆栈</li><li>状态</li></ul></li><li>资源管理的单位是进程而非线程</li></ul><blockquote><p>Q: UNIX中的fork系统调用。如果父进程有多个线程，那么它的子进程也应该拥有这些线程吗？</p><p>A: 如果不是，则该子进程可能会工作不正常；如果是，父进程在read系统调用上被阻塞了会发生什么情况？</p></blockquote><h4 id="常见的线程调用"><a href="#常见的线程调用" class="headerlink" title="常见的线程调用"></a>常见的线程调用</h4><ul><li><code>thread_create</code><ul><li>进程通常会从当前的单个线程开始。这个线程可以通过调用<code>thread_create</code>创建新的线程</li></ul></li><li><code>thread_exit</code><ul><li>当一个线程完成工作，可以通过调用<code>thread_exit</code>退出</li></ul></li><li><code>thread_join</code><ul><li>一个线程可以等待一个特定的线程退出。</li></ul></li><li><code>thread_yielf</code><ul><li>它允许线程自动放弃CPU从而让另一个线程运行。</li></ul></li></ul><h3 id="POSIX线程"><a href="#POSIX线程" class="headerlink" title="POSIX线程"></a>POSIX线程</h3><table><thead><tr><th>线程调用</th><th>描述</th></tr></thead><tbody><tr><td>pthread_create</td><td>创建一个新线程</td></tr><tr><td>pthread_exit</td><td>结束调用的线程</td></tr><tr><td>pthread_join</td><td>等待一个特定的线程退出</td></tr><tr><td>pthread_yield</td><td>释放CPU来运行另外一个线程</td></tr><tr><td>pthread_attr_init</td><td>创建并初始化一个线程的属性结构</td></tr><tr><td>pthread_attr_destroy</td><td>删除一个线程的属性结构</td></tr></tbody></table><h3 id="在用户空间中实现线程"><a href="#在用户空间中实现线程" class="headerlink" title="在用户空间中实现线程"></a>在用户空间中实现线程</h3><p>把整个线程包放在用户空间中，内核对线程包一无所知。</p><img src="/2021/04/22/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%94%A8%E6%88%B7%E7%BA%A7%E7%BA%BF%E7%A8%8B%E5%8C%85%E5%92%8C%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%8C%85.png" class="" title="用户级线程包和内核管理的线程包"><ul><li>在用户空间管理线程时，每个进程需要有其专用的<strong>线程表</strong></li><li>使用用户级线程包的优点：<ul><li>进行一个线程切换比陷入内核要快</li><li>允许每个进程有自己定制的调度算法</li></ul></li><li>使用用户级线程包的缺点：<ul><li>难以实现阻塞系统调用（要允许每个线程使用阻塞调用，还要避免被阻塞的线程影响其他的线程）</li><li>如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU<ul><li>在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度的方式调度线程</li></ul></li><li>我们通常在经常发生线程阻塞的应用中才希望使用多个线程。对于那些基本上是CPU密集型而且极少有阻塞的应用程序而言，没有使用多线程的意义。</li></ul></li></ul><h3 id="在内核中实现线程"><a href="#在内核中实现线程" class="headerlink" title="在内核中实现线程"></a>在内核中实现线程</h3><ul><li>当某个线程希望创建一个新线程或撤销一个已有线程时，它进行了一个系统调用，这个系统调用通过对线程表的更新完成线程创建或撤销工作。</li><li>当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的CPU为止。</li><li>信号是发给进程而不是线程的。</li></ul><h3 id="混合实现"><a href="#混合实现" class="headerlink" title="混合实现"></a>混合实现</h3><p>使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来。</p><img src="/2021/04/22/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%94%A8%E6%88%B7%E7%BA%A7%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" class="" title="用户级线程与内核线程多路复用"><ul><li>内核只识别内核级线程，并对其进行调度</li><li>其中一些内核级线程会被多个用户级线程多路复用</li></ul><h3 id="调度程序激活机制"><a href="#调度程序激活机制" class="headerlink" title="调度程序激活机制"></a>调度程序激活机制</h3><blockquote><p>调度程序激活工作的目标是模拟内核线程的功能，但是为线程包提供通常在用户空间中才能实现的更好的性能和更大的灵活性。</p></blockquote><ul><li>如果用户线程从事某种系统调用时是安全的，那就不应该进行专门的非阻塞调用或者进行提前检查</li></ul><h3 id="使单进程代码多线程化"><a href="#使单进程代码多线程化" class="headerlink" title="使单进程代码多线程化"></a>使单进程代码多线程化</h3><p>把单进程的代码多线程化会碰到以下问题：</p><ul><li>针对全局变量（对线程而言是全局变量，并不是对整个程序是全局的）<ul><li>禁用全局变量</li><li>为每个线程赋予其私有的全局变量</li><li>可以引入新的库过程，以便创建、设置和读取这些线程范围的全局变量</li></ul></li><li>有许多库并不是可重入的<ul><li>为每个过程提供一个包装器，该包装器设置一个二进制位从而标志某个库处于使用中</li></ul></li><li>对于信号的捕捉应该用什么线程</li></ul><h2 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h2><ul><li>一个进程如何把信息传递给另一个</li><li>确保两个或更多的进程在关键活动中不会出现交叉</li><li>与正确的顺序有关</li></ul><h3 id="竞争条件"><a href="#竞争条件" class="headerlink" title="竞争条件"></a>竞争条件</h3><blockquote><p>两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为<strong>竞争条件</strong>。</p></blockquote><h3 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h3><ul><li>可以通过<strong>互斥</strong>的手段来避免<strong>竞争条件（condition race）</strong>。</li><li>把对共享内存进行访问的片段称作<strong>临界区域（critical region）</strong>。使两个进程不可能同时处于临界区中，就能够避免竞争条件。</li></ul><h3 id="忙等待的互斥"><a href="#忙等待的互斥" class="headerlink" title="忙等待的互斥"></a>忙等待的互斥</h3><p>有以下几种实现互斥的方案：</p><h4 id="屏蔽中断"><a href="#屏蔽中断" class="headerlink" title="屏蔽中断"></a>屏蔽中断</h4><p>使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前在打开中断。CPU只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后CPU将不会被切换到其他进程。</p><p>缺点：</p><p>屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。</p><h4 id="锁变量"><a href="#锁变量" class="headerlink" title="锁变量"></a>锁变量</h4><p>进入临界区之前，先读取锁变量的值。</p><p>缺点：</p><p>可能会导致领个进程进入临界区</p><h3 id="严格轮换法"><a href="#严格轮换法" class="headerlink" title="严格轮换法"></a>严格轮换法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// Thread A</span><br><span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>  <span class="hljs-keyword">while</span> (turn != <span class="hljs-number">0</span>) &#123;<br>    critical_region();<br>  &#125;<br>  turn = <span class="hljs-number">1</span>;<br>  noncritical_region();<br>&#125;<br><br><br><span class="hljs-comment">// Thread B</span><br><span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>  <span class="hljs-keyword">while</span> (turn != <span class="hljs-number">1</span>) &#123;<br>    critical_region();<br>  &#125;<br>  turn = <span class="hljs-number">0</span>;<br>  noncritical_region();<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>连续测试一个变量直到某个值出现为止，称为<strong>忙等待（busy waiting）</strong>。</li><li>但这种方式非常消耗CPU资源，只有在有理由认为等待时间是非常短的情况下，才使用忙等待。用于忙等待的锁，称为<strong>自旋锁（spin lock）</strong>。</li></ul><p>缺点：</p><ul><li>只能轮流，在一个进程比另一个进程慢很多的情况下，轮流进入临界区并不是一个好办法。</li></ul><h3 id="Peterson解法"><a href="#Peterson解法" class="headerlink" title="Peterson解法"></a>Peterson解法</h3><h3 id="TSL指令"><a href="#TSL指令" class="headerlink" title="TSL指令"></a>TSL指令</h3><p>一种硬件支持的方案：</p><p><code>TSL RX, LOCK</code> 称为<strong>测试并加锁（test and set lock）</strong></p><ul><li>它将一个内存字lock读到寄存器RX中，然后在该内存地址上存一个非零值。</li><li>这是一个原子操作。</li></ul><p>锁住存储总线不同于屏蔽中断</p><ul><li>屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">enter_region:<br><span class="hljs-meta">#</span><span class="bash"> 复制锁到寄存器并将锁设为1</span><br>TSL REGISTER, LOCK<br><span class="hljs-meta">#</span><span class="bash"> 锁是零嘛？</span><br>CMP REGISTER, #0<br><span class="hljs-meta">#</span><span class="bash"> 若不是零，说明锁已被设置，所以循环</span><br>JNE enter_region<br><span class="hljs-meta">#</span><span class="bash"> 返回调用者，进入临界区</span><br><br>leave_region:<br><span class="hljs-meta">#</span><span class="bash"> 在锁中存入0</span><br>MOVE LOCK, #0<br><span class="hljs-meta">#</span><span class="bash"> 返回调用者</span><br>RET<br></code></pre></td></tr></table></figure><h3 id="睡眠与唤醒"><a href="#睡眠与唤醒" class="headerlink" title="睡眠与唤醒"></a>睡眠与唤醒</h3><blockquote><p>优先级反转问题：</p><p>一台计算机有两个进程，H优先级较高，L优先级较低。调度规定，只要H处于就绪态它就可以运行。在某一时刻，L处于临界区中，此时H变到就绪态，准备运行。现在H开始忙等待，但由于当H就绪时L不会被调度，也就无法离开临界区，所以H将永远忙等待下去。</p></blockquote><p><code>sleep</code>是一个将引起调用进程阻塞的系统调用，即被挂起，直到另一个进程将其唤醒。</p><p><code>wakeup</code>调用有一个参数，即要被唤醒的进程。</p><h4 id="生产者-消费者问题"><a href="#生产者-消费者问题" class="headerlink" title="生产者-消费者问题"></a>生产者-消费者问题</h4>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>读书笔记</tag>
      
      <tag>现代操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>k8s operator</title>
    <link href="/2021/04/01/k8s-operator/"/>
    <url>/2021/04/01/k8s-operator/</url>
    
    <content type="html"><![CDATA[<h1 id="Operator概述"><a href="#Operator概述" class="headerlink" title="Operator概述"></a>Operator概述</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>首先介绍一下本文涉及的基本概念</p><ul><li><p>**CRD(Custom Resource Definition)**： 允许用户自定义Kubernetes资源，是一个类型。</p></li><li><p>**CR(Custom Resource)**： CRD的一个具体实例</p></li><li><p><strong>webhook</strong>： 本质上是一种HTTP回调，会注册到apiserver上。在apiserver特定事件发生时，会查询已注册的webhook，并把相应的消息发送出去。按照处理类型的不同，可以分成两类：</p><ul><li>mutating webhook: 可能会修改传入对象</li><li>validating webhook: 会只读传入对象</li></ul></li><li><p><strong>工作队列</strong>：Controller的核心组件。它会监控集群内的资源变化，并把相关的对象，包括它的动作与key</p></li><li><p><strong>Controller</strong>：它会循环地处理上述工作队列，按照各自的逻辑把集群状态向预期状态推动。不同的controller处理的类型不同。</p></li><li><p><strong>Operator</strong>：Operator是描述、部署和管理Kubernetes应用的一套机制。可以理解为CRD配合可选的webhook与controller来实现用户业务逻辑，即 operator = CRD + webhook + controller</p></li></ul><h2 id="常见的operator工作模式"><a href="#常见的operator工作模式" class="headerlink" title="常见的operator工作模式"></a>常见的operator工作模式</h2><ol><li>用户创建一个自定义资源（CRD）</li><li>apiserver 根据自己注册的一个 pass 列表，把该 CRD 的请求转发给 webhook</li><li>webhook 一般会完成该 CRD 的缺省值设定和参数检验。webhook 处理完之后，相应的 CR 会被写入数据库，返回给用户</li><li>与此同时，controller 会在后台监测该自定义资源，按照业务逻辑，处理与该自定义资源相关联的特殊操作</li><li>上述处理一般会引起集群内的状态变化，controller 会监测这些关联的变化，把这些变化记录到 CRD 的状态中</li></ol><h1 id="Operator-实战-Demo"><a href="#Operator-实战-Demo" class="headerlink" title="Operator 实战 Demo"></a>Operator 实战 Demo</h1><h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><h3 id="安装go"><a href="#安装go" class="headerlink" title="安装go"></a>安装go</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ brew install go<br>$ go version<br>go version go1.16.2 darwin/amd64<br></code></pre></td></tr></table></figure><h3 id="安装kubebuilder"><a href="#安装kubebuilder" class="headerlink" title="安装kubebuilder"></a>安装kubebuilder</h3><h2 id="创建新项目"><a href="#创建新项目" class="headerlink" title="创建新项目"></a>创建新项目</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入目录</span><br>$ <span class="hljs-built_in">cd</span> <span class="hljs-variable">$GOPATH</span>/src/github.com<br>$ mkdir -p operator-demo &amp; <span class="hljs-built_in">cd</span> operator-demo<br>$ <span class="hljs-built_in">pwd</span><br>/Users/zhengchicheng/go/src/github.com/operator-demo<br><span class="hljs-comment"># 初始化项目</span><br>$ kubebuilder init --domain my.domain<br></code></pre></td></tr></table></figure><p>如果报错<code>outside GOPATH, module path must be specified</code>。这是因为<code>go mod init</code>初始化项目时，需要定义一个module，所以我们先运行<code>go mod init ProjectName</code>之后再运行<code>kubebuilder</code>命令即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ tree -L 3<br>.<br>├── Dockerfile<br>├── Makefile<br>├── PROJECT<br>├── bin<br>│   └── manager<br>├── config<br>│   ├── certmanager<br>│   │   ├── certificate.yaml<br>│   │   ├── kustomization.yaml<br>│   │   └── kustomizeconfig.yaml<br>│   ├── default<br>│   │   ├── kustomization.yaml<br>│   │   ├── manager_auth_proxy_patch.yaml<br>│   │   ├── manager_webhook_patch.yaml<br>│   │   └── webhookcainjection_patch.yaml<br>│   ├── manager<br>│   │   ├── kustomization.yaml<br>│   │   └── manager.yaml<br>│   ├── prometheus<br>│   │   ├── kustomization.yaml<br>│   │   └── monitor.yaml<br>│   ├── rbac<br>│   │   ├── auth_proxy_client_clusterrole.yaml<br>│   │   ├── auth_proxy_role.yaml<br>│   │   ├── auth_proxy_role_binding.yaml<br>│   │   ├── auth_proxy_service.yaml<br>│   │   ├── kustomization.yaml<br>│   │   ├── leader_election_role.yaml<br>│   │   ├── leader_election_role_binding.yaml<br>│   │   └── role_binding.yaml<br>│   └── webhook<br>│       ├── kustomization.yaml<br>│       ├── kustomizeconfig.yaml<br>│       └── service.yaml<br>├── go.mod<br>├── go.sum<br>├── hack<br>│   └── boilerplate.go.txt<br>└── main.go<br><br>9 directories, 30 files<br><br>$ go get github.com/onsi/ginkgo@v1.11.0<br>$ go get github.com/onsi/gomega@v1.8.1<br>$ go get github.com/go-logr/logr@v0.1.0<br><br><span class="hljs-comment"># 在项目根目录下执行下面的命令创建 API。</span><br>$ kubebuilder create api --group groupa --version v1 --kind ApiExampleA<br>Create Resource [y/n]<br>y<br>Create Controller [y/n]<br>y<br>Writing scaffold <span class="hljs-keyword">for</span> you to edit...<br>api/v1/guestbook_types.go<br>controllers/guestbook_controller.go<br>Running make:<br>$ make<br>go: creating new go.mod: module tmp<br>go get: added sigs.k8s.io/controller-tools v0.2.5<br>/Users/zhengchicheng/go/bin/controller-gen object:headerFile=<span class="hljs-string">&quot;hack/boilerplate.go.txt&quot;</span> paths=<span class="hljs-string">&quot;./...&quot;</span><br>go fmt ./...<br>go vet ./...<br>go build -o bin/manager main.go<br><br><span class="hljs-comment"># API创建完成后，在项目根目录下查看目录结构</span><br>$ tree -L 3<br>.<br>├── Dockerfile <span class="hljs-comment"># 用于构建 Operator 镜像</span><br>├── Makefile   <span class="hljs-comment"># 构建时使用</span><br>├── PROJECT    <span class="hljs-comment"># 项目配置</span><br>├── api        <span class="hljs-comment"># 新增的api</span><br>│   └── v1<br>│       ├── apiexamplea_types.go<br>│       ├── groupversion_info.go<br>│       └── zz_generated.deepcopy.go<br>├── bin<br>│   └── manager<br>├── config<br>│   ├── certmanager<br>│   │   ├── certificate.yaml<br>│   │   ├── kustomization.yaml<br>│   │   └── kustomizeconfig.yaml<br>│   ├── crd <span class="hljs-comment"># 新增 CRD 定义</span><br>│   │   ├── kustomization.yaml<br>│   │   ├── kustomizeconfig.yaml<br>│   │   └── patches<br>│   ├── default<br>│   │   ├── kustomization.yaml<br>│   │   ├── manager_auth_proxy_patch.yaml<br>│   │   ├── manager_webhook_patch.yaml<br>│   │   └── webhookcainjection_patch.yaml<br>│   ├── manager<br>│   │   ├── kustomization.yaml<br>│   │   └── manager.yaml<br>│   ├── prometheus<br>│   │   ├── kustomization.yaml<br>│   │   └── monitor.yaml<br>│   ├── rbac<br>│   │   ├── apiexamplea_editor_role.yaml<br>│   │   ├── apiexamplea_viewer_role.yaml<br>│   │   ├── auth_proxy_client_clusterrole.yaml<br>│   │   ├── auth_proxy_role.yaml<br>│   │   ├── auth_proxy_role_binding.yaml<br>│   │   ├── auth_proxy_service.yaml<br>│   │   ├── kustomization.yaml<br>│   │   ├── leader_election_role.yaml<br>│   │   ├── leader_election_role_binding.yaml<br>│   │   └── role_binding.yaml<br>│   ├── samples<br>│   │   └── groupa_v1_apiexamplea.yaml<br>│   └── webhook<br>│       ├── kustomization.yaml<br>│       ├── kustomizeconfig.yaml<br>│       └── service.yaml<br>├── controllers <span class="hljs-comment"># 新增controller</span><br>│   ├── apiexamplea_controller.go<br>│   └── suite_test.go<br>├── go.mod<br>├── go.sum<br>├── hack<br>│   └── boilerplate.go.txt<br>└── main.go <span class="hljs-comment"># 新增处理逻辑</span><br><br>15 directories, 40 files<br></code></pre></td></tr></table></figure><h3 id="安装CRD"><a href="#安装CRD" class="headerlink" title="安装CRD"></a>安装CRD</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ make install<br></code></pre></td></tr></table></figure><h3 id="部署Controller"><a href="#部署Controller" class="headerlink" title="部署Controller"></a>部署Controller</h3><p>有两种方式运行controller</p><ul><li>本地运行，用于调试</li><li>部署到kubernetes上运行，作为生产使用</li></ul><h4 id="本地运行controller"><a href="#本地运行controller" class="headerlink" title="本地运行controller"></a>本地运行controller</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ make run<br>go run ./main.go<br>2021-04-01T17:21:14.672+0800INFOcontroller-runtime.metricsmetrics server is starting to listen&#123;<span class="hljs-string">&quot;addr&quot;</span>: <span class="hljs-string">&quot;:8080&quot;</span>&#125;<br>2021-04-01T17:21:14.673+0800INFOsetupstarting manager<br>2021-04-01T17:21:14.673+0800INFOcontroller-runtime.managerstarting metrics server&#123;<span class="hljs-string">&quot;path&quot;</span>: <span class="hljs-string">&quot;/metrics&quot;</span>&#125;<br>2021-04-01T17:21:14.673+0800INFOcontroller-runtime.controllerStarting EventSource&#123;<span class="hljs-string">&quot;controller&quot;</span>: <span class="hljs-string">&quot;guestbook&quot;</span>, <span class="hljs-string">&quot;source&quot;</span>: <span class="hljs-string">&quot;kind source: /, Kind=&quot;</span>&#125;<br>2021-04-01T17:21:14.777+0800INFOcontroller-runtime.controllerStarting Controller&#123;<span class="hljs-string">&quot;controller&quot;</span>: <span class="hljs-string">&quot;guestbook&quot;</span>&#125;<br>2021-04-01T17:21:14.777+0800INFOcontroller-runtime.controllerStarting workers&#123;<span class="hljs-string">&quot;controller&quot;</span>: <span class="hljs-string">&quot;guestbook&quot;</span>, <span class="hljs-string">&quot;worker count&quot;</span>: 1&#125;<br></code></pre></td></tr></table></figure><h4 id="将controller部署到kubernetes"><a href="#将controller部署到kubernetes" class="headerlink" title="将controller部署到kubernetes"></a>将controller部署到kubernetes</h4><p>执行下面的命令部署controller到kubernetes上，这一步将会在本地构建controller镜像，并推送到DockerHub上，然后在kubernetes上部署Deployment资源。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">make docker-build docker-push IMG=jimmysong/kubebuilder-example:latest<br>make deploy IMG=jimmysong/kubebuilder-example:latest<br></code></pre></td></tr></table></figure><p>利用以下命令行查看Deployment对象和Pod资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get deployment -n kubebuilder-example-system<br>NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE<br>kubebuilder-example-controller-manager   1/1     1            1           4m25s<br><br>$ kubectl get pod -n kubebuilder-example-system<br>NAME                                                      READY   STATUS    RESTARTS   AGE<br>kubebuilder-example-controller-manager-689bf786fb-xcqbk   2/2     Running   0          5m16s<br></code></pre></td></tr></table></figure><h3 id="创建-CR"><a href="#创建-CR" class="headerlink" title="创建 CR"></a>创建 CR</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 部署CR</span><br>$ kubectl apply -f config/samples/groupa_v1_apiexamplea.yaml<br><br><span class="hljs-comment"># 查看新建的CR</span><br>$ kubectl get apiexampleas.groupa.k8s.zhuang.com<br>NAME                 AGE<br>apiexamplea-sample   26s<br><br>$ kubectl get apiexampleas.groupa.k8s.zhuang.com -o yaml<br>apiVersion: v1<br>items:<br>- apiVersion: groupa.k8s.zhuang.com/v1<br>  kind: ApiExampleA<br>  metadata:<br>    annotations:<br>      kubectl.kubernetes.io/last-applied-configuration: |<br>        &#123;<span class="hljs-string">&quot;apiVersion&quot;</span>:<span class="hljs-string">&quot;groupa.k8s.zhuang.com/v1&quot;</span>,<span class="hljs-string">&quot;kind&quot;</span>:<span class="hljs-string">&quot;ApiExampleA&quot;</span>,<span class="hljs-string">&quot;metadata&quot;</span>:&#123;<span class="hljs-string">&quot;annotations&quot;</span>:&#123;&#125;,<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;apiexamplea-sample&quot;</span>,<span class="hljs-string">&quot;namespace&quot;</span>:<span class="hljs-string">&quot;default&quot;</span>&#125;,<span class="hljs-string">&quot;spec&quot;</span>:&#123;<span class="hljs-string">&quot;foo&quot;</span>:<span class="hljs-string">&quot;bar&quot;</span>&#125;&#125;<br>    creationTimestamp: <span class="hljs-string">&quot;2021-04-01T12:12:23Z&quot;</span><br>    generation: 1<br>    managedFields:<br>    - apiVersion: groupa.k8s.zhuang.com/v1<br>      fieldsType: FieldsV1<br>      fieldsV1:<br>        f:metadata:<br>          f:annotations:<br>            .: &#123;&#125;<br>            f:kubectl.kubernetes.io/last-applied-configuration: &#123;&#125;<br>        f:spec:<br>          .: &#123;&#125;<br>          f:foo: &#123;&#125;<br>      manager: kubectl-client-side-apply<br>      operation: Update<br>      time: <span class="hljs-string">&quot;2021-04-01T12:12:23Z&quot;</span><br>    name: apiexamplea-sample<br>    namespace: default<br>    resourceVersion: <span class="hljs-string">&quot;415357&quot;</span><br>    selfLink: /apis/groupa.k8s.zhuang.com/v1/namespaces/default/apiexampleas/apiexamplea-sample<br>    uid: 55e88f71-f660-430c-93b5-dd78dd517eed<br>  spec:<br>    foo: bar<br>kind: List<br>metadata:<br>  resourceVersion: <span class="hljs-string">&quot;&quot;</span><br>  selfLink: <span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure><p>至此一个基本的 Operator 框架已经创建完成，但这个 Operator 只是修改了 etcd 中的数据而已，实际上什么事情也没做，因为我们没有在 Operator 中的增加业务逻辑。</p><h2 id="增加业务逻辑"><a href="#增加业务逻辑" class="headerlink" title="增加业务逻辑"></a>增加业务逻辑</h2><p>下面我们将修改 CRD 的数据结构并在 controller 中增加一些日志输出</p><ol><li>初始化项目和API</li><li>安装CRD</li><li>部署Controller</li><li>创建CR</li></ol><h1 id="GitHub-Demo"><a href="#GitHub-Demo" class="headerlink" title="GitHub Demo"></a>GitHub Demo</h1><p><a href="https://github.com/zhuangzhuang131419/operator-demo">operator-demo</a></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://www.kubernetes.org.cn/6746.html">从零开始入门 K8s | Kubernetes API 编程利器：Operator 和 Operator Framework</a></li><li><a href="https://jimmysong.io/kubernetes-handbook/develop/kubebuilder-example.html">使用 kubebuilder 创建 operator 示例</a></li><li><a href="https://cloudnative.to/kubebuilder/introduction.html">The Kubebuilder Book</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>kubernetes</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Ray分布式计算框架——Using Ray</title>
    <link href="/2021/03/23/Ray%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Using-Ray/"/>
    <url>/2021/03/23/Ray%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94Using-Ray/</url>
    
    <content type="html"><![CDATA[<h1 id="Using-Ray"><a href="#Using-Ray" class="headerlink" title="Using Ray"></a>Using Ray</h1><h2 id="Starting-Ray"><a href="#Starting-Ray" class="headerlink" title="Starting Ray"></a>Starting Ray</h2><ul><li>什么是 Ray runtime (内存管理)<ul><li>Ray programs are able to parallelize and distribute by leveraging an underlying Ray runtime.</li><li>The Ray runtime consists of multiple services/processes started in the background for communication, data transfer, scheduling, and more.</li><li>The Ray runtime can be started on a laptop, a single server, or multiple servers.</li></ul></li><li>启动Ray runtime的几种方式<ul><li>隐式的通过<code>ray.init()</code><ul><li>不需要指定<code>address</code></li><li>直接在本机启动一个runtime，本机成为一个<strong>head node</strong>。</li><li>当运行<code>ray.init()</code>的进程终止了，runtime也就终止了。也可以使用<code>ray.shutdown()</code>强制终止。</li></ul></li><li>显示的通过CLI</li><li>显示的通过cluster launch<ul><li><code>ray up</code>使用Ray cluster launcher在云上启动一个集群，创建一个指定的<strong>head node</strong>和一些<strong>worker node</strong>。</li><li>想要和现有的集群连接，调用<code>ray.init</code>并且指定集群的ip地址。</li></ul></li></ul></li></ul><h2 id="Using-Actors"><a href="#Using-Actors" class="headerlink" title="Using Actors"></a>Using Actors</h2><p>一个 <code>actor</code> 实际上就是一个有状态的 <code>worker</code>. 当一个新的 actor 被实例化，那么一个新的 worker 就诞生了，同时这个 actor 的 method 就被安排在那个特定的 worker 上。 actor 可以访问并修改那个 worker 的状态. </p><ul><li>Worker 和 Actor 的区别<ul><li>“Ray worker” 就是一个 Python <code>进程</code></li><li>“Ray worker” 要么被用来运行多个 Ray task 或者开始时对应一个专门的 actor</li></ul></li></ul><blockquote><p>Task: 当 Ray 在一台机器上运行的时候，会自动开始几个 <code>Ray workers</code>. 他们被用来执行 <code>task</code> (类似一个进程池)</p></blockquote><blockquote><p>Actor: 一个 Ray Actor 也是一个 “Ray worker” 只不过是在 runtime 实例化的. 所有的 methods 都运行在同一个进程里，使用相同的资源. 与 <code>Task</code> 不同的是，运行 Ray Actor 的进程不会重复使用并且会在 Actor 被删除后终止。</p></blockquote><p>下面将介绍两种actor同步的方式</p><h2 id="AsyncIO-Concurrency-for-Actors"><a href="#AsyncIO-Concurrency-for-Actors" class="headerlink" title="AsyncIO / Concurrency for Actors"></a>AsyncIO / Concurrency for Actors</h2><p>Ray 提供了两种 concurrency 的办法 <code>async execution</code> 和 <code>threading</code>. </p><p>Python 的 <code>Global Interpreter Lock (GIL)</code> 只允许在某一时刻运行一个thread, 那么我们就无法实现真正意义上的 parallelism. 一些常见的库，比如 Numpy, Cython, Tensorflow, PyTorch 在调用 C/C++ 函数的时候会释放 GIL. 但是<code>async execution</code> 和 <code>threading</code>无法绕开 GIL.</p><h3 id="AsyncIO-for-Actors"><a href="#AsyncIO-for-Actors" class="headerlink" title="AsyncIO for Actors"></a>AsyncIO for Actors</h3><ul><li><a href="https://juejin.cn/post/6844904088677662728">Python 中 async 与 await 的用法</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">import</span> asyncio<br>ray.init()<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AsyncActor</span>:</span><br>    <span class="hljs-comment"># multiple invocation of this method can be running in</span><br>    <span class="hljs-comment"># the event loop at the same time</span><br>    <span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run_concurrent</span>(<span class="hljs-params">self</span>):</span><br>        print(<span class="hljs-string">&quot;started&quot;</span>)<br>        <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">2</span>) <span class="hljs-comment"># concurrent workload here</span><br>        print(<span class="hljs-string">&quot;finished&quot;</span>)<br><br>actor = AsyncActor.remote()<br><br><span class="hljs-comment"># regular ray.get</span><br>ray.get([actor.run_concurrent.remote() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)])<br><br><span class="hljs-comment"># async ray.get</span><br><span class="hljs-keyword">await</span> actor.run_concurrent.remote()<br></code></pre></td></tr></table></figure><h3 id="Threaded-Actors"><a href="#Threaded-Actors" class="headerlink" title="Threaded Actors"></a>Threaded Actors</h3><p>有时候使用 asyncio 并不是一个理想的解决方案。比如你可能有一个method在进行大量的计算任务并阻塞了event loop, 且不能通过 <code>await</code> 去停止。这就对 Async Actor 的整体性能有影响，因为 Async Actor 在某一时刻只能执行一个任务并且依赖<code>await</code> 去进行上下文切换。</p><p>可以使用 <code>max_concurrency</code> Actor 来代替, 类似线程池。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ThreadedActor</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task_1</span>(<span class="hljs-params">self</span>):</span> print(<span class="hljs-string">&quot;I&#x27;m running in a thread!&quot;</span>)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task_2</span>(<span class="hljs-params">self</span>):</span> print(<span class="hljs-string">&quot;I&#x27;m running in another thread!&quot;</span>)<br><br>a = ThreadedActor.options(max_concurrency=<span class="hljs-number">2</span>).remote()<br>ray.get([a.task_1.remote(), a.task_2.remote()])<br></code></pre></td></tr></table></figure><p>每个 threaded actor 的 <code>Invocation</code> 都会在线程池中运行。线程池的大小是由 <code>max_concurrency</code> 控制的。</p><h2 id="GPU-Support"><a href="#GPU-Support" class="headerlink" title="GPU Support"></a>GPU Support</h2><p>Ray可以在<code>ray.remote</code>修饰器中对远程函数和对象中指定GPU的需求</p><h3 id="Starting-Ray-with-GPUs"><a href="#Starting-Ray-with-GPUs" class="headerlink" title="Starting Ray with GPUs"></a>Starting Ray with GPUs</h3><p>Ray会自动监测本机上可用的GPU数量。但我们也可以通过<code>ray.init(num_gpus=N)</code>或者<code>ray start --num-gpus=N</code>来重写。</p><p>Tips: Ray没有对设置超过实际数量GPU的操作采取保护机制。设置过多的GPU可能会导致GPU不存在的报错。</p><h3 id="Using-Remote-Functions-with-GPUs"><a href="#Using-Remote-Functions-with-GPUs" class="headerlink" title="Using Remote Functions with GPUs"></a>Using Remote Functions with GPUs</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-meta">@ray.remote(<span class="hljs-params">num_gpus=<span class="hljs-number">1</span></span>)</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">use_gpu</span>():</span><br>    print(<span class="hljs-string">&quot;ray.get_gpu_ids(): &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(ray.get_gpu_ids()))<br>    print(<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>]))<br></code></pre></td></tr></table></figure><h2 id="Serialization"><a href="#Serialization" class="headerlink" title="Serialization"></a>Serialization</h2><p>因为 Ray 进程不是内存空间共享的，数据在 <code>workers</code> 和 <code>nodes</code> 之间传输需要序列化和反序列化。Ray 使用 <code>Plasma object store</code> 高效的把对象传输给不同的 <code>nodes</code> 和 <code>processes</code>.</p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>Ray 使用 <code>Pickle protocol version 5</code> 作为序列化协议。</p><h3 id="Plasma-Object-Store"><a href="#Plasma-Object-Store" class="headerlink" title="Plasma Object Store"></a>Plasma Object Store</h3><p><strong>Plasma</strong> 是一个基于 Apache Arrow 开发的内对象存储。所有的对象在 <strong>Plasma object store</strong> 中都是不可变的并且保存在共享内存中。</p><p>每个 node 都有自己的 object store. 当数据存入 object store, 它不会自动的广播通知其他的 node. 数据一直保留在本地直到在别的 node 被别的 task 或者 actor 请求。</p><h3 id="Numpy-Arrays"><a href="#Numpy-Arrays" class="headerlink" title="Numpy Arrays"></a>Numpy Arrays</h3><ul><li>Numpy array中存储的都是只读的对象，同一节点上的所有Ray Worker都可以读取对象存储中的numpy array而无需复制（零复制读取）。</li><li>工作进程中的每个numpy array对象都持有一个指向共享内存中相关数组的指针。</li><li>对只读对象的任何写入都需要用户首先将其复制到本地进程内存中。</li></ul><h2 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h2><p>Ray 当中的内存管理</p><p>我们把 Ray 的内存分成两个部分: <code>Ray system memory</code> 和 <code>Application memory</code>.</p><ul><li>Ray system memory (这部分的内存是 Ray 内部在使用)<ul><li>Redis<ul><li>存储在集群中的一系列 nodes 和 actors</li><li>存储这部分用到的内存很小</li></ul></li><li>Raylet<ul><li>C++ raylet 进程在每个 node 上运行所需要的空间</li><li>这部分不能够被控制，但是用到的内存空间也很小</li></ul></li></ul></li><li>Application memory (这部分内存是我们的应用在使用)<ul><li>Worker heap<ul><li>应用所使用的的内存 (e.g., in Python code or TensorFlow)</li><li>需要用应用的 <em>resident set size</em> 减去 <em>shared memory usage</em> 来衡量。</li></ul></li><li>Object store memory<ul><li>当应用通过 <code>ray.put</code> 创建对象并且返回的值来自 remote function</li></ul></li><li>Object store shared memory<ul><li>当应用通过 <code>ray.get</code> 读取对象</li><li>如果一个对象已经存在在一个 node 中, 这将不会导致额外的内存分配。这样可以使得一些比较大的对象在各个 actors 和 tasks 中共享的更有效率。</li></ul></li></ul></li></ul><h3 id="Object-生命周期"><a href="#Object-生命周期" class="headerlink" title="Object 生命周期"></a>Object 生命周期</h3><p>Object的所有者是初始化<code>ObjectRef</code>，<strong>并且</strong>提交了task或者调用了<code>ray up</code>的worker。</p><ul><li>Ray 如果确认所有者还存在，Object最后会解析为它的值</li><li>如果所有者不存在，试图获取Object值得操作不会悬停，而是抛出异常，即使存在Object物理拷贝</li></ul><p>每个worker储存它所属的Object的引用次数。引用仅仅在以下情况被统计：</p><ul><li>传递一个<code>ObjectRef</code>或者包含<code>ObjectRef</code>这个参数的task</li><li>Task返回一个<code>ObjectRef</code>或者包含<code>ObjectRef</code>的返回</li></ul><h3 id="对象管理"><a href="#对象管理" class="headerlink" title="对象管理"></a>对象管理</h3><p>通常，小的对象存储在它自己的进程里，而大的对象储存在分布式对象存储里。</p><p>在进程中的对象能够通过直接内存拷贝的方式快速解析，但是这可能会带来更多的内存占用。如果对象被很多进程引用，就会造成额外的拷贝操作。</p><p>而解析一个分布式内存的对象至少需要一个worker之间的IPC（进程间通信）。如果worker本地共享不存在这个对象的拷贝，还会产生一个RPC通信。因为共享内存存储是通过“共享内存机制”实现的，一个节点上的多个worker可能引用同一块对象的拷贝。采用“零拷贝反序列化”的方式就可以降低总内存占用。这种用法意味着一个进程可以应用一个超过单台机器内存容量的对象，因为对象的多个拷贝可以储存在不同的节点上。</p><h3 id="对象解析"><a href="#对象解析" class="headerlink" title="对象解析"></a>对象解析</h3><p>object的值能够通过一个叫<code>ObjectRef</code>来解析。<code>ObjectRef</code>包含了两个字段：</p><ul><li>一个唯一的20-byte的标识符。这是产生这个object的task id和object id的组合</li><li>object所有者进程的地址。包含worker进程的唯一ID，IP地址和端口，和本地raylet的ID</li></ul><ol><li>在GCS查找Object的地址</li><li>选择一个地址并且发出了一个获取Object的请求</li><li>获得了这个Object</li></ol><h3 id="使用ray-memory命令行"><a href="#使用ray-memory命令行" class="headerlink" title="使用ray memory命令行"></a>使用<code>ray memory</code>命令行</h3><p>当一个Ray应用在运行的时候使用<code>ray memory</code>会返回所有当前被集群中driver, actor和task持有的的<code>ObjectRef</code>的索引。</p><p>此输出中的每个条目都对应于一个ObjectRef，该ObjectRef当前将对象固定在对象存储中，以及引用的位置（在driver、worker等中）、引用的类型（有关引用类型的详细信息）、对象的大小（以字节为单位），实例化对象的进程ID和IP地址，以及在应用程序中创建引用的位置。</p><h4 id="Local-ObjectRef-Reference"><a href="#Local-ObjectRef-Reference" class="headerlink" title="Local ObjectRef Reference"></a>Local ObjectRef Reference</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f</span>(<span class="hljs-params">arg</span>):</span><br>    <span class="hljs-keyword">return</span> arg<br><br>a = ray.put(<span class="hljs-literal">None</span>)<br>b = f.remote(<span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><p>有两个<code>ObjectRef</code>，都是<code>LOCAL_REFERENCE</code>。但是其中一个的Reference是<code>put object</code>（对应a），另一个是<code>task call</code>（对应b）</p><h4 id="Objects-pinned-in-memory"><a href="#Objects-pinned-in-memory" class="headerlink" title="Objects pinned in memory"></a>Objects pinned in memory</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = ray.put(np.zeros(<span class="hljs-number">1</span>))<br>b = ray.get(a)<br><span class="hljs-keyword">del</span> a<br></code></pre></td></tr></table></figure><p>在这种情况下，对象仍然固定在对象存储中，因为反序列化副本（存储在b中）直接指向对象存储中的内存。</p><h4 id="Pending-task-reference"><a href="#Pending-task-reference" class="headerlink" title="Pending task reference"></a>Pending task reference</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f</span>(<span class="hljs-params">arg</span>):</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-keyword">pass</span><br><br>a = ray.put(<span class="hljs-literal">None</span>)<br>b = f.remote(a)<br></code></pre></td></tr></table></figure><p>我们发现同一个ObjectID在worker和driver中都出现了分别是<code>USED_BY_PENDING_TASK</code>和<code>PINNED_IN_MEMORY</code>。因为Python <code>arg</code>直接引用了plasma中的内存。</p><h4 id="Serialized-ObjectRef-references"><a href="#Serialized-ObjectRef-references" class="headerlink" title="Serialized ObjectRef references"></a>Serialized ObjectRef references</h4><p>我们对a进行一个封装，这个例子中是作为一个list传入的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f</span>(<span class="hljs-params">arg</span>):</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-keyword">pass</span><br><br>a = ray.put(<span class="hljs-literal">None</span>)<br>b = f.remote([a])<br></code></pre></td></tr></table></figure><p>这时候就变成了<code>LOCAL_REFERENCE</code></p><h4 id="Captured-ObjectRef-references"><a href="#Captured-ObjectRef-references" class="headerlink" title="Captured ObjectRef references"></a>Captured ObjectRef references</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a = ray.put(<span class="hljs-literal">None</span>)<br>b = ray.put([a])<br><span class="hljs-keyword">del</span> a<br></code></pre></td></tr></table></figure><p>在内存中a是<code>CAPTURED_IN_OBJECT</code>的类型</p><h3 id="Raylet"><a href="#Raylet" class="headerlink" title="Raylet"></a>Raylet</h3><p>我们可以抽象一个相对简单的 Worker 和 GCS 的关系:</p><p>Raylet 在中间的作用非常关键，包含了以下重要内容</p><ul><li>Node Manager<ul><li>基于 boost::asio 的异步通信模块，主要是通信的连接和消息处理管理</li></ul></li><li>Object Manager<ul><li>Object Store 的管理</li></ul></li><li>gcs_client 或者 gcs server<ul><li>gcs_client 是连接 GCS 客户端。如果设置 RAY_GCS_SERVICE_ENABLED 为 true 的话，这个 Server 就是作为 GCS 启动</li></ul></li></ul><h4 id="Raylet-的启动过程"><a href="#Raylet-的启动过程" class="headerlink" title="Raylet 的启动过程"></a>Raylet 的启动过程</h4><ol><li>Raylet 的初始化，这里包含有很多参数。包括 Node Manager 和 gcs client 的初始化</li><li>注册 GCS 准备接收消息。一旦有消息进来，就进入 Node Manager 的 ProcessClientMessage 过程。(TODO ProcessClientMessage的通信模型)</li></ol><h2 id="Placement-Groups-置放群组"><a href="#Placement-Groups-置放群组" class="headerlink" title="Placement Groups (置放群组)"></a>Placement Groups (置放群组)</h2><p><strong>Placement Groups</strong> 允许用户跨多个<code>nodes</code>原子性的保存一组资源.(i.e., gang scheduling). <strong>Placement Groups</strong> 可以被用不同的策略来调度打包 <code>Ray tasks</code> 和 <code>actors</code>.</p><blockquote><p>这里的原子性意味着如果有一个 bundle 不适合当前所在的 node, 那么整个 Placement Group 都不会被创建.</p></blockquote><p><strong>Placement Groups</strong> 有以下应用</p><ul><li>Gang Scheduling: 应用程序要求所有任务/参与者都安排在同一时间开始。</li><li>Maximizing data locality: 您希望将task和actor安排在数据附近，以避免对象传输开销。</li><li>Load balancing: 为了提高应用程序可用性并避免资源过载，您希望尽可能将参与者或任务放置到不同的物理机器中。</li></ul><h4 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h4><ul><li><strong>bundle</strong> : 资源的集合<ul><li>一个 bundle 必须适合一个在集群中的 node</li><li>然后 Bundles 会根据 <code>placement group strategy</code> 在集群中跨 nodes 放置</li></ul></li><li><strong>placement group</strong> : bundle 的集合<ul><li>每一个 bundle 都被给予了一个在 placement group 的编号</li><li>然后 Bundles 会根据 <code>placement group strategy</code> 在集群中跨 nodes 放置</li><li>等 placement group 创建了后，<code>tasks</code> 和 <code>actors</code> 可以根据 placement group 或者个人 bundles 来调度。</li></ul></li></ul><h4 id="策略类型"><a href="#策略类型" class="headerlink" title="策略类型"></a>策略类型</h4><ul><li>STRICT_PACK<ul><li>所有bundles都必须放在集群上的单个节点中。</li></ul></li><li>PACK<ul><li>所有提供的bundle都尽量打包到单个节点上。如果严格打包不可行（即某些bundle不适合节点），则可以将bundle放在其他节点上。</li></ul></li><li>STRICT_SPREAD<ul><li>每个bundle必须安排在单独的节点中。</li></ul></li><li>SPREAD<ul><li>每个bundle将以最大努力的方式分布到单独的节点上。如果严格展开不可行，则可以将bundle放置在重叠的节点上。</li></ul></li></ul><h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><p>如果包含placement group的某些bundle的节点死亡，GCS将在不同的节点上重新调度所有束。这意味着placement group的初始创建是“原子的”，但一旦创建，就可能存在部分placement group。</p><p>Placement group可以容忍工作节点故障（死区节点上的包被重新调度）。但是，放置组目前无法容忍头部节点故障（GCS故障），这是Ray的单点故障。</p><h2 id="Advanced-Usage"><a href="#Advanced-Usage" class="headerlink" title="Advanced Usage"></a>Advanced Usage</h2><h4 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h4><ul><li>Inter-process synchronization using FileLock</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">from</span> filelock <span class="hljs-keyword">import</span> FileLock<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">write_to_file</span>(<span class="hljs-params">text</span>):</span><br>    <span class="hljs-comment"># Create a filelock object. Consider using an absolute path for the lock.</span><br>    <span class="hljs-keyword">with</span> FileLock(<span class="hljs-string">&quot;my_data.txt.lock&quot;</span>):<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;my_data.txt&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            f.write(text)<br><br>ray.init()<br>ray.get([write_to_file.remote(<span class="hljs-string">&quot;hi there!\n&quot;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)])<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;my_data.txt&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    print(f.read())<br><br><span class="hljs-comment">## Output is:</span><br><br><span class="hljs-comment"># hi there!</span><br><span class="hljs-comment"># hi there!</span><br><span class="hljs-comment"># hi there!</span><br></code></pre></td></tr></table></figure><p><a href="https://zhuanlan.zhihu.com/p/26487659">理解 Python 关键字 “with” 与上下文管理器</a></p><ul><li>Multi-node synchronization using SignalActor</li></ul><blockquote><p>当你有多个 tasks 需要等待同一个条件的时候，你可以使用一个 <code>SingnalActor</code> 来调度。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># Also available via `from ray.test_utils import SignalActor`</span><br><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">import</span> asyncio<br><br><span class="hljs-meta">@ray.remote(<span class="hljs-params">num_cpus=<span class="hljs-number">0</span></span>)</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SignalActor</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        self.ready_event = asyncio.Event()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">send</span>(<span class="hljs-params">self, clear=<span class="hljs-literal">False</span></span>):</span><br>        self.ready_event.<span class="hljs-built_in">set</span>()<br>        <span class="hljs-keyword">if</span> clear:<br>            self.ready_event.clear()<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wait</span>(<span class="hljs-params">self, should_wait=<span class="hljs-literal">True</span></span>):</span><br>        <span class="hljs-keyword">if</span> should_wait:<br>            <span class="hljs-keyword">await</span> self.ready_event.wait()<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wait_and_go</span>(<span class="hljs-params">signal</span>):</span><br>    ray.get(signal.wait.remote())<br><br>    print(<span class="hljs-string">&quot;go!&quot;</span>)<br><br>ray.init()<br>signal = SignalActor.remote()<br>tasks = [wait_and_go.remote(signal) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br>print(<span class="hljs-string">&quot;ready...&quot;</span>)<br><span class="hljs-comment"># Tasks will all be waiting for the singals.</span><br>print(<span class="hljs-string">&quot;set..&quot;</span>)<br>ray.get(signal.send.remote())<br><br><span class="hljs-comment"># Tasks are unblocked.</span><br>ray.get(tasks)<br><br><span class="hljs-comment">##  Output is:</span><br><span class="hljs-comment"># ready...</span><br><span class="hljs-comment"># get set..</span><br><br><span class="hljs-comment"># (pid=77366) go!</span><br><span class="hljs-comment"># (pid=77372) go!</span><br><span class="hljs-comment"># (pid=77367) go!</span><br><span class="hljs-comment"># (pid=77358) go!</span><br></code></pre></td></tr></table></figure><ul><li>Message passing using Ray Queue</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">from</span> ray.util.queue <span class="hljs-keyword">import</span> Queue<br><br>ray.init()<br><span class="hljs-comment"># You can pass this object around to different tasks/actors</span><br>queue = Queue(maxsize=<span class="hljs-number">100</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">consumer</span>(<span class="hljs-params">queue</span>):</span><br>    next_item = queue.get(block=<span class="hljs-literal">True</span>)<br>    print(<span class="hljs-string">f&quot;got work <span class="hljs-subst">&#123;next_item&#125;</span>&quot;</span>)<br><br>consumers = [consumer.remote(queue) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]<br><br>[queue.put(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br></code></pre></td></tr></table></figure><ul><li>Dynamic Remote Parameters</li></ul><h4 id="Dynamic-Custom-Resources"><a href="#Dynamic-Custom-Resources" class="headerlink" title="Dynamic Custom Resources"></a>Dynamic Custom Resources</h4><blockquote><p>我们可以动态的去调整资源的需求或者返回在运行时调用<code>.option</code> 返回 <code>ray.remote</code> 的值</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-meta">@ray.remote(<span class="hljs-params">num_cpus=<span class="hljs-number">4</span></span>)</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Counter</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        self.value = <span class="hljs-number">0</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">increment</span>(<span class="hljs-params">self</span>):</span><br>        self.value += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> self.value<br><br>a1 = Counter.options(num_cpus=<span class="hljs-number">1</span>, resources=&#123;<span class="hljs-string">&quot;Custom1&quot;</span>: <span class="hljs-number">1</span>&#125;).remote()<br>a2 = Counter.options(num_cpus=<span class="hljs-number">2</span>, resources=&#123;<span class="hljs-string">&quot;Custom2&quot;</span>: <span class="hljs-number">1</span>&#125;).remote()<br>a3 = Counter.options(num_cpus=<span class="hljs-number">3</span>, resources=&#123;<span class="hljs-string">&quot;Custom3&quot;</span>: <span class="hljs-number">1</span>&#125;).remote()<br></code></pre></td></tr></table></figure><h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
    
    
    <categories>
      
      <category>Ray</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Docker课堂笔记</title>
    <link href="/2021/03/17/Docker%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/17/Docker%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Docker简介"><a href="#Docker简介" class="headerlink" title="Docker简介"></a>Docker简介</h1><h1 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker安装</h1><h2 id="Docker的基本组成"><a href="#Docker的基本组成" class="headerlink" title="Docker的基本组成"></a>Docker的基本组成</h2><h3 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h3><blockquote><p> Docker 镜像（Image）就是一个<strong>只读</strong>的模板。镜像可以用来创建 Docker 容器，<strong>一个镜像可以创建很多容器</strong>。</p></blockquote><h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><blockquote><p> Docker 利用容器（Container）独立运行的一个或一组应用。<strong>容器是用镜像创建的运行实例</strong>。</p></blockquote><ul><li><p>它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。</p></li><li><p><strong>可以把容器看做是一个简易版的 Linux 环境</strong>（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。</p></li><li><p>容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。</p></li></ul><h3 id="仓库"><a href="#仓库" class="headerlink" title="仓库"></a>仓库</h3><blockquote><p>仓库（Repository）是集中存放镜像文件的场所。</p></blockquote><ul><li><p>仓库(Repository)和仓库注册服务器（Registry）是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。</p></li><li><p>仓库分为公开仓库（Public）和私有仓库（Private）两种形式。</p></li><li><p>最大的公开仓库是 Docker Hub(<a href="https://hub.docker.com/)%EF%BC%8C%E5%AD%98%E6%94%BE%E4%BA%86%E6%95%B0%E9%87%8F%E5%BA%9E%E5%A4%A7%E7%9A%84%E9%95%9C%E5%83%8F%E4%BE%9B%E7%94%A8%E6%88%B7%E4%B8%8B%E8%BD%BD%E3%80%82">https://hub.docker.com/)，存放了数量庞大的镜像供用户下载。</a></p></li><li><p>国内的公开仓库包括阿里云 、网易云等</p></li></ul><h3 id="Docker的架构图"><a href="#Docker的架构图" class="headerlink" title="Docker的架构图"></a>Docker的架构图</h3><img src="/2021/03/17/Docker%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/Docker%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class="" title="Docker架构图"><h3 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a>小总结</h3><p>Docker 本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就似乎 image镜像文件。只有通过这个镜像文件才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。</p><ul><li><p> image 文件生成的容器实例，本身也是一个文件，称为镜像文件。</p></li><li><p> 一个容器运行一种服务，当我们需要的时候，就可以通过docker客户端创建一个对应的运行实例，也就是我们的容器</p></li><li><p>至于仓储，就是放了一堆镜像的地方，我们可以把镜像发布到仓储中，需要的时候从仓储中拉下来就可以了。</p></li></ul><h2 id="永远的HelloWorld"><a href="#永远的HelloWorld" class="headerlink" title="永远的HelloWorld"></a>永远的HelloWorld</h2><h4 id="启动Docker后台容器（测试运行hello-world）"><a href="#启动Docker后台容器（测试运行hello-world）" class="headerlink" title="启动Docker后台容器（测试运行hello-world）"></a>启动Docker后台容器（测试运行hello-world）</h4><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker <span class="hljs-keyword">run</span><span class="bash"> hello-word <span class="hljs-comment"># hello-word是一个镜像, 要以这个镜像生成一个容器实例</span></span><br><br>Unable to find image <span class="hljs-string">&#x27;hello-world:latest&#x27;</span> locally <span class="hljs-comment"># 本地没有这个镜像, latest是镜像的tag</span><br>latest: Pulling <span class="hljs-keyword">from</span> library/hello-world<br>b8dfde127a29: Pull complete<br>Digest: sha256:<span class="hljs-number">308866</span>a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24<br>Status: Downloaded newer image for hello-world:latest<br><br>Hello <span class="hljs-keyword">from</span> Docker!<br>This message shows that your installation appears to be working correctly.<br><br>To generate this message, Docker took the following steps:<br> <span class="hljs-number">1</span>. The Docker client contacted the Docker daemon.<br> <span class="hljs-number">2</span>. The Docker daemon pulled the <span class="hljs-string">&quot;hello-world&quot;</span> image <span class="hljs-keyword">from</span> the Docker Hub.<br>    (amd64)<br> <span class="hljs-number">3</span>. The Docker daemon created a new container <span class="hljs-keyword">from</span> that image which runs the<br>    executable that produces the output you are currently reading.<br> <span class="hljs-number">4</span>. The Docker daemon streamed that output to the Docker client, which sent it<br>    to your terminal.<br><br>To try something more ambitious, you can <span class="hljs-keyword">run</span><span class="bash"> an Ubuntu container with:</span><br> $ docker <span class="hljs-keyword">run</span><span class="bash"> -it ubuntu bash</span><br><br>Share images, automate workflows, and more with a free Docker ID:<br> https://hub.docker.com/<br><br>For more examples and ideas, visit:<br> https://docs.docker.com/get-started/<br></code></pre></td></tr></table></figure><h2 id="底层原理"><a href="#底层原理" class="headerlink" title="底层原理"></a>底层原理</h2><h3 id="Docker是怎么工作的"><a href="#Docker是怎么工作的" class="headerlink" title="Docker是怎么工作的"></a>Docker是怎么工作的</h3><p>Docker是一个Client-Server结构的系统，Docker守护进程运行在主机上， 然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。 <strong>容器，是一个运行时环境，就是我们前面说到的集装箱</strong>。</p><h3 id="为什么Docker比VM快"><a href="#为什么Docker比VM快" class="headerlink" title="为什么Docker比VM快"></a>为什么Docker比VM快</h3><ul><li><p>Docker有着比虚拟机更少的抽象层。由于Docker不需要Hypervisor实现硬件资源虚拟化，运行在Docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上Docker将会在效率上有明显优势。</p></li><li><p>Docker利用的是宿主机的内核，而不需要Guest OS。因此，当新建一个容器时，Docker不需要和虚拟机一样重新加载一个操作系统内核。仍而避免引寻、加载操作系统内核返个比较费时费资源的过程，当新建一个虚拟机时，虚拟机软件需要加载Guest OS，返个新建过程是分钟级别的。而Docker由于直接利用宿主机的操作系统,则省略了返个过程，因此新建一个Docker容器只需要几秒钟。</p></li></ul><table><thead><tr><th></th><th>Docker容器</th><th>虚拟机（VM）</th></tr></thead><tbody><tr><td>操作系统</td><td>与宿主机共享OS</td><td>宿主机OS上运行虚拟机OS</td></tr><tr><td>存储大小</td><td>镜像小，便于存储与传输</td><td>镜像庞大（vmdk, vdi…）</td></tr><tr><td>运行性能</td><td>几乎无额外性能损失</td><td>操作系统额外的CPU、内存消耗</td></tr><tr><td>移植性</td><td>轻便、灵活、适应于Linux</td><td>笨重，与虚拟化技术耦合度高</td></tr><tr><td>硬件亲和性</td><td>面向软件开发者</td><td>面向硬件开发者</td></tr><tr><td>部署速度</td><td>快速，秒级</td><td>较慢，10s以上</td></tr></tbody></table><h1 id="Docker常用命令"><a href="#Docker常用命令" class="headerlink" title="Docker常用命令"></a>Docker常用命令</h1><h2 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h2><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker version<br><br>-&gt; docker info<br><br>-&gt; docker --help<br></code></pre></td></tr></table></figure><h2 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a>镜像命令</h2><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker images <span class="hljs-comment"># 列出本地主机上所有的镜像</span><br>REPOSITORY               TAG       IMAGE ID       CREATED         SIZE<br>hello-world              latest    d1165f221234   <span class="hljs-number">11</span> days ago     <span class="hljs-number">13.3</span>kB<br><br><span class="hljs-comment"># REPOSITORY: 表示镜像的仓库源</span><br><span class="hljs-comment"># TAG: 镜像的标签</span><br><span class="hljs-comment"># IMAGE ID: 镜像ID</span><br><span class="hljs-comment"># CREATED: 镜像创建时间</span><br><span class="hljs-comment"># SIZE: 镜像大小</span><br><br>-a: 列出本地所有的镜像（含中间映像层）<br>-q: 只显示镜像ID<br>--digests: 显示镜像的摘要信息<br>--no-trunc: 显示完整的镜像信息<br></code></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker search [OPTIONS]镜像的名字 <span class="hljs-comment"># 在hub中查找镜像</span><br><br>--no-trunc: 显示完整的镜像描述<br>-s: 列出收藏数不小于指定值的镜像<br>--automated: 只列出 automated build类型的镜像<br></code></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker pull 镜像名称[:TAG] <span class="hljs-comment"># 下载镜像</span><br><br><span class="hljs-comment"># TAG默认latest</span><br>-&gt; docker pull tomcat <br>-&gt; docker pull tomcat:latest<br></code></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker rmi -f 镜像ID <span class="hljs-comment"># 删除单个</span><br>-&gt; docker rmi -f 镜像名<span class="hljs-number">1</span>:TAG 镜像名<span class="hljs-number">2</span>:TAG <span class="hljs-comment"># 删除多个</span><br>-&gt; docker rmi -f $(docker images -qa)  <span class="hljs-comment"># 删除全部（子语句）</span><br></code></pre></td></tr></table></figure><h2 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a>容器命令</h2><h3 id="新建并启动容器"><a href="#新建并启动容器" class="headerlink" title="新建并启动容器"></a>新建并启动容器</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker <span class="hljs-keyword">run</span><span class="bash"> [OPTIONS] IMAGE [COMMAND][ARG...]</span><br><br>--name=<span class="hljs-string">&quot;容器新名字&quot;</span>: 为容器指定一个名称；<br>-d: 后台运行容器，并返回容器ID，也即启动守护式容器；<br><br><span class="hljs-comment"># 用的最多</span><br>-i: 以交互模式运行容器，通常与 -t 同时使用；<br>-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；<br><br>-P: 随机端口映射；<br>-p: 指定端口映射，有以下四种格式<br>      ip:hostPort:containerPort<br>      ip::containerPort<br>      hostPort:containerPort<br>      containerPort<br>      <br>-&gt; docker <span class="hljs-keyword">run</span><span class="bash"> -it centos</span><br><span class="hljs-comment"># 进入新的实例</span><br></code></pre></td></tr></table></figure><h3 id="列出当前所有正在运行的容器"><a href="#列出当前所有正在运行的容器" class="headerlink" title="列出当前所有正在运行的容器"></a>列出当前所有正在运行的容器</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker ps [OPTIONS]<br><br>-a: 列出当前所有正在运行的容器+历史上运行过的<br>-l: 显示最近创建的容器。<br>-n: 显示最近n个创建的容器。<br>-q: 静默模式，只显示容器编号。<br>--no-trunc: 不截断输出。<br><br>-&gt; docker ps<br>CONTAINER ID   IMAGE     COMMAND       CREATED         STATUS         PORTS     NAMES<br><span class="hljs-number">09</span>aad010c2bd   centos    <span class="hljs-string">&quot;/bin/bash&quot;</span>   <span class="hljs-number">3</span> minutes ago   Up <span class="hljs-number">7</span> seconds             funny_tharp<br></code></pre></td></tr></table></figure><h3 id="退出容器"><a href="#退出容器" class="headerlink" title="退出容器"></a>退出容器</h3><ul><li>exit <ul><li>容器停止退出</li></ul></li><li>Ctrl + P + Q<ul><li>容器不停止退出</li></ul></li></ul><h3 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker start 容器ID或者容器名<br></code></pre></td></tr></table></figure><h3 id="重启容器"><a href="#重启容器" class="headerlink" title="重启容器"></a>重启容器</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker restart 容器ID或者容器名<br></code></pre></td></tr></table></figure><h3 id="停止容器"><a href="#停止容器" class="headerlink" title="停止容器"></a>停止容器</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker stop 容器ID或者容器名<br></code></pre></td></tr></table></figure><h3 id="强制停止容器"><a href="#强制停止容器" class="headerlink" title="强制停止容器"></a>强制停止容器</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker kill 容器ID或者容器名<br></code></pre></td></tr></table></figure><h3 id="删除已停止的容器"><a href="#删除已停止的容器" class="headerlink" title="删除已停止的容器"></a>删除已停止的容器</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker rm 容器ID<br><br><span class="hljs-comment"># 一次性删除多个容器</span><br>-&gt; docker rm -f $(docker ps -a -q)<br>-&gt; docker ps -a -q | xargs docker rm <br></code></pre></td></tr></table></figure><h3 id="启动守护式线程"><a href="#启动守护式线程" class="headerlink" title="启动守护式线程"></a>启动守护式线程</h3><p>与之相对的是启动交互式容器，我们不希望交互，希望后台以守护式进程的方式启动</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker <span class="hljs-keyword">run</span><span class="bash"> -d 容器名</span><br>-&gt; docker ps<br><span class="hljs-comment"># 发现容器已经退出了</span><br>CONTAINER ID   IMAGE     COMMAND       CREATED         STATUS         PORTS     NAMES<br></code></pre></td></tr></table></figure><p>问题：然后docker ps -a 进行查看, 会发现容器已经退出<br>很重要的要说明的一点: <strong>Docker容器后台运行,就必须有一个前台进程</strong>。容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail），就是会自动退出的。</p><p>这个是docker的机制问题，比如你的web容器，我们以nginx为例，正常情况下，我们配置启动服务只需要启动响应的service即可。例如 service nginx start。但是,这样做，nginx为后台进程模式运行，就导致docker前台没有运行的应用（因为不是以交互的方式启动的），这样的容器后台启动后，<strong>会立即自杀</strong>因为他觉得他没事可做了。所以，最佳的解决方案是，将你要运行的程序以前台进程的形式运行。</p><h3 id="查看容器日志"><a href="#查看容器日志" class="headerlink" title="查看容器日志"></a>查看容器日志</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">-&gt; docker logs -f -t --tail 容器ID<br><br>-t: 加入时间戳<br>-f: 跟随最新的日志打印<br>--tail: 数字 显示最后多少条<br></code></pre></td></tr></table></figure><h3 id="查看容器内运行进程"><a href="#查看容器内运行进程" class="headerlink" title="查看容器内运行进程"></a>查看容器内运行进程</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">-&gt; docker top 容器ID<br></code></pre></td></tr></table></figure><h3 id="查看容器内部细节"><a href="#查看容器内部细节" class="headerlink" title="查看容器内部细节"></a>查看容器内部细节</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">-&gt; docker inspect 容器ID<br></code></pre></td></tr></table></figure><h3 id="进入正在运行的容器并以命令行交互"><a href="#进入正在运行的容器并以命令行交互" class="headerlink" title="进入正在运行的容器并以命令行交互"></a>进入正在运行的容器并以命令行交互</h3><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs livescript">-&gt; docker exec -<span class="hljs-literal">it</span> 容器ID [bashShell]<br>-&gt; docker attach 容器ID<br></code></pre></td></tr></table></figure><ul><li>attach: 直接进入容器启动命令的终端，不会启动新的进程</li><li>exec: 是在容器中打开新的终端，并且可以启动新的进程 （隔山打牛）</li></ul><h3 id="从容器内拷贝文件到主机上"><a href="#从容器内拷贝文件到主机上" class="headerlink" title="从容器内拷贝文件到主机上"></a>从容器内拷贝文件到主机上</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">-&gt; docker cp 容器ID:容器内路径 目的主机路径<br></code></pre></td></tr></table></figure><h1 id="Docker镜像"><a href="#Docker镜像" class="headerlink" title="Docker镜像"></a>Docker镜像</h1><p>镜像就是一个“千层饼”</p><h2 id="镜像的含义"><a href="#镜像的含义" class="headerlink" title="镜像的含义"></a>镜像的含义</h2><p>镜像是一种轻量级、可执行的独立软件包，<strong>用来打包软件运行环境和基于运行环境开发的软件</strong>，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。</p><h3 id="UnionFS（联合文件系统）"><a href="#UnionFS（联合文件系统）" class="headerlink" title="UnionFS（联合文件系统）"></a>UnionFS（联合文件系统）</h3><blockquote><p> Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持<strong>对文件系统的修改作为一次提交来一层层的叠加</strong>，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。</p></blockquote><p>Union 文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。</p><p>特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录</p><h3 id="Docker镜像加载原理"><a href="#Docker镜像加载原理" class="headerlink" title="Docker镜像加载原理"></a>Docker镜像加载原理</h3><p>Docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。</p><p>bootfs(boot file system)主要包含bootloader和kernel。bootloader主要是引导加载kernel, Linux刚启动时会加载bootfs文件系统，<strong>在Docker镜像的最底层是bootfs</strong>。这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。</p><p>rootfs (root file system) ，在bootfs之上。包含的就是典型 Linux 系统中的 /dev, /proc, /bin, /etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。 </p><p>Q: 平时我们安装进虚拟机的CentOS都是好几个G，为什么docker这里才200M？</p><p>对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供 rootfs 就行了。由此可见对于不同的linux发行版, bootfs基本是一致的, rootfs会有差别, 因此不同的发行版可以公用bootfs。</p><h3 id="分层的原因"><a href="#分层的原因" class="headerlink" title="分层的原因"></a>分层的原因</h3><p>最大的好处就是可以共享资源</p><h2 id="镜像的特点"><a href="#镜像的特点" class="headerlink" title="镜像的特点"></a>镜像的特点</h2><p>Docker镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。</p><h2 id="镜像commit操作补充"><a href="#镜像commit操作补充" class="headerlink" title="镜像commit操作补充"></a>镜像commit操作补充</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 提交容器副本使之成为一个新的镜像</span><br>-&gt; docker commit <br><br>-&gt; docker commit -m=<span class="hljs-string">&quot;提交的描述信息&quot;</span> -a=<span class="hljs-string">&quot;作者&quot;</span> 容器ID 要创建的目标镜像名:[标签名]<br></code></pre></td></tr></table></figure><h1 id="Docker容器数据卷"><a href="#Docker容器数据卷" class="headerlink" title="Docker容器数据卷"></a>Docker容器数据卷</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>类似Redis里面的rdb和aof文件。</p><p>先来看看Docker的理念：</p><ul><li> 将运用与运行的环境打包形成容器运行 ，运行可以伴随着容器，但是我们对数据的要求希望是持久化的</li><li> 容器之间希望有可能共享数据</li></ul><p>Docker容器产生的数据，如果不通过docker commit生成新的镜像，使得数据做为镜像的一部分保存下来，<br>那么当容器删除后，数据自然也就没有了。</p><p>为了能保存数据在docker中我们使用卷。</p><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><ul><li>容器的持久化</li><li>容器间继承+共享数据</li></ul><h2 id="数据卷"><a href="#数据卷" class="headerlink" title="数据卷"></a>数据卷</h2><p>在容器内添加数据有两种方法：直接命令添加和DockerFile添加</p><h3 id="直接命令添加"><a href="#直接命令添加" class="headerlink" title="直接命令添加"></a>直接命令添加</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">-&gt;  docker run -it -v /宿主机绝对路径目录:/容器内目录    镜像名<br>-&gt;  docker run -it -v /宿主机绝对路径目录:/容器内目录:ro 镜像名 <span class="hljs-comment"># read-only 只读（只允许主机单向写操作传给它）</span><br></code></pre></td></tr></table></figure><p>数据卷挂载成功，容器和宿主机之间数据共享。容器停止退出后，主机修改后数据仍然同步。</p><h3 id="DockerFile添加"><a href="#DockerFile添加" class="headerlink" title="DockerFile添加"></a>DockerFile添加</h3><blockquote><p>dockerfile与image的关系有点类似使用java文件生成的class文件。可以理解为镜像这个模板的描述文件。</p></blockquote><p>示例：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 基于centos构建</span><br><span class="hljs-keyword">FROM</span> centos <br><span class="hljs-comment"># 新建两个容器卷</span><br><span class="hljs-keyword">VOLUME</span><span class="bash"> [<span class="hljs-string">&quot;/dataVolumeContainer1&quot;</span>, <span class="hljs-string">&quot;/dataVolumeContainer2&quot;</span>]</span><br><span class="hljs-comment"># 运行命令行</span><br><span class="hljs-keyword">CMD</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;finished,-----success1&quot;</span></span><br><span class="hljs-keyword">CMD</span><span class="bash"> /bin/bash</span><br></code></pre></td></tr></table></figure><p>整个dockerfile等价于：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">-&gt; docker run -it -v /host1:/dataVolumeContainer1 -v /host2:/dataVolumeContainer2 centos /bin/bash<br></code></pre></td></tr></table></figure><p> 如果没有指定host1和host2将会使用默认的</p><h2 id="数据卷容器"><a href="#数据卷容器" class="headerlink" title="数据卷容器"></a>数据卷容器</h2><h3 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h3><blockquote><p>命名的容器挂载数据卷，其它容器通过挂载这个(父容器)实现数据共享，挂载数据卷的容器，称之为数据卷容器</p></blockquote><p>活动硬盘上面挂活动硬盘，实现数据的传递</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">-&gt; docker run -it --name dc01 zzyy/centos<br>-&gt; docker run -it --name dc02 --volumes-from dc01 zzyy/centos<br>-&gt; docker run -it --name dc03 --volumes-from dc01 zzyy/centos<br></code></pre></td></tr></table></figure><p>dc02和dc03分别在dataVolumeContainer2各自新增内容，回到dc01可以看到02/03各自添加的都能共享了。</p><p>删除dc01，dc02的修改可以被dc03看到。（即使dc03 是 volume from dc01的）</p><p>更像是共享而不是继承。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>容器之间配置信息的的传递，数据卷的生命周期一直持续到没有容器使用它为止。</p><h1 id="DockerFile解析"><a href="#DockerFile解析" class="headerlink" title="DockerFile解析"></a>DockerFile解析</h1><h2 id="含义-1"><a href="#含义-1" class="headerlink" title="含义"></a>含义</h2><blockquote><p>Dockerfile是用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本。</p></blockquote><h3 id="构建三步骤"><a href="#构建三步骤" class="headerlink" title="构建三步骤"></a>构建三步骤</h3><ul><li><p>编写dockerfile文件</p></li><li><p><code>docker build</code></p></li><li><p><code>docker run</code></p></li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>以centos的dockerfile为例</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># scratch 是一个基础的镜像</span><br><span class="hljs-keyword">FROM</span> scratch<br><span class="hljs-comment"># 作者信息</span><br><span class="hljs-keyword">MAINTAINER</span> The CentOS Project &lt;cloud-ops@centos.org&gt;<br><br><span class="hljs-keyword">ADD</span><span class="bash"> c68-docker.tar.xz /</span><br><span class="hljs-keyword">LABEL</span><span class="bash"> name=<span class="hljs-string">&quot;CentOS Base Image&quot;</span> \</span><br><span class="bash">vendor=<span class="hljs-string">&quot;CentOS&quot;</span> \ </span><br>license=<span class="hljs-string">&quot;GPLv2&quot;</span> \<br>build-date=<span class="hljs-string">&quot;2016-06-02&quot;</span><br><br><span class="hljs-comment"># Default command</span><br><span class="hljs-keyword">CMD</span><span class="bash"> [<span class="hljs-string">&quot;/bin/bash&quot;</span>]</span><br></code></pre></td></tr></table></figure><h2 id="DockerFile构建过程解析"><a href="#DockerFile构建过程解析" class="headerlink" title="DockerFile构建过程解析"></a>DockerFile构建过程解析</h2><h3 id="Dockerfile内容基础知识"><a href="#Dockerfile内容基础知识" class="headerlink" title="Dockerfile内容基础知识"></a>Dockerfile内容基础知识</h3><ol><li>每条保留字指令都必须为大写字母且后面要跟随至少一个参数</li><li>指令按照从上到下，顺序执行</li><li>#表示注释</li><li>每条指令都会创建一个新的镜像层，并对镜像进行提交</li></ol><h3 id="Docker执行Dockerfile的大致流程"><a href="#Docker执行Dockerfile的大致流程" class="headerlink" title="Docker执行Dockerfile的大致流程"></a>Docker执行Dockerfile的大致流程</h3><ol><li>docker从基础镜像运行一个容器</li><li>执行一条指令并对容器作出修改</li><li>执行类似docker commit的操作提交一个新的镜像层</li><li>docker再基于刚提交的镜像运行一个新容器</li><li>执行dockerfile中的下一条指令直到所有指令都执行完成</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段，</p><ul><li> Dockerfile是软件的原材料</li><li> Docker镜像是软件的交付品</li><li> Docker容器则可以认为是软件的运行态。<br>Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。</li></ul><ol><li><p>Dockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制)等等;</p></li><li><p>Docker镜像，在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，当运行 Docker镜像时，会真正开始提供服务;</p></li><li><p>Docker容器，容器是直接提供服务的。</p></li></ol><h2 id="DockerFile体系结构（保留字指令）"><a href="#DockerFile体系结构（保留字指令）" class="headerlink" title="DockerFile体系结构（保留字指令）"></a>DockerFile体系结构（保留字指令）</h2><table><thead><tr><th>保留字</th><th>含义</th></tr></thead><tbody><tr><td><code>FROM</code></td><td>基础镜像，当前镜像是基于哪个镜像</td></tr><tr><td><code>MAINTAINER</code></td><td>镜像维护者的姓名和邮箱地址</td></tr><tr><td><code>RUN</code></td><td>容器构建<strong>时</strong>需要运行的命令</td></tr><tr><td><code>EXPOSE</code></td><td>当前容器对外暴露出的端口</td></tr><tr><td><code>WORKDIR</code></td><td>指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点</td></tr><tr><td><code>ENV</code></td><td>用来在构建镜像过程中设置环境变量（<code>ENV MY_PATH /usr/mytest</code>，这样就可以直接使用<code>MY_PATH</code>）</td></tr><tr><td><code>ADD</code></td><td>将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar压缩包（拷贝+解压）</td></tr><tr><td><code>COPY</code></td><td>类似ADD，拷贝文件和目录到镜像中。将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置</td></tr><tr><td><code>VOLUME</code></td><td>容器数据卷，用于数据保存和持久化工作</td></tr><tr><td><code>CMD</code></td><td>指定一个容器启动时要运行的命令；Dockerfile 中可以有多个 CMD 指令，<strong>但只有最后一个生效</strong>，CMD 会被 docker run 之后的参数替换</td></tr><tr><td><code>ENTRYPOINT</code></td><td>指定一个容器启动时要运行的命令；ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数</td></tr><tr><td><code>ONBUILD</code></td><td>当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的onbuild被触发</td></tr></tbody></table><h2 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h2><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> centos<br><span class="hljs-keyword">ENV</span> MY_PATH /tmp<br><span class="hljs-keyword">WORKDIR</span><span class="bash"> <span class="hljs-variable">$MY_PATH</span></span><br><br><span class="hljs-keyword">RUN</span><span class="bash"> yum -y install vim</span><br><span class="hljs-keyword">RUN</span><span class="bash"> yum -y install net-tools</span><br><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">80</span><br><span class="hljs-keyword">CMD</span><span class="bash"> /bin/bash</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>k8s课堂笔记</title>
    <link href="/2021/03/16/k8s%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/03/16/k8s%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="第一部分-k8s基本概念"><a href="#第一部分-k8s基本概念" class="headerlink" title="第一部分 k8s基本概念"></a>第一部分 k8s基本概念</h1><h2 id="k8s概述和特性"><a href="#k8s概述和特性" class="headerlink" title="k8s概述和特性"></a>k8s概述和特性</h2><h3 id="k8s概述"><a href="#k8s概述" class="headerlink" title="k8s概述"></a>k8s概述</h3><ul><li>k8s是谷歌在2014年开业的容器化集群管理系统</li><li>使用k8s进行容器化应用部署</li><li>使用k8s利于应用扩展</li><li>k8s目标实施让部署容器化应用更加简洁和高效</li></ul><h3 id="k8s特性"><a href="#k8s特性" class="headerlink" title="k8s特性"></a>k8s特性</h3><h4 id="自动装箱"><a href="#自动装箱" class="headerlink" title="自动装箱"></a>自动装箱</h4><ul><li>基于容器对应用运行环境的资源配置要求自动部署应用容器</li></ul><h4 id="自我修复"><a href="#自我修复" class="headerlink" title="自我修复"></a>自我修复</h4><ul><li>当容器失败时，会对容器进行重启</li><li>当所部署的 Node 节点有问题时，会对容器进行重新部署和重新调度</li><li>当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务</li></ul><h4 id="水平扩展"><a href="#水平扩展" class="headerlink" title="水平扩展"></a>水平扩展</h4><ul><li>通过简单的命令、用户 UI 界面或基于 CPU 等资源使用情况，对应用容器进行规模扩大 或规模剪裁</li></ul><h4 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h4><ul><li>用户不需使用额外的服务发现机制，就能够基于 Kubernetes 自身能力实现服务发现和 负载均衡</li></ul><h4 id="滚动更新"><a href="#滚动更新" class="headerlink" title="滚动更新"></a>滚动更新</h4><ul><li>可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新</li></ul><h4 id="版本回退"><a href="#版本回退" class="headerlink" title="版本回退"></a>版本回退</h4><ul><li>可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退</li></ul><h4 id="密钥和配置管理"><a href="#密钥和配置管理" class="headerlink" title="密钥和配置管理"></a>密钥和配置管理</h4><ul><li>在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署。</li></ul><h4 id="存储编排"><a href="#存储编排" class="headerlink" title="存储编排"></a>存储编排</h4><ul><li>自动实现存储系统挂载及应用，特别对有状态应用实现数据持久化非常重要</li><li>存储系统可以来自于本地目录、网络存储(NFS、Gluster、Ceph 等)、公共云存储服务</li></ul><h4 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h4><ul><li>提供一次性任务，定时任务;满足批量数据处理和分析的场景</li></ul><h2 id="k8s架构组件"><a href="#k8s架构组件" class="headerlink" title="k8s架构组件"></a>k8s架构组件</h2><p>在硬件级别, 一个 Kubernetes 集群由很多节点组成, 这些节点被分成以下两种类型:</p><ul><li>主节点: 承载着 Kubernetes 控制和管理整个集群系统的控制面板<ul><li>控制面板<ul><li><em>Kubernetes</em> API 服务器, 你和其他控制面板组件都要和它通信。集群统一入口，以restful方式，交给etcd存储。</li><li><em>Scheculer</em> 它调度你的应用 (为应用的每个可部署组件分配一个工作节点)。</li><li><em>Controller Manager</em> 它执行集群级别的功能, 如复制组件、持续跟踪工作节点、处理节点失败。</li><li><em>etcd</em> 一个可靠的分布式数据存储, 它能持久化存储集群配置。</li></ul></li><li>控制面板的组件持有并控制集群状态, 但是它们不运行你的应用程序, 是由工作节点完成的。</li></ul></li><li>工作结点: 它们运行用户实际部署的应用<ul><li>Docker, rtk 或其他的容器类型</li><li><em>Kubelet</em> 它与 API 服务器通信, 并管理它所在节点的容器。master派到worker的代表，管理本机。</li><li><em>Kubernetes Service Proxy (kube-proxy)</em> 它负责组件之间的负载均衡网络流量</li></ul></li></ul><h2 id="k8s核心概念"><a href="#k8s核心概念" class="headerlink" title="k8s核心概念"></a>k8s核心概念</h2><h3 id="pod"><a href="#pod" class="headerlink" title="pod"></a>pod</h3><ul><li>最小的部署单元</li><li>一组容器的集合</li><li>共享网络</li><li>生命周期是短暂的</li></ul><h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><ul><li>确保预期的pod副本数量</li><li>无状态应用部署</li><li>有状态应用部署<ul><li>网络ip需要唯一</li><li>依赖存储</li></ul></li></ul><p>确保所有的node运行同一个pod</p><p>一次性任务和定时任务</p><h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><ul><li>定义一组pod的访问规则</li></ul><h1 id="第二部分-搭建k8s集群"><a href="#第二部分-搭建k8s集群" class="headerlink" title="第二部分 搭建k8s集群"></a>第二部分 搭建k8s集群</h1><h2 id="搭建k8s环境平台规划"><a href="#搭建k8s环境平台规划" class="headerlink" title="搭建k8s环境平台规划"></a>搭建k8s环境平台规划</h2><h3 id="单master集群"><a href="#单master集群" class="headerlink" title="单master集群"></a>单master集群</h3><h3 id="多master集群"><a href="#多master集群" class="headerlink" title="多master集群"></a>多master集群</h3><h2 id="搭建k8s集群部署方式"><a href="#搭建k8s集群部署方式" class="headerlink" title="搭建k8s集群部署方式"></a>搭建k8s集群部署方式</h2>]]></content>
    
    
    <categories>
      
      <category>kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式锁的实现（1）——Redis</title>
    <link href="/2021/03/08/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94Redis/"/>
    <url>/2021/03/08/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94Redis/</url>
    
    <content type="html"><![CDATA[<p>分布式锁一直是一个经常听到的名词，但是一直没有将它与普通的锁区分开来。这次打算来一次整理，具体了解一下分布式锁。</p><h1 id="分布式锁背景"><a href="#分布式锁背景" class="headerlink" title="分布式锁背景"></a>分布式锁背景</h1><p>首先，分布式锁和我们平常讲到的锁原理基本一样，目的就是确保在多个线程并发时，只有一个线程在同一刻操作这个业务或者说方法、变量。</p><p>由于客观存在的业务量的需求，我们会把请求平均分配在多台服务器中。这里就可以把多台服务器理解成一个集群。分布式锁可以把整个集群就当做是一个应用一样去处理，那么也就需要这个锁独立于每一个服务之外，而不是在服务里面。这样一台机器接收到一个请求后，不能在自己的应用中完成闭环，需要向外请求整个服务。</p><h1 id="分布式锁实现方式"><a href="#分布式锁实现方式" class="headerlink" title="分布式锁实现方式"></a>分布式锁实现方式</h1><ul><li>Redis</li><li>Memcached</li><li>ZooKeeper</li><li>Chubby</li></ul><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><p>这篇文章就详细讲讲如何利用Redis来实现分布式锁。</p><p>首先，Redis是单线程的，这里的单线程指的是网络请求模块使用了一个线程（所以不需要考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。</p><h2 id="核心要素"><a href="#核心要素" class="headerlink" title="核心要素"></a>核心要素</h2><p>我们需要首先了解分布式锁实现的三个核心要素：</p><ol><li><p>加锁</p><p>最简单的方式是使用<code>setnx</code>命令。<code>key</code>是锁唯一标识，按业务来决定命名。</p><p>加锁的伪代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">setnx(key, 1)<br></code></pre></td></tr></table></figure><p>当一个线程执行<code>setnx</code>返回1，说明<code>key</code>原本不存在，该线程成功得到了锁；当一个线程执行<code>setnx</code>返回0，说明<code>key</code>已经存在，该线程抢锁失败。</p></li><li><p>解锁</p><p>有加锁就得有解锁。当得到锁的线程执行完任务，需要释放锁，以便其他线程可以进入。释放锁的最简单方式是执行<code>del</code>指令，伪代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">del(key)<br></code></pre></td></tr></table></figure><p>释放锁之后，其他线程就可以继续执行<code>setnx</code>命令来获得锁。</p></li><li><p>锁超时</p><p>如果一个得到锁的线程在执行任务的过程中挂掉，来不及显示地释放锁，这块资源将会永远被锁住，别的线程再也别想进来。</p><p>所以，<code>setnx</code>的<code>key</code>必须设置一个超时时间，以保证即使没有被显示释放，这把锁也要在一定时间后自动释放。<code>setnx</code>不支持超时参数，所以需要额外的指令，伪代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">expire(key, 30)<br></code></pre></td></tr></table></figure><p>综上所述，我们分布式锁实现的第一版伪代码：</p></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">if</span> (setnx(key, <span class="hljs-number">1</span>) == <span class="hljs-number">1</span>) &#123;<br>expire(key, <span class="hljs-number">30</span>)<br>  <span class="hljs-keyword">try</span> &#123;<br>    <span class="hljs-comment">// do something ...</span><br>  &#125; <span class="hljs-keyword">finally</span> &#123;<br>    del(key)<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="问题改进"><a href="#问题改进" class="headerlink" title="问题改进"></a>问题改进</h2><p>但是上述这个伪代码还是存在着很多问题的</p><h3 id="setnx和expire的非原子性"><a href="#setnx和expire的非原子性" class="headerlink" title="setnx和expire的非原子性"></a>setnx和expire的非原子性</h3><p>设想一个极端场景，当某线程执行<code>setnx</code>，成功得到了锁。</p><p><code>setnx</code>刚执行成功，还未来得及执行<code>expire</code>指令，节点宕机了。这样一来，这把锁就没有设置过期时间，别的线程再也无法获得锁了。</p><p>解决方案：</p><p>Redis2.6.12以上的版本为<code>set</code>指令增加了可选参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">set</span>(key, 1, 30, NX)<br></code></pre></td></tr></table></figure><p>这样就可以取代<code>setnx</code>指令</p><h3 id="del导致误删"><a href="#del导致误删" class="headerlink" title="del导致误删"></a>del导致误删</h3><p>假设线程A成功得到了锁，并且设置的超时时间是30秒。</p><p>可能存在某些原因导致线程A执行的很慢，过了30秒还没执行完，这时候锁过期自动释放，线程B得到了锁。</p><p>随后，线程A执行完了任务，线程A接着执行<code>del</code>指令来释放锁。但这时，线程B还没执行完，所以<strong>线程A实际上删除的是线程B加的锁。</strong></p><p>解决方案：</p><p>可以在<code>del</code>释放锁之前做一个判断，验证当前的锁是不是自己加的锁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 加锁</span><br>String threadId = Thread.currentThread().getId();<br>set(key，threadId ，<span class="hljs-number">30</span>，NX);<br><br><span class="hljs-comment">// 解锁</span><br><span class="hljs-keyword">if</span>（threadId.equals(redisClient.get(key))）&#123;<br>    del(key)<br>&#125;<br></code></pre></td></tr></table></figure><p>但是，这样做又隐含了一个新的问题，<strong>判断和释放锁是两个独立操作，不是原子性</strong>。</p><p>所以这一块要用Lua脚本来实现：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua">String luaScript = <span class="hljs-string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then returnredis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;</span>;<br>redisClient.eval(luaScript , Collections.singletonList(key), Collections.singletonList(threadId));<br></code></pre></td></tr></table></figure><p>这样一来，验证和删除过程就是原子操作了。</p><h3 id="出现并发的可能性"><a href="#出现并发的可能性" class="headerlink" title="出现并发的可能性"></a>出现并发的可能性</h3><p>虽然我们避免了线程A误删掉key的情况，但是同一时间有A, B两个线程在访问代码块，这仍然是不完美的。</p><p>解决方案：</p><p>可以让获得锁的线程开启一个守护线程，用来给快要过期的锁”续航“。</p><p>当过去了29秒，线程A还没执行完，这时候守护线程会执行<code>expire</code>指令，为这把锁”续命“20秒。</p><p>守护线程从第29秒开始执行，每20秒执行一次。当线程A执行完任务，会显示关掉守护线程。</p><p>另一种情况，如果线程A突然宕机，由于线程A和守护线程在同一个进程，守护进程也会停下。这把锁到了超时的时候，没人给它续命，就会自动释放。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://zhuanlan.zhihu.com/p/72896771">通俗讲解分布式锁，看完不懂算作者输</a></li><li><a href="https://cloud.tencent.com/developer/article/1467797">漫画：什么是分布式锁</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式锁</tag>
      
      <tag>Redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Google三驾马车（3）——MapReduce</title>
    <link href="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94MapReduce/"/>
    <url>/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94MapReduce/</url>
    
    <content type="html"><![CDATA[<p>这是我认为在三驾马车中相对比较简单的<a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf">MapReduce</a>，之前跟着MIT6.824中的lab1中模拟了一遍。顺便推荐一下这个神课，网上的资料也非常齐全，算是我的分布式系统入门课程。</p><h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><p>我们一般使用MapReduce作为一个算法的框架来处理海量的数据。假设我们有1TB的数据，我们可能会统计单词数，或者建立倒排索引。这时候就会用到这个MapReduce的框架。</p><h2 id="什么是Map和Reduce"><a href="#什么是Map和Reduce" class="headerlink" title="什么是Map和Reduce"></a>什么是Map和Reduce</h2><h3 id="什么是Map"><a href="#什么是Map" class="headerlink" title="什么是Map"></a>什么是Map</h3><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94MapReduce/%E4%BB%80%E4%B9%88%E6%98%AFMap.png" class="" title="什么是Map"><h3 id="什么是Reduce"><a href="#什么是Reduce" class="headerlink" title="什么是Reduce"></a>什么是Reduce</h3><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94MapReduce/%E4%BB%80%E4%B9%88%E6%98%AFReduce.png" class="" title="什么是Reduce"><h2 id="如何统计单词出现数"><a href="#如何统计单词出现数" class="headerlink" title="如何统计单词出现数"></a>如何统计单词出现数</h2><p>在Map和Reduce的过程，实际上是高度并行的。</p><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94MapReduce/%E7%BB%9F%E8%AE%A1%E5%8D%95%E8%AF%8D%E5%87%BA%E7%8E%B0%E6%95%B0.png" class="" title="统计单词出现数"><h2 id="如何构建倒排索引"><a href="#如何构建倒排索引" class="headerlink" title="如何构建倒排索引"></a>如何构建倒排索引</h2><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94MapReduce/%E6%9E%84%E5%BB%BA%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.png" class="" title="构建倒排索引"><h2 id="MapReduce的框架是什么"><a href="#MapReduce的框架是什么" class="headerlink" title="MapReduce的框架是什么"></a>MapReduce的框架是什么</h2><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94MapReduce/MapReduce%E7%9A%84%E6%9E%B6%E6%9E%84.png" class="" title="MapReduce的架构">]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Google</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Google三驾马车（2）——BigTable</title>
    <link href="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/"/>
    <url>/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/</url>
    
    <content type="html"><![CDATA[<p>这一篇是Google的另一个经典论文“<a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/bigtable-osdi06.pdf">Big Table</a>”。这跟上一篇文章同属一个系列的YouTube视频——<a href="https://www.youtube.com/watch?v=r1bh90_8dsg">深入浅出Big Table</a></p><h1 id="BigTable"><a href="#BigTable" class="headerlink" title="BigTable"></a>BigTable</h1><h2 id="如何在文件内快速查询"><a href="#如何在文件内快速查询" class="headerlink" title="如何在文件内快速查询"></a>如何在文件内快速查询</h2><p>我们在GFS中已经讲到了文件的读写，那么我们如何在文件内快速的查询呢。</p><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E5%9C%A8%E6%96%87%E4%BB%B6%E5%86%85%E5%BF%AB%E9%80%9F%E6%9F%A5%E6%89%BE.png" class="" title="在文件内快速查找"><p>把key排好序后，就可以用二分查找再加上范围查找。</p><h2 id="如何保存一个很大的表"><a href="#如何保存一个很大的表" class="headerlink" title="如何保存一个很大的表"></a>如何保存一个很大的表</h2><p>我们的基本思路是将大表拆成小表（tablet），在元数据（metadata）中保存每一个小表的位置。</p><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E4%BF%9D%E5%AD%98%E5%BE%88%E5%A4%A7%E7%9A%84%E8%A1%A8.png" class="" title="保存很大的表"><h2 id="如果保存超大表"><a href="#如果保存超大表" class="headerlink" title="如果保存超大表"></a>如果保存超大表</h2><p>如果还是不够，就可以再把小表（tablet）拆成小小表（SSTable）</p><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E4%BF%9D%E5%AD%98%E8%B6%85%E5%A4%A7%E8%A1%A8.png" class="" title="保存超大表"><h2 id="如何向表中写数据"><a href="#如何向表中写数据" class="headerlink" title="如何向表中写数据"></a>如何向表中写数据</h2><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E5%A6%82%E4%BD%95%E5%86%99%E6%95%B0%E6%8D%AE.png" class="" title="如何写数据"><p>我们在整个架构中，有内存（Memory）和硬盘（GFS/Disk）两部分。我们可以在内存中存放小小表（SSTable）的位置，所以内存就会有小小表（SSTable）的索引。为了加快写速度，我们并不是马上去往硬盘上去写的，我们在硬盘中修改排序是很难的，但是我们在内存中修改排序是简单的，因为在内存中是随机存储。</p><h3 id="内存表过大时怎么办"><a href="#内存表过大时怎么办" class="headerlink" title="内存表过大时怎么办"></a>内存表过大时怎么办</h3><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E5%86%85%E5%AD%98%E8%A1%A8%E8%BF%87%E5%A4%A7.png" class="" title="内存表过大"><p>当内存表达到64M的时候，就会把自己存到硬盘上，称为一个新的SSTable，并持久性保存。</p><h3 id="如何避免丢失内存数据"><a href="#如何避免丢失内存数据" class="headerlink" title="如何避免丢失内存数据"></a>如何避免丢失内存数据</h3><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E9%81%BF%E5%85%8D%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1.png" class="" title="避免内存数据丢失"><p>我们通过添加log来避免丢失内存数据。</p><h2 id="如何读数据"><a href="#如何读数据" class="headerlink" title="如何读数据"></a>如何读数据</h2><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E5%A6%82%E4%BD%95%E8%AF%BB%E6%95%B0%E6%8D%AE.png" class="" title="如何读数据"><p>我们存储的小小表（SSTable）内部是有序的，各个SSTable之间时无序的。所以如果想要找一个key，需要到所有的SSTable以及内存表中去查找。由于需要到硬盘去查询，查询的效率就会很低。</p><h3 id="如何加速读数据"><a href="#如何加速读数据" class="headerlink" title="如何加速读数据"></a>如何加速读数据</h3><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E5%8A%A0%E9%80%9F%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE.png" class="" title="加速读取数据"><p>通过添加索引的方式来进行加速，预先把索引表加到内存中来。</p><h3 id="如何继续加速读数据"><a href="#如何继续加速读数据" class="headerlink" title="如何继续加速读数据"></a>如何继续加速读数据</h3><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E7%BB%A7%E7%BB%AD%E5%8A%A0%E9%80%9F%E8%AF%BB%E6%95%B0%E6%8D%AE.png" class="" title="继续加速读数据"><p>我们引入布隆过滤器，可以加速判断一个key是否能够命中（<strong>只能起辅助作用</strong>）</p><h2 id="如何将表存入GFS"><a href="#如何将表存入GFS" class="headerlink" title="如何将表存入GFS"></a>如何将表存入GFS</h2><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E5%B0%86%E8%A1%A8%E5%AD%98%E5%85%A5GFS.png" class="" title="将表存入GFS"><p>BigTable用的是内存的结构，GFS是硬盘的结构，在GFS中给SSTable和log各备份三份。</p><h2 id="表的逻辑视图是什么"><a href="#表的逻辑视图是什么" class="headerlink" title="表的逻辑视图是什么"></a>表的逻辑视图是什么</h2><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E8%A1%A8%E7%9A%84%E9%80%BB%E8%BE%91%E8%A7%86%E5%9B%BE.png" class="" title="表的逻辑视图"><p>Photo列下面可以记录Steve不同时间戳下的照片，相当于搜索引擎抓到不同页面的不同版本。Weight和Height可以作为一个Column Family。</p><h3 id="将逻辑视图转换为物理存储"><a href="#将逻辑视图转换为物理存储" class="headerlink" title="将逻辑视图转换为物理存储"></a>将逻辑视图转换为物理存储</h3><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/%E5%B0%86%E9%80%BB%E8%BE%91%E8%A7%86%E5%9B%BE%E8%BD%AC%E6%8D%A2%E4%B8%BA%E7%89%A9%E7%90%86%E5%AD%98%E5%82%A8.png" class="" title="将逻辑视图转换为物理存储"><p>可以将相同的key聚合在一起，加快查询速度。NoSQL天然不支持join操作的。</p><h2 id="BigTable的架构是什么"><a href="#BigTable的架构是什么" class="headerlink" title="BigTable的架构是什么"></a>BigTable的架构是什么</h2><img src="/2021/03/05/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94BigTable/BigTable%E7%9A%84%E6%9E%B6%E6%9E%84.png" class="" title="BigTable的架构"><p>首先需要一个client进行连接，为了连接需要一个library提供库函数以及权限的控制。连接之前需要获得锁服务（Chubby），以及各种表的元数据的获得。获得请求能力之后，就会到特定的Tablet Server去获得Tablet的数据。Tablet的底层有一个master在处理数据的。上面有一个master负责处理各个原始信息以及负载均衡，可以指定Tablet之间的存放。还有一些Cluster Schedule来监控整个服务或者系统的过程。</p>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Google</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Google三驾马车（1）——GFS</title>
    <link href="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/"/>
    <url>/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/</url>
    
    <content type="html"><![CDATA[<p>最近阅读了号称Google分布式系统的三驾马车中的”<a href="https://dl.acm.org/doi/pdf/10.1145/945445.945450?casa_token=oR7grA26w34AAAAA:foohVEqDKPuAtLOsysk87pEoO7zTgcYRPFKtOxG7QLzOMI8HnT1vybCb6kibsHO5RWxPm8C4RSRKiTw">The Google File System</a>“。由于水平尚浅，即便读的是<a href="https://duanmeng.github.io/2017/12/07/gfs-notes/">中译</a>仍觉得倍感吃力，偶然间发现这个YouTube上的讲解视频——<a href="https://www.youtube.com/watch?v=WLad7CCexo8">深入浅出Google File System</a>，可谓豁然开朗，打算回头再重读原文，收获颇丰。</p><h1 id="架构的层次"><a href="#架构的层次" class="headerlink" title="架构的层次"></a>架构的层次</h1><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E6%9E%B6%E6%9E%84%E7%9A%84%E5%B1%82%E6%AC%A1.png" class="" title="架构的层次"><p>最底层是一个文件系统（GFS），往上需要你把数据模型抽象出来以便使用（BigTable），再往上就是算法（MapReduce…）。算法除了能和数据模型直接挂钩以外，它也能直接访问文件系统。再往上就是各类应用。</p><h1 id="Google-File-System"><a href="#Google-File-System" class="headerlink" title="Google File System"></a>Google File System</h1><h2 id="如何保存一个文件"><a href="#如何保存一个文件" class="headerlink" title="如何保存一个文件"></a>如何保存一个文件</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E4%BF%9D%E5%AD%98%E6%96%87%E4%BB%B6.png" class="" title="保存文件"><p>我们有一个硬盘（disk），这个硬盘最初会有一些原始信息（metadata）。为了寻找到数据在硬盘当中的位置，就用到了索引（index）。</p><h2 id="如何保存大文件"><a href="#如何保存大文件" class="headerlink" title="如何保存大文件"></a>如何保存大文件</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E4%BF%9D%E5%AD%98%E5%A4%A7%E6%96%87%E4%BB%B6.png" class="" title="保存大文件"><p>对于大文件来说，我们就不能保存小块了，因为块数太多了。大块（chunk）由65536个小块（block）构成。但是如果我们用这个方式存储小文件，就会造成空间上的浪费。</p><h2 id="如何保存超大文件"><a href="#如何保存超大文件" class="headerlink" title="如何保存超大文件"></a>如何保存超大文件</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E4%BF%9D%E5%AD%98%E8%B6%85%E5%A4%A7%E6%96%87%E4%BB%B6.png" class="" title="保存超大文件"><p>超大文件我们就无法在一个机器上存了，因为一个机器存不下，那么我们就需要一个主从结构。master就是一个存储所有原始信息的地方，索引可以照样建立，只不过现在指向的是chunkserver中的数据。这样的方法也有问题，chunkserver数据任何变动都要通知master</p><h3 id="如何减少Master存储的数据和流量"><a href="#如何减少Master存储的数据和流量" class="headerlink" title="如何减少Master存储的数据和流量"></a>如何减少Master存储的数据和流量</h3><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E5%87%8F%E5%B0%91Master%E7%9A%84%E6%95%B0%E6%8D%AE%E5%92%8C%E6%B5%81%E9%87%8F.png" class="" title="减少Master的数据和流量"><p>我们可以参考解耦的思想，master不直接对chunk负责，而是转而对chunkserver负责，再由chunkserver去负责chunk。这样就可以减少master的元数据信息，减少master和chunkserver之间的通信。</p><h2 id="如何发现数据损坏"><a href="#如何发现数据损坏" class="headerlink" title="如何发现数据损坏"></a>如何发现数据损坏</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E5%8F%91%E7%8E%B0%E6%95%B0%E6%8D%AE%E6%8D%9F%E5%9D%8F.png" class="" title="发现数据损坏"><p>为了能够发现数据损坏，我们需要一个机制来建立数据损坏。每个小块（block）保存一个ckecksum，在读取的时候比较一下。这样也不会给整体带来很大的冗余。</p><h2 id="如何减少ChunkServer挂掉带来的损失"><a href="#如何减少ChunkServer挂掉带来的损失" class="headerlink" title="如何减少ChunkServer挂掉带来的损失"></a>如何减少ChunkServer挂掉带来的损失</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E5%87%8F%E5%B0%91chunkserver%E6%8C%82%E6%8E%89%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%8D%9F%E5%A4%B1.png" class="" title="减少chunkserver挂掉带来的损失"><p>我们通过把一个chunk存在多个chunkserver上的方式来增加容错。</p><p>跨机架胯中心2+1指的是把chunkserver分在三个地方，其中两个放在California的数据中心，另一个放在Washington的数据中心。在同一个数据中心中呢，又可以把两个chunkserver放在不同的机架上。</p><h2 id="如何恢复损坏的Chunk"><a href="#如何恢复损坏的Chunk" class="headerlink" title="如何恢复损坏的Chunk"></a>如何恢复损坏的Chunk</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E6%81%A2%E5%A4%8D%E6%8D%9F%E5%9D%8F%E7%9A%84chunk.png" class="" title="恢复损坏的chunk"><p>利用存储在别的chunkserver上的副本对已损坏的chunk进行修复。</p><h2 id="如何发现ChunkServer挂掉了"><a href="#如何发现ChunkServer挂掉了" class="headerlink" title="如何发现ChunkServer挂掉了"></a>如何发现ChunkServer挂掉了</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E5%8F%91%E7%8E%B0ChunkServer%E6%8C%82%E6%8E%89.png" class="" title="发现ChunkServer挂掉"><p>chunkserver通过发送心跳包在Master上留下时间戳来告诉Master自己还活着</p><h3 id="ChunkServer挂掉后恢复数据"><a href="#ChunkServer挂掉后恢复数据" class="headerlink" title="ChunkServer挂掉后恢复数据"></a>ChunkServer挂掉后恢复数据</h3><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/ChunkServer%E6%8C%82%E6%8E%89%E5%90%8E%E6%81%A2%E5%A4%8D%E6%95%B0%E6%8D%AE.png" class="" title="ChunkServer挂掉后恢复数据"><p>我在索引里就会发现chunkserver4下线了，我就会启动一个修复进程。修复进程中的working list是基于存活副本数的恢复策略。副本越少说明越危险，应当尽早的修复。</p><h2 id="如何应对热点"><a href="#如何应对热点" class="headerlink" title="如何应对热点"></a>如何应对热点</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E5%BA%94%E5%AF%B9%E7%83%AD%E7%82%B9.png" class="" title="应对热点"><p>我们引入一个热点平衡进程，记录chunk和chunkserver访问的频次。基于ChunkServer的硬盘和带宽利用率，当副本过度繁忙，我们就把它复制到更多的chunkserver。</p><h2 id="如何读文件"><a href="#如何读文件" class="headerlink" title="如何读文件"></a>如何读文件</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E8%AF%BB%E6%96%87%E4%BB%B6%E8%BF%87%E7%A8%8B.png" class="" title="读文件过程"><p>chunkserver的底层还是利用Linux 的文件系统来实现。</p><h2 id="如何写文件"><a href="#如何写文件" class="headerlink" title="如何写文件"></a>如何写文件</h2><img src="/2021/03/04/Google%E4%B8%89%E9%A9%BE%E9%A9%AC%E8%BD%A6%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94GFS/%E5%86%99%E6%96%87%E4%BB%B6%E8%BF%87%E7%A8%8B.png" class="" title="写文件过程"><p>primary就是主副本，这是临时被选定的，本身的各个副本之间是没有优先级的。但我的client首先连接的可以不是primary，而是去找一个离它最近的server。因为在服务器和服务器之间有很高的带宽，所以服务器之间可以互相传。</p><p>为了更有效的使用网络我们将数据流和控制流分离。控制流从client到达主副本，然后到达其他的所有次副本，而数据则是线性地通过一个仔细选择的chunkserver链像流水线那样推送过去的。我们的目标是充分利用每个机器的网络带宽，避免网络瓶颈和高延时链路，最小化数据推送的延时。</p><p> 为了充分利用每个机器的网络带宽，数据通过chunkserver链线性的推送过去而不是以其他的拓扑进行分布比如树型。因此每个机器的带宽可以全部用来发送数据而不是为多个接受者进行切分。</p><p>不用设计处理错误的机制，错误机制会引发更多的错误。直接让client重试就好了。</p>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Google</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一致性大一统</title>
    <link href="/2021/03/01/%E4%B8%80%E8%87%B4%E6%80%A7%E5%A4%A7%E4%B8%80%E7%BB%9F/"/>
    <url>/2021/03/01/%E4%B8%80%E8%87%B4%E6%80%A7%E5%A4%A7%E4%B8%80%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<p>在写这篇文章之前，对一致性的理解尚处于一种非常混乱的地步。很多名字搅在一起serializable, linearizable, sequential… 并没有一个很好的理解每一种模型之间的不同以及每一个模型背后的底层逻辑。这里准备整合一下网上的资料，阅读一些提出模型的论文来一个深度的理解。</p><p>[TOC]</p><h1 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h1><p>下图向我们展示了在并发系统中常见的一致性模型之间的关系。箭头显示一致性模型之间的关系。例如，严格可串行化（Strict Serializable）意味着可串行化（Serializable）和可线性化（Linearizable），可线性化意味着序列一致性（Sequential）等等。颜色显示每个模型对于异步网络上的分布式系统的可用性。</p><img src="/2021/03/01/%E4%B8%80%E8%87%B4%E6%80%A7%E5%A4%A7%E4%B8%80%E7%BB%9F/consistency-model.png" class="" title="一致性模型"><h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><h2 id="系统-（Systems）"><a href="#系统-（Systems）" class="headerlink" title="系统 （Systems）"></a>系统 （Systems）</h2><p><em>分布式系统</em> 是<em>并发系统</em> 的一种类型，许多关于并发控制的文献直接应用于分布式系统。实际上，我们将要讨论的大多数概念最初都是针对单节点并发系统。但是，在可用性和性能方面存在一些重要的差异。</p><p>系统具有随时间变化的逻辑状态。例如，一个简单的系统可以是一个整数变量，状态为0、3和42。互斥只有两种状态：locked 或 unlocked。键值存储的状态可能是键到值的映射，例如：<code>&#123;cat: 1, dog: 1&#125;</code> 或 <code>&#123;cat: 4&#125;</code>。</p><h2 id="进程（Processes）"><a href="#进程（Processes）" class="headerlink" title="进程（Processes）"></a>进程（Processes）</h2><p>进程是执行计算和运行操作的逻辑单线程程序。进程从来都不是异步的我们通过独立的进程来模拟异步计算。我们说“逻辑单线程”是为了强调，虽然一个进程一次只能做一件事，但它的实现可能会分布在多个线程、操作系统进程甚至物理节点上，只要这些组件提供了一致的单线程程序的假象。</p><h2 id="操作（Operations）"><a href="#操作（Operations）" class="headerlink" title="操作（Operations）"></a>操作（Operations）</h2><p>操作是从一个状态到另一个状态的转换。例如，一个单变量系统可能有<code>read</code>和<code>write</code>这样的操作，分别获取和设置该变量的值。计数器可能具有<code>increments</code>、<code>decrements</code>和<code>reads</code>等操作。SQL存储可能有<code>selects</code>和<code>updates</code>等操作。</p><h3 id="函数，参数和返回（Functions-Arguments-amp-Return-Values）"><a href="#函数，参数和返回（Functions-Arguments-amp-Return-Values）" class="headerlink" title="函数，参数和返回（Functions, Arguments &amp; Return Values）"></a>函数，参数和返回（Functions, Arguments &amp; Return Values）</h3><p>理论上，我们可以给每次状态转移一个唯一的名字。一个锁有两种状态：<code>lock</code>和<code>unlock</code>。一个整形的寄存器有无数种<code>read</code>和<code>write</code>：<code>read-the-value-1</code>, <code>read-the-value-2</code> 和 <code>write-1</code>,<code>write-2</code>…</p><p>为了让它更容易理解，我们把这些转换分解为<code>read</code>, <code>write</code>, <code>cas</code>, <code>increment</code>等 <em>函数（ function）</em>以及参数化这些函数的值（values）。在单寄存器系统中，write 1这个操作可以写成：</p><p><code>&#123;:f :write, :value 1&#125;</code></p><p>给定一个键值存储，我们可以将键“a”的值增加3，如下所示：</p><p><code>&#123;:f :increment, :value[&quot;a&quot; 3]&#125;</code></p><p>在事务存储中，值可以是一个复杂的事务。在这里，我们读取a的当前值，找到2，并将b设置为3，在一个状态转换中：</p><p><code>&#123;:f :txn, :value [[:read &quot;a&quot; 2] [:write &quot;b&quot; 3]]&#125;</code></p><h3 id="调用和完成时间（Invocation-amp-Completion-Time）"><a href="#调用和完成时间（Invocation-amp-Completion-Time）" class="headerlink" title="调用和完成时间（Invocation &amp; Completion Time）"></a>调用和完成时间（Invocation &amp; Completion Time）</h3><p>一般来说，操作都需要时间。在多线程程序中，操作可能是函数调用。在分布式系统中，操作可能意味着向服务器发送请求并接收响应。</p><p>为了对此进行建模，我们说每个操作都有一个<em>调用（ invocation）</em>时间，如果它完成了，则有一个更大的完成时间<em>（ completion time）</em>，这两个时间都由一个理想的，完美同步的，全局可访问的时钟给出。我们将这些时钟称为提供实时（real-time）顺序，而不是只跟踪因果顺序的时钟。</p><h3 id="并发（Concurrency）"><a href="#并发（Concurrency）" class="headerlink" title="并发（Concurrency）"></a>并发（Concurrency）</h3><p>由于操作需要时间，两个操作可能会在某个时间点重合。例如，给定两个操作A和B，A可以开始，B可以开始，A可以完成，然后B可以完成。如果有一段时间A和B都在执行，那么我们说两个操作A和B是 <em>并发</em> 的。</p><p>进程是单线程的，这意味着由同一进程执行的两个操作永远不会并发。</p><h3 id="崩溃（Crashes）"><a href="#崩溃（Crashes）" class="headerlink" title="崩溃（Crashes）"></a>崩溃（Crashes）</h3><p>如果一个操作因为一些意外（可能是因为超时或者一个关键的组件崩溃了）没有执行成功，那么这个操作就 <em>没有完成时间（completion time）</em> 。并且通常必须在调用后被视为与每个操作并发。它可以执行也可以不执行。</p><p>具有某个操作的进程处于这种状态时，实际上会被卡住，并且永远不能再次调用另一个操作。如果它调用另一个操作，它将违反我们的单线程约束：进程一次只做一件事。</p><h2 id="Histories（历史）"><a href="#Histories（历史）" class="headerlink" title="Histories（历史）"></a>Histories（历史）</h2><p><em>历史（ history）</em> 是操作的集合，包括它们的并发结构。</p><p>一些论文将其表示为一组操作，其中每个操作包含两个数字，表示它们的调用和完成时间；通过比较进程之间的时间窗口来推断并发结构。</p><p>Jepsen将历史表示为调用和完成操作的有序列表，有效地将每个操作一分为二。这种表示法对于迭代历史的算法更为方便，它保持了并发操作和可能状态的表示。</p><h1 id="一致性模型-1"><a href="#一致性模型-1" class="headerlink" title="一致性模型"></a>一致性模型</h1><p><em>一致性模型</em> 是一组历史。我们使用一致性模型来定义系统中哪些历史是“好的”，哪些是“合法的”。当我们说一个历史“违反了可序列化性”或“不可序列化”时，我们的意思是该历史不在可序列化历史的集合中。</p><p>如果A是B的子集，则一致性模型A意味着模型B。例如，线性化意味着序列一致性，因为每个可线性化的历史也是序列一致的。这允许我们在层次结构中关联一致性模型。</p><p>非正式地说，我们将更小、更严格的一致性模型称为“更强”，将更大、更宽松的一致性模型称为“较弱”。</p><p>并非所有的一致性模型都具有直接可比性。通常，两个模型允许不同的行为，但都不包含另一个。</p><h2 id="一致性（Consistency）"><a href="#一致性（Consistency）" class="headerlink" title="一致性（Consistency）"></a>一致性（Consistency）</h2><p>数据库和分布式系统中都有一致性的概念，但是英文的文献也没有翻译出它们的区别，都是统一翻译成“Consistency”。</p><ul><li><p>在数据库事务中的ACID中，C是Consistency，这里这个C主要强调应用逻辑的一致性，比如应用定义的约束，包括外键等。</p><ul><li>主要强调读是否能读到最新，以及并发场景下操作执行的时序关系，主要包括线性一致性（Linearizability），顺序一致性（Sequential Consistency），因果一致性（Causal Consistency）等；</li></ul></li><li><p>分布式系统的CAP以及一致性协议，也称为一致性。</p><ul><li>主要强调“共识”，分布式中的多个节点对某个事情（leader选举，事务提交）达成一致，常见的共识算法包括paxos协议，raft协议。</li></ul></li></ul><h2 id="正确性（Correctness）"><a href="#正确性（Correctness）" class="headerlink" title="正确性（Correctness）"></a>正确性（Correctness）</h2><blockquote><p>Given some <em>rules</em> which realte the operations and state, the history of operations in the system should always follow those rules.</p></blockquote><p>要求我们的系统从头到尾必须遵循同一种一致性模型，那么我们就可以说这个系统具有正确性。</p><p>一致性模型的限制从最宽松到最严格可以被分为不同的档位。最宽松的一致性模型，允许所有的行为（即你的输出是什么都可以）。为了描述并发，就可以调整模型的限制。</p><h2 id="严格可串行化-（Strict-Serializability）"><a href="#严格可串行化-（Strict-Serializability）" class="headerlink" title="严格可串行化 （Strict Serializability）"></a>严格可串行化 （Strict Serializability）</h2><p>非正式地说，严格序列化意味着操作似乎以某种顺序发生，与这些操作的实时顺序一致；例如，如果操作A在操作B开始之前完成，那么A应该在序列化顺序中出现在B之前。</p><p>严格串行化是一种 <em>事务</em> 模型：操作（通常称为“事务”）可以包括按顺序执行的几个基本操作。严格的可序列化性保证了操作以原子方式进行：事务的子操作看起来不会与其他事务的子操作交织在一起。</p><p>它也是一个 <em>多对象</em> 属性：操作可以作用于系统中的多个对象。实际上，严格的序列化不仅适用于事务中涉及的特定对象，而且适用于整个系统——操作可能作用于谓词，如“所有cats的集合”。</p><p>严格的序列化功能不能完全或停滞可用；在网络分区的情况下，某些或所有节点将无法取得进展。</p><p>严格可串行化意味着可串行化和线性化。您可以将严格的可串行化看作是可串行化的事务性多对象操作的总顺序，再加上线性化的实时约束。或者，您可以将严格可序列化的数据库视为可线性化的对象，其中对象的状态是整个数据库。</p><h3 id="Formally"><a href="#Formally" class="headerlink" title="Formally"></a>Formally</h3><blockquote><p>A history is serializable if it is equivalent to one in which transactions appear to execute sequentiallly, i.e., without interleaving. A (partial) precedence order can be defined on non-overlapping pairs of transactions in the obvious way. A history is strictly serializable if the transcations’ order in the sequential history is compatibel with their precedence order.</p></blockquote><h2 id="顺序一致性-（Sequential-Consistency）"><a href="#顺序一致性-（Sequential-Consistency）" class="headerlink" title="顺序一致性 （Sequential Consistency）"></a>顺序一致性 （Sequential Consistency）</h2><p>这个是出现在1979年的论文中</p><p>进程的操作可能会在调用之前或是调用之后生效，但仍然保证一个约束——任意进程中的操作必须按照进程中定义的顺序发生。</p><p>顺序一致性的性质：</p><ol><li>不要求操作按照真实的时间序发生。</li><li>不同进程间的操作执行先后顺序也没有强制要求，但必须是原子的。</li><li>单个进程内的操作顺序必须和编码时的顺序一致。</li></ol><h2 id="线性一致性-（Linearizability）"><a href="#线性一致性-（Linearizability）" class="headerlink" title="线性一致性 （Linearizability）"></a>线性一致性 （Linearizability）</h2><blockquote><p>An operation cannot take effect <em>before</em> its invocation. </p><p>No operation may take effect <em>after</em> its completion.</p></blockquote><p>假设：</p><ul><li>有一个全局的状态于每个进程进行通信</li><li>与这个全局状态交互的操作都是<strong>原子的</strong></li><li><strong>每个操作会在它调用和完成之间的某个时间点原子生效</strong></li></ul><p>这样的模型就被称为<strong>线性一致性模型</strong>。尽管操作都是并发且耗时的，但每一个操作都会在某地以严格的线性顺序发生。相比于<strong>顺序一致性</strong>添加了时间维度。（顺序一致性中只有偏序关系）</p><p>“全局单点状态”并不一定是一个单独的节点，同样的，操作也并不一定全是原子的，状态也可以被分片成横跨多台机器，或者分多步完成——只要从进程的角度看来，外部记录的表现与<strong>一个原子的单点状态等效</strong>。一旦一个操作完成，它或它之后的某一状态将对<strong>所有参与者可见</strong>。</p><p>我们可以利用线性一致性的原子性约束来<strong>安全地修改状态</strong>。我们定义一个类似<code>CAS（compare-and-set）</code>的操作，当且仅当寄存器持有某个值的时候，我们可以往它写入新值。 <code>CAS</code>操作可以作为互斥量，信号量，通道，计数器，列表，集合，映射，树等等的实现基础，使得这些共享数据结构变得可用。线性一致性保证了变更的<strong>安全交错</strong>。</p><p>此外，线性一致性的时间界限保证了操作完成后，所有变更都对其他参与者可见。于是线性一致性禁止了过时的读。每次读都会读到某一介于<code>调用时间</code>与<code>完成时间</code>的状态，但永远不会读到读请求调用之前的状态。线性一致性同样禁止了<strong>非单调</strong>的读，比如一个读请求先读到了一个新值，后读到一个旧值。</p><p>保证：</p><ol><li><em>对于观察者来说，所有的读和写都在一个单调递增的时间线上串行地向前推进。</em></li><li><em>所有的读总能返回最近的写操作的值</em>。</li></ol><img src="/2021/03/01/%E4%B8%80%E8%87%B4%E6%80%A7%E5%A4%A7%E4%B8%80%E7%BB%9F/%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E5%92%8C%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7.png" class="" title="线性一致性和顺序一致性"><h2 id="因果一致性（Casual-Consistency）"><a href="#因果一致性（Casual-Consistency）" class="headerlink" title="因果一致性（Casual Consistency）"></a>因果一致性（Casual Consistency）</h2><p>我们不必对一个进程中的<strong>每个</strong>操作都施加顺序约束。只有<strong>因果相关</strong>的操作必须按顺序发生。同样拿帖子举例子：一篇帖子下的所有评论必须以同样的顺序展示给所有人，并且只有帖子可见<strong>后</strong>，帖子下的回复才可见<em>（也就是说帖子和帖子下的评论有因果关系）</em>。如果我们将这些因果关系编码成类似“我依赖于操作X”的形式，作为每个操作明确的一部分，数据库就可以将这些操作延迟直到它们的依赖都就绪后才可见。</p><p>因果一致性比同一进程下对每个操作严格排序的一致性<em>（即顺序一致性）</em>来的更宽松——属于同一进程但不同因果关系链的操作能以相对的顺序执行<em>（也就是说按因果关系隔离，无因果关系的操作可以并发执行）</em>，这能防止许多不直观的行为发生。</p><img src="/2021/03/01/%E4%B8%80%E8%87%B4%E6%80%A7%E5%A4%A7%E4%B8%80%E7%BB%9F/%E5%9B%A0%E6%9E%9C%E4%B8%80%E8%87%B4%E6%80%A7.png" class="" title="因果一致性"><p>每个线程自己认为所看到的是符合逻辑的就行。但不能保证每个线程看到的逻辑都是一样的。</p><h2 id="串行一致性-（Serializable-Consistency）"><a href="#串行一致性-（Serializable-Consistency）" class="headerlink" title="串行一致性 （Serializable Consistency）"></a>串行一致性 （Serializable Consistency）</h2><p>这是一个非常容易搞混的概念。原因在于数据库的隔离级别中有一个最高的隔离级别是可串行化（Serializable），这个是纯粹数据库领域的概念与分布式系统并没有交集。</p><p>对于数据库而言，Serializable是指在并发场景下，多个并发事务最终执行的序列与某个串行执行的序列相同（无事务并发，事务的执行没有重叠）。可以通过多种方式来实现，具体可见《数据密集型应用系统设计》读书笔记。</p><p>串行一致性允许对操作顺序执行任意的重排（只要操作顺序是原子序的）。</p><h3 id="Linearizability-vs-Serializability"><a href="#Linearizability-vs-Serializability" class="headerlink" title="Linearizability vs. Serializability"></a>Linearizability vs. Serializability</h3><ul><li>Linearizability: single-operation, single-object, real-time order<ul><li>它对单个对象（例如，分布式寄存器或数据项）上的一组单个操作（通常是读写）的行为提供实时（即挂钟）保证。</li></ul></li><li>Serializability: multi-operation, multi-object, arbitrary total order<ul><li>它保证在多个项目上执行一组事务（通常包含读写操作）等同于事务的<strong>某些</strong>串行执行（总排序）。</li></ul></li><li>Serializability对事务的排序施加任何实质性约束，这一点与Linearizabililty不一样。<ul><li>Serializability是不可组合的，它并不意味着任何类型的确定顺序，它只是要求存在一些等效的串行执行。</li></ul></li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://jepsen.io/consistency">Consistency Models</a></p><p><a href="http://www.bailis.org/blog/linearizability-versus-serializability/">Linearizability vs. Serializablity</a></p>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>一致性</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《数据密集型应用系统设计》-读书笔记3</title>
    <link href="/2021/02/02/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B03/"/>
    <url>/2021/02/02/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B03/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>《数据密集型应用系统设计》-读书笔记2</title>
    <link href="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/"/>
    <url>/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/</url>
    
    <content type="html"><![CDATA[<h1 id="第二部分：分布式数据系统"><a href="#第二部分：分布式数据系统" class="headerlink" title="第二部分：分布式数据系统"></a>第二部分：分布式数据系统</h1><ul><li>扩展性<ul><li>当数据量或者读写负载巨大，严重超出了单台机器的处理上限，需要将负载分散到多台机器上。</li></ul></li><li>容错和高可用性<ul><li>当单台机器出现故障，还希望应用系统可以继续工作，这是需要采用多台机器提供冗余。</li></ul></li><li>延迟考虑<ul><li>如果客户遍布世界各地，通常需要考虑在全球范围内部署服务，以方便用户就近访问最近数据中心所提供的服务。</li></ul></li></ul><h2 id="系统扩展能力"><a href="#系统扩展能力" class="headerlink" title="系统扩展能力"></a>系统扩展能力</h2><p>当负载增加需要更强的处理能力时，最简单的办法就是购买更强大的机器（垂直扩容）。</p><ul><li><strong>共享内存架构</strong><ul><li>所有这些组件的集合可看做一台大机器。</li><li>共享内存架构的问题在于，成本增长过快甚至超过了线性：两倍的CPU，两倍的内存，两倍的磁盘容量可能不能将成本控制在两倍。</li></ul></li><li><strong>共享磁盘架构</strong><ul><li>拥有多台服务器，每个服务器各自拥有独立的CPU和内存，然后将数据存储在可共享访问的磁盘阵列上。</li><li>服务器与磁盘阵列之间往往通过高速网络连接。</li></ul></li></ul><h2 id="无共享结构"><a href="#无共享结构" class="headerlink" title="无共享结构"></a>无共享结构</h2><p>与上面的垂直扩容相比较之下，无共享架构优点更加明显。</p><ul><li>运行数据库软件的机器或者虚拟机成为<strong>节点</strong>。</li><li>每个<strong>节点</strong>独立使用本地的CPU，内存和磁盘。</li><li>节点之间的多有协调通信等任务全部运行在传统网络之上且核心逻辑主要依靠软件来实现。</li></ul><h2 id="复制与分区"><a href="#复制与分区" class="headerlink" title="复制与分区"></a>复制与分区</h2><ul><li>复制<ul><li>在多个节点上保存相同数据的副本，每个副本具体的存储位置可能不尽相同。</li></ul></li><li>分区<ul><li>将一个大块头的数据库拆分成多个较小的子集即<strong>分区</strong>，不同的分区分配给不同的节点。</li></ul></li></ul><h1 id="第五章-数据复制"><a href="#第五章-数据复制" class="headerlink" title="第五章 数据复制"></a>第五章 数据复制</h1><p>我们将讨论三种流行的复制数据变化的方法：主从复制、多主节点复制和无主节点复制。</p><h2 id="主节点与从节点"><a href="#主节点与从节点" class="headerlink" title="主节点与从节点"></a>主节点与从节点</h2><ol><li>指定某一个副本为主副本（或称为主节点）。当客户写数据库时，必须将 写请求首先发送给主副本，主副本首先将新数据写入本地存储。</li><li>其他副本则全部称为从副本（或称为从节点）。主副本把新数据写入本地存储后，然后将数据更改作为复制的日志或更改流发送给所有从副本。每个从副本获得更改日志之后将其应用到本地，且严格保持与主副本相同的写入顺序。</li><li>客户端从数据库中读数据时，可以在主副本或者从副本上执行查询。只有主副本才可以接受请求；从客户端的角度来看，从副本都是只读的。</li></ol><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%B3%BB%E7%BB%9F.png" class="" title="主从复制系统"><h3 id="同步复制与异步复制"><a href="#同步复制与异步复制" class="headerlink" title="同步复制与异步复制"></a>同步复制与异步复制</h3><p>对于关系型数据库系统，同步或异步通常是一个可配置的选项；而其他系统则可能是硬性指定或者只能二选一</p><h4 id="同步复制"><a href="#同步复制" class="headerlink" title="同步复制"></a>同步复制</h4><ul><li>优点：一旦向用户确认，从节点可以明确保证完成了与主节点的更新同步，数据已经处于最新版本。</li><li>缺点：如果同步的从节点无法完成确认，写入就不能视为成功。主节点会阻塞其后所有的写操作，直到同步副本确认完成。</li></ul><blockquote><p>半同步：其中某一个从节点是同步的，而其他节点则是异步模式。这样可以保证至少有两个节点（即主节点和一个同步从节点）拥有最新的数据副本。</p></blockquote><h4 id="异步复制"><a href="#异步复制" class="headerlink" title="异步复制"></a>异步复制</h4><ul><li>优点：不管从节点上数据多么滞后，主节点总是可以继续响应写请求，系统的吞吐性能更好。</li></ul><h4 id="链式复制"><a href="#链式复制" class="headerlink" title="链式复制"></a>链式复制</h4><p>// todo </p><p>【10】</p><p>【11】</p><h3 id="配置新的从节点"><a href="#配置新的从节点" class="headerlink" title="配置新的从节点"></a>配置新的从节点</h3><p>我们需要做到在不停机、数据服务不中断的前提下完成从节点的设置。</p><ol><li>在某个时间点对主节点的数据副本产生一个一致性快照。</li><li>将此快照拷贝到新的从节点</li><li>从节点连接到主节点并请求快照点之后所发生的数据更改日志。</li><li>获得日志之后，从节点来应用这些快照点之后所有数据变更，这个过程称之为“追赶”。接下来，继续处理主节点上新的数据变化。重复步骤1~步骤4</li></ol><h3 id="处理节点失效"><a href="#处理节点失效" class="headerlink" title="处理节点失效"></a>处理节点失效</h3><h4 id="从节点失效：追赶式恢复"><a href="#从节点失效：追赶式恢复" class="headerlink" title="从节点失效：追赶式恢复"></a>从节点失效：追赶式恢复</h4><p>根据副本的复制日志，从节点可以知道在发生故障之前所处理的最后一个事务，然后连接主节点，并请求自那个事务之后中断期间内所有的数据变更。在收到数据变更日止之后，将其应用到本地来追赶主节点。</p><h4 id="主节点失效：节点切换"><a href="#主节点失效：节点切换" class="headerlink" title="主节点失效：节点切换"></a>主节点失效：节点切换</h4><ol><li>确认主节点失效<ul><li>大多数系统采用了基于超时的机制</li></ul></li><li>选举新的主节点<ul><li>通过超过半数的节点达成共识的方式来选举新的主节点，或者由之前选定的某控制节点来指定新的主节点。</li><li>候选节点最好与原主节点的数据差异最小。</li></ul></li><li>重新配置系统使新主节点生效<ul><li>系统要确保原主节点降级为从节点，并认可新的主节点</li></ul></li></ol><h3 id="复制日志的实现"><a href="#复制日志的实现" class="headerlink" title="复制日志的实现"></a>复制日志的实现</h3><h4 id="基于语句的复制"><a href="#基于语句的复制" class="headerlink" title="基于语句的复制"></a>基于语句的复制</h4><p>主节点记录所执行的每个写请求并将该操作语句作为日志发送给从节点。</p><p>不适用的场景：</p><ul><li>任何调用非确定性函数的语句</li><li>语句中依赖于数据库的现有数据，则所有副本必须按照完全相同的顺序执行</li><li>有side effect的语句</li></ul><h4 id="基于预写日志（WAL）传输"><a href="#基于预写日志（WAL）传输" class="headerlink" title="基于预写日志（WAL）传输"></a>基于预写日志（WAL）传输</h4><h4 id="基于行的逻辑日志复制"><a href="#基于行的逻辑日志复制" class="headerlink" title="基于行的逻辑日志复制"></a>基于行的逻辑日志复制</h4><h4 id="基于触发器的复制"><a href="#基于触发器的复制" class="headerlink" title="基于触发器的复制"></a>基于触发器的复制</h4><h2 id="复制滞后问题"><a href="#复制滞后问题" class="headerlink" title="复制滞后问题"></a>复制滞后问题</h2><p>复制滞后可能会出现以下三个问题：<strong>读自己的写</strong>，<strong>单调读</strong>，<strong>前缀一致读</strong></p><h3 id="读自己的写"><a href="#读自己的写" class="headerlink" title="读自己的写"></a>读自己的写</h3><p>提交新数据须发送到主节点，但是当用户读取数据时，数据可能来自从节点。这对于读密集和偶尔写入的负载是个非常合适的方案。</p><p>对于这种情况，我们需要“写后读一致性”，也称为<strong>读写一致性</strong></p><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ul><li>如果用户访问可能会被修改的内容，从主节点读取；否则，在从节点读取。<ul><li>总是从主节点读取用户自己的首页配置文件，而在从节点读取其他用户的配置文件</li></ul></li><li>跟踪最近更新的时间，如果更新后一分钟之内，则总是在主节点读取；并监控从节点的复制滞后程度，避免从那些滞后时间超过一分钟的从节点读取</li><li>客户端还可以记住最近更新的时间戳，并附带在读请求中。</li></ul><h3 id="单调读"><a href="#单调读" class="headerlink" title="单调读"></a>单调读</h3><p>用户从不同的副本进行了多次读取，可能会看到回滚的现象（即在读取较新值之后又发生读旧值的情况）。</p><p><strong>单调读一致性</strong>可以确保不会发生这种异常。</p><h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><ul><li>确保每个用户总是从固定的同一副本执行读取</li></ul><h3 id="前缀一致读"><a href="#前缀一致读" class="headerlink" title="前缀一致读"></a>前缀一致读</h3><p>要保证因果的一致。对于一系列按照某个顺序发生的写请求，那么读取这些内容时也会按照当时写入的顺序。</p><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E5%89%8D%E7%BC%80%E4%B8%80%E8%87%B4%E8%AF%BB.png" class="" title="前缀一致读"><h4 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h4><ul><li>确保任何具有因果顺序关系的写入都交给一个分区来完成</li></ul><h2 id="多主节点复制"><a href="#多主节点复制" class="headerlink" title="多主节点复制"></a>多主节点复制</h2><p>主从复制存在一个明显的缺点：系统只有一个主节点，而所有写入都必须经由主节点。</p><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>多数据中心<ul><li>可以在每个数据中心都配置主节点。</li><li>在每个数据中心内，采用常规的主从复制方案；而在数据中心之间，由各个数据中心的主节点来负责同其他数据中心的主节点进行数据的交换、更新。</li></ul></li><li>离线客户端操作<ul><li>在离线状态下进行的任何更改，会在下次设备上线时，与服务器以及其他设备同步。</li><li>每个设备都有一个充当主节点的本地数据库，然后所有设备之间采用异步方式同步这些多主节点上的副本，同步滞后的具体时间取决于设备何时可以再次联网。</li></ul></li><li>协作编辑</li></ul><h3 id="处理写冲突"><a href="#处理写冲突" class="headerlink" title="处理写冲突"></a>处理写冲突</h3><p>多主复制的最大问题是可能发生写冲突，这意味着必须有方案来解决。</p><h4 id="同步与异步冲突检测"><a href="#同步与异步冲突检测" class="headerlink" title="同步与异步冲突检测"></a>同步与异步冲突检测</h4><p>如果是主从复制数据库，第二个写请求要么会被阻塞直到第一个写完成，要么被终止。理论上， 也可以做到同步冲突检测，即等待写请求完成对所有副本的同步，然后再通 知用户 写入成功 。 但是，这样做将会失去多主节点的主要优势：允许每个主节点独立接受写请求。</p><h4 id="收敛于一致状态"><a href="#收敛于一致状态" class="headerlink" title="收敛于一致状态"></a>收敛于一致状态</h4><p>对于主从复制模型，数据更新符合顺序性原则，即如果同一个字段有多个更新，则最后一个写操作将决定该字段的最终值。对于多主节点复制模型，由于不存在这样的写入顺序，所以最终值也会变得不确定。</p><p>解决方式：</p><ul><li><p>给每个写入分配唯一的ID，挑选最高ID的写入作为胜利者，并将其他写入丢弃。</p><ul><li>但是这种方法容易造成数据丢失。【TODO】</li></ul></li><li><p>利用预定义好的格式来记录和保留冲突相关的所有信息，然后依靠应用层的逻辑，事后解决冲突 （可能会提示用户）</p></li><li><p>以某种方式讲这些冲突的值合并在一起。</p></li></ul><h3 id="拓扑结构"><a href="#拓扑结构" class="headerlink" title="拓扑结构"></a>拓扑结构</h3><ul><li>全部-至-全部结构<ul><li>每个主节点将其写入同步到其他所有的主节点。</li></ul></li><li>环形拓扑结构<ul><li>MySQL默认情况下只支持环形拓扑结构</li><li>其中的每个节点接受来自前序节点的写入，并将这些写入（加上自己的写入）转发给后序节点</li></ul></li><li>星型结构<ul><li>一个指定的根节点将写入转发给所有其他节点。</li></ul></li></ul><p>各种拓扑结构的优缺点</p><ul><li>环形和星型拓扑的问题是，如果某一个节点发生了故障，在修复之前，会影响其他节点之间复制日志的转发。</li><li>全链接拓扑也存在一些自身的问题。主要是存在某些网络链路比其他链路更快的情况（例如由于不同网络拥塞），从而导致复制日志之间的覆盖。</li></ul><blockquote><p>为了使得日志消息正确有序，可以使用一种称为版本向量的技术</p></blockquote><h2 id="无主节点复制"><a href="#无主节点复制" class="headerlink" title="无主节点复制"></a>无主节点复制</h2><h3 id="节点失效时写入数据库"><a href="#节点失效时写入数据库" class="headerlink" title="节点失效时写入数据库"></a>节点失效时写入数据库</h3><p>当一个客户端从数据库中读取数据时，它不是向一个副本发送请求，而是并行地发送到多个副本。客户端可能会得到不同节点的不同响应，包括某些节点的新值和某些节点的旧值。可以采用版本号技术确定哪个值更新。</p><h4 id="读修复与反熵"><a href="#读修复与反熵" class="headerlink" title="读修复与反熵"></a>读修复与反熵</h4><ul><li>读修复<ul><li>当客户端并行读取多个副本时，可以检测到过期的返回值。</li></ul></li><li>反熵过程<ul><li>一些数据存储有后台进程不断查找副本之间数据的差异，将任何缺少的数据从一个副本复制到另一个副本。</li></ul></li></ul><h4 id="读写quorum"><a href="#读写quorum" class="headerlink" title="读写quorum"></a>读写quorum</h4><p>如果有<em>n</em>个副本，写入需要<em>w</em>个节点确认，读取必须至少查询<em>r</em>个节点，则只要<em>w + r &gt; n</em>，读取的节点中一定会包含最新值。（抽屉原理）</p><p>我们只需要确保在<em>r</em>次的查询中有查到最新值，就可以通过版本号来确定。</p><h3 id="Quorum一致性的局限性"><a href="#Quorum一致性的局限性" class="headerlink" title="Quorum一致性的局限性"></a>Quorum一致性的局限性</h3><h3 id="检测并发写"><a href="#检测并发写" class="headerlink" title="检测并发写"></a>检测并发写</h3><p>一个核心问题是，由于网络延迟不稳定或者局部失效，请求在不同的节点上可能会呈现不同的顺序</p><p>如果节点每当收到新的写请求时就简单的覆盖原有的逐渐，那么这些节点将永远无法达成一致。</p><p>下面来介绍一些解决冲突的技巧：</p><h4 id="最后写入者获胜"><a href="#最后写入者获胜" class="headerlink" title="最后写入者获胜"></a>最后写入者获胜</h4><p>每个副本总是保存最新值，允许覆盖并丢弃旧值。只要我们有一个明确的方法来确定哪一个写入是“最新”的，则副本可以最终收敛到相同的值。</p><blockquote><p>最后写入者获胜（last write wins, LWW）：</p><p>为每个写请求附加一个时间戳，然后选择最新即最大的时间戳，丢弃较早时间戳的写入。</p></blockquote><p>LWW的缺点：</p><ul><li><p>LWW可以实现最终收敛的目标，但是以牺牲数据持久性为代价。</p></li><li><p>在一些场景如缓存系统，覆盖写是可以接受的。</p></li></ul><h4 id="Happens-before关系和并发"><a href="#Happens-before关系和并发" class="headerlink" title="Happens-before关系和并发"></a>Happens-before关系和并发</h4><blockquote><p>如果B知道A，或者依赖于A，或者以某种方式在A基础上构建，则称操作A在操作B之前发生。</p></blockquote><p>对于两个操作A和B，一共存在三种可能性：A在B之前发生，或者B在A之前发生，或者A和B并发。如果属于并发，就需要解决潜在的冲突问题。</p><h5 id="确定前后关系"><a href="#确定前后关系" class="headerlink" title="确定前后关系"></a>确定前后关系</h5><ul><li>服务器为每个主键维护一个版本号，每当主键新值写入时递增版本号，并将新版本号与写入的值一起保存。</li><li>当客户端读取主键时，服务器将返回所有当前值以及最新的版本号。且要求写之前，客户必须先发送读请求。</li><li>客户端写主键，写请求必须包含之前读到的版本号、读到的值和新值合并后的集合。写请求的响应可以像读操作一样，会返回所有当前值，这样就可以像购物车例子那样一步步链接起多个写入的值。</li><li>当服务器收到带有特定版本号的写入时，覆盖该版本号或更低版本的所有值，但必须保存更高版本号的所有值。</li></ul><h5 id="合并同时写入的值"><a href="#合并同时写入的值" class="headerlink" title="合并同时写入的值"></a>合并同时写入的值</h5><p>如果多个操作并发发生，则客户端必须通过合并并发写入的值来继承旧值。</p><p>解决方案：</p><p>项目在删除时不能简单地从数据库中删除，系统必须保留一个对应的版本号以恰当的标记该项目需要在合并时被剔除。</p><h5 id="版本矢量"><a href="#版本矢量" class="headerlink" title="版本矢量"></a>版本矢量</h5><p>我们需要为每个副本和每个主键均定义一个版本号。每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本看到的版本号。通过这些信息来指示要覆盖哪些值、该保留哪些并发值。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><h3 id="三种多副本方案"><a href="#三种多副本方案" class="headerlink" title="三种多副本方案"></a>三种多副本方案</h3><ul><li>主从复制<ul><li>所有的客户端写入操作都发送到某一个节点（主节点），由该节点负责将数据更改时间发送到其他副本（从节点）。每个副本都可以接受读请求，但内容可能是过期值。</li></ul></li><li>多主节点复制<ul><li>系统存在多个主节点，每个都可以接受写请求，客户端将写请求发送到其中的一个主节点上，由该主节点负责将数据更改时间同步到其他主节点和自己的从节点。</li></ul></li><li>无主节点复制<ul><li>客户端将写请求发送到多个节点上，读取时从多个节点上并行读取，以此检测和纠正某些过期数据。</li></ul></li></ul><h3 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h3><p>应用程序处理复制滞后</p><ul><li>写后读一致性<ul><li>保证用户总能看到自己所提交的最新数据</li></ul></li><li>单调读<ul><li>用户在某个时间点读到数据之后，保证此后不会出现比该时间点更早的数据</li></ul></li><li>前缀一致读<ul><li>保证数据之间的因果关系，例如，总是以正确的顺序先读取问题，然后看到回答。</li></ul></li></ul><h1 id="第六章-分区"><a href="#第六章-分区" class="headerlink" title="第六章 分区"></a>第六章 分区</h1><blockquote><p>每一条数据只属于某个特定分区</p></blockquote><h2 id="数据分区与数据复制"><a href="#数据分区与数据复制" class="headerlink" title="数据分区与数据复制"></a>数据分区与数据复制</h2><p>分区通常与复制结合使用，即每个分区在多个节点都存有副本。</p><ul><li>每个分区都有自己的主副本</li><li>可能主副本被分配给A节点，从副本被分配给B节点</li><li>一个节点可能即是某些分区的主副本，又是其他分区的从副本</li></ul><h2 id="键-值数据的分区"><a href="#键-值数据的分区" class="headerlink" title="键-值数据的分区"></a>键-值数据的分区</h2><p>分区的主要 目标是将数据和查询负载均匀分布在所有节点上。如果分区不均匀，则会出现某些分区节点比其他分区承担更多的数据量或查询负载，称之为倾斜。</p><h3 id="基于关键字区间分区"><a href="#基于关键字区间分区" class="headerlink" title="基于关键字区间分区"></a>基于关键字区间分区</h3><blockquote><p>为每个分区分配一段连续的关键字或者关键字区间范围</p></blockquote><p>缺点：某些访问模式会导致热点。如果关键字是时间戳，则分区对应于一个时间范围，例如每天一个分区。</p><h3 id="基于关键字哈希值分区"><a href="#基于关键字哈希值分区" class="headerlink" title="基于关键字哈希值分区"></a>基于关键字哈希值分区</h3><p>这种方法可以很好地将关键字均匀地分配到多个分区中。</p><p>缺点：通过关键子哈希进行分区，我们丧失了良好的区间查询特性。即使关键字相邻，但经过哈希之后会分散在不同的分区中，区间查询就失去了原有的有序相邻的特性。</p><p><a href="https://segmentfault.com/a/1190000021199728">一致性哈希</a>是一种平均分配负载的方法。</p><h2 id="分区与二级索引"><a href="#分区与二级索引" class="headerlink" title="分区与二级索引"></a>分区与二级索引</h2><p>上述讨论的分区方案都依赖于键-值数据模型。但是，如果涉及二级索引，情况就会变得复杂。二级索引通常不能唯一表示一条记录，而是用来加速特定值的查询。</p><h3 id="基于文档分区的二级索引"><a href="#基于文档分区的二级索引" class="headerlink" title="基于文档分区的二级索引"></a>基于文档分区的二级索引</h3><ul><li><p>每个列表都有一个唯一的文档ID，用此ID对数据库进行分区。</p></li><li><p>每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中的数据</p></li></ul><p>缺点：</p><p>这种二级索引的查询代价高昂。如果想要搜索符合某个条件的记录，就需要将查询发送到所有的分区，然后合并所有返回的结果。</p><h3 id="基于词条的二级索引分区"><a href="#基于词条的二级索引分区" class="headerlink" title="基于词条的二级索引分区"></a>基于词条的二级索引分区</h3><p>另一种方法：</p><blockquote><p>可以对所有的数据构建全局索引，而不是每个分区维护自己的本地索引。</p></blockquote><p>索引本身也是分区的</p><ul><li><p>优点：</p><ul><li>相比于文档分区索引，它的读取更为高效，客户端只需要向包含词条的那一个分区发出读请求。</li></ul></li><li><p>缺点：</p><ul><li>写入速度较慢且非常复杂，因为单个文档的更新，里面可能会涉及多个二级索引，而二级索引的分区又可能完全不同甚至在不同的节点上。</li></ul></li><li><p>实践中，对全局二级索引的更新往往都是异步的（如果在写入之后马上去读索引，那么刚刚发生的更新可能还没有反应在索引中）</p></li></ul><h2 id="分区再平衡"><a href="#分区再平衡" class="headerlink" title="分区再平衡"></a>分区再平衡</h2><p>由于查询压力增加，数据规模增加，节点可能出现故障等潜在变化，要求数据和请求可以从一个节点转移到另一个节点。这样一个迁移负载的过程称为<strong>再平衡（或者动态平衡）</strong></p><p>分区再平衡后需要满足：</p><ul><li>平衡之后，负载、数据存储、读写请求应该在集群范围更均匀地分布</li><li>再平衡执行过程中，数据库应该可以继续正常提供读写服务</li><li>避免不必要的负载迁移，以加快动态再平衡，并尽量减少网络和磁盘I/O影响</li></ul><h3 id="动态再平衡的策略"><a href="#动态再平衡的策略" class="headerlink" title="动态再平衡的策略"></a>动态再平衡的策略</h3><h4 id="固定数量的分区"><a href="#固定数量的分区" class="headerlink" title="固定数量的分区"></a>固定数量的分区</h4><p>首先，创建远超实际节点数的分区数，然后为每个节点分配多个分区。接下来，如果集群中添加了一个新节点，该新节点可以从每个现有的节点上匀走几个分区，直到分区再次达到全局平衡。</p><p>分区大小应该“恰到好处”，不要太大，也不能过小，如果分区数量固定了但总数据量却高度不确定，就难以达到一个最佳取舍点。</p><h4 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h4><p>当分区的数据增长超过一个可配的参数阈值，它就拆分为两个分区，每个承担一半的数据量。相反，如果大量数据被删除，并且分区缩小到某个阈值以下，则将其与相邻分区进行合并。</p><h4 id="按节点比例分区"><a href="#按节点比例分区" class="headerlink" title="按节点比例分区"></a>按节点比例分区</h4><p>采用动态分区策略，拆分和合并操作使每个分区的大小维持在设定的最小值和最大值之间，因此<strong>分区的数量</strong>与数据集的大小成正比关系。另一方面，对于固定数量的分区方式，其每个<strong>分区的大小</strong>也与数据集的大小成正比 。两种情况，分区的数量都与节点 数无关。</p><h2 id="请求路由"><a href="#请求路由" class="headerlink" title="请求路由"></a>请求路由</h2><p>当客户端需要发送请求时，如何知道应该连接哪个节点？如果发生了分区再平衡，分区与节点的对应关系随之还会变化。</p><p>这个问题有以下几种不同的处理策略：</p><ol><li>允许客户端链接任意的节点。如果某节点恰好拥有所请求的分区，则直接处理该请求；否则，将请求转发到下一个合适的节点，接受答复，并将答复返回给客户端。</li><li></li></ol><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><h1 id="第七章-事务"><a href="#第七章-事务" class="headerlink" title="第七章 事务"></a>第七章 事务</h1><blockquote><p>事务将应用程序的多个读、写操作捆绑在一起成为一个逻辑操作单元</p></blockquote><p>但是并非每个应用程序都需要事务机制，有时可以弱化事务处理或完全放弃事务（为了实现更高的性能或更高的可用性）。</p><h2 id="深入理解事务"><a href="#深入理解事务" class="headerlink" title="深入理解事务"></a>深入理解事务</h2><p>随着非关系（NoSQL）数据库开始兴起。它们的目标是通过提供新的数据模型，以及内置的复制和分区等手段来改进传统的关系模型。</p><h3 id="ACID的含义"><a href="#ACID的含义" class="headerlink" title="ACID的含义"></a>ACID的含义</h3><p>实际上，各家数据库所实现的ACID并不尽相同。</p><h4 id="原子性-Atomicity"><a href="#原子性-Atomicity" class="headerlink" title="原子性 Atomicity"></a>原子性 Atomicity</h4><p>有一个误区：</p><blockquote><p>ACID中的原子性并不关乎多个操作的并发性，它没有描述多个线程试图访问相同的数据会发生什么情况，这其实是隔离性所定义的。</p></blockquote><p>ACID原子性实际上描述的是：</p><p><strong>客户端发起一个包含多个写操作的请求时可能发生的情况。</strong></p><p>在完成一部分写入操作后，系统发生了故障</p><ul><li>进程崩溃</li><li>网络中断</li><li>磁盘变满</li><li>违反了某种完整性约束</li></ul><p>出现了上述故障而导致无法完成最终提交时，事务会终止，数据库回滚。</p><blockquote><p>ACID中原子性所定义的特征是：在出错时中止事务，并将部分完成的写入全部丢弃。</p></blockquote><h4 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性 Consistency"></a>一致性 Consistency</h4><p>一致性这个词目前有多种含义：</p><ul><li>第五章讨论副本一致性以及异步复制模型时，引出最终一致性问题。</li><li>一致性哈希则是某些系统用于动态分区再平衡的方法。</li><li>CAP理论中，一致性一词用来表示线性化。</li><li>ACID中，一致性主要指数据库处于应用程序所期待的“预期状态”。</li></ul><blockquote><p>如果某事物从一个有效的状态开始，并且事务中任何更新操作都没有违背约束，那么最后的结果依然符合有效状态。</p></blockquote><p>这种一致性本质要求应用层来维护状态一致，应用程序有责任正确的定义事务来保持一致性。</p><p>ACID中的一致性更多是应用层的属性。</p><h4 id="隔离性-Isolation"><a href="#隔离性-Isolation" class="headerlink" title="隔离性 Isolation"></a>隔离性 Isolation</h4><blockquote><p>意味着并发执行的多个事务相互隔离，它们不能互相交叉。</p></blockquote><ul><li>串行性隔离<ul><li>虽然实际上它们可能同时运行，但数据库系统要确保当事务提交时，其结果与串行执行完全相同。</li></ul></li><li>快照隔离<ul><li>提供了比串行化更弱的保证。</li></ul></li></ul><h4 id="持久性-Durability"><a href="#持久性-Durability" class="headerlink" title="持久性 Durability"></a>持久性 Durability</h4><blockquote><p>保证一旦事务提交成功，即使存在硬件故障或数据库崩溃，事务所写入的任何数据也不会消失。</p></blockquote><h3 id="单对象与多对象事务操作"><a href="#单对象与多对象事务操作" class="headerlink" title="单对象与多对象事务操作"></a>单对象与多对象事务操作</h3><p>多对象事务目的通常是为了在多个数据对象之间保持同步。</p><p>对于关系数据库，客户端通常与数据库服务器建立TCP网络连接，因而对于特定的某个连接，SQL语句BEGIN TRANSACTION和COMMIT之间的所有操作都属于同一个事物。</p><p>例：电子邮件应用</p><ul><li>其他用户看到要么是更新后的电子邮件和更新后的计数器，要么是两者都未更新，而不会是两者不一致。（隔离性）</li><li>如果事务执行过程中发生错误，导致邮箱和未读计数器二者不同步。则事务将被终止，且此前插入的电子邮件将被回滚。（原子性）</li></ul><h4 id="单对象写入"><a href="#单对象写入" class="headerlink" title="单对象写入"></a>单对象写入</h4><ul><li><p>存储引擎在单节点、单个对象层面上提供原子性和隔离性。</p><ul><li>出现宕机时，基于日志回复来实现原子性（第三章“可靠的B-Tree”）</li><li>对每个对象采用加锁的方式来实现隔离，确保每次只允许一个线程访问对象。</li></ul></li><li><p>某些数据库还提供了高级的原子操作</p><ul><li>原子自增操作</li><li>compare-and-set</li></ul></li></ul><blockquote><p>通常意义上的事务针对的是多个对象，将多个操作聚合为一个逻辑执行单元。</p></blockquote><h4 id="多对象事务的必要性"><a href="#多对象事务的必要性" class="headerlink" title="多对象事务的必要性"></a>多对象事务的必要性</h4><ul><li>对于关系型数据模型，表中的某行可能是另一个表中的外键。</li><li>对于文档数据模型，更新非规范化数据时，就需要一次更新多个文档。此时多对象食物就可以有效防止非规范化数据之间出现不同步。</li><li>对于带有二级索引的数据库，每次更改值时都需要同步更新索引。</li></ul><h4 id="处理错误与中止"><a href="#处理错误与中止" class="headerlink" title="处理错误与中止"></a>处理错误与中止</h4><blockquote><p>ACID数据库基于这样的一个理念：如果存在违反原子性、隔离性或持久性的风险，则完全放弃整个事务，而不是部分放弃。</p></blockquote><ul><li>如果事务实际已经执行成功，但返回给客户端的消息在网络传输时发生意外，那么重试就会导致重复执行，此时需要额外的应用级重复数据删除机制。</li><li>如果错误是由于系统超负荷所导致，则重试事务将使情况变得更槽。为此，可以设定一个重试次数上限，例如指数回退，同时要尝试解决系统过载本身的问题。</li><li>由临时性故障（例如死锁，隔离违例，网络闪断和节点切换等）所导致的错误需要重试。但出现永久性故障（例如违反约束），则重试毫无意义。</li><li>如果在数据库之外，事务还产生其他副作用，即使事务被终止，这些副作用可能已事实生效。可以采用两阶段提交。</li><li>如果客户端在重试过程中也发生失败，没有其他人继续负责重试，则那些待写入的数据可能会因此而丢失。</li></ul><h2 id="弱隔离级别"><a href="#弱隔离级别" class="headerlink" title="弱隔离级别"></a>弱隔离级别</h2><blockquote><p>可串行化隔离（serializable）意味着数据库保证事务的最终执行结果与串行执行结果相同</p></blockquote><p>但是往往可串行化隔离意味着性能方面的损失。需要我们在实际开发环境中进行选择。</p><h3 id="读-提交-Read-Committed"><a href="#读-提交-Read-Committed" class="headerlink" title="读-提交 Read Committed"></a>读-提交 Read Committed</h3><ol><li><p>读数据库时，只能看到已成功提交的数据。（防止脏读）</p></li><li><p>写数据库时，只会覆盖已成功提交的数据。（防止脏写）</p></li></ol><h4 id="防止脏读"><a href="#防止脏读" class="headerlink" title="防止脏读"></a>防止脏读</h4><blockquote><p>脏读：某个事务已经完成部分数据写入，但事务尚未提交（或终止），另一个事务可以看到尚未提交的数据。</p></blockquote><p>有以下需求时，需要防止脏读</p><ul><li><p>事务需要更新多个对象，脏读意味着另一个事物可能会看到部分更新，而非全部。</p></li><li><p>如果事务发生终止，则所有写入操作都需要回滚。如果发生了脏读，这意味着他可能会看到一些稍后被回滚的数据。</p></li></ul><h4 id="防止脏写"><a href="#防止脏写" class="headerlink" title="防止脏写"></a>防止脏写</h4><blockquote><p>脏写：覆盖先写尚未提交事务的写入。</p></blockquote><p>防止脏写可以避免：</p><ul><li><p>如果事务需要更新多个对象，脏写会带来非预期的错误结果。</p></li><li><p>但是脏读不能解决“更新丢失”的问题。</p></li></ul><h4 id="实现读-提交"><a href="#实现读-提交" class="headerlink" title="实现读-提交"></a>实现读-提交</h4><p>数据库通常采用<strong>行级锁</strong>来防止脏写/读：</p><p>当事务想修改/读取某个对象（例如行或文档）时，它必须首先获得该对象的锁；然后一直持有锁直到事务提交（终止）。这种锁是由处于读-提交模式（或更强隔离级别）数据库自动完成的。</p><p>但是读锁在实际中并不可行，因为运行时间较长的写事务会导致许多只读的事务等待太久。</p><p>因此大多数数据库采用了多版本的方法来防止脏读：对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。（在事务提交之前，所有其他读操作都读取旧值；仅当写事务提交之后，才会切换到读取新值）</p><h3 id="快照级别隔离与可重复读-Snapshot-Isolation-and-Repeatable-Read"><a href="#快照级别隔离与可重复读-Snapshot-Isolation-and-Repeatable-Read" class="headerlink" title="快照级别隔离与可重复读 Snapshot Isolation and Repeatable Read"></a>快照级别隔离与可重复读 Snapshot Isolation and Repeatable Read</h3><blockquote><p>不可重复读：在一个事务中，两次读取的值不一样。</p></blockquote><p>有些场景不允许这种不一致的情况发生：</p><ul><li>备份场景<ul><li>在备份的过程中，可以继续写入数据库，得到的镜像里可能包含部分旧版本数据和部分新版本数据。如果从这样的备份进行恢复，最终就导致了永久性的不一致。</li></ul></li><li>分析查询与完整性检查场景</li></ul><p>可以使用<strong>快照隔离级别</strong>来解决上述问题。</p><blockquote><p>每个事务都从数据库的一致性快照中读取，事务一开始所看到是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事物都只看到该特定时间点的旧数据，</p></blockquote><h4 id="实现快照级别隔离"><a href="#实现快照级别隔离" class="headerlink" title="实现快照级别隔离"></a>实现快照级别隔离</h4><p>快照级别隔离的实现通常采用写锁来防止脏写。但是，读取则不需要加锁。</p><blockquote><p>数据库是采用多版本并发控制（MultiVersion Concurrency Control, MVCC）来实现快照级别隔离。</p></blockquote><p>因为读-提交只需要保留对象的两个版本就足够了：一个已提交的旧版本和尚未提交的新版本。所以，支持快照级别隔离的存储引擎往往直接采用MVCC来实现读-提交隔离。</p><p>做法为：</p><ul><li>在读-提交级别下，对每一个不同的查询单独创建一个快照</li><li>在快照级别下，使用一个快照来运行整个事务</li></ul><h4 id="一致性快照的可见性规则"><a href="#一致性快照的可见性规则" class="headerlink" title="一致性快照的可见性规则"></a>一致性快照的可见性规则</h4><blockquote><p>当事务读数据库时，通过事务ID可以决定哪些对象可见，哪些不可见。</p></blockquote><p>当以下两个条件都成立，则该数据对象对事务可见：</p><ul><li>事务开始时刻，创建该对象的事务已经完成了提交。</li><li>对象没有被标记删除；或者即使标记了，但删除事务在当前事务开始时还没有完成提交。</li></ul><h4 id="索引与快照级别隔离"><a href="#索引与快照级别隔离" class="headerlink" title="索引与快照级别隔离"></a>索引与快照级别隔离</h4><p>这种多版本数据库如何支持索引呢？</p><ol><li>索引直接指向对象的所有版本，然后想办法过滤对当前事务不可见的那些版本。</li><li>采用追加/写时复制的技术。当需要更新时，不会修改现有的页面，而总是创建一个新的修改副本，拷贝必要的内容，然后让父结点，或者递归向上直到树的root结点都指向新创建的结点。<ul><li>每次写入事务都会创建一个新的B-Tree root，代表该时刻数据库的一致性快照。</li><li>这时候就没有必要根据事务ID再去过滤掉某些对象，每笔写入都会修改现有的B-Tree，因为之后的查询可以直接作用于特定快照B-Tree。</li></ul></li></ol><h3 id="防止更新丢失"><a href="#防止更新丢失" class="headerlink" title="防止更新丢失"></a>防止更新丢失</h3><p>当有两个事务在同样的数据对象上执行类似操作时，由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一个事务的修改值可能会丢失。</p><p>目前有以下集中解决方案：</p><h4 id="原子写操作"><a href="#原子写操作" class="headerlink" title="原子写操作"></a>原子写操作</h4><ul><li>原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前不会被其他事务读取。</li><li>另一种实现方式是强制所有的原子操作都在单线程上执行。</li></ul><h4 id="显示加锁"><a href="#显示加锁" class="headerlink" title="显示加锁"></a>显示加锁</h4><p>由应用程序显示锁定待更新的对象。</p><p>例如，考虑一个多人游戏，其中几个玩家可以同时移动同一个数字。只靠原子操作可能还不够，因为应用程序还需要确保玩家的移动还需要遵守其他游戏规则，这涉及一些应用层逻辑。</p><h4 id="自动监测更新丢失"><a href="#自动监测更新丢失" class="headerlink" title="自动监测更新丢失"></a>自动监测更新丢失</h4><p>原子操作和锁都是通过强制“读-修改-写回”操作序列串行执行来防止丢失更新。</p><p>也可以先让他们并发执行，但如果事务管理其检测到了更新丢失风险，则会终止当前事务，并强制回退到安全的“读-修改-写回”方式。</p><blockquote><p>MySQL/InnoDB的可重复读却并不支持检测更新丢失。</p></blockquote><h4 id="原子比较和设置"><a href="#原子比较和设置" class="headerlink" title="原子比较和设置"></a>原子比较和设置</h4><p>在有的不提供事务支持的数据库中，会支持原子“比较和设置”操作。（只有在上次读取的数据没有发生变化时才允许更新；如果已经发生更新，则回退到“读-修改-写回”方式。）</p><h4 id="冲突解决与复制"><a href="#冲突解决与复制" class="headerlink" title="冲突解决与复制"></a>冲突解决与复制</h4><p>由于多节点上的数据副本，不同的节点可能会并发修改数据，因此必须采取一些额外的措施来防止丢失更新。</p><p>对于多主节点或者无主节点的多副本数据库，由于支持多个并发写，且通常以异步方式来同步更新，所以会出现多个最新的数据副本。</p><p>多副本数据库通常支持多个并发写，然后保留多个冲突版本（互称为兄弟），之后由应用层逻辑或依靠特定的数据结构来解决、合并多版本。</p><p>将在第九章详细介绍。</p><h3 id="写倾斜和幻读"><a href="#写倾斜和幻读" class="headerlink" title="写倾斜和幻读"></a>写倾斜和幻读</h3><p>可以把写倾斜视为一种更广义的更新丢失问题。</p><blockquote><p>如果两个事务读取相同的一组对象，然后更新其中一部分：不同的事务可能更新不同的对象，则可能发生写倾斜；而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失。</p></blockquote><p>如果不能使用可串行化级别隔离，一个次优的选择是对事务依赖的行来显示的加锁。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">BEGIN</span> TRANSACTION;<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> doctors <span class="hljs-keyword">WHERE</span> on_call <span class="hljs-operator">=</span> <span class="hljs-literal">true</span> <span class="hljs-keyword">AND</span> shift_id <span class="hljs-operator">=</span> <span class="hljs-number">1234</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><span class="hljs-keyword">UPDATE</span> doctors <span class="hljs-keyword">SET</span> on_call <span class="hljs-operator">=</span> <span class="hljs-literal">false</span> <span class="hljs-keyword">WHERE</span> name <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;Alice&#x27;</span> <span class="hljs-keyword">AND</span> shift_id <span class="hljs-operator">=</span> <span class="hljs-number">1234</span>;<br><span class="hljs-keyword">COMMIT</span>;<br></code></pre></td></tr></table></figure><p>其中 <code>FOR UPDATE</code> 语句会通知数据库对返回的所有结果行自动加锁。</p><h4 id="为何会发生写倾斜"><a href="#为何会发生写倾斜" class="headerlink" title="为何会发生写倾斜"></a>为何会发生写倾斜</h4><ol><li>首先输入一些匹配条件，即采用SELECT查询所有满足条件的行。</li><li>根据查询的结果，应用层代码来决定下一步的操作。</li><li>如果应用程序决定继续执行，它将发起数据库写入（INSERT, UPDATE 或 DELETE）并提交事务。<strong>而这个写操作通常会改变步骤2做出的前提条件。</strong></li></ol><h4 id="实体化冲突"><a href="#实体化冲突" class="headerlink" title="实体化冲突"></a>实体化冲突</h4><p>并没有看懂书中的意思</p><h2 id="串行化"><a href="#串行化" class="headerlink" title="串行化"></a>串行化</h2><p>可串行化隔离是最强的隔离级别。它保证即使事务可能会并行执行，但最终的结果与每次一个个串行执行结果相同。</p><h4 id="采用存储过程封装事务"><a href="#采用存储过程封装事务" class="headerlink" title="采用存储过程封装事务"></a>采用存储过程封装事务</h4><blockquote><p>因为性能影响，采用单线程串行执行的系统往往不支持交互式的多语句事务。应用程序必须提交整个事务代码作为存储过程（stored procedure）打包发送到数据库。</p></blockquote><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E4%BA%A4%E4%BA%92%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B8%8E%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB.png" class="" title="交互式事务与存储过程的区别"><p>优点：</p><ul><li>存储过程与内存式数据储存使得单线程上执行所有事务变得可行。</li></ul><p>缺点：</p><ul><li>在数据库中运行代码难以管理：与应用服务器相比，调试更加困难，版本控制与部署复杂，测试不便，并且不容易和指标监控系统集成。</li><li>数据库通常比应用服务器要求更高的性能。数据库中一个设计不好的存储过程要比同样低效的应用服务器代码带来更大的麻烦。</li></ul><h4 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h4><p>对于那些高写入需求的应用程序，单线程事务处理很容易称为严重的瓶颈。为了扩展到多个CPU核和多节点，可以对数据进行分区。</p><p>但是，对于跨分区的事务，数据库必须在设计的所有分区之间协调事务。存储过程需要跨越所有分区加锁执行，以确保整个系统的可串行化。</p><p>跨分区的事物具有额外的协调开销，其性能比单分区内要慢得多。</p><h4 id="串行执行小结"><a href="#串行执行小结" class="headerlink" title="串行执行小结"></a>串行执行小结</h4><p>满足下面的条件，串行执行事务可以实现串行隔离：</p><ul><li>事务必须简短而高效，否则一个缓慢的事务会影响到所有其他事务的执行性能。</li><li>仅限于活动数据集完全可以加载到内存的场景。有些很少访问的数据可能会被移到磁盘，但万一单线程事务需要访问它，就会严重拖累性能。</li><li>写入吞吐量必须足够低，才能在单个CPU核上处理；否则就需要采用分区，最好没有跨分区事务。</li><li>跨分区事务虽然也支持，但是占比必须很小。</li></ul><h3 id="两阶段加锁-two-phase-locking"><a href="#两阶段加锁-two-phase-locking" class="headerlink" title="两阶段加锁 two-phase locking"></a>两阶段加锁 two-phase locking</h3><blockquote><p>两阶段加锁（2PL）听起来和两阶段提交（2PC）很相近，但并不是同一个东西。</p></blockquote><p>2PL不仅在并发写操作之间互斥，读取也会和修改产生互斥。这就是两阶段加锁和快照级别隔离（读写互不干扰）的区别。</p><p>因为2PL提供了串行化，所以它可以防止前面讨论的所有竞争条件，包括更新丢失和写倾斜。</p><h4 id="实现两阶段加锁"><a href="#实现两阶段加锁" class="headerlink" title="实现两阶段加锁"></a>实现两阶段加锁</h4><blockquote><p>目前，2PL已经用于MySQL 和 SQL Server 中的“可串行化隔离”，以及DB2中的“可重复读隔离”</p></blockquote><ul><li>如果事务要读取对象，必须先以共享模式获得锁。</li><li>如果事务要修改对象，必须以独占模式获取锁。</li><li>如果事务首先读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁。</li><li>事务获得锁之后，一直持有所直到事务结束（包括提交或中止）。</li></ul><p>数据库会自动检测事务之间死锁情况，并强制中止其中一个，稍后由应用层重试。</p><h4 id="两阶段加锁的性能"><a href="#两阶段加锁的性能" class="headerlink" title="两阶段加锁的性能"></a>两阶段加锁的性能</h4><blockquote><p>其事务吞吐量和查询响应时间相比于其他弱隔离级别下降非常多</p></blockquote><p>当一个事务还需要等待另一个事务时，那么最终的等待时间是没有上限的</p><p>如果事务由于死锁而被强行终止，应用层就必须从头重试。</p><h4 id="谓词锁-Predicate-locks"><a href="#谓词锁-Predicate-locks" class="headerlink" title="谓词锁 Predicate locks"></a>谓词锁 Predicate locks</h4><p>类似于之前描述的共享/独占锁，而区别在于，它并不属于某个特定的对象，而是作用于<strong>满足某些搜索条件</strong>的所有查询对象。</p><ul><li>事务A想要读取某些满足匹配条件的对象，它必须以共享模式获的查询条件的谓词锁。如果另一个事务B正持有任何一个匹配对象的互斥锁，那么A必须等到B释放锁之后才能继续执行查询。</li><li>如果事务A想要插入、更新或删除任何对象，则必须首先检查所有旧值和新值是否与现有的任何谓词锁匹配。如果事务B持有这样的谓词锁，那么A必须等到B完成提交后才能继续。</li></ul><p>谓词锁甚至可以保护数据库中那些尚不存在但可能马上会被插入的对象。将两阶段加锁与谓词锁结合使用，数据库可以防止所有形式的写倾斜以及其他竞争条件，隔离变的真正可串行化。</p><p>缺点：</p><p>谓词锁性能不佳，如果活动事务中存在许多锁，那么检测匹配这些锁就变得非常耗时。</p><h4 id="索引区间锁-next-key-locking"><a href="#索引区间锁-next-key-locking" class="headerlink" title="索引区间锁 next-key locking"></a>索引区间锁 next-key locking</h4><p>是一种简化的谓词锁，将其保护的对象扩大化。如果没有合适的索引可以施加区间锁，则数据库可以回退到对整个表施加共享锁。</p><h3 id="可串行化的快照隔离-Serializable-Snapshot-Isolation"><a href="#可串行化的快照隔离-Serializable-Snapshot-Isolation" class="headerlink" title="可串行化的快照隔离 Serializable Snapshot Isolation"></a>可串行化的快照隔离 Serializable Snapshot Isolation</h3><p>它提供了完整的可串行性保证，而性能相比于快照隔离损失很小。</p><h4 id="悲观与乐观的并发控制"><a href="#悲观与乐观的并发控制" class="headerlink" title="悲观与乐观的并发控制"></a>悲观与乐观的并发控制</h4><p>两阶段加锁是一种典型的悲观并发控制机制。相比之下，可串行化的快照隔离（Serializable Snapshot Isolation, SSI）则是一种乐观并发控制。</p><p>如果系统还有足够的性能提升空间，且如果事物之间的竞争不大，乐观并发控制会比悲观方式高效很多。</p><h4 id="基于过期的条件做决定"><a href="#基于过期的条件做决定" class="headerlink" title="基于过期的条件做决定"></a>基于过期的条件做决定</h4><p>安全起见，数据库假定对查询结果的任何变化都应使写事务失效。</p><p>数据库如何知道查询结果是否发生了改变呢？</p><ol><li>读取是否作用于一个过期的MVCC对象（读取之前已经有未提交的写入）</li><li>检查写入是否影响即将完成的读取</li></ol><h4 id="检测是否读取了过期的MVCC对象"><a href="#检测是否读取了过期的MVCC对象" class="headerlink" title="检测是否读取了过期的MVCC对象"></a>检测是否读取了过期的MVCC对象</h4><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E6%A3%80%E6%B5%8B%E4%BA%8B%E5%8A%A1%E6%98%AF%E5%90%A6%E4%BB%8EMVCC%E5%BF%AB%E7%85%A7%E4%B8%AD%E8%AF%BB%E5%8F%96%E4%BA%86%E6%97%A7%E5%80%BC.png" class="" title="检测事务是否从MVCC快照中读取了旧值"><p><strong>当事务提交时</strong>，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是则必须终止当前事务。</p><p>一定要等到提交是因为：</p><ul><li>如果事务43是个只读事务，就不需要中止。事务43读取数据库时，数据库还不知道事务是否稍后有任何写操作</li><li>有可能事务42发生了中止或者还处于未提交状态，不一定读的就是过期值。</li></ul><h4 id="检测写是否影响了之前的读"><a href="#检测写是否影响了之前的读" class="headerlink" title="检测写是否影响了之前的读"></a>检测写是否影响了之前的读</h4><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E6%A3%80%E6%B5%8B%E4%BA%8B%E5%8A%A1%E6%98%AF%E5%90%A6%E4%BF%AE%E6%94%B9%E4%BA%86%E5%8F%A6%E4%B8%80%E4%B8%AA%E4%BA%8B%E5%8A%A1%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C.png" class="" title="检测事务是否修改了另一个事务查询结果"><p>另一个事务尝试修改的时，首先检查索引，从而确定是否最近存在一些读目标数据的其他事物。</p><h4 id="可串行化快照隔离的性能"><a href="#可串行化快照隔离的性能" class="headerlink" title="可串行化快照隔离的性能"></a>可串行化快照隔离的性能</h4><p>与两阶段加锁相比，可串行化快照隔离的一大优点是事务不需要等待其他事务所持有的锁。</p><p>事务中止的比例会显著影响SSI的性能表现。</p><h2 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h2><ul><li>脏读<ul><li>客户端读到了其他客户端尚未提交的写人。读-提交以及更强的隔离级别可以防止脏读。</li></ul></li><li>脏写<ul><li>客户端覆盖了另一个客户端尚未提交的写入。几乎所有的数据库实现都可以防止脏写。</li></ul></li><li>读倾斜（不可重复读）<ul><li>客户在不同的时间点看到了不同值。快照隔离是最用的防范手段，即事务总是在某个时间点的一致性快照中读取数据。通常采用多版本井发控制（ MVCC ）来实现快照隔离。</li></ul></li><li>更新丢失<ul><li>两个客户端同时执行读－修改－写入操作序列，出现了其中一个覆盖了另一个的写入，但又没有包含对方最新值的情况，最终导致了部分修改数据发生了丢失。快照隔离的一些实现可以自动防止这种异常，而另 一些则需要手动锁定查询结果 (SELECT FOR UPDATE ）。</li></ul></li><li>写倾斜<ul><li>事务首先查询数据，根据返回的结果而作出某些决定，然后修改数据库 。当事务提交时，支持决定的前提条件已不再成立。只有可串行化的隔离才能防止这种异常。</li></ul></li><li>幻读<ul><li>事务读取了某些符合查询条件的对象，同时另一个客户端执行写入，改变了先前的查询结果。快照隔离可以防止简单的幻读，但写倾斜情况则需要特殊处理，例如采用区间范围锁。</li></ul></li></ul><p>弱隔离级别可以防止上面的某些异常，只有可串行化的隔离可以防止所有这些问题。实现可串行化隔离有以下几种：</p><ul><li>严格串行执行事务<ul><li>如果每个事务的执行速度非常快，且单个CPU核可以满足事务的吞吐量要求，严格串行执行是一个非常简单有效的方案。</li></ul></li><li>两阶段加锁<ul><li>几十年来，这一直是实现可串行化的标准方式，但还是有很多系统出于性能原因而放弃使用它。</li></ul></li><li>可串行化的快照隔离<ul><li>一种最新的算法，可以避免前面方法的大部分缺点。它秉持乐观预期的原则， 允许多个事务并发执行而不互相阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，则某些事务会被中止。</li></ul></li></ul><h1 id="第八章：分布式系统的挑战"><a href="#第八章：分布式系统的挑战" class="headerlink" title="第八章：分布式系统的挑战"></a>第八章：分布式系统的挑战</h1><p>本章节对分布式系统可能出现的故障做了一个全面的总结。故障可能来自网络，时钟时序问题。</p><h2 id="不可靠的网络"><a href="#不可靠的网络" class="headerlink" title="不可靠的网络"></a>不可靠的网络</h2><p>处理网络的问题通常采用超时机制：在等待一段时间之后，如果仍然没有收到回复则选择放弃，并且认为响应不会到达。</p><h3 id="检测故障"><a href="#检测故障" class="headerlink" title="检测故障"></a>检测故障</h3><ul><li>负载均衡器需要避免向已失效的节点继续分发请求</li><li>对于主从复制的分布式数据库，如果主节点失败，需要将某个从节点提升为主节点。</li></ul><h3 id="超时与无限期的延迟"><a href="#超时与无限期的延迟" class="headerlink" title="超时与无限期的延迟"></a>超时与无限期的延迟</h3><p>没有一个标准的设置超时时间的值。</p><p>异步网络理论上的延迟无限大（即使尽力发送数据包，但数据包到达时间并没有上确界），多数服务端也无法保证在给定的某个时间内一定完成请求处理（参阅本章后面的“响应时间保证”）。如果超时设置太小，只需要一个短暂的网络延迟尖峰就会导致包超时进而将系统标记为失效。</p><h4 id="网络拥塞与排队"><a href="#网络拥塞与排队" class="headerlink" title="网络拥塞与排队"></a>网络拥塞与排队</h4><p>更好的做法是， 超时设置并不是一个不变的常量，而是持续测量响应时间及其变化（抖动），然后根据最新的响应时间分布来自动调整。</p><h3 id="同步与异步网络"><a href="#同步与异步网络" class="headerlink" title="同步与异步网络"></a>同步与异步网络</h3><h4 id="电路交换-vs-分组交换"><a href="#电路交换-vs-分组交换" class="headerlink" title="电路交换 vs. 分组交换"></a>电路交换 vs. 分组交换</h4><p>电路方式总是预留固定带宽，电路建立之后其他人无法使用；TCP连接的数据包则会尝试使用所有可用的网络带宽。</p><p>以太网和IP都是基于分组交换协议，这种协议注定受到排队的影响，从而导致网络延迟不确定， 在这些协议里完全没有电路的概念。</p><p>数据中心网络和互联网采用分组交换是因为无法事先确定带宽，只希望尽快完成。对于突发数据的传输，电路网络无法充分利用网络容量。相比之下，TCP动态调整传输速率则可以充分利用所有可用的网络容量。</p><h2 id="不可靠的时钟"><a href="#不可靠的时钟" class="headerlink" title="不可靠的时钟"></a>不可靠的时钟</h2><h3 id="单调时钟与墙上时钟"><a href="#单调时钟与墙上时钟" class="headerlink" title="单调时钟与墙上时钟"></a>单调时钟与墙上时钟</h3><h4 id="墙上时钟"><a href="#墙上时钟" class="headerlink" title="墙上时钟"></a>墙上时钟</h4><blockquote><p>墙上时钟根据某个日历返回当前的日期与时间。</p></blockquote><ul><li>Linux的clock_gettime</li><li>Java中的System.currentTimeMillis()</li></ul><p>墙上时钟可以与NTP同步。NTP（Network Time Protocol）是用来同步网络设备的时间协议。</p><h4 id="单调时钟"><a href="#单调时钟" class="headerlink" title="单调时钟"></a>单调时钟</h4><p>单调时钟更适合测量持续时间段（时间间隔）。可以在一个时间点读取单调时钟的值，完成某项工作，然后再次检查时钟。时钟值之间的差值即两次检查之间的时间间隔。</p><h3 id="时钟同步与准确性"><a href="#时钟同步与准确性" class="headerlink" title="时钟同步与准确性"></a>时钟同步与准确性</h3><p>单调时钟不需要同步，但是墙上时钟需要根据NTP服务器或其他外部时间源做必要的调整。</p><p>可能会出现一下的一些问题：</p><ul><li>计算机中的石英钟不够精确，存在漂移现象（运行速度会加快或减慢）</li><li>如果时钟与NTP服务器的时钟差别太大，可能会出现拒绝同步，或者本地时钟将被强制重置（时间突然倒退或突然跳跃的现象）。</li><li>可能会与NTP服务器链接失败，可能会很长一段时间没有留意到错误配置最终导致同步失败。</li><li>NTP同步会受限于当时的网络环境。</li><li>闰秒会产生一个59秒或者61秒的现象，可能会使一些对闰秒毫无防范的系统出现混乱。</li><li>在虚拟机中，由于硬件时钟也是被虚拟化的，这对需要精确计时的应用程序提出了额外的挑战。</li><li>运行在未完全可控的设备（移动设备或嵌入式设备）上，需要留意不能完全相信设备上的硬件时钟。</li></ul><h3 id="依赖同步的时钟"><a href="#依赖同步的时钟" class="headerlink" title="依赖同步的时钟"></a>依赖同步的时钟</h3><p>如果应用需要精确同步的时钟，最好仔细监控所有节点上的时钟偏差。如果某个节点的时钟漂移超出上限，应将其宣告为失效，并从集群中移除。</p><h4 id="时间戳与时间顺序"><a href="#时间戳与时间顺序" class="headerlink" title="时间戳与时间顺序"></a>时间戳与时间顺序</h4><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E8%B7%A8%E8%8A%82%E7%82%B9%E6%97%B6%E9%97%B4%E6%8E%92%E5%BA%8F.png" class="" title="跨节点时间排序"><p>客户端B的写入比客户端A写入要晚，但是B写入的时间戳却更早</p><p>这种冲突解决策略被称为最后写入获胜（Last Write Win, LWW），它的根本问题在于：</p><ul><li>数据库写入可能会奇怪地丢失：明明后续发生的写操作却没法覆盖另一个较早的值，原因是后者节点的时钟太快了。</li><li>LWW无法区分连续快速发生的连续写操作和并发写入（每个写操作都不依赖于其他写 ）</li><li>由于时钟精度的限制（例如毫秒级），两个节点可能各自独立产生了完全相同的时间戳。</li></ul><blockquote><p>我们很难利用NTP时钟同步来做到极高的精度来避免这种错误</p></blockquote><h4 id="时钟的置信区间"><a href="#时钟的置信区间" class="headerlink" title="时钟的置信区间"></a>时钟的置信区间</h4><blockquote><p>我们不应该将时钟读数视为一个精确的时间点，而更应该视为带有置信区间的时间范围。</p></blockquote><h4 id="全局快照的同步时钟"><a href="#全局快照的同步时钟" class="headerlink" title="全局快照的同步时钟"></a>全局快照的同步时钟</h4><p>常见的快照隔离实现中需要单调递增事务ID。如果写入发生在快照之后（即写入具有比快照更大的事务ID），那么该写入对于快照不可见。在单节点数据库上，一个简单的计数器足以生成事务ID。</p><p>但是，当数据库分布在多台机器上（可能跨越多个数据中心）时，由于需要复杂的协调以产生全局的、单调递增的事务ID（跨所有分区）。考虑到大量、频繁的小数据包，在分布式系统中创建事务ID通常会引入瓶颈。</p><h5 id="Google-Spanner"><a href="#Google-Spanner" class="headerlink" title="Google Spanner"></a>Google Spanner</h5><p>Google Spanner采用以下思路来实现跨数据中心的快照隔离。它根据TrueTime API返回的时钟置信区间，并基于以下观察结果：如果有两个置信区间，每个置信区间都包含最早和最新可能的时间戳（ <em>A</em>=[ <em>A<sub>earliest</sub> , A<sub>latest</sub></em> ] 和 <em>B</em> =[ <em>B<sub>earliest</sub> , B<sub>latest</sub></em> ] ），且这两个区间没有重叠（即 <em>A<sub>earliest</sub> &lt; A<sub>latest</sub></em> &lt; *B<sub>earliest</sub>* &lt; *B<sub>latest</sub>* ），那么可以断定<em>B</em>一定发生在<em>A</em>之后。只有发生了重叠，<em>A</em>和<em>B</em>发生顺序才无法明确。</p><p>为了确保事务时间戳反映因果关系， Spanner在提交读写事务之前故意等待置信区间的长度。这样做的目的是，确保所有读事务要足够晚才发生，避免与先前的事务的置信区间产生重叠。</p><h3 id="进程暂停"><a href="#进程暂停" class="headerlink" title="进程暂停"></a>进程暂停</h3><p>假设数据库每个分区只有一个主节点，只有主节点可以接受写入。那么其他节点该如何确信该主节点没有被宣告失效，可以安全地写入呢？</p><blockquote><p>一种思路是主节点从其他节点获得一个租约（lease），类似一个带有超时的锁。某一个时间只有一个节点可以拿到租约，某节点获得租约之后，在租约到期之前，它就是这段时间内的主节点。为了维持主节点的身份，节点必须在到期之前定期去更新租约 。如果 节点发生了故障， 则续约失败，这样另一个节点到期之后就可以接管。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>  request = getIncomingRequest();<br>  <br>  <span class="hljs-keyword">if</span> (lease.expiryTimeMillis - System.currentTimeMillis() &lt; <span class="hljs-number">10000</span>) &#123;<br>    lease = lease.renew();<br>  &#125;<br>  <br>  <span class="hljs-keyword">if</span> (lease.isValid()) &#123;<br>    process(request);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可能存在的问题：</p><ol><li>依赖于同步时钟：lease到期时间由另一台机器所设置，并和本地时钟进行比较。</li><li><code>System.currentTimeMillis()</code>与请求处理<code>process(request)</code>间隔时间不可预测。如果发生了线程暂停的情况，将会出现两个节点同时持有租期处理的情况。</li></ol><p>发生线程暂停的原因有很多：</p><ul><li>垃圾回收机制可能会导致所有正在运行的线程暂停几分钟。</li><li>在虚拟化的环境中，可能会暂停虚拟机然后继续。</li><li>用户关闭了笔记本电脑或休眠也有可能导致暂停。</li><li>当操作系统执行线程上下文切换时，或者虚拟机管理程序切换到另一个虚拟机时，正在运行的线程可能会在代码的任意位置被暂停。</li><li>应用程序执行同步磁盘操作，则线程可能暂停并等待磁盘I/O完成。</li><li>如果操作系统配置了基于磁盘的内存交换分区， 内存访问可能触发缺页中断， 进而需要从磁盘中加载内存页。</li></ul><blockquote><p>分布式系统中的一个节点必须假定，执行过程中的任何时刻都可能被暂停相当长一段时间。暂停期间，整个集群的其他部分都在照常运行，甚至会一直将暂停的节点宣告为故障节点。</p></blockquote><h4 id="响应时间保证"><a href="#响应时间保证" class="headerlink" title="响应时间保证"></a>响应时间保证</h4><blockquote><p>实时系统：软件有一个必须做出相应的上限。</p></blockquote><p>提供实时保证需要来自软件栈的多个层面支持：</p><ul><li>一个实时操作系统（real-time operating system, RTOS），保证进程在给定的间隔内完成CPU时间片的调度分配</li><li>库函数也必须考虑最坏的执行时间</li><li>动态内存分配很可能要受限或者完全被禁止</li></ul><p>对于大多数服务器端数据处理系统来说，实时性保证并不经济或者不合适。因此，现在这些运行在非实时环境下的系统就得承受如进程暂停、 时钟不稳定等困扰。</p><h5 id="调整垃圾回收的影响"><a href="#调整垃圾回收的影响" class="headerlink" title="调整垃圾回收的影响"></a>调整垃圾回收的影响</h5><ul><li>把GC暂停视为节点的一个计划内的临时离线，当节点启动垃圾回收时，通知其他节点来接管客户端的请求。</li><li>系统可以提前为前端应用发出预警，应用会等待当前请求完成，但停止向该节点发送新的请求，这样垃圾回收可以在无干扰的情况下更加高效运行。</li><li>只对短期对象执行垃圾回收，然后在其变成长期存活对象之前，采取定期重启的策略从而避免对长期存活对象执行全面回收。</li></ul><h2 id="知识，真相与谎言"><a href="#知识，真相与谎言" class="headerlink" title="知识，真相与谎言"></a>知识，真相与谎言</h2><h3 id="真相由多数决定"><a href="#真相由多数决定" class="headerlink" title="真相由多数决定"></a>真相由多数决定</h3><p>节点不能根据自己的信息来判断自身状态。由于节点可能随时会失效，可能会暂停-假死，甚至最终无法恢复，因此，分布式系统不能完全依赖与单个节点。</p><p>目前，许多分布式算法都依靠法定票数，即在节点之间进行投票。任何决策都需要来自多个节点的最小投票数，从而减少对特定节点的依赖。</p><h4 id="主节点和锁"><a href="#主节点和锁" class="headerlink" title="主节点和锁"></a>主节点和锁</h4><blockquote><p>在分布式系统实现时需要额外注意：即使某个节点自认为它是“唯一的那个”，但不一定获得了系统法定票数的同意！</p></blockquote><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E4%B8%8D%E6%AD%A3%E7%A1%AE%E5%AE%9E%E7%8E%B0.png" class="" title="分布式锁的不正确实现"><h4 id="Fencing令牌"><a href="#Fencing令牌" class="headerlink" title="Fencing令牌"></a>Fencing令牌</h4><p>我们假设每次锁服务在授予锁或租约时，还会同时返回一个fencing令牌，该令牌每授予一次就会递增。要求客户端每次向存储系统发送写请求时，都必须包含所持有的fencing令牌。</p><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E9%80%92%E5%A2%9Efencing%E4%BB%A4%E7%89%8C.png" class="" title="递增fencing令牌"><p>存储服务器由于记录了最近已经完成了更高令牌号，因此拒绝令牌号33的写请求。</p><h3 id="拜占庭故障-Byzantine-Faults"><a href="#拜占庭故障-Byzantine-Faults" class="headerlink" title="拜占庭故障 Byzantine Faults"></a>拜占庭故障 Byzantine Faults</h3><p>当节点故意发送错误的或者破坏性的响应，就被称为拜占庭故障。在这样不信任的环境中需要达成共识的问题也被称之为拜占庭将军问题。如果某个系统中即使发生部分节点故障，甚至不遵从协议，或者恶意攻击、干扰网络，但仍可继续正常运行，那么我们称之为拜占庭式容错系统。</p><p>解决拜占庭容错的系统协议异常复杂，而容错的嵌入式系统还依赖与硬件层面的支持。因为在绝大多数服务器端数据系统中，部署拜占庭容错解决方案基本不太可行。</p><h3 id="理论系统模型与现实"><a href="#理论系统模型与现实" class="headerlink" title="理论系统模型与现实"></a>理论系统模型与现实</h3><p>在计时方面，有常见的三种模型：</p><ul><li>同步模型<ul><li>同步模型假定有上届的网络延迟，有上届的进程暂停和由上届的时钟误差。</li></ul></li><li>部分同步模型<ul><li>部分同步意味着系统在大多数情况下像一个同步系统一样运行，但有时会超出网络延迟，进程暂停和时钟漂移的预期上届。</li></ul></li><li>异步模型<ul><li>在这个模型中，一个算法不会对时机作任何的假设，甚至里面根本没有时钟（也就没有超时机制）。</li></ul></li></ul><p>除了时机之外，我们还需要考虑节点失效。</p><ul><li>崩溃-终止模型<ul><li>算法假设一个节点只能以一种方式发生故障，即遭遇系统崩溃。这意味着节点可能在任何时候突然停止响应，且该结点以后永远消失，无法恢复。</li></ul></li><li>崩溃-恢复模型<ul><li>节点可能会在任何时候发生崩溃，且可能会在一段（未知的）时间之后得到恢复并再次响应。在崩溃－恢复模型中，节点上持久性存储（即非易失性存储）的数据会在崩溃之后得以保存，而内存中状态可能会丢失。</li></ul></li><li>拜占庭失效模型<ul><li>节点可能发生任何事情，包括试图作弊和欺骗其他节点。</li></ul></li></ul><h2 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h2><p>分布式系统中可能发生的各种典型问题：</p><ul><li>当通过网络发送数据包时， 数据包可能会丢失或者延迟； 同样，回复也可能会丢失或延迟。所以如果没有收到回复，并不能确定消息是否发送成功。</li><li>节点的时钟可能会与其他节点存在明显的不同步（尽管尽最大努力设置了NTP服务器），时钟还可能会突然向前跳跃或者倒退 ，依靠精确的时钟存在一些风险，没有特别简单的办法来精确测量时钟的偏差范围。</li><li>进程可能在执行过程中的任意时候遭遇长度未知的暂停（ 一个重要的原因是垃圾回收），结果它被其他节点宣告为失效毫无所知。</li></ul><p>为了容错，需要先检测错误：</p><p>多数系统没有检测节点是否发生故障的准确机制，因此分布式算法更多依靠超时来确定远程节点是否仍然可用。</p><p>检测到错误之后：</p><p>信息从一个节点流动到另一个节点只能是通过不可靠的网络来发送。单个节点无法安全的做出任何决策，而是需要多个节点之间的共识协议，井争取达到位定票数。</p><p>虽然网络、时钟和进程的不可靠性不是不可避免的自然规律，但代价昂贵，且硬件资源利用率很低。除了安全关键场景，目前绝大多数都选择了低成本。</p><h1 id="第九章-一致性与共识"><a href="#第九章-一致性与共识" class="headerlink" title="第九章 一致性与共识"></a>第九章 一致性与共识</h1><p>这一章，我们将主要研究解决共识问题的相关算法。</p><h2 id="一致性保证"><a href="#一致性保证" class="headerlink" title="一致性保证"></a>一致性保证</h2><p>大多数多副本数据库都至少提供了最终一致性。不一致的现象是暂时的，最终会达到一致。</p><ul><li><p>首先介绍线性化，是最强的一致性模型</p></li><li><p>探讨分布式系统中事件顺序问题，主要是因果关系和全局顺序。</p></li><li><p>在“分布式事务与共识”，将探索如何让自动提交分布式事务，并最终解决共识问题。</p></li></ul><h2 id="可线性化-Linearizability"><a href="#可线性化-Linearizability" class="headerlink" title="可线性化 Linearizability"></a>可线性化 Linearizability</h2><blockquote><p>让数据库看起来对外只提供“单个副本”的假象。</p></blockquote><p>可线性化=原子一致性=强一致性=linearizability=atomic consistency=strong consistency=immediate consistency=external consistency</p><h3 id="如何达到线性化"><a href="#如何达到线性化" class="headerlink" title="如何达到线性化"></a>如何达到线性化</h3><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E7%BA%BF%E6%80%A7%E5%8C%961.png" class="" title="线性化1"><p>与写操作有时间重叠的任何读取操作则可能返回0或者1，这是因为读写之间存在并发，无法确切知道在执行读取时，写入是否已经生效。</p><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E7%BA%BF%E6%80%A7%E5%8C%962.png" class="" title="线性化2"><p>一旦某个读操作返回了新值，之后所有的读（包括相同或不同的客户端）都必须返回新值。</p><blockquote><p>一旦新值被写入或读取，所有后续的读都看到的是最新的值，直到被再次覆盖。</p></blockquote><h3 id="可线性化-vs-可串行化"><a href="#可线性化-vs-可串行化" class="headerlink" title="可线性化 vs. 可串行化"></a>可线性化 vs. 可串行化</h3><ul><li>可串行化<ul><li>可串行化是事务的隔离属性，其中每个事务可以读写<strong>多个对象</strong>。它用来确保事务执行的结果与串行一致，即使串行执行的顺序可能与事务实际执行顺序不同。</li></ul></li><li>可线性化<ul><li>可线性化是读写寄存器（<strong>单个对象</strong>）的最新值保证。它并不要求将操作组合到事务中，因此无法避免写倾斜等问题，除非采取其他额外措施。</li></ul></li></ul><p>数据库可以同时支持可串行化与线性化。但是可串行化的快照隔离（SSI）则不是线性化的：他可以从一致性快照中读取以避免读、写之间的竞争。一致性快照的要点在于它里面不包括快照点创建时刻之后的写入数据，因此从快照读取肯定不满足线性化。</p><h3 id="线性化的依赖条件"><a href="#线性化的依赖条件" class="headerlink" title="线性化的依赖条件"></a>线性化的依赖条件</h3><h4 id="加锁与主节点选举"><a href="#加锁与主节点选举" class="headerlink" title="加锁与主节点选举"></a>加锁与主节点选举</h4><p>主从复制的系统需要确保有且只有一个主节点，否则会 split brain。选举新的主节点常见的方法是使用锁，不管锁具体如何实现，它必须满足可线性化：所有节点都必须同意哪个节点持有锁，否则就会出现问题。</p><h4 id="约束与唯一性保证"><a href="#约束与唯一性保证" class="headerlink" title="约束与唯一性保证"></a>约束与唯一性保证</h4><p>如果要在写入数据时强制执行这些约束，则也需要线性化。</p><h4 id="跨通道的时间依赖"><a href="#跨通道的时间依赖" class="headerlink" title="跨通道的时间依赖"></a>跨通道的时间依赖</h4><p>线性化违例之所以被注意到，是因为系统中存在其他的通信渠道。</p><p>例：用户可以上传照片，有一个后台的进程将照片调整为更低的分辨率以方便快速下载</p><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E5%9B%BE%E5%83%8F%E5%AD%98%E5%82%A8.png" class="" title="图像存储"><p>Web服务器并不会把照片直接放在队列中，照片会先写入文件存储服务，当写入完成后，把调整的命令放入队列。如果没有可线性化的保证，消息队列可能比存储服务内部的复制执行更快，这样调整模块可能会读取到旧数据。</p><p>出现这个问题是因为Web服务器和调整模块之间存在两个不同的通信信道：文件存储器和消息队列。</p><h3 id="实现线性化系统"><a href="#实现线性化系统" class="headerlink" title="实现线性化系统"></a>实现线性化系统</h3><ul><li>主从复制（部分支持线性化）<ul><li>只有主节点承担数据写入，从节点则在各自节点上维护数据的备份副本。</li><li>如果从主节点或者同步更新的从节点上读取，则可以满足线性化。</li><li>但并非每个主从复制的具体数据库实例都是可线性化的，主要是因为他们可能采用了快照隔离的设计，或者实现时存在并发方面的bug。</li></ul></li><li>共识算法（可线性化）<br>* </li><li>多主复制（不可线性化）<ul><li>它们同时在多个节点上执行并发写入，并将数据一步复制到其他节点。因此它们可能会产生冲突的写入。</li></ul></li><li>无主复制（可能不可线性化）</li></ul><h3 id="线性化的代价"><a href="#线性化的代价" class="headerlink" title="线性化的代价"></a>线性化的代价</h3><p>基于多主复制的数据库，每个数据中心都可以继续正常运行：</p><blockquote><p>由于从一个数据中心到另一个数据中心的复制是异步，期间发生的写操作都暂存在本地队列，等网络恢复之后再继续同步。</p></blockquote><p>而基于主从复制的数据库，则主节点肯定位于其中的某一个数据中心。所有写请求和线性化读取都必须发送给主节点。因此，对于这样的主从复制系统，数据中心之间的网络一旦中断，连接到从数据中心的客户端无法再联系上主节点，也就无法完成任何数据库写入和线性化。</p><h4 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h4><p>CAP-<em>Consistency, Availablity, Partition tolerance</em> 代表的是一种取舍的思路。</p><p>正式定义的CAP定理范围很窄，它只考虑了一种一致性模型（即线性化）和一种故障（网络分区，节点仍处于活动状态但相互断开），而没有考虑网络延迟、节点失败或其他需要折中的情况。</p><h4 id="可线性化与网络延迟"><a href="#可线性化与网络延迟" class="headerlink" title="可线性化与网络延迟"></a>可线性化与网络延迟</h4><p>现代多核CPU上的内存甚至就是非线性化。每个CPU核都有自己独立的cache和寄存器。内存访问首先进入cache系统，所有修改默认会异步地刷新到主存。但是，这就导致出现了多个数据副本（一个在主存，另外几个在不同级别的cache中），而副本更新是异步方式，无法保证线性化。</p><blockquote><p>之所以放弃线性化的原因就是性能，而不是为了容错。</p></blockquote><h2 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h2><h3 id="顺序与因果关系"><a href="#顺序与因果关系" class="headerlink" title="顺序与因果关系"></a>顺序与因果关系</h3><p>因果关系对所发生的事件施加了某种排序：发送信息先于收到信息；问题的出现在答案之前。</p><blockquote><p>如果系统服从因果关系所规定的顺序，我们称之为因果一致性。</p></blockquote><h4 id="因果顺序并非全序"><a href="#因果顺序并非全序" class="headerlink" title="因果顺序并非全序"></a>因果顺序并非全序</h4><p>全序关系支持任何两个元素之间进行比较，即对于任意两个元素，总是可以指出哪个更大，哪个更小。</p><p>对于不可比较的集合，我们称之为偏序。</p><ul><li>可线性化<ul><li>在一个可线性化的系统中，存在全序操作关系。</li><li>对于任意两个操作，我们总是可以指出哪个操作在先。</li></ul></li><li>因果关系<ul><li>如果两个事件是因果关系，那么这两个事件可以被排序</li><li>而并发的事件则无法排序比较。</li><li>因果关系至少可以定义为偏序，而非全序。</li></ul></li></ul><blockquote><p>在可线性化数据存储中不存在并发操作，一定有一个时间线将所有操作都全序执行。</p></blockquote><h4 id="可线性化强于因果一致性"><a href="#可线性化强于因果一致性" class="headerlink" title="可线性化强于因果一致性"></a>可线性化强于因果一致性</h4><p>可线性化一定意味着因果关系：任何可线性化的系统都将正确地保证因果关系。</p><blockquote><p>因果一致性可以认为是，不会由于网络延迟而显著影响性能，又能对网络故障提供容错的最强的一致性模型。</p></blockquote><h3 id="序列号排序"><a href="#序列号排序" class="headerlink" title="序列号排序"></a>序列号排序</h3><p>可以使用序列号或时间戳来排序事件。每一个操作都有唯一的顺序号，并且总是可以通过比较来确定哪个更大。</p><p>在主从复制数据库中，复制日志定义了与因果关系一致的写操作全序关系。主节点可以简单地为每个操作递增某个计数器，从而为复制日志中的每个操作复制一个单调递增的序列号。</p><h4 id="非因果序列发生器"><a href="#非因果序列发生器" class="headerlink" title="非因果序列发生器"></a>非因果序列发生器</h4><p>如果系统不存在这样唯一的主节点：</p><ul><li>每个节点都独立产生自己的一组序列号。<ul><li>如果有两个节点，则一个节点只生成奇数，而另一个节点只生成偶数。</li><li>每个节点可能有不同的处理速度。</li></ul></li><li>可以把墙上时间戳信息附加到每个操作上。<ul><li>物理时钟的时间戳会收到时钟偏移的影响，也可能导致与实际因果关系不一致。</li></ul></li><li>可以预先分配序列号的区间范围。<ul><li>一个后发的操作可能拿到一个之前的区间</li></ul></li></ul><h4 id="Lamport时间戳"><a href="#Lamport时间戳" class="headerlink" title="Lamport时间戳"></a>Lamport时间戳</h4><p>这个时间戳可以产生与因果关系一致的序列号。</p><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/Lamport%E6%97%B6%E9%97%B4%E6%88%B3.png" class="" title="Lamport时间戳"><blockquote><p>给定两个Lamport时间戳，计数器较大那个时间戳大；如计数器数值正好相同，则节点ID越大，时间戳越大</p></blockquote><p><strong>每个节点以及每个客户端都跟踪迄今为止所见到的最大计数器值，并在每个请求中附带该最大计数器值。</strong>当节点收到某个请求（或者回复）时，如果发现请求内嵌的最大计数器值大于节点自身的计数器值，则它立即把自己的计数器修改为该最大值。这样就可以保证后发生的请求得到更大的时间戳。</p><h4 id="时间戳排序依然不够"><a href="#时间戳排序依然不够" class="headerlink" title="时间戳排序依然不够"></a>时间戳排序依然不够</h4><p>只有在收集了所有的请求信息之后，才能清楚这些请求之间的全序关系。要想知道什么时候全序关系已经确定就需要之后的“全序关系广播”。</p><h3 id="全序关系广播"><a href="#全序关系广播" class="headerlink" title="全序关系广播"></a>全序关系广播</h3><blockquote><p>全序关系广播通常指节点之间交换消息的某种协议。</p></blockquote><ul><li>可靠发送<ul><li>没有消息丢失，如果消息发送到了某一个节点，则它一定要发送到所有节点</li></ul></li><li>严格有序<ul><li>消息总是以相同的顺序发送给每个节点</li></ul></li></ul><h4 id="使用全序关系广播"><a href="#使用全序关系广播" class="headerlink" title="使用全序关系广播"></a>使用全序关系广播</h4><ul><li>数据库复制需要全序关系广播<ul><li>如果每条消息代表数据库写请求，并且每个副本都按相同的顺序处理这些写请求，那么所有副本可以保持一致。</li></ul></li><li>可以使用全序关系广播来实现可串行化事务<ul><li>如果每条消息表示一个确定性事务并且作为存储过程来执行，且每个节点都遵从相同的执行顺序，那么可以保证数据库各分区以及个副本之间的一致性</li></ul></li><li>顺序在发送信息时已经确定<ul><li>如果消息发送成功，节点不允许追溯地将某条消息插入到先前的某个位置上</li></ul></li></ul><h4 id="采用全序关系广播实现线性化存储"><a href="#采用全序关系广播实现线性化存储" class="headerlink" title="采用全序关系广播实现线性化存储"></a>采用全序关系广播实现线性化存储</h4><p>全序关系广播 vs. 可线性化</p><ul><li>全序关系广播<ul><li>基于异步模型</li><li>保证消息以固定的顺序可靠地发送，但是不保证消息何时发送成功（某个接受者可能明显落后于其他接受者）</li></ul></li><li>可线性化<ul><li>读取时保证能够看到最新的写入值</li></ul></li></ul><p>通过使用全序关系广播以追加日志的方式来实现线性化的原子比较-设置操作</p><ol><li>在日志中追加一条消息，并指明想要的用户名</li><li>读取日志，将其广播给所有节点，并等待回复</li><li>检查是否有任何消息声称该用户名已被占用。如果第一条这样的回复来自于当前节点，那么就成功获得该用户名，可以提交该获取声明并返回给客户端。</li></ol><p><strong>此过程可以保证线性化写入，但它无法保证线性化读取，即从异步日志更新的存储中读取数据时，可能是旧值。</strong></p><h4 id="采用线性化存储实现全序关系广播"><a href="#采用线性化存储实现全序关系广播" class="headerlink" title="采用线性化存储实现全序关系广播"></a>采用线性化存储实现全序关系广播</h4><p>同样可以假定已有了线性化存储，在其上构建全序关系广播。</p><p>假设有一个线性化的寄存器来存储一个计数，然后使其支持原子自增-读取操作或者原子比较-设置操作</p><p>对于每个要通过全序关系广播的消息，原子递增并读取该线性化的计数，然后将其作为序列号附加到消息中。接下来，将消息广播到所有节点（如果发生丢失，则重新发送），而接受者也严格按照序列化来发送回复消息。</p><h2 id="分布式事务与共识"><a href="#分布式事务与共识" class="headerlink" title="分布式事务与共识"></a>分布式事务与共识</h2><p>共识的不可能性：</p><p>FLP(Fisher, Lynch, and Paterson)表明如果结点存在崩溃的风险，则不存在总是能够达成共识的稳定算法。</p><h3 id="原子提交与两阶段提交"><a href="#原子提交与两阶段提交" class="headerlink" title="原子提交与两阶段提交"></a>原子提交与两阶段提交</h3><h4 id="从单节点到分布式的原子提交"><a href="#从单节点到分布式的原子提交" class="headerlink" title="从单节点到分布式的原子提交"></a>从单节点到分布式的原子提交</h4><p><strong>单节点</strong></p><ul><li><p>当客户端请求数据库节点提交事务时，数据库首先使事务的写入持久化。</p></li><li><p>把提交记录追加写入到磁盘的日志文件中</p><ul><li>如果数据库在该过程中间发生了崩溃，那么当节点重启后，事务可以从日志中恢复；</li><li>如果在崩溃之前提交记录已成功写入磁盘，则认为事务已安全提交；</li><li>否则，回滚该事务的写入</li></ul></li></ul><p><strong>多节点</strong></p><p>向所有节点简单地发送一个提交请求，然后各个节点独立执行事务提交是不够的。如果一部分节点提交了事务，而其他节点却放弃了事务，节点之间就会变得不一致。</p><h4 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h4><blockquote><p>两阶段提交是一种在多节点之间实现事务原子提交的算法，用来确保所有节点要么全部提交，要么全部中止。</p></blockquote><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.png" class="" title="两阶段提交"><p>区分<strong>两阶段提交</strong>（2PC）和<strong>两阶段加锁</strong>（2PL）。2PC在分布式数据库中负责原子提交，而2PL则提供可串行化的隔离。</p><p>2PC引入了新组件：协调者（也称为事务管理器）。协调者通常实现为共享库，运行在请求事务相同进程中，但也可以是单独的进程或服务。</p><p>当应用程序准备提交事务时 ，协调者开始阶段1：发送一个准备请求到所有节点，询问他们是否可以提交。</p><ul><li>如果所有参与者回答“是”，表示他们已经准备好提交，那么协调者接下来在阶段2会发出提交请求，提交开始实际执行。</li><li>如果有任何参与者回复“否”，则协调者在阶段2中向所有节点发送放弃请求。</li></ul><h4 id="系统的承诺"><a href="#系统的承诺" class="headerlink" title="系统的承诺"></a>系统的承诺</h4><p>两阶段提交的流程：</p><ol><li>当应用程序启动一个分布式事务时，它首先向协调者请求事务ID。该ID全局唯一。</li><li>应用程序在每个参与节点上执行单节点事务，并将全局唯一事务ID附加到事务上。此时，读写都是在单节点内完成。如果在这个阶段出现问题（例如节点崩溃或请求超时），则协调者和其他参与者都可以安全中止。</li><li>当应用程序准备提交时，协调者向所有参与者发送准备请求，并附带全局事务ID。如果准备请求有任何一个发生失败或者超时，则协调者会通知所有参与者放弃事务。</li><li>参与者在收到准备请求后，确保在任何情况下都可以提交事务，包括安全地将事务数据写入磁盘，并检查是否存在冲突或约束违规。一旦向协调者回答“是”，节点就承诺会提交事务。</li><li>当协调者受到所有准备请求的答复时，就是否提交（或放弃）事务要做出明确的决定。协调者把最后的决定写入到磁盘的事务日志中，防止稍后系统崩溃，并可以恢复之前的决定。这个时刻称为<strong>提交点</strong></li><li>协调者的决定写入磁盘后，接下来向所有参与者发送提交（或放弃）请求。如果此请求出现失败或超时，则协调者必须一直重试，直到成功为止。</li></ol><blockquote><p>参与者投票“是”，它作出了肯定提交的承诺；协调者作出了提交的决定。这两个承诺确保了2PC的原子性。</p></blockquote><h4 id="协调者发生故障"><a href="#协调者发生故障" class="headerlink" title="协调者发生故障"></a>协调者发生故障</h4><img src="/2021/01/27/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/%E5%8D%8F%E8%B0%83%E8%80%85%E5%8F%91%E7%94%9F%E6%95%85%E9%9A%9C.png" class="" title="协调者发生故障"><p>如果在决定到达之前，出现协调者崩溃或网络故障，则参与者只能无奈等待。此时参与者处在一种不确定的状态。</p><p>2PC能够顺利完成的唯一方法是等待协调者恢复。这就是为什么协调者必须在向参与者发送提交（或中止）请求之前要将决定写入磁盘的事务日志；等协调者恢复之后，通过读取事务日志来确定所有未决的事务状态。</p><h3 id="实践中的分布式事务"><a href="#实践中的分布式事务" class="headerlink" title="实践中的分布式事务"></a>实践中的分布式事务</h3><h4 id="Exactly-once-消息处理"><a href="#Exactly-once-消息处理" class="headerlink" title="Exactly-once 消息处理"></a>Exactly-once 消息处理</h4><p>如果消息发送或数据库事务任何一个发生失败，则两者都需中止，消息队列可以在稍后再次重传消息。因此，通过自动提交消息</p><h3 id="支持容错的共识"><a href="#支持容错的共识" class="headerlink" title="支持容错的共识"></a>支持容错的共识</h3><blockquote><p>共识是让几个节点就某项提议达成一致</p></blockquote><p>共识算法必须满足的性质：</p><ul><li>协商一致性 Uniform agreement<ul><li>所有的节点都接受相同的决议。</li></ul></li><li>诚实性 Integrity<ul><li>所有的节点不能反悔，即对一项提议不能有两次决定。</li></ul></li><li>合法性 Validity<ul><li>如果决定了值v，则v一定是由某个节点所提议的。</li></ul></li><li>可终止性 Termination<ul><li>节点如果不崩溃则最终一定可以达成协议</li><li>引入了容错的思想，重点强调了一个共识算法不能原地空转，永远不做事情。</li></ul></li></ul><p>所有采取等待节点恢复的算法都无法满足终止性，特别是2PC不符合可终止性要求。事实上，可以证明任何共识算法都需要至少大部分节点正确运行才能确保终止性。而这个多数就可以安全地构成quorum。</p><blockquote><p>quorum机制：</p><p>是一种分布式系统中常用的，用来保证数据冗余和最终一致性的投票算法，其主要数学思想来源于鸽巢原理。</p></blockquote><h4 id="共识算法与全序广播"><a href="#共识算法与全序广播" class="headerlink" title="共识算法与全序广播"></a>共识算法与全序广播</h4><p>最著名的容错式共识算法包括VSR, Paxos, Raft和Zab.</p><blockquote><p>全序关系广播的要点是，消息按照相同的顺序发送到所有节点，有且只有一次。如果仔细想想，这其实相当于进行了多轮的共识过程：在每一轮，节点提出他们接下来想要发送的消息，然后决定下一个消息的全局顺序。</p></blockquote><h4 id="主从复制与共识"><a href="#主从复制与共识" class="headerlink" title="主从复制与共识"></a>主从复制与共识</h4><p>如何选择主节点将会影响我们是否去考虑共识问题。如果主节点是由运营人员手动选择和配置的，那基本上就是一个独裁性质的”一致性算法“：只允许一个节点接受写入，如果该结点发生故障，系统将无法写入，直到操作人员再手动配置新的节点称为主节点。但这个方案不满足共识的可终止性。</p><p>存在一个问题：</p><p>我们需要共识算法选出一位主节点。但是，如果这里描述的共识算法实际上是全序关系广播，且全序关系广播很像主从复制，但主从复制现在有需要选举主节点。</p><h4 id="Epoch和Quorum"><a href="#Epoch和Quorum" class="headerlink" title="Epoch和Quorum"></a>Epoch和Quorum</h4><p>目前所讨论的所有共识协议在其内部都使用了某种形式的主节点，虽然主节点并不是固定的。相反，他们都采用了一种弱化的保证：协议定义了一个epoch number，并保证在每个世代（对应于Raft中的term）里，主节点是唯一确定的。</p><p>后面这个部分讲的其实就是Raft的基础原理。存在两轮不同的投票：首先是投票决定谁是主节点，然后是主节点的提议进行投票。</p><h4 id="共识的局限性"><a href="#共识的局限性" class="headerlink" title="共识的局限性"></a>共识的局限性</h4><ul><li>采用异步复制，原因正是为了更好的性能</li><li>多数共识算法假定一组固定参与投票的节点集，这意味着不能动态添加或删除节点</li><li>共识系统通常依靠超时机制来检测节点失效。在网络延迟高度不确定的环境中，特别是那些跨区域分布的系统，经常由于网络延迟的原因，导致节点错误地认为主节点发生了故障。</li></ul><h3 id="成员与协调服务"><a href="#成员与协调服务" class="headerlink" title="成员与协调服务"></a>成员与协调服务</h3><p>ZooKeeper 和 etcd 主要针对保存少量、可完全载入内存的数据（虽然它们最终仍要写入磁盘以支持持久性）而设计，所以不要用他们保存大量的数据。</p><h4 id="节点任务分配"><a href="#节点任务分配" class="headerlink" title="节点任务分配"></a>节点任务分配</h4><p>以下场景可以借助ZooKeeper中的原子操作，ephemeral nodes和通知机制来实现：</p><ul><li>如果系统有多个流程或服务的实例，并且需求其中一个实例充当主节点；而如果主节点失效，由其他某个节点来接管。</li><li>对于一些分区资源（可以是数据库，消息流，文件存储等），需要决定将哪个分区分配给哪个节点。</li></ul><h4 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h4><p>ZooKeeper, etcd和Consul还会用于服务发现。</p><blockquote><p>每当节点启动时将其网络端口信息向ZooKeeper等服务注册，然后其他人只需向ZooKeeper的注册表中询问即可。</p></blockquote><h4 id="成员服务"><a href="#成员服务" class="headerlink" title="成员服务"></a>成员服务</h4><blockquote><p>成员服务用来确定当前哪些节点处于活动状态并属于集群的有效成员</p></blockquote><h2 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h2>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>读书笔记</tag>
      
      <tag>数据密集型应用系统设计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Elasticsearch 初步探索</title>
    <link href="/2021/01/25/Elasticsearch-%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/"/>
    <url>/2021/01/25/Elasticsearch-%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<p>前一段时间在听左耳朵耗子前辈的分享，开始决定渐渐解除对知乎和微信公众号的依赖，决定去向官网的英文文档以及一些paper靠拢。学习，仍然是一件很长的事情。</p><p>前一段时间在啃《数据密集型应用系统设计》，由于所学尚浅，其中有诸多不甚理解之处。在仁飞导师的建议下，决定先从es入手，再回头看这本堪称“圣经”的书。</p><h1 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h1><blockquote><p>定义：Elastic search is a highly scalable open-source full-text search and analytics engine. </p><p>作用：It allows you to store, search, and analyze big volumes of data quickly and  in near real time.</p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>Elasticsearch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/01/25/hello-world/"/>
    <url>/2021/01/25/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>LSM-Tree初探</title>
    <link href="/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/"/>
    <url>/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/</url>
    
    <content type="html"><![CDATA[<p>在阅读《数据密集型应用系统设计》的时候，接触到了LSM-Tree。觉得书中讲述的十分简略，没能深入理解这个存储结构。打算单独拎出来写一篇笔记。</p><h1 id="LSM-Tree背景"><a href="#LSM-Tree背景" class="headerlink" title="LSM-Tree背景"></a>LSM-Tree背景</h1><p>传统关系型数据库使用B-Tree或者一些变体作为存储结构，但这有一个缺点：有的数据逻辑上相离很近但是物理上相离甚远，这就会导致大量的<strong>磁盘随机读写</strong>。而随机读写比顺序读写要慢很多，为了提升IO性能，我们需要一种能将随机操作变为顺序操作的机制。这就有了LSM-Tree的诞生。LSM树能让我们进行顺序写磁盘，从而大幅提升写操作，作为代价的是牺牲了一些读性能。</p><h1 id="LSM-Tree原理"><a href="#LSM-Tree原理" class="headerlink" title="LSM-Tree原理"></a>LSM-Tree原理</h1><p>LSM-Tree实际上和Tree的关系不大，它是一种分层的存储结构。</p><h2 id="组件介绍"><a href="#组件介绍" class="headerlink" title="组件介绍"></a>组件介绍</h2><p>LSM-Tree由两个或更多的类Tree组成。我们暂时先讨论最简单的两个组件的情况</p><img src="/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/LSM-Tree%E4%B8%A4%E7%BB%84%E4%BB%B6.png" class="" title="LSM-Tree两组件"><p>LSM-Tree有两部分：</p><ul><li>一个较小的位于<strong>内存</strong>的组件，就是C0 Tree</li><li>一个较大的位于<strong>磁盘</strong>的组件，就是C1 Tree</li></ul><p>历史记录表的数据每生成一行新纪录流程如下：</p><ol><li><p>首先向顺序日至文件中写一条用于恢复这次插入行为的日志记录</p></li><li><p>该行数据的索引被插入到常驻内存的C0 Tree</p></li><li><p>会适时地将这些C0 Tree上的数据迁移到磁盘上的C1 Tree中</p></li><li><p>每个索引的搜索过程都是先C0后C1</p></li></ol><h2 id="组件合并"><a href="#组件合并" class="headerlink" title="组件合并"></a>组件合并</h2><h3 id="C0-合并到-C1"><a href="#C0-合并到-C1" class="headerlink" title="C0 合并到 C1"></a>C0 合并到 C1</h3><p>当C0 Tree上的插入数据达到一个指定阈值时，有一个持续循环的合并进程服务会删除C0 Tree上的一些连续segment段，将他们合并到磁盘中的C1 Tree。</p><img src="/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/C0%E5%90%88%E5%B9%B6%E8%87%B3C1.png" class="" title="C0合并至C1"><table><thead><tr><th></th><th>大小</th><th>描述</th><th>用途</th></tr></thead><tbody><tr><td>单页块</td><td>4KB</td><td>根节点；每个层级上的单页节点</td><td>单页节点被用在匹配索引查找中，以最小化缓存需求</td></tr><tr><td>多页块</td><td>256KB</td><td>根目录下的每个层级上的单页节点序列会被打包，然后一起放入连续的多页磁盘块中（囊括了根节点以下的节点），利于磁盘顺序访问</td><td>多页块IO，在滚动合并期间、大范围的范围搜索中被使用</td></tr></tbody></table><h3 id="Empty-Block和Filling-Block"><a href="#Empty-Block和Filling-Block" class="headerlink" title="Empty Block和Filling Block"></a>Empty Block和Filling Block</h3><blockquote><p>Empty Block: 在合并前，已缓存、且包含旧的C1 Tree节点的多页块。意味着它们会被清空、移除。</p><p>Filling Block: 新的叶节点被写入与旧的多页块不同的<strong>已缓存</strong>的多页块。意味着它们会被填满。</p></blockquote><ol><li>从C1中读取未合并叶子节点，放置在内存中的 <code>empty block</code> 中</li><li>从小到大找C0中的节点，与 <code>empty block</code> 进行合并排序，合并结果保存到<code>filling block</code>中，并将C0对应的节点删除。</li><li>不断执行第2步操作，合并排序结果不断填入 <code>filling block</code> 中，当其满了则将其追加到磁盘的新位置上，注意是追加而不是改变原来的节点。合并期间如故宫 <code>empty block</code> 使用完了则再从C1中读取未合并的叶子节点。</li><li>C0和C1所有叶子节点都按以上合并完成后即完成一次合并。</li></ol><p>具体插入例子可见：</p><p><a href="https://juejin.cn/post/6844903688075477000">看图轻松理解数据结构与算法系列（NoSQL存储-LSM树）</a></p><h2 id="LSM-Tree-索引查找"><a href="#LSM-Tree-索引查找" class="headerlink" title="LSM Tree 索引查找"></a>LSM Tree 索引查找</h2><h3 id="搜索原则"><a href="#搜索原则" class="headerlink" title="搜索原则"></a>搜索原则</h3><blockquote><p>C<sub>0</sub> Tree 是驻留在内存中的，而其他组件都在磁盘。这种情况下，每当C<sub>i-1</sub> 条目达到阈值时，每个 (C<sub>i-1</sub>, C<sub>i</sub>) 之间的异步滚动合并过程会从较小的组件中移动条目到较大的组件。</p></blockquote><img src="/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/LSM-Tree%E5%A4%9A%E7%BB%84%E4%BB%B6.png" class="" title="LSM-Tree多组件"><p>当一个需要立刻返回的精确匹配查询或是范围查询在LSM Tree的索引上执行时，会先在C<sub>0</sub>树执行搜索值，然后搜C<sub>1</sub>树。这暗含着少许额外的CPU开销(相对于B-Tree来说)，因为分别去两棵树目录进行搜索。</p><h2 id="LSM-Tree-删除、更新"><a href="#LSM-Tree-删除、更新" class="headerlink" title="LSM Tree 删除、更新"></a>LSM Tree 删除、更新</h2><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>删除操作为了能快速执行，主要是通过标记来实现，在内存中将要删除的记录标记一下，后面异步执行合并时将相应记录删除。</p><ul><li>比如要删除“U”，假设标为#的表示删除，则C0树的“U”节点变为“U(#)”</li><li>而如果C0树不存在的记录，则在C0树中生成一个节点，并标为#，查找时就能再内存中得知该记录已被删除，无需去磁盘找了。比如要删除“B”，那么没有必要去磁盘执行删除操作，直接在C0树中插入一个“B”节点，并标为#。</li></ul><h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>导致索引值更改的记录更新，这在任何类型的应用程序中都是不常见的。但如果我们将更新视为删除后紧跟着插入，则可以由LSM树以延迟方式处理此类更新。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://juejin.cn/post/6844903688075477000">看图轻松理解数据结构与算法系列（NoSQL存储-LSM树）</a></li><li><a href="https://my.oschina.net/u/4064459/blog/2999407">论文阅读-The Log-Structured Merge-Tree</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>《数据密集型应用系统设计》- 读书笔记1</title>
    <link href="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/"/>
    <url>/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/</url>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="第二章-数据模型与查询语言"><a href="#第二章-数据模型与查询语言" class="headerlink" title="第二章 数据模型与查询语言"></a>第二章 数据模型与查询语言</h1><h2 id="关系模型与文档模型"><a href="#关系模型与文档模型" class="headerlink" title="关系模型与文档模型"></a>关系模型与文档模型</h2><blockquote><p>数据被组织成关系（relations），在SQL中称为表（table），其中每个关系都是元组（tuples）的无序集合（在SQL中称为行）。</p></blockquote><h3 id="NoSQL的诞生"><a href="#NoSQL的诞生" class="headerlink" title="NoSQL的诞生"></a>NoSQL的诞生</h3><p>采用NoSQL数据库有这样几个驱动因素 ，包括 ：</p><ul><li><p>比关系数据库更好的扩展性需求，包括支持超大数据集或超高写入吞吐量。</p></li><li><p>普遍偏爱免费和开源软件而不是商业数据库产品 。</p></li><li><p>关系模型不能很好地支持一些特定的查询操作。</p></li><li><p>对关系模式一些限制性感到沮丧，渴望更具动态和表达力的数据模型。</p></li></ul><h3 id="对象-关系不匹配"><a href="#对象-关系不匹配" class="headerlink" title="对象-关系不匹配"></a>对象-关系不匹配</h3><p>大多数开发都采用面向对象的编程语言，如果数据存储在关系表中，那么应用层代码中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层。</p><p>Object-relational mapping(ORM) 对象-关系映射</p><p>对于像简历这样的数据结构，它主要是一个自包含的文档（document），因此用JSON表示非常适合。面向文档的数据库（MongoDB, RethinkDB, CouchDB, Espresso）都支持该数据模型。</p><h3 id="文档数据库是否在重演历史？"><a href="#文档数据库是否在重演历史？" class="headerlink" title="文档数据库是否在重演历史？"></a>文档数据库是否在重演历史？</h3><p>最早的计算机数据库系统是IBM信息管理系统。IMS采用了相当简单的数据模型，称为层次模型（类似JSON，它将所有数据表示为嵌套在记录中的记录）。IMS可以很好地支持一对多关系中，但是它支持多对多关系则有些困难，而且不支持联结。为了解决层次模型的局限性，之后提出了关系模型（relation model，后来演变成SQL）和网络模型（network model）</p><h4 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h4><p>在层次模型的树结构中，每个记录只有一个父节点；而在网络模型中，一个记录可能有多个父结点。访问路记录的唯一方法是选择一条始于根记录的路径，并沿着相关链接依次访问。</p><p>在20世纪70年代，尽管手动路径选择能够最有效地利用当时非常有限的硬件资源，但最大的问题在于它们使查询和更新数据库变得异常复杂而没有灵活性。</p><h4 id="关系模型"><a href="#关系模型" class="headerlink" title="关系模型"></a>关系模型</h4><p>关系模型所做的则是定义了所有数据的格式：关系（table）只是元组（tuple）的集合。没有复杂的嵌套结构，也没有复杂的访问逻辑。</p><h4 id="文档数据库的比较"><a href="#文档数据库的比较" class="headerlink" title="文档数据库的比较"></a>文档数据库的比较</h4><p>文档数据库是某种方式的层次模型：即在其父记录中保存了嵌套记录，而不是存储在单独的表中。</p><h3 id="关系数据库与文档数据库现状"><a href="#关系数据库与文档数据库现状" class="headerlink" title="关系数据库与文档数据库现状"></a>关系数据库与文档数据库现状</h3><p>支持文档数据模型的主要论点是模式灵活性，由于局部性而带来较好的性能 ，对于某些应用来说，它更接近于应用程序所使用的数据结构。关系模型则强在联结操作、多对一和多对多关系更简洁的表达上，与文档模型抗衡。</p><p><strong>如果应用数据具有类似文档的结构（即一对多关系树，通常一次加载整个树） ， 那么使用文档模型更为合适。而关系型模型则倾向于某种数据分解，它把文档结构分解为多个表，有可能使得模式更为笨重，以及不必要的应用代码复杂化。</strong></p><h2 id="数据查询语言"><a href="#数据查询语言" class="headerlink" title="数据查询语言"></a>数据查询语言</h2><h2 id="图状数据模型"><a href="#图状数据模型" class="headerlink" title="图状数据模型"></a>图状数据模型</h2><h1 id="第三章-数据存储与检索"><a href="#第三章-数据存储与检索" class="headerlink" title="第三章 数据存储与检索"></a>第三章 数据存储与检索</h1><h2 id="数据库核心：数据结构"><a href="#数据库核心：数据结构" class="headerlink" title="数据库核心：数据结构"></a>数据库核心：数据结构</h2><p>适当的索引可以加速度取查询，但每个索引都会减慢写速度</p><h3 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h3><p>假设数据存储全部采用追加式文件组成。</p><blockquote><p>保存内存中的hash map, 把每个键一一映射到数据文件中特定的字节偏移量，这样就可以找到每个值的位置。</p></blockquote><p>Bitcask （Riak 中的默认存储引擎）就是采用哈希索引的。它非常适合每个键的值频繁更新的场景。</p><p>如何避免最终用尽磁盘空间？</p><blockquote><p>我们可以将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以在这些段上执行压缩，在日志中丢弃重复的键，并且只保留每个键最近的更新。</p></blockquote><h4 id="需要考虑的问题"><a href="#需要考虑的问题" class="headerlink" title="需要考虑的问题"></a>需要考虑的问题</h4><ul><li>文件格式<ul><li>csv 不是日志的最佳格式，应该使用二进制的格式，首先以字节为单位来记录字符串的长度，之后再跟上原始字符串。</li></ul></li><li>删除记录<ul><li>如果要删除一个键和它关联的记录，在数据文件中追加一个tag。合并日志的时候，一旦发现tag，则会丢弃这个已经删除键的值。</li></ul></li><li>崩溃恢复<ul><li>因为hash map是存在内存中的，数据库重新启动之后会丢失。Bitcask 通过将每个段的hash map的快照存储在磁盘上，可以更快的加载到内存中，以此加快恢复速度。</li></ul></li><li>部分写入的记录<ul><li>Bitcask 文件包括校验值，这样可以发现损坏部分并丢弃。</li></ul></li><li>并发控制<ul><li>因为写入以严格的先后顺序追加到日志中，通常的实现选择是只有一个写线程。数据文件段是追加的，并且是不可变的，所以他们可以被多个线程同时读取。</li></ul></li></ul><h4 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h4><ul><li>因为hash map 必须放在内存中，如果一旦有大量的键，就需要在磁盘维护hash map，这会导致整体的性能下降。</li><li>区间查询效率不高。</li></ul><h3 id="SSTables和LSM-Tree"><a href="#SSTables和LSM-Tree" class="headerlink" title="SSTables和LSM-Tree"></a>SSTables和LSM-Tree</h3><h4 id="SSTables"><a href="#SSTables" class="headerlink" title="SSTables"></a>SSTables</h4><blockquote><p>要求每个存储段的key-value对的顺序按键排序。要求每个键在合并的段文件中只能出现一次。</p></blockquote><blockquote><p>SSTable 是一个<strong>持久化的、有序的、不可变的</strong>映射表（map），其中的<strong>键和值都可以 是任意字节字符串</strong>。它提供了按 key 查询和对指定的 key range 进行遍历的操作。</p></blockquote><p>SSTable相比哈希索引，具有优点：</p><ul><li>合并段更加简单高效，即使文件大于可用内存</li><li>在文件中查找特定的键时，不再需要在内存中保存所有键的索引。仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的。</li></ul><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/SSTable%E5%8F%8A%E5%85%B6%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95.png" class="" title="SSTable及其内存中的索引"><h5 id="从SSTables到LSM-Tree"><a href="#从SSTables到LSM-Tree" class="headerlink" title="从SSTables到LSM-Tree"></a>从SSTables到LSM-Tree</h5><blockquote><p>基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎。</p></blockquote><p>LSM Tree的树节点可以分为两种，保存在内存中的称之为MemTable， 保存在磁盘上的称之为SSTable。</p><h5 id="构建和维护SSTables"><a href="#构建和维护SSTables" class="headerlink" title="构建和维护SSTables"></a>构建和维护SSTables</h5><ul><li>当写入时，将其添加到内存中的平衡树数据结构中。这个内存中的树有时被称为内存表。</li><li>当内存表大于某个阈值时，将其作为SSTable文件写入磁盘。由于树已经维护了按键排序的key-value对，写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当SSTable写磁盘的同时，写入可以继续添加到一个新的内存表实例。</li><li>处理读请求时，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件……</li><li>后台进程周期性的执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。</li></ul><p>LevelDB 和 RocksDB 使用的就是上面这段算法。</p><p>不同的策略会影响甚至决定SSTables压缩和合并时的具体顺序和时机。</p><ul><li>LevelDB和RocksDB使用分层压缩<ul><li>键的范围分裂成多个更小的SSTables，旧数据被移动到单独的“层级”。</li></ul></li><li>HBase使用大小分级<ul><li>较新的和较小的SSTables 被连续合并到较旧和较大的SSTables</li></ul></li><li>Cassandra则同时支持这两种压缩。</li></ul><p>LSM-Tree 的基本思想：</p><blockquote><p>保存在后台合并的一系列SSTable</p></blockquote><p><a href="https://zhuangzhuang131419.github.io/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/">LSM-Tree初探</a></p><h3 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B-Tree"></a>B-Tree</h3><p>B-Tree 已经比较熟悉它的基本原理了，这里讲一些新的收获。</p><blockquote><p>B-Tree 将数据库分解成固定大小的块或页，页是内部读/写的最小单元。每个页面都可以使用地址或位置进行标识，不过是指向磁盘地址，而不是内存。</p></blockquote><h4 id="B-Tree-可靠"><a href="#B-Tree-可靠" class="headerlink" title="B-Tree 可靠"></a>B-Tree 可靠</h4><ul><li><p>预写日志（write-ahead log, WAL）</p><ul><li>这是一个仅支持追加修改的文件，每个B-Tree的修改必须先更新 WAL 然后再修改树本身的页。当数据库在崩溃后需要恢复时，该日志用于将B-Tree恢复到最近一直的状态。</li></ul></li><li><p>原地更新页</p><ul><li>如果多个线程要同时访问B-Tree，则需要注意并发控制，否则线程可能会看到树处于不一致的状态。</li></ul></li></ul><h4 id="B-Tree-优化"><a href="#B-Tree-优化" class="headerlink" title="B-Tree 优化"></a>B-Tree 优化</h4><ul><li><p>一些数据库（LMDB）不使用覆盖页和维护WAL来进行崩溃恢复，而是使用写时复制方案。</p></li><li><p>保存键的缩略信息，而不是完整的键，这样可以节省页空间。</p></li><li><p>相邻叶子页可以按顺序保存在磁盘上。但是相比之下，LSM-Tree在合并过程中一次重写大量存储段，更容易让那个连续的键在磁盘上相互靠近。</p></li><li><p>添加额外的指针到树中。例如，每个叶子页面可能会向左和向右引用其同级的兄弟页。</p></li><li><p>B-Tree的变体如分形树，借鉴了一些日志结构的想法来减少磁盘寻道。</p></li></ul><h3 id="B-Tree-vs-LSM-Tree"><a href="#B-Tree-vs-LSM-Tree" class="headerlink" title="B-Tree vs. LSM-Tree"></a>B-Tree vs. LSM-Tree</h3><p>根据经验，LSM-Tree通常对于写入更快而读取较慢，因为必须在不同的压缩阶段检查多个不同的数据结构和SSTable。B-Tree被认为对于读取更快。</p><h4 id="LSM-Tree-的优点"><a href="#LSM-Tree-的优点" class="headerlink" title="LSM-Tree 的优点"></a>LSM-Tree 的优点</h4><ul><li><p>LSM-Tree 通常能够承受比 B-Tree 更高的写入吞吐量</p><ul><li>具有较低的写放大（在数据库内，由于一次数据库写入请求导致的多次磁盘写）</li><li>以顺序方式写入紧凑的SSTable，而不必重写树中的多个页。</li></ul></li><li><p>LSM-Tree 可以支持更好的压缩。</p><ul><li>由于碎片，B-Tree存储引擎使某些磁盘空间无法使用。</li></ul></li></ul><h4 id="LSM-Tree-的缺点"><a href="#LSM-Tree-的缺点" class="headerlink" title="LSM-Tree 的缺点"></a>LSM-Tree 的缺点</h4><ul><li>日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。<ul><li>由于磁盘的并发资源有限，所以当磁盘执行昂贵的压缩操作时，很容易发生读写请求等待的情况。</li></ul></li><li>磁盘的有限写入带宽需要在初始写入（记录并刷新内存表到磁盘）和后台运行的压缩线程之间所共享。<ul><li>数据量越大，压缩所需的磁盘带宽就越多。</li></ul></li></ul><h4 id="B-Tree-的优点"><a href="#B-Tree-的优点" class="headerlink" title="B-Tree 的优点"></a>B-Tree 的优点</h4><ul><li>每个键都恰好唯一对应于索引中的某个位置，而日志结构的存储引擎可能在不同的段中具有相同建的多个副本<ul><li>可以提供强大的事务语义</li></ul></li></ul><h3 id="其他索引结构"><a href="#其他索引结构" class="headerlink" title="其他索引结构"></a>其他索引结构</h3><h4 id="在索引中存储值"><a href="#在索引中存储值" class="headerlink" title="在索引中存储值"></a>在索引中存储值</h4><ul><li>聚集索引<ul><li>在索引中直接保存行数据</li><li>InnoDB</li></ul></li><li>非聚集索引<ul><li>仅存储索引中的数据的引用</li><li>MySQL</li></ul></li><li>覆盖索引<ul><li>包含列的索引，在索引中保存一些表的列值。</li></ul></li></ul><h5 id="多列索引"><a href="#多列索引" class="headerlink" title="多列索引"></a>多列索引</h5><p>如果需要同时查询表的多个列，就需要使用到多列索引。</p><ul><li><p>级联索引</p><ul><li>通过将一列追加到另一列，将几个字段简单地组合成一个键（索引的定义指定字段连接的顺序）。</li></ul></li><li><p>多维索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> restaurants <span class="hljs-keyword">where</span> latitude <span class="hljs-operator">&gt;</span> <span class="hljs-number">51</span> <span class="hljs-keyword">AND</span> latitude <span class="hljs-operator">&lt;</span> <span class="hljs-number">51.5</span> <span class="hljs-keyword">AND</span> longitude <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span> <span class="hljs-keyword">AND</span> longitude <span class="hljs-operator">&lt;</span> <span class="hljs-number">0.5</span> <br></code></pre></td></tr></table></figure><ul><li>B-Tree或LSM-Tree索引无法高效的应对这种查询。</li><li>更常见的是使用专门的空间索引 （R-Tree）</li></ul></li></ul><h4 id="全文搜索和模糊索引"><a href="#全文搜索和模糊索引" class="headerlink" title="全文搜索和模糊索引"></a>全文搜索和模糊索引</h4><p>全文搜索引擎通常支持对一个单词的所有同义词进行查询。</p><p>在Lucene中，内存中的索引是键中的字符序列的有限状态自动机，类似字典树。这个自动机可以转换成Levenshtein自动机，支持在给定编辑距离内高效地搜索单词。</p><p>这部分内容还有非常多深挖的细节，计划在第一遍读完本书后再做后续拓展。</p><h5 id="在内存中保存所有内容"><a href="#在内存中保存所有内容" class="headerlink" title="在内存中保存所有内容"></a>在内存中保存所有内容</h5><blockquote><p> 一些VoltDB、MemSQL和Oracle TimesTen的产品是具有关系模型的内存数据库。</p></blockquote><p>内存数据库的性能优势并不是因为它们不需要从磁盘读取。即使是基于磁盘的存储引擎，也可能永远不需要从磁盘读取，因为操作系统将最近使用的磁盘缓存在内存中。实际上，内存数据库可以更快，<strong>是因为它们避免使用写磁盘的格式对内存数据结构编码的开销</strong>。</p><p>内存数据库提供了基于磁盘索引难以实现的某些数据类型。例如，Redis为各种数据结构（如优先级队列和集合）都提供了类似数据库的访问接口。</p><h2 id="事务处理与分析处理"><a href="#事务处理与分析处理" class="headerlink" title="事务处理与分析处理"></a>事务处理与分析处理</h2><ul><li>在线事务处理（OLTP）<ul><li>根据用户的输入插入或更新记录。因为这些应用程序是交互式的。</li><li>OLTP要求高度可用，处理事务时延迟足够低。</li></ul></li><li>在线分析处理（OLAP）<ul><li>为了区分使用数据库与事务处理的模式。</li></ul></li></ul><p>现在的趋势是，放弃使用OLTP系统用于分析目的，而是在单独的数据库上运行分析。这个单独的数据库被称为<strong>数据仓库</strong>。</p><h3 id="数据仓库"><a href="#数据仓库" class="headerlink" title="数据仓库"></a>数据仓库</h3><blockquote><p>数据仓库就是面向主题的（Subject-Oriented ）、集成的（Integrated）、非易失的（Non-Volatile）和时变的（Time-Variant ）数据集合，用以支持管理决策 。</p></blockquote><p>现在国内最常用的是一款基于Hadoop的开源数据仓库 <strong>Hive</strong>，可以对存储在HDFS上的文件数据集进行查询和分析处理。</p><h4 id="数据仓库的特点"><a href="#数据仓库的特点" class="headerlink" title="数据仓库的特点"></a>数据仓库的特点</h4><ul><li>主题性<ul><li>数据仓库是围绕一个主题进行获取数据和分析数据，以此来满足数据分析的需求。</li></ul></li><li>集成性<ul><li>要整合成最终的数据集合，需要对数据进行抽取、清洗、转换的过程。</li></ul></li><li>稳定性<ul><li>数据仓库不允许对数据进行修改，只能进行查询和分析。</li></ul></li><li>及时性<ul><li>数据仓库一定要获取最新的数据，这样数据分析出来的结果才是有效的。</li></ul></li></ul><h4 id="数据仓库如何集成不同数据源"><a href="#数据仓库如何集成不同数据源" class="headerlink" title="数据仓库如何集成不同数据源"></a>数据仓库如何集成不同数据源</h4><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%92%8C%E7%AE%80%E5%8C%96%E7%9A%84ETL%E8%BF%87%E7%A8%8B.png" class="" title="数据仓库和简化的ETL过程"><p>将数据导入数据仓库的过程称为提取-转换-加载（Extract-Transform-Load, ETL）。</p><ul><li>Extract<ul><li>读取数据</li></ul></li><li>Transform<ul><li>把数据转换成需要的维度和格式，同时包含数据清洗，清洗掉一些噪音数据。</li></ul></li><li>Load<ul><li>把数据加载到目标仓库以供分析使用</li></ul></li></ul><p>使用单独的数据仓库而不是直接查询OLTP系统进行分析，很大的优势在于数据仓库可以针对分析访问模式进行优化。</p><h4 id="OLTP数据库和数据仓库之间的差异"><a href="#OLTP数据库和数据仓库之间的差异" class="headerlink" title="OLTP数据库和数据仓库之间的差异"></a>OLTP数据库和数据仓库之间的差异</h4><h3 id="星型与雪花型分析模式"><a href="#星型与雪花型分析模式" class="headerlink" title="星型与雪花型分析模式"></a>星型与雪花型分析模式</h3><h4 id="星型模式"><a href="#星型模式" class="headerlink" title="星型模式"></a>星型模式</h4><p>模式的中心是一个所谓的<strong>事实表</strong>。事实表的每一行表示在特定时间发生的事件。事实表中的列是属性，其他列可能会引用其他表的外键，称为<strong>维度表</strong>。</p><blockquote><p>由于事实表中的每一行都代表一个事件，维度通常代表事件的对象（who）、什么（what）、地点（where）、时间（when）、方法（how）以及原因（why）。</p></blockquote><p>事实表位于中间，被一系列维度表包围。</p><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F.png" class="" title="星型模式"><h4 id="雪花模式"><a href="#雪花模式" class="headerlink" title="雪花模式"></a>雪花模式</h4><p>维度进一步细分为子空间，每一行都可以再次引用品牌和类别作为外键，而不是将其作为字符串直接存储在表中。</p><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E9%9B%AA%E8%8A%B1%E5%9E%8B%E6%A8%A1%E5%BC%8F.png" class="" title="雪花型模式"><h2 id="列式储存"><a href="#列式储存" class="headerlink" title="列式储存"></a>列式储存</h2><p>我们将首先关注事实表的存储。</p><blockquote><p>面向行存储：来自表的一行所有值彼此相邻存储。</p><p>面向列存储：将每列中的所有值存储在一起。</p></blockquote><p>因为我们在查询的时候通常只会需要某几个字段，显然使用列存储是一个更为优化的办法。</p><h3 id="列压缩"><a href="#列压缩" class="headerlink" title="列压缩"></a>列压缩</h3><h4 id="位图编码"><a href="#位图编码" class="headerlink" title="位图编码"></a>位图编码</h4><p>现在可以使用n个不同值的列，并将其转换为n个单独的位图：一个位图对应每个不同的值，一个位对应一行。如果行具有该值，该位为1，否则为0。</p><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E5%8E%8B%E7%BC%A9%E7%9A%84%E4%BD%8D%E5%9B%BE%E7%B4%A2%E5%BC%95%E5%AD%98%E5%82%A8%E5%8D%95%E5%88%97.png" class="" title="压缩的位图索引存储单列"><h4 id="内存带宽和矢量化处理"><a href="#内存带宽和矢量化处理" class="headerlink" title="内存带宽和矢量化处理"></a>内存带宽和矢量化处理</h4><ul><li>内存带宽<ul><li>如何高效地将内存的带宽用于CPU缓存，避免分支错误预测和CPU指令处理流水线中的气泡，并利用现代CPU中的单指令多数据指令。</li></ul></li><li>矢量化处理<ul><li>列压缩使得列中更多的行可以加载到L1缓存。</li></ul></li></ul><h3 id="列存储中的排序"><a href="#列存储中的排序" class="headerlink" title="列存储中的排序"></a>列存储中的排序</h3><ul><li><p>可以基于常见查询的知识来选择要排序表的列。</p></li><li><p>排序可以帮忙进一步压缩列</p><ul><li>如果主排序列上没有很多不同的值，在排序后，会出现一个非常长的序列，其中相同的值在一行中重复多次。</li></ul></li></ul><h3 id="列存储的写操作"><a href="#列存储的写操作" class="headerlink" title="列存储的写操作"></a>列存储的写操作</h3><p>面向列的存储、压缩和排序都非常有助于加速读取查询，但是可以使用<strong>LSM-Tree</strong>。</p><blockquote><p>所有的写入首先进入内存存储区，将其添加到已排序的结构中，接着再准备写入磁盘。当累积了足够的写入时，它们将与磁盘上的列文件合并，并批量写入新文件。</p></blockquote><h2 id="聚合：数据立方体与物化视图"><a href="#聚合：数据立方体与物化视图" class="headerlink" title="聚合：数据立方体与物化视图"></a>聚合：数据立方体与物化视图</h2><p>如果许多不同查询使用相同的聚合，每次都处理原始数据将非常浪费</p><h3 id="物化视图"><a href="#物化视图" class="headerlink" title="物化视图"></a>物化视图</h3><blockquote><p>一个类似表的对象，其内容是一些查询的结果。</p></blockquote><p>当底层数据发生变化时，物化视图也需要随之更新，因为它是数据的非规范化副本。</p><h3 id="数据立方体"><a href="#数据立方体" class="headerlink" title="数据立方体"></a>数据立方体</h3><p>物化视图一种特殊情况。它是由不同维度分组的聚合网络。</p><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E6%95%B0%E6%8D%AE%E7%AB%8B%E6%96%B9%E4%BD%93.png" class="" title="数据立方体"><ul><li><p>优点</p><ul><li>某些查询会很快，因为已经被预先计算出来了。</li></ul></li><li><p>缺点</p><ul><li>缺乏像查原始数据那样的灵活性。</li></ul></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>存储引擎分为两大类：<strong>针对事务处理（OLTP）优化的结构</strong>和<strong>针对分析型（OLAP）的优化结构</strong>。</p><ul><li><p>OLTP</p><ul><li>OLTP通常面向用户，磁盘寻道时间往往是瓶颈。</li><li>有两个主要流派的存储引擎<ul><li>日志结构流派</li><li>原地更新流派</li></ul></li></ul></li><li><p>OLAP</p><ul><li>OLAP主要由业务分析师用，磁盘带宽通常是瓶颈，可以通过面向列的存储来解决。</li><li>当查询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的是非常紧凑地编码数据，以尽量减少磁盘读取的数据量。</li></ul></li></ul><h1 id="第四章-数据编码与演化"><a href="#第四章-数据编码与演化" class="headerlink" title="第四章 数据编码与演化"></a>第四章 数据编码与演化</h1><h2 id="数据编码格式"><a href="#数据编码格式" class="headerlink" title="数据编码格式"></a>数据编码格式</h2><ol><li>在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）。</li><li>将数据写入文件或通过网络发送时，必须将其编码为某种自包含的字节序列（例如JSON文档）。</li></ol><blockquote><p>从内存中的表示到字节序列的转化称为编码（序列化），相反的过程称为解码（反序列化）。</p></blockquote><h3 id="JSON、XML与二进制变体"><a href="#JSON、XML与二进制变体" class="headerlink" title="JSON、XML与二进制变体"></a>JSON、XML与二进制变体</h3><p>这些编码都有一定的缺点</p><ul><li>在XML和CSV中，无法区分数字和碰巧由数字组成的字符串。</li><li>JSON区分字符串和数字，但不区分整数和浮点数，并且不指定精度。</li><li>JSON和XML对Unicode字符串有很好的支持，但是它们不支持二进制字符串。</li><li>由于数据的正确解释取决于模式中的信息，因此不使用XML/JSON架构的应用程序可能不得不硬编码适当的编码/解码逻辑。</li><li>CSV没有任何模式，因此应用程序需要定义每行和每列的含义。</li></ul><h4 id="二进制编码"><a href="#二进制编码" class="headerlink" title="二进制编码"></a>二进制编码</h4><p>JSON不像XML那么冗长，但与二进制格式相比，两者仍然占用大量空间。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json">&#123;<br>  <span class="hljs-attr">&quot;userName&quot;</span>: <span class="hljs-string">&quot;Martin&quot;</span>,<br>  <span class="hljs-attr">&quot;favoriteNumber&quot;</span>: <span class="hljs-number">1337</span>,<br>  <span class="hljs-attr">&quot;interests&quot;</span>: [<span class="hljs-string">&quot;daydreaming&quot;</span>, <span class="hljs-string">&quot;hacking&quot;</span>]<br>&#125;<br></code></pre></td></tr></table></figure><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E7%A0%81.png" class="" title="二进制编码"><h3 id="Thrift与Protocol-Buffers"><a href="#Thrift与Protocol-Buffers" class="headerlink" title="Thrift与Protocol Buffers"></a>Thrift与Protocol Buffers</h3><p>接下来介绍的是模式（schemas）</p><h4 id="Thrift"><a href="#Thrift" class="headerlink" title="Thrift"></a>Thrift</h4><figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs thrift"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Person</span> </span>&#123;<br><span class="hljs-number">1</span>: <span class="hljs-keyword">required</span> <span class="hljs-built_in">string</span>       userName,<br><span class="hljs-number">2</span>: <span class="hljs-keyword">optional</span> <span class="hljs-built_in">i64</span>          favoriteNumber,<br><span class="hljs-number">3</span>: <span class="hljs-keyword">optional</span> list&lt;<span class="hljs-keyword">string</span>&gt; interests<br>&#125;<br></code></pre></td></tr></table></figure><p>Thrift有两种不同的二进制编码格式：BinaryProtocol和CompactProtocol</p><h5 id="BinaryProtocol"><a href="#BinaryProtocol" class="headerlink" title="BinaryProtocol"></a>BinaryProtocol</h5><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/BinaryProtocol.png" class="" title="BinaryProtocol"><p>最大的区别是没有字段名。相反，编码数据包含数字类型的字段标签。</p><h5 id="CompactProtocol"><a href="#CompactProtocol" class="headerlink" title="CompactProtocol"></a>CompactProtocol</h5><ul><li>将字段类型和标签号打包到单字节中，并使用可变长度整数来实现。</li><li>对数字1337，不使用全部8字节，而是使用两个字节进行编码。每个字节的最高位用来指示是否还有更多的字节。</li></ul><h4 id="Protocol-Buffers"><a href="#Protocol-Buffers" class="headerlink" title="Protocol Buffers"></a>Protocol Buffers</h4><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-class"><span class="hljs-keyword">message</span> <span class="hljs-title">Person</span> </span>&#123;<br><span class="hljs-keyword">required</span> <span class="hljs-built_in">string</span> user_name      = <span class="hljs-number">1</span>;<br><span class="hljs-keyword">optional</span> <span class="hljs-built_in">int64</span> favorite_number = <span class="hljs-number">2</span>;<br><span class="hljs-keyword">repeated</span> <span class="hljs-built_in">string</span> interests      = <span class="hljs-number">3</span>;<br>&#125;<br></code></pre></td></tr></table></figure><img src="/2021/01/13/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/ProtocolBuffers.png" class="" title="ProtocolBuffers"><blockquote><p>在前面所示的模式中，每个字段被标记为required或optional，但这对字段如何编码没有任何影响。区别在于，如果字段设置了required，但字段未填充，则运行时检查将出现失败。</p></blockquote><h4 id="字段标签和模式演化"><a href="#字段标签和模式演化" class="headerlink" title="字段标签和模式演化"></a>字段标签和模式演化</h4><p>为了保持向后兼容性，在模式的初始部署之后添加的每个字段都必须是可选的或具有默认值。</p><p>为了保持向前兼容性，只能删除可选的字段（必填字段永远不能被删除）。</p><h4 id="数据类型和模式演化"><a href="#数据类型和模式演化" class="headerlink" title="数据类型和模式演化"></a>数据类型和模式演化</h4><p>Protocal Buffers 没有列表或数组数据类型，而是有字段的重复标记（repeated）。对于重复字段，表示同一个字段标签只是简单的多次出现在记录中。可以将可选（单值）字段更改为重复（多值）字段。</p><p>读取旧数据的新代码会看到一个包含零个或一个元素的列表。</p><p>读取新数据的旧代码只能看到列表的最后一个元素。</p><h3 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h3><p>TODO</p><h3 id="模式（schema）的优点"><a href="#模式（schema）的优点" class="headerlink" title="模式（schema）的优点"></a>模式（schema）的优点</h3><p>Protocal Buffers, Thrift和Avro都使用了模式来描述二进制编码格式。</p><ol><li>可以比各种“二进制JSON”变体更紧凑（可以省略编码数据中的变量名）。</li><li>模式是一种有价值的文档形式（而手动维护文档的成本是巨大的）。</li><li>可以向前兼容和向后兼容。</li><li>可以在编译时进行类型检查。</li></ol><h2 id="数据流模式"><a href="#数据流模式" class="headerlink" title="数据流模式"></a>数据流模式</h2><p>这里我们将探讨一些最常见的进程间数据流动的方式：</p><h3 id="基于数据库的数据流"><a href="#基于数据库的数据流" class="headerlink" title="基于数据库的数据流"></a>基于数据库的数据流</h3><blockquote><p>在数据库中，写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。</p></blockquote><p>由于可能存在新旧不同版本的进程对数据库进行编码或者解码，数据库需要向前或者向后兼容。</p><h4 id="归档存储"><a href="#归档存储" class="headerlink" title="归档存储"></a>归档存储</h4><p>数据传储通常使用最新的模式进行编码，即使源数据库中的原始编码包含了不同时代的各种模式版本。</p><h3 id="基于服务的数据流：REST和RPC"><a href="#基于服务的数据流：REST和RPC" class="headerlink" title="基于服务的数据流：REST和RPC"></a>基于服务的数据流：REST和RPC</h3><p>客户端和服务器。服务器通过网络公开API，客户端可以连接到服务器以向该API发出请求。服务器公开的API称为<strong>server</strong>。</p><ul><li>web浏览器<ul><li>发出GET请求来下载HTML, CSS, JavaScript, 图像</li><li>发出POST请求提交数据到服务器</li></ul></li><li>移动设备或桌面计算机上运行的本地应用程序<ul><li>服务器的响应通常是便于客户端应用程序进一步处理的编码数据（如JSON）</li></ul></li><li>服务器本身可以是另一项服务的客户端<ul><li>微服务体系架构<ul><li>通过使服务可独立部署和演化，让应用程序更易于更改和维护。</li></ul></li></ul></li></ul><h4 id="网络服务"><a href="#网络服务" class="headerlink" title="网络服务"></a>网络服务</h4><blockquote><p>当HTTP被用作与服务通信的底层协议时，它被称为Web服务。</p></blockquote><h5 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h5><p>REST不是一种协议，而是一个基于HTTP原则的设计理念。</p><ul><li>强调简单的数据格式</li><li>使用URL来标识资源</li><li>使用HTTP功能进行缓存控制、身份验证和内容类型协商。</li></ul><blockquote><p>根据REST原则所设计的API称为RESTful</p></blockquote><h5 id="SOAP"><a href="#SOAP" class="headerlink" title="SOAP"></a>SOAP</h5><p>基于XML的协议，用于发出网络API请求。</p><h4 id="远程过程调用（RPC）的问题"><a href="#远程过程调用（RPC）的问题" class="headerlink" title="远程过程调用（RPC）的问题"></a>远程过程调用（RPC）的问题</h4><ul><li>本地函数调用是可预测的，并且成功或失败仅取决于控制的参数。网络请求是不可预测的：请求或响应可能由于网络问题而丢失，或者远程计算机可能速度慢或不可用。</li><li>本地函数要么返回一个结果，要么抛出一个异常。网络请求有另一个可能：由于超时，它返回时可能没有结果。</li><li>重试失败的网络请求，可能会发生请求实际上已经完成，只是响应丢失的情况。需要在协议中建立重复数据消除（幂等性）机制</li><li>调用本地函数时，通常需要大致相同的时间来执行。网络请求比函数调用要慢得多，而且期延迟也有很大的变化。</li><li>调用本地函数时，可以高效地将引用传递给本地内存中的对象。当发出网络请求时，所有这些参数都需要被编码称可以通过网络发送的字节序列。</li><li>客户端和服务端可以用不同的编程语言来实现，所以RPC框架必须将数据类型从一种语言转换成另一语言。</li></ul><h4 id="RPC的发展方向"><a href="#RPC的发展方向" class="headerlink" title="RPC的发展方向"></a>RPC的发展方向</h4><p>REST似乎是公共API的主流风格。RPC框架主要侧重于同一组织内多项服务之间的请求，通常发生在统一数据中心内。</p><h4 id="RPC的数据编码和演化"><a href="#RPC的数据编码和演化" class="headerlink" title="RPC的数据编码和演化"></a>RPC的数据编码和演化</h4><blockquote><p>重要的是可以独立地更改和部署RPC客户端和服务器。</p></blockquote><p>可以假定所有的服务器都先更新，其次再是客户端。因此只需要在请求上具有向后兼容性，而在响应上具有向前兼容性即可</p><p>关于API版本管理暂时没有统一的方案</p><ul><li>对于RESTFUL API，常用的方法是在URL或HTTP Accept头中使用版本号。（目前我在字节实习所用的一种方式）</li><li>对于使用API密钥来表示特定客户端的服务，另一种选择是将客户端请求的API版本存储在服务器上，并允许通过单独的管理接口更新该本本选项。</li></ul><h3 id="基于消息传递的数据流"><a href="#基于消息传递的数据流" class="headerlink" title="基于消息传递的数据流"></a>基于消息传递的数据流</h3><p>RPC和数据库之间的异步消息传递系统。不是通过直接的网络连接发送消息，而是通过称为消息代理（消息队列，或面向消息的中间件）的中介发送的，该中介会暂存消息。</p><h4 id="消息代理"><a href="#消息代理" class="headerlink" title="消息代理"></a>消息代理</h4><p>优点：</p><ul><li>可以充当缓冲区，从而提高系统的可靠性。</li><li>可以自动将消息重新发送到崩溃的进程，防止消息丢失。</li><li>避免了发送方需要知道接收方的IP地址和端口号。</li><li>支持将一条消息发送给多个接收方。</li><li>在逻辑上将发送方与接收方分离。</li></ul><p>消息传递通信通常是单向的。</p><p>使用方式：</p><ol><li>一个进程向指定的队列或主题发送消息。</li><li>代理确保消息被传递给队列或主题的一个或多个消费者或订阅者。</li><li>在同一主题上可以有许多生产者和许多消费者。</li></ol><h4 id="分布式Actor框架"><a href="#分布式Actor框架" class="headerlink" title="分布式Actor框架"></a>分布式Actor框架</h4><p>每个Actor通常代表一个客户端或实体，它可能具有某些本地状态（不与其他任何Actor共享），并且它通过发送和接收异步消息与其他Actor通信。</p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。因此，在系统内流动的所有数据都以提供向后兼容性和向前兼容性的方式进行编码。</p><p>数据流的几种模型</p><ul><li>数据库，其中写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。</li><li>RPC和REST API，其中客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。</li><li>异步消息传递（使用消息代理或Actor），节点之间通过互相发送消息进行通信，消息由发送者编码并由接受者解码。</li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>读书笔记</tag>
      
      <tag>数据密集型应用系统设计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL实战-读书笔记</title>
    <link href="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>实习期间在导师的力荐下读到了这部极客网的 MySQL 课程，实在受益匪浅。初次速读，很多东西不能深刻的记在脑中，不能完全消化，先记录下来，日后再度翻阅。这份资料值得多次品味。</p><h1 id="18-为什么有的-SQL-语句逻辑相同，性能差异巨大"><a href="#18-为什么有的-SQL-语句逻辑相同，性能差异巨大" class="headerlink" title="18.为什么有的 SQL 语句逻辑相同，性能差异巨大"></a>18.为什么有的 SQL 语句逻辑相同，性能差异巨大</h1><h2 id="案例一："><a href="#案例一：" class="headerlink" title="案例一："></a>案例一：</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `tradelog` (<br>    `id`            <span class="hljs-type">int</span>(<span class="hljs-number">11</span>)     <span class="hljs-keyword">NOT</span>     <span class="hljs-keyword">NULL</span>,<br>    `tradeid`       <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    `operator`      <span class="hljs-type">int</span>(<span class="hljs-number">11</span>)     <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    `t_modified`    datetime    <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (`id`),<br>    KEY `tradeid` (`tradeid`),<br>    KEY `t_modified` (`t_modified`)<br>) ENGINE<span class="hljs-operator">=</span>InnoDB <span class="hljs-keyword">DEFAULT</span> CHARSET<span class="hljs-operator">=</span>utf8mb4;<br></code></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> <span class="hljs-keyword">month</span>(t_modified) <span class="hljs-operator">=</span> <span class="hljs-number">7</span>;  # 无法命中索引<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> <br>    (t_modified <span class="hljs-operator">&gt;=</span> <span class="hljs-string">&#x27;2016-7-1&#x27;</span> <span class="hljs-keyword">and</span> t_modified <span class="hljs-operator">&lt;</span> <span class="hljs-string">&#x27;2016-8-1&#x27;</span>) <span class="hljs-keyword">or</span><br>    (t_modified <span class="hljs-operator">&gt;=</span> <span class="hljs-string">&#x27;2017-7-1&#x27;</span> <span class="hljs-keyword">and</span> t_modified <span class="hljs-operator">&lt;</span> <span class="hljs-string">&#x27;2017-8-1&#x27;</span>) <span class="hljs-keyword">or</span> <br>    (t_modified <span class="hljs-operator">&gt;=</span> <span class="hljs-string">&#x27;2018-7-1&#x27;</span> <span class="hljs-keyword">and</span> t_modified <span class="hljs-operator">&lt;</span> <span class="hljs-string">&#x27;2018-8-1&#x27;</span>) ...     # 可以命中索引<br></code></pre></td></tr></table></figure><blockquote><p>如果对字段做了函数计算，就用不上索引了。</p><p>原因是：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。</p></blockquote><h2 id="案例二："><a href="#案例二：" class="headerlink" title="案例二："></a>案例二：</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"># tradeid 的类型是 <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>)<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> tradeid<span class="hljs-operator">=</span><span class="hljs-number">110717</span>;  # 无法命中索引<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> <span class="hljs-built_in">CAST</span>(tradidAS signed <span class="hljs-type">int</span>) <span class="hljs-operator">=</span> <span class="hljs-number">110717</span>;   # 等价于执行这条语句<br></code></pre></td></tr></table></figure><p><strong>MySQL 类型转换的规则是将字符串转换成数字。</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> &quot;10&quot; <span class="hljs-operator">&gt;</span> <span class="hljs-number">9</span> # 返回 <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"># id 的类型是 <span class="hljs-type">int</span><br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span>&quot;83126&quot;;  # 可以命中索引<br></code></pre></td></tr></table></figure><h2 id="案例三："><a href="#案例三：" class="headerlink" title="案例三："></a>案例三：</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `trade_detail` (<br>    `id`            <span class="hljs-type">int</span>(<span class="hljs-number">11</span>)     <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>    `tradeid`       <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    `trade_step`    <span class="hljs-type">int</span>(<span class="hljs-number">11</span>)     <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>, <span class="hljs-comment">/*操作步骤*/</span><br>    `step_info`     <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>, <span class="hljs-comment">/*步骤信息*/</span><br>    <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (`id`),<br>    KEY `tradeid` (`tradeid`)<br>) ENGINE<span class="hljs-operator">=</span>InnoDB <span class="hljs-keyword">DEFAULT</span> CHARSET<span class="hljs-operator">=</span>utf8;<br></code></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> d.<span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tradelog l, trade_detail d <span class="hljs-keyword">where</span> d.tradeid<span class="hljs-operator">=</span>l.tradeid <span class="hljs-keyword">and</span> l.id<span class="hljs-operator">=</span><span class="hljs-number">2</span>;<br># 优化器先在 tradelog 上查到 id<span class="hljs-operator">=</span><span class="hljs-number">2</span> 的行，使用了主键索引<br># 没有使用 trade_detail 上的 trade_id 进行了全表扫描<br></code></pre></td></tr></table></figure><blockquote><p>原因：因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4</p></blockquote><blockquote><p>字符集 utf8mb4 是 utf8 的超集，所以在作比较的时候，先把 utf8 转成 utf8mb4。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> trade_detail <span class="hljs-keyword">where</span> <span class="hljs-keyword">CONVERT</span>(traideid <span class="hljs-keyword">USING</span> utf8mb4)<span class="hljs-operator">=</span>$L2.tradeid.value; # 等价于执行这条语句<br></code></pre></td></tr></table></figure><p><strong>字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是导致对被驱动表做全表扫描的原因。</strong></p><ol><li>当使用left join时，左表是驱动表，右表是被驱动表 </li><li>当使用right join时，右表时驱动表，左表是驱动表</li><li>当使用join时，mysql会选择数据量比较小的表作为驱动表，大表作为被驱动表</li></ol><p>作为对比：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> l.operator <span class="hljs-keyword">from</span> tradelog l, trade_detail d <span class="hljs-keyword">where</span> d.tradeid<span class="hljs-operator">=</span>l.tradeid <span class="hljs-keyword">and</span> d.id<span class="hljs-operator">=</span><span class="hljs-number">4</span>; # 两次查找都可以命中索引<br><br><br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> operator <span class="hljs-keyword">from</span> tradelog <span class="hljs-keyword">where</span> traideid <span class="hljs-operator">=</span><span class="hljs-keyword">CONVERT</span>($R4.tradeid.value <span class="hljs-keyword">USING</span> utf8mb4);<br># 与之前不同的是，这里的 <span class="hljs-keyword">CONVERT</span> 函数是加在参数里的<br><br></code></pre></td></tr></table></figure><h1 id="19-为什么我只查一行的语句，也执行这么慢"><a href="#19-为什么我只查一行的语句，也执行这么慢" class="headerlink" title="19 为什么我只查一行的语句，也执行这么慢"></a>19 为什么我只查一行的语句，也执行这么慢</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `t` (  <br>    `id`    <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>    `c`     <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (`id`)<br>) ENGINE<span class="hljs-operator">=</span>InnoDB;<br></code></pre></td></tr></table></figure><p>我们再往里插入十万条数据</p><h2 id="查询时间长时间不返回"><a href="#查询时间长时间不返回" class="headerlink" title="查询时间长时间不返回"></a>查询时间长时间不返回</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AD%89MDL%E9%94%81.png" class="" title="等MDL锁"><p>出现这个状态表示的是，现在有一个线程正在表上请求或者持有 MDL 写锁，把 <code>select</code> 语句 block 住了。</p><p>有一个 <code>flush table</code> 命令被别的语句 block 住了，然后又 block 住了我们的 <code>select</code> 语句。</p><h2 id="查询慢"><a href="#查询慢" class="headerlink" title="查询慢"></a>查询慢</h2><blockquote><p>坏查询不一定是慢查询</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">1</span>;                    # 慢<br>mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">1</span> lock <span class="hljs-keyword">in</span> share mode; # 快<br></code></pre></td></tr></table></figure><p>带 lock in share mode 的 SQL 是当前读，因此会直接读到最后结果；而没有 share mode 的是一致读，要从最后的结果，依次执行 undo log，才能返回正确的结果。</p><h1 id="20-幻读是什么，幻读有什么问题"><a href="#20-幻读是什么，幻读有什么问题" class="headerlink" title="20 幻读是什么，幻读有什么问题"></a>20 幻读是什么，幻读有什么问题</h1><h2 id="幻读是什么"><a href="#幻读是什么" class="headerlink" title="幻读是什么"></a>幻读是什么</h2><blockquote><p><strong>幻读</strong>指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</p></blockquote><p>在可重读度隔离级别下，普通的查询时快照读，是不会看到别的事务插入数据的。因此幻读在当前读下才会出现。</p><h2 id="幻读有什么问题"><a href="#幻读有什么问题" class="headerlink" title="幻读有什么问题"></a>幻读有什么问题</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `t` (<br>    `id`    <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>    `c`     <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    `d`     <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span>,<br>    <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (`id`),<br>    KEY `c` (`c`)<br>) ENGINE<span class="hljs-operator">=</span>InnoDB;<br><br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>,<span class="hljs-number">5</span>),(<span class="hljs-number">10</span>,<span class="hljs-number">10</span>,<span class="hljs-number">10</span>),(<span class="hljs-number">15</span>,<span class="hljs-number">15</span>,<span class="hljs-number">15</span>),(<span class="hljs-number">20</span>,<span class="hljs-number">20</span>,<span class="hljs-number">20</span>),(<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>);<br></code></pre></td></tr></table></figure><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select * from t where d=5 for update;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>update t set d=5 where id=0;</code> <br> <code>update t set c=5 where id=0;</code></td><td></td></tr><tr><td>T3</td><td><code>select * from t where d=5 for update;</code></td><td></td><td></td></tr><tr><td>T4</td><td></td><td></td><td><code>insert into t values(1, 1, 5);</code> <br> <code>update t set c=5 where id=1;</code></td></tr><tr><td>T5</td><td><code>select * from t where d=5 for update;</code></td><td></td><td></td></tr><tr><td>T6</td><td><code>commit;</code></td><td></td><td></td></tr></tbody></table><ol><li>语义上的问题<br>sessionA 在 T1 时刻声明 “我要将d=5的行锁住，不允许别的事务进行读写操作”。</li><li>数据不一致<br>会导致数据和日志在逻辑上的不一致<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d<span class="hljs-operator">=</span><span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">0</span>; <span class="hljs-comment">/*(0,0,5)*/</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> c<span class="hljs-operator">=</span><span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">0</span>; <span class="hljs-comment">/*(0,5,5)*/</span><br><br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">5</span>); <span class="hljs-comment">/*(1,1,5)*/</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> c<span class="hljs-operator">=</span><span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">1</span>; <span class="hljs-comment">/*(1,5,5)*/</span><br><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d<span class="hljs-operator">=</span><span class="hljs-number">100</span> <span class="hljs-keyword">where</span> d<span class="hljs-operator">=</span><span class="hljs-number">5</span>;<span class="hljs-comment">/*所有d=5的行,d改成100*/</span><br></code></pre></td></tr></table></figure>拿这个语句序列，无法克隆一个一模一样的库，会存在数据的不一致。</li></ol><h2 id="如何解决幻读"><a href="#如何解决幻读" class="headerlink" title="如何解决幻读"></a>如何解决幻读</h2><p>即使把所有的记录都加上锁，还是阻止不了新插入的记录。</p><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>InnoDB 引入新的锁，也就是间隙锁 (Gap Lock)。在一行行扫描的过程中，不仅将给行加上了行锁，还给两边的空隙，也加上了间隙锁，就可以确保无法再插入新的记录。</p><p>间隙锁和行锁合称 <strong>next-key lock</strong>。但是间隙锁的引入，可能会导致同样的语句锁住更大的范围</p><p>|   |  sessionA  | sessionB |<br>| - | - | - | - |<br>| T1 | <code>begin;</code> <br> <code>select * from t where id=9 for update;</code> | |<br>| T2 | | <code>begin;</code> <br> <code>select * from t where id=9 for update;</code> |<br>| T3 | | <code>insert into t values(9, 9, 9)</code> <br> (blocked)|<br>| T4 | <code>insert into t values(9, 9, 9);</code> <br> (ERROR: DEADLOCK)| |</p><p>上述情况出现的原因是 sessionA 被 sessionB 的间隙锁 block 了，同时 sessionB 也被 sessionA block 了。（因为间隙锁之间不会冲突）</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>如果把隔离级别设置为 Read Commit 就没有间隙锁了，但这时有需要解决数据与日志不一致的问题，需要把 binlog 格式设置为 row。</p><p>如果业务场景 Read Commit级别够用，即业务不需要可重复读的保证，考虑到读提交下操作数据的锁范围更小，这个选择是合理的。</p><h1 id="21-为什么我只改一行语句，锁这么多"><a href="#21-为什么我只改一行语句，锁这么多" class="headerlink" title="21 为什么我只改一行语句，锁这么多"></a>21 为什么我只改一行语句，锁这么多</h1><p>本篇还是在之前 20 的场景下</p><h2 id="两个原则，两个优化，一个bug"><a href="#两个原则，两个优化，一个bug" class="headerlink" title="两个原则，两个优化，一个bug"></a>两个原则，两个优化，一个bug</h2><ol><li>原则1：加锁的基本单位是 next-key lock。next-key lock 是前开后闭区间。</li><li>原则2：查找过程中访问到的对象才会加锁</li><li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li><li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li><li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止</li></ol><h2 id="案例一：等值查询间隙锁"><a href="#案例一：等值查询间隙锁" class="headerlink" title="案例一：等值查询间隙锁"></a>案例一：等值查询间隙锁</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>update t set d=d+1 where id=7;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>insert into t values(8, 8, 8);</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>update t set d=d+1 where id=10;</code> <br> (Query OK)</td></tr></tbody></table><p>根据<strong>优化2</strong>，next-key lock会退化为间隙锁，最终加锁的范围是(5, 10)，所以 sessionC 的修改是可以成功的。</p><h2 id="案例二：非唯一索引等值锁"><a href="#案例二：非唯一索引等值锁" class="headerlink" title="案例二：非唯一索引等值锁"></a>案例二：非唯一索引等值锁</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select id from t where c=5 lock in share mode;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>update t set d=d+1 where id=5;</code> <br> (Query OK)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>insert into t values(7, 7, 7);</code> <br> (blocked)</td></tr></tbody></table><ol><li>根据<strong>原则1</strong>，加锁单位是 next-key lock，因此会给(0, 5]加上 next-key lock。</li><li>因为c是普通索引，仅访问c=5这一条记录是不能马上停下来的，需要向右遍历，查到c=10才放弃。根据<strong>原则2</strong>，访问到的都要加锁，因此要给(5, 10]加next-key lock。</li><li>根据<strong>优化2</strong>，等值判断，向右遍历，最后一个值不满足c=5这个等值条件，退化成间隙锁(5, 10)</li><li>根据<strong>原则2</strong>，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，所以 sessionB 的 update 语句可以执行完成。但是 sessionC 要插入一个(7, 7, 7)的记录，就会被sessionA 的间隙锁锁住。</li></ol><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>锁是加在索引上的</li><li>如果要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入所有中不存在的字段。</li></ul><h2 id="案例三：主键索引范围锁"><a href="#案例三：主键索引范围锁" class="headerlink" title="案例三：主键索引范围锁"></a>案例三：主键索引范围锁</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select * from t where id&gt;=10 and id&lt;11 for update;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>insert into t values(8, 8, 8);</code> <br> (Query OK) <br> <code>insert into t values(13, 13, 13);</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>update t set d=d+1 where id=15;</code> <br> (blocked)</td></tr></tbody></table><ol><li>开始执行的时候，要找到一个id=10的行，next-key lock(5, 10]。根据<strong>优化一</strong>，主键id上的等值条件，退化成行锁，只加了id=10这一行的行锁。</li><li>范围查找就往后继续找，找到id=15这一行，需要next-key lock(10, 15]</li><li>sessionA 这时候锁的范围就是主键索引上，行锁id=10和next-key lock(10, 15]</li></ol><h2 id="案例四：非唯一索引范围锁"><a href="#案例四：非唯一索引范围锁" class="headerlink" title="案例四：非唯一索引范围锁"></a>案例四：非唯一索引范围锁</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select * from t where c&gt;=10 and c&lt;11 for update;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>insert into t values(8, 8, 8);</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>update t set d=d+1 where c=15;</code> <br> (blocked)</td></tr></tbody></table><ol><li>由于c是普通索引，不能退化成行锁，因此最终 sessionA 加的锁是，索引c上的(5, 10]和(10, 15]这两个next-key lock</li><li>InnoDB 要扫到c=15 才知道不需要继续往后找了。</li></ol><h2 id="案例五：唯一索引范围锁bug"><a href="#案例五：唯一索引范围锁bug" class="headerlink" title="案例五：唯一索引范围锁bug"></a>案例五：唯一索引范围锁bug</h2><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>select * from t where id&gt;10 and id&lt;=15 for update;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>update t set d=d+1 where id=20;</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>insert t values(16, 16, 16);</code> <br> (blocked)</td></tr></tbody></table><ol><li>根据<strong>原则1</strong>，应该是索引id上只加(10, 15]这个next-key lock，并且因为id是唯一键，所以循环判断到id=15这一行就应该停止了</li><li>但是根据<strong>一个bug</strong>，InnoDB 会往前扫描到第一个不满足条件的行 为止，因此索引id上的(15, 20]这个next-key lock也会被锁上。</li></ol><h2 id="案例六：非唯一索引上存在“等值”的例子"><a href="#案例六：非唯一索引上存在“等值”的例子" class="headerlink" title="案例六：非唯一索引上存在“等值”的例子"></a>案例六：非唯一索引上存在“等值”的例子</h2><p>先插入一条新纪录</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">mysql<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">30</span>, <span class="hljs-number">10</span>, <span class="hljs-number">30</span>);<br></code></pre></td></tr></table></figure><table><thead><tr><th></th><th>sessionA</th><th>sessionB</th><th>sessionC</th></tr></thead><tbody><tr><td>T1</td><td><code>begin;</code> <br> <code>delete from t where c=10;</code></td><td></td><td></td></tr><tr><td>T2</td><td></td><td><code>insert into t values(12, 12, 12);</code> <br> (blocked)</td><td></td></tr><tr><td>T3</td><td></td><td></td><td><code>update t set d=d+1 where c=15;</code> <br> (Query OK)</td></tr></tbody></table><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/21-%E6%A1%88%E4%BE%8B%E5%85%AD.png" class="" title="21-案例六"><p>两个c=10的记录之间，也是有间隙的。</p><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/21-%E6%A1%88%E4%BE%8B%E5%85%AD%E5%8A%A0%E9%94%81%E7%A4%BA%E6%84%8F%E5%9B%BE.png" class="" title="21-案例六加锁示意图"><p>根据<strong>优化2</strong>，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10, id=10) 到 (c=15, id=15)的间隙锁。</p><h2 id="案例七：limit-语句加锁"><a href="#案例七：limit-语句加锁" class="headerlink" title="案例七：limit 语句加锁"></a>案例七：limit 语句加锁</h2><p>|   |  sessionA  | sessionB |<br>| - | - | - | - |<br>| T1 | <code>begin;</code> <br> <code>delete from t where c=10 limit 2;</code> | |<br>| T2 | | <code>insert into t values(12, 12, 12);</code> <br> (Query OK) |</p><p><code>delete</code> 语句明确加了 limit 2 的限制，因此在遍历到(c=10, id=30)这一行后，满足条件的语句就已经有两条，循环就结束了。</p><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/21-%E6%A1%88%E4%BE%8B%E4%B8%83%E5%8A%A0%E9%94%81%E7%A4%BA%E6%84%8F%E5%9B%BE.png" class="" title="21-案例七加锁示意图"><blockquote><p>在删除数据的时候尽量加limit</p></blockquote><h2 id="案例八：一个死锁的例子"><a href="#案例八：一个死锁的例子" class="headerlink" title="案例八：一个死锁的例子"></a>案例八：一个死锁的例子</h2><p>|   |  sessionA  | sessionB |<br>| - | - | - | - |<br>| T1 | <code>begin;</code> <br> <code>select id from t where c=10 lock in share mode;</code> | |<br>| T2 | | <code>update t set d=d+1 where c=10;</code> <br> (blocked) |<br>| T3 | <code>insert into t values(8, 8, 8)</code>| |<br>| T4 | | (ERROR: DEADLOCK) |</p><ol><li>sessionA 启动事务后执行查询语句加 lock in share mode，在索引c上加了next-key locks(5, 10]和间隙锁(10, 15)</li><li>sessionB 的update语句也要在索引c上加next-key lock(5, 10]，进入锁等待</li><li>然后sessionA 要再插入(8, 8, 8)这一行，被sessionB 的间隙锁锁住。由于出现了死锁，需要回滚。</li></ol><h2 id="案例九：desc导致的顺序差异"><a href="#案例九：desc导致的顺序差异" class="headerlink" title="案例九：desc导致的顺序差异"></a>案例九：desc导致的顺序差异</h2><p>|   |  sessionA  | sessionB |<br>| - | - | - | - |<br>| T1 | <code>begin;</code> <br> <code>select * from t where c&gt;=15 and c&lt;=20 order by c desc in share mode;</code> | |<br>| T2 | | <code>insert into t values(6, 6, 6);</code> <br> (blocked) |</p><ol><li>因为这里使用的是 <code>desc</code> 所以是从右往左扫描的。</li><li>根据<strong>优化2</strong>，先判断条件c&lt;=20，普通索引等值c=20，所以间隙锁(20, 25)</li><li>20 到 15，所以next-key locks(20, 15]</li><li>判断c&gt;=15，普通索引c=15，向左匹配到c=10这个记录，因为next-key locks是前开后闭的，所以只能是(5, 10]</li><li>最后的范围是 (5, 15)+[15, 20)+[20, 25)</li><li>c=20、c=15、c=10 都存在值， select *主键 id 加三个行锁。</li></ol><p>如果没有desc 锁的应该是(10, 15] + (15, 20] + (20, 25) 加上 15 20 主键id 两个行锁</p><h1 id="22-MySQL-有哪些“饮鸩止渴”提高性能的方法"><a href="#22-MySQL-有哪些“饮鸩止渴”提高性能的方法" class="headerlink" title="22 MySQL 有哪些“饮鸩止渴”提高性能的方法"></a>22 MySQL 有哪些“饮鸩止渴”提高性能的方法</h1><h2 id="短连接风暴"><a href="#短连接风暴" class="headerlink" title="短连接风暴"></a>短连接风暴</h2><ol><li>先处理掉那些占着连接但是不工作的线程</li></ol><ul><li>如果是连接数过多，你可以优先断开事务外空闲太久的连接。</li><li>如果这样还不够，可以考虑断开事务内空闲太久的连接。 </li></ul><blockquote><p>从数据库端断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的 handler 重试查询。这会导致从应用端看上去——“MySQL一直没恢复”。</p></blockquote><ol start="2"><li>减少连接过程的消耗</li></ol><p>如果现在数据库确认是被连接行为打挂了，那么可以让数据库跳过权限验证阶段。重启数据库，并使用 <code>-skip-grant-tables</code> 参数启动。但是这个方法风险极高。</p><h2 id="慢查询性能问题"><a href="#慢查询性能问题" class="headerlink" title="慢查询性能问题"></a>慢查询性能问题</h2><h3 id="索引没有设计好"><a href="#索引没有设计好" class="headerlink" title="索引没有设计好"></a>索引没有设计好</h3><p>通过紧急创建索引来解决</p><ol><li>在备库B上执行 <code>set sql_log_bin=off</code>, 也就是不写 binlog, 然后执行 <code>alter table</code> 语句加上索引</li><li>执行主备切换</li><li>这时候主库是B, 备库是A。在A上执行 <code>set sql_log_bin=off</code>, 然后执行 <code>alter table</code> 语句加上索引<h3 id="SQL-语句没有写好"><a href="#SQL-语句没有写好" class="headerlink" title="SQL 语句没有写好"></a>SQL 语句没有写好</h3>详见 <a href="">18 为什么这些SQL语句逻辑相同，性能却差异巨大</a><h3 id="MySQL-选错了索引"><a href="#MySQL-选错了索引" class="headerlink" title="MySQL 选错了索引"></a>MySQL 选错了索引</h3>详见 <a href="">10 MySQL 为什么有时候会选错索引</a><br>可以通过添加语句 <code>force index</code> </li></ol><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>那么我们如何尽量避免这类性能问题的发生呢？</p><ol><li>上线前，在测试环境，把慢查询日志（slow log）打开，并且把long_query_time设置成0，确保每个语句都会被记录入慢查询日志</li><li>在测试表里插入模拟线上的数据，做一遍回归测试</li><li>观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致。</li></ol><h2 id="QPS-突增问题"><a href="#QPS-突增问题" class="headerlink" title="QPS 突增问题"></a>QPS 突增问题</h2><p>有时候由于业务突然出现高峰，或者应用程序bug，导致某个语句的QPS突然暴涨，也可能导致MySQL压力过大，影响服务。</p><h1 id="23-MySQL-是怎么保证数据不丢的"><a href="#23-MySQL-是怎么保证数据不丢的" class="headerlink" title="23 MySQL 是怎么保证数据不丢的"></a>23 MySQL 是怎么保证数据不丢的</h1><h2 id="binlog-的写入机制"><a href="#binlog-的写入机制" class="headerlink" title="binlog 的写入机制"></a>binlog 的写入机制</h2><blockquote><p>事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p></blockquote><p>TODO</p><h1 id="24-MySQL-是怎么保证主备一致的？"><a href="#24-MySQL-是怎么保证主备一致的？" class="headerlink" title="24 MySQL 是怎么保证主备一致的？"></a>24 MySQL 是怎么保证主备一致的？</h1><h2 id="MySQL-主备的基本原理"><a href="#MySQL-主备的基本原理" class="headerlink" title="MySQL 主备的基本原理"></a>MySQL 主备的基本原理</h2><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/24-MySQL%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%B5%81%E7%A8%8B.png" class="" title="24-MySQL主备切换流"><p>这就是基本的主备切换流程。</p><img src="/2021/01/12/MySQL%E5%AE%9E%E6%88%98-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/24-%E4%B8%BB%E5%A4%87%E6%B5%81%E7%A8%8B%E5%9B%BE.png" class="" title="24-主备流程图"><ol><li>在备库B上通过 change master 命令，设置主库A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。</li><li>在备库B上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。</li><li>主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取 binlog，发给B。</li><li>备库B拿到 binlog 后，写到本地文件，称为中转日志(relay log)</li><li>sql_thread 读取中转日志，解析出日志里的命令，并执行。</li></ol><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://drive.google.com/drive/folders/168dQ754KYC9QFikDy6iTq0mKHWYJkz8p">MySQL实战45讲</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>读书笔记</tag>
      
      <tag>极客</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL-索引</title>
    <link href="/2021/01/05/MySQL-%E7%B4%A2%E5%BC%95/"/>
    <url>/2021/01/05/MySQL-%E7%B4%A2%E5%BC%95/</url>
    
    <content type="html"><![CDATA[<p>B树和B+树的具体结构在此不做赘述。好不容易弄明白了索引的底层实现，结果被面试官问为什么要使用B+索引，用Hash不香嘛。下了面试一查，发现居然还有Hash索引，真是吃了没有文化的亏呀。防不胜防，在此补作一笔。</p><p>首先要明白索引(index)是在存储引擎层面实现的，而不是server层面</p><h1 id="什么是索引"><a href="#什么是索引" class="headerlink" title="什么是索引"></a>什么是索引</h1><p>索引（Index）是帮助数据库高效获取数据的数据结构。索引是在基于数据库表创建的，它包含一个表中某些列的值以及记录对应的地址，并且把这些值存储在一个数据结构中。最常见的就是使用哈希表、B+树作为索引。我们会为每一个字段去建索引。</p><h1 id="从数据结构角度分类"><a href="#从数据结构角度分类" class="headerlink" title="从数据结构角度分类"></a>从数据结构角度分类</h1><p>实际上，还有Fulltext索引和R-Tree索引，但是这里简略带过。</p><ul><li>InnoDB存储引擎：默认是B+Tree 索引</li><li>MyISAM存储引擎：默认是Fulltext 索引</li><li>Memory存储引擎：默认Hash 索引。（也是可以使用B+Tree索引的）</li></ul><h2 id="Hash索引"><a href="#Hash索引" class="headerlink" title="Hash索引"></a>Hash索引</h2><p>来，说说这个神奇的东西。Hash索引把数据以hash形式组织起来，因此当查找某一条记录的时候，速度非常快。但是因为hash结构，每个键只对应一个值，而且是散列的方式分布。<strong>所以它并不支持范围查找和排序等功能。</strong></p><ul><li>Hash 索引无法完成排序</li><li>不支持最左匹配原则</li><li>在有大量重复键值情况下，Hash 索引的效率也很低</li><li>不支持范围查询</li></ul><h2 id="B-Tree索引"><a href="#B-Tree索引" class="headerlink" title="B+Tree索引"></a>B+Tree索引</h2><p>相比Hash索引，B+Tree在查找单条记录的速度比不上Hash索引，但是因为更加适合排序等操作，所以更加受欢迎。(想起我跟面试官信誓旦旦的说B+Tree肯定查的快真是丢人😢)</p><ul><li>带顺序访问指针的B+Tree<ul><li>B+Tree所有的缩影数据都在叶子节点上，并且相比于B Tree增加了顺序访问指针，每个叶子结点都有指向相邻叶子节点的指针。</li><li>这样做是为了提高区间效率，例如查询key为从18到49的所有数据记录，当找到18后，只要顺着节点和指针顺序遍历就可以以此向访问到所有数据节点，极大提高了区间查询效率。</li></ul></li><li>大大减少磁盘I/O读取<ul><li>数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点需要一次I/O就可以完全载入。</li></ul></li></ul><h2 id="Full-Text全文索引"><a href="#Full-Text全文索引" class="headerlink" title="Full-Text全文索引"></a>Full-Text全文索引</h2><ul><li>可以用全文索引代替效率较低的LIKE模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。</li><li>同样适用B-Tree存放索引数据，但使用的是特定的算法，将字段数据分割后再进行索引，索引文件存储的是分割前的索引字符串集合，与分割后的索引信息，对应B-Tree结构的节点储存的是分割后的词信息以及它在分割前的索引字符串集合中的位置。</li></ul><h2 id="R-Tree空间索引"><a href="#R-Tree空间索引" class="headerlink" title="R-Tree空间索引"></a>R-Tree空间索引</h2><ul><li>空间索引是MyISAM的一种特殊索引类型，主要用于地理空间数据类型</li></ul><h1 id="从物理存储角度：聚簇索引与非聚簇索引"><a href="#从物理存储角度：聚簇索引与非聚簇索引" class="headerlink" title="从物理存储角度：聚簇索引与非聚簇索引"></a>从物理存储角度：聚簇索引与非聚簇索引</h1><p>B+Tree索引可以分为聚簇缩影和非聚簇索引，但本质还是使用B+Tree实现的，即高度是平衡的，叶子节点存放所有的数据<b>聚集索引与非聚集索引的区别是：叶节点是否存放一整行记录。非聚簇索引是叶子节点存储的是索引+索引对应的记录的数据，聚簇索引是叶子节点上的数据是主键与具体记录(数据内容)</b>每张表只能有一个聚簇索引。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://juejin.im/post/5cdd701ee51d453a36384939">https://juejin.im/post/5cdd701ee51d453a36384939</a></p><h1 id="从逻辑角度分类"><a href="#从逻辑角度分类" class="headerlink" title="从逻辑角度分类"></a>从逻辑角度分类</h1><ul><li><p>主键索引</p><ul><li>是一种特殊的唯一索引，不允许有空值。</li></ul></li><li><p>唯一索引</p><ul><li>与“普通索引”类似，不同的就是：索引列的值必须唯一，但允许有空值。</li></ul></li><li><p>普通索引</p><ul><li>最基本的索引，没有任何限制。</li></ul></li><li><p>全文索引</p><ul><li>仅可用于MyISAM和InnoDB，针对较大的数据，生成全文索引很耗时耗空间。</li></ul></li><li><p>倒排索引</p><ul><li><p>全文检索使用倒排索引来实现，倒排索引同B+树索引一样，也是一种数据结构，它在辅助表中存储了单词与单词自身在一个或多个文档中所在位置的映射，这通常利用关联数组实现。</p></li><li><p>倒排索引它需要将分词（word）存储在一个辅助表（Auxiliary Table）中，为了提高全文检索的并行性能，共有6张辅助表。辅助表中存储了单词和单词在各行记录中位置的映射关系。它分为两种：<b>倒排文件索引</b>，<b>详细倒排索引</b></p><ul><li>Inverted file index 倒排文件索引，表现为{单词，单词所在文档ID}</li><li>Full inverted index 详细倒排索引，表现为{单词，(单词所在文档ID, 文档中的位置)}</li></ul></li><li><p><a href="https://www.zhihu.com/question/23202010">倒排索引为什么叫倒排索引？</a></p></li></ul></li></ul><h2 id="组合索引"><a href="#组合索引" class="headerlink" title="组合索引"></a>组合索引</h2><p>为了更多的提高mysql效率可建立组合索引，遵循”最左前缀”原则。创建复合索引应该将最常用（频率）做限制条件的列放在最左边，一次递减。组合索引最左字段用in是可以用到索引的。</p><h2 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h2><p>覆盖索引只一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。如果一个索引包含(或覆盖)满足查询语句中字段与条件的数据就叫做覆盖索引。</p><h1 id="最左匹配原则"><a href="#最左匹配原则" class="headerlink" title="最左匹配原则"></a>最左匹配原则</h1><p>最左匹配原则就是指在联合索引中，如果你的 SQL 语句中用到了联合索引中的最左边的索引，那么这条 SQL 语句就可以利用这个联合索引去进行匹配。</p><blockquote><p>示例1 </p></blockquote><p>假设有索引(a,b,c)</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样可以利用到定义的索引（a,b,c）<br><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样可以利用到定义的索引（a,b,c）<br><br># 借助mysql查询优化器explain，explain会纠正<span class="hljs-keyword">sql</span>语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样可以利用到定义的索引（a,b,c）<br><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样也可以利用到定义的索引（a,b,c）<br><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样不可以利用到定义的索引（a,b,c）<br><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c<span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样不可以利用到定义的索引（a,b,c）<br><br># 当遇到范围查询(<span class="hljs-operator">&gt;</span>、<span class="hljs-operator">&lt;</span>、<span class="hljs-keyword">between</span>、<span class="hljs-keyword">like</span>)就会停止匹配<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b<span class="hljs-operator">&gt;</span><span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span><span class="hljs-number">1</span>;     #这样a,b可以用到（a,b,c），c不可以<br><br></code></pre></td></tr></table></figure><blockquote><p>示例2</p></blockquote><p>假设对列<code>col1</code>,<code>col2</code>,<code>col3</code>建立一个联合索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs SQL">KEY test_col1_col2_col3 <span class="hljs-keyword">on</span> test(col1,col2,col3)<br></code></pre></td></tr></table></figure><p>联合索引<code>test_col1_col2_col3</code>实际上建立了<code>(col1)</code>,<code>(col1,col2)</code>,<code>(col1,col2,col3)</code>三个索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> test <span class="hljs-keyword">WHERE</span> col1<span class="hljs-operator">=</span>“<span class="hljs-number">1</span>” <span class="hljs-keyword">AND</span> clo2<span class="hljs-operator">=</span>“<span class="hljs-number">2</span>” <span class="hljs-keyword">AND</span> clo4<span class="hljs-operator">=</span>“<span class="hljs-number">4</span>”<br></code></pre></td></tr></table></figure><p>上面这个查询语句执行时会依照最左前缀匹配的原则，检索时会使用索引<code>(col1,col2)</code>进行数据匹配</p><h2 id="最左匹配原则的原理"><a href="#最左匹配原则的原理" class="headerlink" title="最左匹配原则的原理"></a>最左匹配原则的原理</h2><p>因为构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树</p><blockquote><p>示例</p></blockquote><p>假如创建一个(a,b,c)的联合索引</p><p>该图就是一个形如(a,b,c)联合索引的 b+ 树，其中的非叶子节点存储的是第一个关键字的索引 a，而叶子节点存储的是三个关键字的数据。这里可以看出 a 是有序的，而 b，c 都是无序的。但是当在 a 相同的时候，b 是有序的，b 相同的时候，c 又是有序的。通过对联合索引的结构的了解，那么就可以很好的了解为什么最左匹配原则中如果遇到范围查询就会停止了。以 <code>select * from t where a=5 and b&gt;0 and c =1; </code>这样a,b可以用到（a,b,c），c不可以 为例子，当查询到 b 的值以后（这是一个范围值），c 是无序的。所以就不能根据联合索引来确定到低该取哪一行。</p><h1 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.cnblogs.com/aspirant/p/9214485.html">https://www.cnblogs.com/aspirant/p/9214485.html</a></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL-事务</title>
    <link href="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/"/>
    <url>/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="数据库ACID特性"><a href="#数据库ACID特性" class="headerlink" title="数据库ACID特性"></a>数据库ACID特性</h1><h2 id="原子性-Atomicity"><a href="#原子性-Atomicity" class="headerlink" title="原子性 Atomicity"></a>原子性 Atomicity</h2><p>一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部回滚失败。</p><h2 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性 Consistency"></a>一致性 Consistency</h2><p>数据库总是从一个一致性状态转换到另一个一致性状态。</p><h2 id="隔离性-Isolation"><a href="#隔离性-Isolation" class="headerlink" title="隔离性 Isolation"></a>隔离性 Isolation</h2><p>一个事务在做提交之前，对其他事物是不可见的。</p><h2 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h2><p>一旦事务提交，其所作的修改就会永久的保存在数据库中。</p><h1 id="MVCC-多版本并发控制"><a href="#MVCC-多版本并发控制" class="headerlink" title="MVCC 多版本并发控制"></a>MVCC 多版本并发控制</h1><p>我们在数据库表中看到的一行记录可能实际上有多个版本，每个版本的记录除了有数据本身外，还要有一个表示版本的字段 <code>row trx_id</code>，这个字段就是使其产生的事务id，记为 <code>transcation id</code>，在事务开始的时候向事务系统申请，按时间顺序递增。</p><img src="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/%E4%BA%8B%E5%8A%A1ID.png" class="" title="事务ID"><p>可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。</p><p><b>MVCC 的实现是通过保存数据在某个时间点的快照来实现的。</b>也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。</p><p>典型的MVCC实现方式，分为乐观（optimistic）并发控制和悲观（pressimistic）并发控制。下边通过 InnoDB的简化版行为来说明 MVCC 是如何工作的。</p><p>InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是真实的时间，而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。</p><ul><li>SELECT<ul><li>InnoDB会根据以下两个条件检查没行记录：<ul><li>a. InnoDB只会查找版本早于当前事务版本的数据行（也就是，行的系统版本小于或等于事务的系统版本号），<br>这样可以确保事务读取到的行，要么是事务开始前已经存在的，要么是事务自身插入或者修改过的。</li><li>b. 行的删除版本要么未定义，要么大于当前事务的版本号。这样可以确保事务读取到的行，在事务之前未被<br>删除。<br>只有符合上述两个条件的记录，才能被作为返回查询结果</li></ul></li></ul></li><li>INSERT<ul><li>InnoDB 为新插入的每一行保存当前系统版本号作为行版本号</li></ul></li><li>DELETE<ul><li>InnoDB 为删除的每一行保存当前系统版本号作为行删除标识</li></ul></li><li>UPDATE<ul><li>InnoDB 为插入一行新纪录，保存当前系统版本号作为版本号，同时保存当前系统版本号到原来的行作为行删除标识。</li></ul></li></ul><h1 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h1><h2 id="数据库事务隔离级别"><a href="#数据库事务隔离级别" class="headerlink" title="数据库事务隔离级别"></a>数据库事务隔离级别</h2><table><thead><tr><th></th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>Read Uncommitted</td><td>可能</td><td>可能</td><td>可能</td></tr><tr><td>Read Committed</td><td>不可能</td><td>可能</td><td>可能</td></tr><tr><td>Repeatable Read</td><td>不可能</td><td>不可能</td><td>可能</td></tr><tr><td>Serializable</td><td>不可能</td><td>不可能</td><td>不可能</td></tr></tbody></table><h3 id="脏读、不可重复读、幻读"><a href="#脏读、不可重复读、幻读" class="headerlink" title="脏读、不可重复读、幻读"></a>脏读、不可重复读、幻读</h3><ul><li><p>脏读</p><p>  脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。</p></li><li><p>不可重复读</p><p>  是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。（即不能读到相同的数据内容）</p><p>  例如，一个编辑人员两次读取同一文档，但在两次读取之间，作者重写了该文档。当编辑人员第二次读取文档时，文档已更改。原始读取不可重复。如果只有在作者全部完成编写后编辑人员才可以读取文档，则可以避免该问题。</p></li><li><p>幻读</p><p>  是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。</p><p>  例如，一个编辑人员更改作者提交的文档，但当生产部门将其更改内容合并到该文档的主复本时，发现作者已将未编辑的新材料添加到该文档中。如果在编辑人员和生产部门完成对原始文档的处理之前，任何人都不能将新材料添加到文档中，则可以避免该问题。</p></li></ul><h3 id="四种隔离级别的解读"><a href="#四种隔离级别的解读" class="headerlink" title="四种隔离级别的解读"></a>四种隔离级别的解读</h3><h4 id="Read-Uncommitted"><a href="#Read-Uncommitted" class="headerlink" title="Read Uncommitted"></a>Read Uncommitted</h4><p>最差的隔离级别，一个事务可以读到另一个事务没有commit时的数据</p><h4 id="Read-Committed"><a href="#Read-Committed" class="headerlink" title="Read Committed"></a>Read Committed</h4><p>当隔离级别设置为Read committed 时，一个事务虽然不能读未commit的数据，但是别的事务可以修改当前读过的数据，造成前后不一致。大多数数据库的默认级别就是Read committed，比如Sql Server , Oracle。</p><h4 id="Repeatable-Read"><a href="#Repeatable-Read" class="headerlink" title="Repeatable Read"></a>Repeatable Read</h4><p>虽然Repeatable read避免了不可重复读，但还有可能出现幻读 。</p><h4 id="Serializable"><a href="#Serializable" class="headerlink" title="Serializable"></a>Serializable</h4><p>Serializable 是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。</p><h2 id="快照-Snapshot"><a href="#快照-Snapshot" class="headerlink" title="快照 (Snapshot)"></a>快照 (Snapshot)</h2><p>快照又叫一致性视图，快照需要遵循以下规则：</p><ul><li>当前事务内的更新，可读</li><li>版本未提交，不可读</li><li>版本已提交，但是在快照创建后提交的，不可读</li><li>版本已提交，且是在快照创建前提交的，可读</li></ul><h3 id="快照读-vs-当前读"><a href="#快照读-vs-当前读" class="headerlink" title="快照读 vs. 当前读"></a>快照读 vs. 当前读</h3><ul><li>快照读<ul><li>读取的是记录数据的可见版本（可能是过期的数据），不用加锁</li></ul></li><li>当前读<ul><li>读取的是记录数据的最新版本，并且当前读返回的记录都会加上锁，保证其他事务不会再并发的修改这条记录</li></ul></li></ul><h2 id="隔离的实现"><a href="#隔离的实现" class="headerlink" title="隔离的实现"></a>隔离的实现</h2><h3 id="四种隔离级别的实现"><a href="#四种隔离级别的实现" class="headerlink" title="四种隔离级别的实现"></a>四种隔离级别的实现</h3><h4 id="读未提交-Read-Uncommitted"><a href="#读未提交-Read-Uncommitted" class="headerlink" title="读未提交 (Read Uncommitted)"></a>读未提交 (Read Uncommitted)</h4><p>这种隔离性是不加锁的。</p><h4 id="串行化"><a href="#串行化" class="headerlink" title="串行化"></a>串行化</h4><p>读的时候加共享锁(其他事务可以并发读)，但是不能写；写的时候加排他锁，其他事务不能并发写也不能并发读。</p><h4 id="读提交-Read-Committed"><a href="#读提交-Read-Committed" class="headerlink" title="读提交 (Read Committed)"></a>读提交 (Read Committed)</h4><p>而读提交则是每次执行语句的时候都重新生成一次快照。</p><h4 id="可重复读-Repeatable-Read"><a href="#可重复读-Repeatable-Read" class="headerlink" title="可重复读 (Repeatable Read)"></a>可重复读 (Repeatable Read)</h4><p>可重复读是在事务开始的时候生成一个当前事务全局性的快照。</p><h3 id="并发写问题"><a href="#并发写问题" class="headerlink" title="并发写问题"></a>并发写问题</h3><p>更新之前要先读取数据，这里用的是<strong>当前读</strong>，总是当前版本的数据，也就是多版本中最新一次提交的那版。</p><p>假设事务A要执行 update 操作，需要对所修改的行加行锁，这个行锁会在提交之后才释放。这时候事务B就没办法更新这行，直到事务A提交后释放行锁。</p><p>加锁过程要分有索引和无索引</p><ul><li>有索引<ul><li>MySQL 直接就在索引数中找到了这行数据，然后干净利落的加上行锁就可以了。</li></ul></li><li>无索引<ul><li>MySQL 会为这张表中<strong>所有行</strong>加行锁，在加上行锁后，MySQL 会进行一遍过滤，发现不满足的行就释放锁，最终只留下符合条件的行。</li></ul></li></ul><h3 id="解决幻读"><a href="#解决幻读" class="headerlink" title="解决幻读"></a>解决幻读</h3><blockquote><p>MySQL 如果使用 InnoDB 是可以在可重复读隔离级别下解决幻读问题。MyISAM 是不支持行级锁的，所以还会出现幻读的问题。</p></blockquote><p>MySQL 把行锁和间隙锁合并在一起，解决了并发写和幻读的问题，这个锁叫做 Next-Key 锁。</p><p>假设现在表中有两条记录，并且 age 字段已经添加了索引，两条记录 age 的值分别为 10 和 30。</p><img src="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/%E5%B9%BB%E8%AF%BB-1.png" class="" title="幻读-1"><p>此时，在数据库中会为索引维护一套 B+ 树，用来快速定位行记录。</p><img src="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/%E5%B9%BB%E8%AF%BB-2.png" class="" title="幻读-2"><p>如图所示，分成了3 个区间，(负无穷,10]、(10,30]、(30,正无穷]，在这3个区间是可以加间隙锁的。</p><p>之后，我用下面的两个事务演示一下加锁过程。</p><img src="/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/%E5%B9%BB%E8%AF%BB-3.png" class="" title="幻读-3"><p>在事务A提交之前，事务B的插入操作只能等待，这就是间隙锁起得作用。当事务A执行<code>update user set name=&#39;风筝2号’ where age = 10;</code> 的时候，由于条件 where age = 10 ，数据库不仅在 age = 10 的行上添加了行锁，而且在这条记录的两边，也就是(负无穷,10]、(10,30]这两个区间加了间隙锁，从而导致事务B插入操作无法完成，只能等待事务A提交。不仅插入 age = 10 的记录需要等待事务A提交，age &lt; 10、10 &lt; age &lt; 30 的记录页无法完成，而大于等于30的记录则不受影响，这足以解决幻读问题了。</p><p>这是有索引的情况，如果 age 不是索引列，那么数据库会为整个表加上间隙锁。所以，如果是没有索引的话，不管 age 是否大于等于30，都要等待事务A提交才可以成功插入。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.cnblogs.com/fengzheng/p/12557762.html">一文讲清楚MySQL事务隔离级别和实现原理</a></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ZooKeeper初探</title>
    <link href="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/"/>
    <url>/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="ZooKeeper-是什么"><a href="#ZooKeeper-是什么" class="headerlink" title="ZooKeeper 是什么"></a>ZooKeeper 是什么</h1><blockquote><p>ZooKeeper 是一个分布式协调服务 (service for coordinating processes of distributed applications)</p></blockquote><ul><li>协调: 在一个并发的环境里，我们为了避免多个运行单元对共享数据同时进行修改，造成数据损坏的情况出现，我们就必须依赖像锁这样的协调机制.</li><li>我们在进程内还有各种各样的协调机制(一般我们称之为同步机制)。现在我们大概了解了什么是协调了，但是上面介绍的协调都是在进程内进行协调。在进程内进行协调我们可以使用语言，平台，操作系统等为我们提供的机制。</li><li>有两台机器A、B，A 对一个数据进行了一个操作，B是如何同步得到这个结果的，在分布式环境中，就需要一个分布式协调服务。</li><li>ZooKeeper = 文件系统 + 通知机制</li></ul><h1 id="ZooKeeper-可以干什么"><a href="#ZooKeeper-可以干什么" class="headerlink" title="ZooKeeper 可以干什么"></a>ZooKeeper 可以干什么</h1><p><code>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.</code></p><p>这句话描述了 ZooKeeper 可以进行: <code>配置管理</code>, <code>命名服务</code>, <code>分布式同步</code>, <code>集群管理</code>.</p><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><p>如果我们的配置很多，分布式系统中的服务器都需要这个配置。这时候，往往需要寻找一种集中管理配置的办法——我们在集群中的地方修改了配置，所有对这个配置感兴趣的都可以获得变更。</p><p>把公用的配置文件提取出来放在一个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会受到 ZooKeeper 的通知，然后从 ZooKeeper 获取新的配置应用信息。由于需要很高的可靠性，一般我们用一个集群来提供配置服务，但是用集群提升可靠性，如何保证及群众的一致性呢？</p><p>需要使用一种已经实现了一致性协议的服务。ZooKeeper 就是这种服务，它使用了 Zab 这种一致性协议来提供一致性。</p><h2 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h2><p>由于 IP 地址对人非常不友好，我们需要使用域名来访问。但是因为计算机不能识别域名，所以每台机器都有一份域名到 IP 地址的映射。如果域名对应的 IP 地址发生了变化怎么处理呢？</p><p>于是我们使用 DNS (Domain Name System) 。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。</p><p>Zookeeper的命名功能就是这么一个服务器。在集群中，相同的一个服务有很多个提供者，这些提供者启动时，提供者的相关信息（服务接口，地址，端口等）注册到 ZooKeeper 中，当消费者要消费某服务的时候，从 ZooKeeper 中获取该服务的所有提供者的信息目录，再根据 Dubbo 的负载均衡机制选择一个提供者。</p><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>可以利用 ZooKeeper 来协调多个分布式进程之间的活动。使用分布式锁，在某个时刻只让一个服务去干活，当这台服务出问题的时候锁释放，立即 fail over 到另外的服务。</p><p>这种机制也被称为 Leader Election</p><h2 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h2><p>集群中的机器要感知到其他节点的变化(有新的节点加入进来，或者有老的节点退出集群)</p><h1 id="ZooKeeper-的数据模型"><a href="#ZooKeeper-的数据模型" class="headerlink" title="ZooKeeper 的数据模型"></a>ZooKeeper 的数据模型</h1><p>很像数据结构当中的树，也很像文件系统的目录</p><img src="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/ZooKeeper%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" class="" title="ZooKeeper数据结构"><p>这种节点叫做<strong>Znode</strong>，<strong>Znode</strong>的引用方式是<strong>路径引用</strong>：</p><ul><li>/动物/仓鼠</li><li>/植物/荷花</li></ul><p>这样的层级结构，让每一个<strong>Znode</strong>节点拥有唯一的路径</p><h2 id="Znode"><a href="#Znode" class="headerlink" title="Znode"></a>Znode</h2><p>Znode 包含了数据、子节点引用、访问权限</p><ul><li>data<ul><li>Znode 存储的数据信息</li></ul></li><li>ACL<ul><li>记录 Znode 的访问权限，即哪些人哪些 IP 可以访问本节点</li></ul></li><li>stat<ul><li>包含 Znode 的各种元数据，比如事务ID，版本号，时间戳，大小等等</li></ul></li><li>child<ul><li>当前节点的子节点引用</li></ul></li></ul><p>一共有三种类型的Znode</p><ul><li>Regular<ul><li>这种 Znode 一旦创建，就永久存在，除非你删除了它</li></ul></li><li>Ephemeral<ul><li>如果 ZooKeeper 认为创建它的客户端挂了，他会删除这种类型的 Znode。</li><li>这种类型的 Znode 与客户端会话绑在一起，所以客户端会定时发送心跳给 ZooKeeper。</li></ul></li><li>Sequential<ul><li>当你想要以特定的名字创建一个文件，ZooKeeper 实际上创建的文件名是你指定的文件名再加上一个数字。</li><li>当有多个客户端同时创建 Sequential 文件时，ZooKeeper 会确保这里的数字是递增的。</li></ul></li></ul><p>ZooKeeper 是为读多写少的场景所设计，用于存储少量的状态和配置信息，每个节点的数据最大不能超过 1 MB</p><h1 id="ZooKeeper-基本操作和事件通知"><a href="#ZooKeeper-基本操作和事件通知" class="headerlink" title="ZooKeeper 基本操作和事件通知"></a>ZooKeeper 基本操作和事件通知</h1><ul><li><code>create(path, data, flag)</code> 创建节点<ul><li>flag 是表明 Znode 的类型的</li><li>如果得到了 yes 的返回，那么说明这个文件之前是不存在的</li><li>如果得到了 no 或者一个错误返回，那么说明这个文件之前就已经存在了</li></ul></li><li><code>delete(path, version)</code> 删除节点<ul><li>当且仅当 Znode 的当前版本号与传入的 version 相同，才执行操作。</li></ul></li><li><code>exist(path, watch)</code> 判断一个节点是否存在<ul><li>watch 可以监听对应文件的变化</li><li>判断文件是否存在和 watch 文件的变化在 ZooKeeper 中属于原子操作。</li></ul></li><li><code>getData(path, watch)</code> 获取一个节点的数据</li><li><code>setData(path, data, watch)</code> 设置一个节点的数据<ul><li>当且仅当文件的版本号与传入的 version 一致时，才会更新文件</li></ul></li><li><code>getChildren(watch)</code> 获取节点下的所有子节点</li></ul><p><strong>watch</strong> 是指注册在特定 Znode 上的触发器。当这个 Znode 发生改变，也就是调用了 <code>getData</code>, <code>setData</code>, <code>getChildren</code> 的时候，将会触发 Znode 上注册的对应事件，请求 <strong>watch</strong> 的客户端会接受到异步通知。</p><ol><li>客户端调用 <code>getData</code> 方法，watch 参数是 true。服务端接到请求，返回节点数据，并且在对应的哈希表里插入被 Watch 的 Znode 路径，以及 Watcher 列表。</li></ol><img src="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/watch%E7%9A%84%E5%85%B7%E4%BD%93%E4%BA%A4%E4%BA%92-1.png" class="" title="watch的具体交互-1"><ol start="2"><li>当被 Watch 的 Znode 已删除，服务端会查找哈希表，找到该 Znode 对应的所有 Watcher，异步通知客户端，并且删除哈希表中对应的 Key-Value。</li></ol><img src="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/watch%E7%9A%84%E5%85%B7%E4%BD%93%E4%BA%A4%E4%BA%92-2.png" class="" title="watch的具体交互-2"><h1 id="ZooKeeper-的一致性"><a href="#ZooKeeper-的一致性" class="headerlink" title="ZooKeeper 的一致性"></a>ZooKeeper 的一致性</h1><p>ZooKeeper 为了防止单机挂掉的情况，维护了一个集群。</p><img src="/2020/12/30/ZooKeeper%E5%88%9D%E6%8E%A2/ZooKeeper%E9%9B%86%E7%BE%A4.png" class="" title="ZooKeeper集群"><ul><li>ZooKeeper Service 集群是一主多从结构</li><li>在更新数据时，首先更新到主节点(服务器, 不是 Znode)，再同步到从节点。</li><li>在读取数据时，直接读取任意从节点。</li></ul><h2 id="ZAB-协议"><a href="#ZAB-协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h2><p>ZAB (ZooKeeper Atomic Broadcast) 可以解决 ZooKeeper 集群崩溃恢复以及主从同步数据的问题。</p><ul><li>Looking: 选举状态</li><li>Following: 从节点所处的状态</li><li>Leading: 主节点所处的状态</li></ul><h2 id="最大ZXID"><a href="#最大ZXID" class="headerlink" title="最大ZXID"></a>最大ZXID</h2><p>最大 ZXID 也就是节点本地的最新事务编号，包含 epoch 和计数两部分。</p><ul><li>epoch 相当于 Raft 算法中的 term</li></ul><h3 id="恢复模式"><a href="#恢复模式" class="headerlink" title="恢复模式"></a>恢复模式</h3><p>加入 ZooKeeper 当前的主节点挂掉了，集群会进行崩溃恢复</p><ol><li>Leader Election</li></ol><ul><li>选举阶段，此时集群中的节点处于Looking状态。它们会各自向其他节点发起投票，投票当中包含自己的服务器ID和最新事务ID（ZXID）。</li><li>接下来，节点会用自身的ZXID和从其他节点接收到的ZXID做比较，如果发现别人家的ZXID比自己大，也就是数据比自己新，那么就重新发起投票，投票给目前已知最大的ZXID所属节点。</li><li>每次投票后，服务器都会统计投票数量，判断是否有某个节点得到半数以上的投票。如果存在这样的节点，该节点将会成为准Leader，状态变为Leading。其他节点的状态变为Following。</li></ul><ol start="2"><li>Discovery</li></ol><ul><li>发现阶段，用于在从节点中发现最新的ZXID和事务日志。(为什么还要寻找ZXID最大的呢)</li><li>这是为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。</li><li>所以这一阶段，Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。</li><li>各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。</li></ul><ol start="3"><li>Synchronization</li></ol><ul><li>同步阶段，把Leader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。</li></ul><p>自此，故障恢复正式完成。</p><h2 id="广播模式"><a href="#广播模式" class="headerlink" title="广播模式"></a>广播模式</h2><p>写入数据，涉及到 ZAB 协议的 Broadcast 阶段</p><ol><li>客户端发出写入数据请求给任意Follower。</li><li>Follower把写入数据请求转发给Leader。</li><li>Leader采用二阶段提交方式，先发送Propose广播给Follower。</li><li>Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader。</li><li>Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower。</li></ol><blockquote><p>Zab协议既不是强一致性，也不是弱一致性，而是处于两者之间的单调一致性。它依靠事务ID和版本号，保证了数据的更新和读取是有序的。</p></blockquote><h1 id="ZooKeeper-的应用"><a href="#ZooKeeper-的应用" class="headerlink" title="ZooKeeper 的应用"></a>ZooKeeper 的应用</h1><h2 id="分布式锁-1"><a href="#分布式锁-1" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>这是雅虎研究员设计Zookeeper的初衷。利用Zookeeper的临时顺序节点，可以轻松实现分布式锁。</p><h2 id="服务注册和发现"><a href="#服务注册和发现" class="headerlink" title="服务注册和发现"></a>服务注册和发现</h2><p>利用Znode和Watcher，可以实现分布式服务的注册和发现。最著名的应用就是阿里的分布式RPC框架Dubbo。</p><h2 id="共享配置和状态信息"><a href="#共享配置和状态信息" class="headerlink" title="共享配置和状态信息"></a>共享配置和状态信息</h2><p>Redis的分布式解决方案Codis，就利用了Zookeeper来存放数据路由表和 codis-proxy 节点的元信息。同时 codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://juejin.cn/post/6844903684610981895">ZooKeeper简介（浅入）</a></li><li><a href="http://www.360doc.com/content/18/0521/09/36490684_755631753.shtml">漫画：什么是ZooKeeper</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ray 新手常见错误</title>
    <link href="/2020/12/08/Ray-%E6%96%B0%E6%89%8B%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    <url>/2020/12/08/Ray-%E6%96%B0%E6%89%8B%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="Delay-ray-get"><a href="#Delay-ray-get" class="headerlink" title="Delay ray.get()"></a>Delay ray.get()</h1><p>调用 <code>get</code> 会产生一个副作用, 会阻塞 <code>driver</code> 程序去做别的操作，这样就会影响并行性.</p><p>首先看一个普通的例子:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">1</span>) <span class="hljs-comment"># Replace this with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br>start = time.time()<br>results = [do_some_work(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br>print(<span class="hljs-string">&quot;results = &quot;</span>, results)<br><br><br><span class="hljs-comment"># Output</span><br><span class="hljs-comment"># duration = 4.0149290561676025</span><br><span class="hljs-comment"># results =  [0, 1, 2, 3]</span><br></code></pre></td></tr></table></figure><p>现在当我们给这个函数加上 <code>remote</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>) <span class="hljs-comment"># Specify this system has 4 CPUs.</span><br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">1</span>) <span class="hljs-comment"># Replace this is with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br>start = time.time()<br>results = [do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br>print(<span class="hljs-string">&quot;results = &quot;</span>, results)<br><br><br><span class="hljs-comment"># Output</span><br><span class="hljs-comment"># duration = 0.0003619194030761719</span><br><span class="hljs-comment"># results =  [ObjectRef(df5a1a828c9685d3ffffffff0100000001000000), ObjectRef(cb230a572350ff44ffffffff0100000001000000), ObjectRef(7bbd90284b71e599ffffffff0100000001000000), ObjectRef(bd37d2621480fc7dffffffff0100000001000000)]</span><br></code></pre></td></tr></table></figure><p>但是这个 result 不是我们想要的, 我们调用 <code>ray.get()</code> 来获取结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Python">results = [ray.get(do_some_work.remote(x)) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br></code></pre></td></tr></table></figure><p>但是改成这样之后呢，输出就变成:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Python">duration = <span class="hljs-number">4.018050909042358</span><br>results =  [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br></code></pre></td></tr></table></figure><p>现在结果是对的, 但程序因此也退化成了串行. 原因也是显而易见的, 每次调用 <code>ray.get</code> 都会阻塞住程序.</p><p>修改的办法就是在调用完所有的 <code>task</code> 后再调用 <code>ray.get</code> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Python">results = ray.get([do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)])<br><br><span class="hljs-comment"># Output: </span><br><span class="hljs-comment"># duration = 1.0064549446105957</span><br><span class="hljs-comment"># results =  [0, 1, 2, 3]</span><br></code></pre></td></tr></table></figure><p>时刻保持警惕 <code>ray.get()</code> 是一个会阻塞的操作, 尽可能晚的去调用这个方法 <code>ray.get()</code></p><h1 id="Avoid-tiny-tasks"><a href="#Avoid-tiny-tasks" class="headerlink" title="Avoid tiny tasks"></a>Avoid tiny tasks</h1><p>避免出现执行时间过短的 <code>task</code>, 因为并行的结果可能适得其反.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tiny_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">0.0001</span>) <span class="hljs-comment"># Replace this with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br>start = time.time()<br>results = [tiny_work(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>)]<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 13.36544418334961</span><br></code></pre></td></tr></table></figure><p>这是一个符合逻辑的结果，当我们换成 <code>remote</code> 时</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tiny_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">0.0001</span>) <span class="hljs-comment"># Replace this is with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br>start = time.time()<br>result_ids = [tiny_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>)]<br>results = ray.get(result_ids)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 27.46447515487671</span><br></code></pre></td></tr></table></figure><p>结果非常的出乎意料, 因为我们并行的运行总时间反而增加了. 这是因为调用每一个 <code>task</code> 都会有一个小的开销(调度, 进程间通讯, 更新系统的状态), 由于 <code>task</code> 本身所需的时间太小, 那么这些额外的开销反而占据了大头.</p><p>修改的办法就是平摊这些开销</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tiny_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(<span class="hljs-number">0.0001</span>) <span class="hljs-comment"># replace this is with work you need to do</span><br>    <span class="hljs-keyword">return</span> x<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mega_work</span>(<span class="hljs-params">start, end</span>):</span><br>    <span class="hljs-keyword">return</span> [tiny_work(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start, end)]<br><br>start = time.time()<br>result_ids = []<br>[result_ids.append(mega_work.remote(x*<span class="hljs-number">1000</span>, (x+<span class="hljs-number">1</span>)*<span class="hljs-number">1000</span>)) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)]<br>results = ray.get(result_ids)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 3.2539820671081543</span><br></code></pre></td></tr></table></figure><p>经过测试, 运行一个空的 <code>task</code> 大概需要 0.5s, 这就说明我们的 <code>task</code> 需要一定的运行时间来摊平这个额外的开销.</p><h1 id="Avoid-passing-same-object-repeatedly-to-remote-tasks"><a href="#Avoid-passing-same-object-repeatedly-to-remote-tasks" class="headerlink" title="Avoid passing same object repeatedly to remote tasks"></a>Avoid passing same object repeatedly to remote tasks</h1><p>当我们给一个 remote function 传递一个大的对象时, Ray 调用 <code>ray.put()</code> 来把对象存在本地 object store 中. 这种操作可以显著的提升性能, 但是也会导致一些问题. 比如: 重复地传递相同的对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">no_work</span>(<span class="hljs-params">a</span>):</span><br>    <span class="hljs-keyword">return</span><br><br>start = time.time()<br>a = np.zeros((<span class="hljs-number">5000</span>, <span class="hljs-number">5000</span>))<br>result_ids = [no_work.remote(a) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br>results = ray.get(result_ids)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><span class="hljs-comment"># Output: </span><br><span class="hljs-comment"># duration = 1.0837509632110596</span><br></code></pre></td></tr></table></figure><p>这个时间对于一个仅仅进行了10个 <code>tasks</code> 显然偏大了. 造成这个情况的原因是每次我们调用 <code>no_work(a)</code>, Ray 就会会调用 <code>ray.put(a)</code> 就会导致复制一个非常大的数组导致时间的开销. </p><p>解决这个问题我们可以 显式地调用 <code>ray.put(a)</code> 然后把 obejct 的 ID 传递过去就可以避免复制</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">no_work</span>(<span class="hljs-params">a</span>):</span><br>    <span class="hljs-keyword">return</span><br><br>start = time.time()<br>a_id = ray.put(np.zeros((<span class="hljs-number">5000</span>, <span class="hljs-number">5000</span>)))<br>result_ids = [no_work.remote(a_id) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br>results = ray.get(result_ids)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start)<br><br><span class="hljs-comment"># Output: </span><br><span class="hljs-comment"># duration = 0.132796049118042</span><br></code></pre></td></tr></table></figure><h1 id="Pipeline-data-processing"><a href="#Pipeline-data-processing" class="headerlink" title="Pipeline data processing"></a>Pipeline data processing</h1><p>如果我们对一系列 <code>tasks</code> 使用 <code>ray.get()</code>. 我们就需要等到最后一个 <code>task</code> 完成, 当每一个 <code>task</code> 完成的时间相差很大的时候, 就会导致一些问题.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)) <span class="hljs-comment"># Replace this with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_results</span>(<span class="hljs-params">results</span>):</span><br>    <span class="hljs-built_in">sum</span> = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results:<br>        time.sleep(<span class="hljs-number">1</span>) <span class="hljs-comment"># Replace this with some processing code.</span><br>        <span class="hljs-built_in">sum</span> += x<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span><br><br>start = time.time()<br>data_list = ray.get([do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)])<br><span class="hljs-built_in">sum</span> = process_results(data_list)<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start, <span class="hljs-string">&quot;\nresult = &quot;</span>, <span class="hljs-built_in">sum</span>)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 7.82636022567749</span><br><span class="hljs-comment"># result =  6</span><br><br></code></pre></td></tr></table></figure><p>总的时间由两部分组成(do_some_work + process_results), 由于需要等所有的 <code>task</code> 都完成(花费了将近4s)</p><p>解决这个问题我们可以对一系列 object ID调用 <code>ray.wait()</code>. 返回的参数(1) 就绪的 object ID. (2) 还未就绪的 object ID.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> ray<br><br>ray.init(num_cpus = <span class="hljs-number">4</span>)<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span>(<span class="hljs-params">x</span>):</span><br>    time.sleep(random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)) <span class="hljs-comment"># Replace this is with work you need to do.</span><br>    <span class="hljs-keyword">return</span> x<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_incremental</span>(<span class="hljs-params"><span class="hljs-built_in">sum</span>, result</span>):</span><br>    time.sleep(<span class="hljs-number">1</span>) <span class="hljs-comment"># Replace this with some processing code.</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span> + result<br><br>start = time.time()<br>result_ids = [do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)]<br><span class="hljs-built_in">sum</span> = <span class="hljs-number">0</span><br><span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(result_ids):<br>    done_id, result_ids = ray.wait(result_ids)<br>    <span class="hljs-built_in">sum</span> = process_incremental(<span class="hljs-built_in">sum</span>, ray.get(done_id[<span class="hljs-number">0</span>]))<br>print(<span class="hljs-string">&quot;duration =&quot;</span>, time.time() - start, <span class="hljs-string">&quot;\nresult = &quot;</span>, <span class="hljs-built_in">sum</span>)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># duration = 4.852453231811523</span><br><span class="hljs-comment"># result =  6</span><br></code></pre></td></tr></table></figure><img src="/2020/12/08/Ray-%E6%96%B0%E6%89%8B%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/PipelineDataProcessing.png" class="" title="PipelineDataProcessing">]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes介绍</title>
    <link href="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/"/>
    <url>/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="深入浅出地了解-Kubernetes"><a href="#深入浅出地了解-Kubernetes" class="headerlink" title="深入浅出地了解 Kubernetes"></a>深入浅出地了解 Kubernetes</h1><p>Kubernetes 是一个<strong>软件系统</strong>, 它允许你在其上很容易地部署和管理容器化的应用.</p><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/Kubernetes%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD.png" class="" title="Kubernetes的核心功能"><p>组件被部署在哪一个结点对于开发者和系统管理员来说都不用关心</p><h2 id="Kubernetes-集群架构"><a href="#Kubernetes-集群架构" class="headerlink" title="Kubernetes 集群架构"></a>Kubernetes 集群架构</h2><p>在硬件级别, 一个 Kubernetes 集群由很多节点组成, 这些节点被分成以下两种类型:</p><ul><li>主节点: 承载着 Kubernetes 控制和管理整个集群系统的控制面板<ul><li>控制面板<ul><li><em>Kubernetes</em> API 服务器, 你和其他控制面板组件都要和它通信</li><li><em>Scheculer</em> 它调度你的应用 (为应用的每个可部署组件分配一个工作节点)</li><li><em>Controller Manager</em> 它执行集群级别的功能, 如复制组件、持续跟踪工作节点、处理节点失败</li><li><em>etcd</em> 一个可靠的分布式数据存储, 它能持久化存储集群配置</li></ul></li><li>控制面板的组件持有并控制集群状态, 但是它们不运行你的应用程序, 是由工作节点完成的.</li></ul></li><li>工作结点: 它们运行用户实际部署的应用<ul><li>Docker, rtk 或其他的容器类型</li><li><em>Kubelet</em> 它与 API 服务器通信, 并管理它所在节点的容器</li><li><em>Kubernetes Service Proxy (kube-proxy)</em> 它负责组件之间的负载均衡网络流量</li></ul></li></ul><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/Kubernetes%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6.png" class="" title="Kubernetes集群组件"><h2 id="在-Kubernetes-中运行应用"><a href="#在-Kubernetes-中运行应用" class="headerlink" title="在 Kubernetes 中运行应用"></a>在 Kubernetes 中运行应用</h2><ol><li>首先需要将应用打包进一个或多个容器镜像</li><li>再将镜像推送到镜像仓库</li><li>然后将应用的描述发布到 Kubernetes API 服务器</li></ol><h3 id="描述信息怎样成为一个运行的容器"><a href="#描述信息怎样成为一个运行的容器" class="headerlink" title="描述信息怎样成为一个运行的容器"></a>描述信息怎样成为一个运行的容器</h3><ol><li>当 API 服务器处理应用的描述时, 调度器调度指定组的容器到可用的工作节点 (基于每组所需的计算资源以及调度时每个节点未分配的资源)</li><li>那些节点上的 Kubelet 指示容器运行时拉取所需的镜像并运行容器.</li></ol><h3 id="保持容器运行"><a href="#保持容器运行" class="headerlink" title="保持容器运行"></a>保持容器运行</h3><p>一旦应用程序运行起来, Kubernetes 就会不断地确认应用程序的部署状态始终与你提供的描述相匹配.</p><p>如果整个工作节点死亡或无法访问, Kubernetes 将为在故障节点上运行的所有容器选择新节点, 并在新选择的节点上运行它们.</p><h3 id="扩展副本数量"><a href="#扩展副本数量" class="headerlink" title="扩展副本数量"></a>扩展副本数量</h3><p>当应用程序运行的时候, 可以决定要增加或减少副本量, 而 Kubernetes 将分别增加附加的或停止多余的副本</p><h3 id="命中移动目标"><a href="#命中移动目标" class="headerlink" title="命中移动目标"></a>命中移动目标</h3><p>为了让客户能够轻松地找到提供特定服务的容器, 可以告诉 Kubernetes 哪些容器提供相同的服务. Kubernetes 将通过一个静态IP 地址暴露所有容器, 并将该地址暴露给集群中运行的所有应用程序. <em>kube-proxy</em> 将确保到服务的连接可跨提供服务的容器实现负载均衡.</p><h1 id="开始使用-Kubernetes-和-Docker"><a href="#开始使用-Kubernetes-和-Docker" class="headerlink" title="开始使用 Kubernetes 和 Docker"></a>开始使用 Kubernetes 和 Docker</h1><h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run busybox <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Hello World&quot;</span><br></code></pre></td></tr></table></figure><ol><li>Docker 首先会检查 busybox:latest 镜像是否已经存在于本机</li><li>如果没有, Docker 会从镜像中心拉取 busybox 镜像</li><li>Docker 在被隔离的容器里运行 <code>echo &quot;Hello World&quot;</code></li></ol><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/%E5%9F%BA%E4%BA%8EDockerfile%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F.png" class="" title="基于Dockerfile构建一个新的容器镜"><blockquote><p>镜像不是一个大的二进制块, 而是由多层组成的, 不同镜像可能会共享分层.</p></blockquote><h2 id="运行容器镜像"><a href="#运行容器镜像" class="headerlink" title="运行容器镜像"></a>运行容器镜像</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --name kubia-container -p 8080:8080 -d kubia<br><span class="hljs-comment"># 基于 kubia 镜像创建一个叫 kubia-container 的新容器. 这个容器与命令行分离 (-d), 意味着后台运行. 本机上的 8080 端口会被映射到容器内的 8080 端口 (-p 8080:8080), 所以可以通过 http://localhost:8080 来访问应用.</span><br></code></pre></td></tr></table></figure><ul><li>容器使用独立的 PID Linux 命名空间并且有着独立的系列号, 完全独立于进程树.</li><li>容器的文件系统也是独立的.</li></ul><h2 id="介绍-pod"><a href="#介绍-pod" class="headerlink" title="介绍 pod"></a>介绍 pod</h2><p>Kubernetes 不直接处理单个容器, 它使用多个共存容器的理念. 这组容器就叫做 <strong>pod</strong>.</p><blockquote><p>一个 pod 是一组紧密相关的容器, 他们总是运行在同一工作节点上, 以及同一个 Linux 命名空间中.</p></blockquote><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/%E5%AE%B9%E5%99%A8%E3%80%81pod%E5%8F%8A%E7%89%A9%E7%90%86%E5%B7%A5%E4%BD%9C%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.png" class="" title="容器、pod及物理工作节点之间的关系"><ul><li>每个 pod 就像一个独立的逻辑机器, 拥有自己的 IP, 主机名, 进程等, 运行一个独立的应用程序.</li><li>应用程序可以是单个进程, 运行在单个容器中, 也可以是一个主应用进程或者其他支持进程, 每个进程都在自己的容器中运行.</li><li>一个 pod 所有的容器都运行在同一逻辑机器上, 而其他 pod 中的容器, 即使运行在同一工作节点上, 也会出现在不同的节点上.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl run kubia --image=luksa/kubia --port=8080 --generator=run/v1<br><br><span class="hljs-comment"># 现在还处于创建容器的阶段</span><br>kubectl get pods<br><span class="hljs-comment"># NAME    READY   STATUS              RESTARTS   AGE</span><br><span class="hljs-comment"># kubia   0/1     ContainerCreating   0          14s</span><br><br><span class="hljs-comment"># 现在 pod 已变成运行状态</span><br>kubectl get pods<br><span class="hljs-comment"># NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="hljs-comment"># kubia   1/1     Running   0          90s</span><br></code></pre></td></tr></table></figure><p>上述幕后发生的事情</p><ol><li>构建镜像并将其推送到 Docker Hub (在本机上构建的镜像只能在本地机器上可用, 但是需要使它可以访问运行在工作节点上的 Docker 守护进程)</li><li>运行 <code>kubectl</code> 命令时, 它通过向 Kubernetes API 服务器发送一个 REST HTTP 请求, 在集群中创建一个新的 ReplicationController 对象.</li><li>ReplicationController 创建了一个新的 pod, 调度器将其调度到一个工作节点上.</li><li>Kubelet 看到 pod 被调度到节点上, 就告知 Docker 从镜像中心中拉取指定的镜像, 因为本地没有该镜像.</li><li>下载镜像后, Docker 创建并运行容器.</li></ol><img src="/2020/12/08/Kubernetes%E4%BB%8B%E7%BB%8D/%E5%9C%A8Kubernetes%E4%B8%AD%E8%BF%90%E8%A1%8C%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F.png" class="" title="在Kubernetes中运行容器镜像"><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li>《 Kubernetes in Action 中文版 》</li></ul>]]></content>
    
    
    <categories>
      
      <category>kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ray初步探索</title>
    <link href="/2020/12/02/Ray%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/"/>
    <url>/2020/12/02/Ray%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="Overview-of-Ray"><a href="#Overview-of-Ray" class="headerlink" title="Overview of Ray"></a>Overview of Ray</h1><h2 id="Why-Ray"><a href="#Why-Ray" class="headerlink" title="Why Ray ?"></a>Why Ray ?</h2><p>有很多教程解释了怎么去使用 Python 的 <code>multiprocessing module</code>. 但不幸的是, <code>multiprocessing module</code> 在解决现代应用的需求时有很大的局限性. 我们现在应用的需求有:</p><ul><li>在多台计算机上运行相同的代码</li><li>在不同服务器之间可以进程通信</li><li>可以轻松解决debug</li><li>有效地处理大型对象和数值数据</li></ul><blockquote><p>Ray是一个分布式执行引擎。同样的代码可以在一台机器上实现高效的多处理，也可以在集群是用于大型的计算。</p></blockquote><h2 id="Necessary-Concept"><a href="#Necessary-Concept" class="headerlink" title="Necessary Concept"></a>Necessary Concept</h2><p>传统的编程依赖两个核心的概念: <strong>function</strong> 和 <strong>classes</strong>. 但是当我们把我们的应用迁移到分布式系统的时候，这时候概念就变了. </p><blockquote><p>Ray takes the existing concepts of <strong>functions</strong> and <strong>classes</strong> and translates them to the distributed setting as <strong>tasks</strong> and <strong>actors</strong>.</p></blockquote><h3 id="From-Classes-to-Actors"><a href="#From-Classes-to-Actors" class="headerlink" title="From Classes to Actors"></a>From Classes to Actors</h3><p>如何理解 class 和 actor 之间的关系呢</p><p>Python 允许你用 <code>@ray.remote</code> 去修饰一个 class. 当这个 class 被实例化的时候, Ray 就会在集群中创建一个 <code>actor</code> 进程, 它拥有这个object 的副本. 在这个 <code>actor</code> 上的方法调用会转变成 <code>task</code> 在 <code>actor</code> 进程上运行并且可以访问和修改 <code>actor</code>的状态.</p><p>单个 <code>actor</code> 线性的执行函数 (每一个单独的函数都是原子的)</p><h2 id="Starting-Ray"><a href="#Starting-Ray" class="headerlink" title="Starting Ray"></a>Starting Ray</h2><p>调用<code>ray.init()</code> 启动所有 Ray 相关的进程.</p><ul><li>一些 <code>worker</code> 进程启动, 用来并行的处理 Python function (基本是一个 CPU 核一个<code>worker</code>)</li><li>一个 <code>scheduler</code> 进程启动, 用来分配 <code>tasks</code> 给 <code>workers</code>. <code>task</code> 是 Ray 用来分配任务的单位, 对应一个 function invocation 或者 method invocation.</li><li>创建一个 <code>shared-memory object store</code>, 用来在 <code>workers</code> 之间高效的共享对象 (而不是通过创造副本)</li><li>一个在内存中的数据库用来对元数据排序，元数据可以作为 machine failures 事件的返回</li></ul><h3 id="进程介绍"><a href="#进程介绍" class="headerlink" title="进程介绍"></a>进程介绍</h3><p>当我们使用Ray时，涉及到多个进程。</p><ul><li>多 <code>worker</code> 进程执行多个任务并将结果存储在对象存储中，每个 <code>worker</code> 都是一个独立的进程。<ul><li>为什么不是对应的 thread 是因为多线程在 Python 中由于 global interpreter lock 的影响有很大的限制. (即某一时刻, 只能有一个 thread 在运行)</li></ul></li><li>每个 <code>node</code> 上的对象存储都将<strong>不可变</strong>的对象存储存在共享内存 (shared memory) 中, 允许 <code>worker</code> 以少量的复制和并行化有效的共享同一 <code>node</code> 上的存储对象。</li><li>每个 <code>node</code> 上的本地调度将任务分配给同一 <code>node</code> 上的 <code>worker</code>. (一个<code>node</code> 上的本地调度把任务分配给本 <code>node</code> 上的 <code>worker</code>)</li><li>一个 <code>driver</code> 是用户控制 python 进程. 例如，如果用户正在运行脚本或者使用 python shell, 那么 <code>driver</code> 就是运行脚本或者 shell 的 python 进程。<code>driver</code> 和 <code>worker</code> 很相似，他们都可以提交任务给本地调度并从对象存储中获取对象，但是不同之处是本地调度不会将任务分配给 <code>driver</code> 执行。</li><li>Redis 服务器维护系统的大部分状态。</li></ul><p>Q: Ray 执行异步任务时，是怎样实现平行的</p><blockquote><p>A: Ray 集群中每个 <code>node</code> 共享本 <code>node</code> 本地存储, <code>node</code> 中 <code>worker</code> 并行运行, 集群间 <code>worker</code> 的并行</p></blockquote><p>Q: Ray 是怎么使用对象 ID 来表示不可变对象的远程对象的</p><blockquote><p>A: 任务执行前, 对象值已经存入存储对象中, 任务执行是通过对象 ID 调用存储对象的</p></blockquote><h2 id="不可变的远程-remote-对象"><a href="#不可变的远程-remote-对象" class="headerlink" title="不可变的远程 (remote) 对象"></a>不可变的远程 (remote) 对象</h2><ul><li>在 Ray 中, 我们可以在对象上创建和计算. 我们将这些对象称为远程对象, 并使用<strong>对象 ID</strong> 来引用它们.</li><li>远程对象是被存储在对象存储中的, 在集群中每个节点都有一个存储对象.</li><li>在集群设置中, 我们可能实际上不知道每个存储对象的位置.</li><li>由于远程对象是不可变的，那么他们的值在创建之后不能更改。这允许在多个对象存储中复制远程对象，而不需要同步副本</li></ul><h2 id="Put-Get"><a href="#Put-Get" class="headerlink" title="Put, Get"></a>Put, Get</h2><p>Ray 中的 <code>ray.get</code> 和 <code>ray.put</code> 是用作 Python 对象和对象 ID 之间的转换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Python">x = <span class="hljs-string">&quot;example&quot;</span><br><span class="hljs-comment"># 把一个 Python 对象复制到本地对象存储中(本地意味着同一节点). 一旦对象被存入存储对象后, 他的值就不能被改变了.</span><br>ray.put(x)  <span class="hljs-comment"># ObjectID(b49a32d72057bdcfc4dda35584b3d838aad89f5d)</span><br></code></pre></td></tr></table></figure><p>Ray的 <code>ray.put()</code> 返回的是一个对象 ID (其实就是一个引用), 可以被用来创建新的远程对象.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Python">x_id = ray.put(<span class="hljs-string">&quot;example&quot;</span>)<br><span class="hljs-comment"># 接受一个对象 ID, 并从相应的远程对象创建一个 Python 对象.</span><br>ray.get(x_id) <span class="hljs-comment"># &quot;example&quot;</span><br></code></pre></td></tr></table></figure><p>对于数组这样的对象, 我们可以使用内存的共享从而避免复制对象. 对于其他对象, 它将对象从对象存储中复制到 worker 进程的堆. 如果与对象 ID <code>x_id</code> 对应的远程(remote)对象与调用 <code>ray.get(x_id)</code> 的 <code>worker</code> 不在同一 <code>node</code> 上, 那么远程对象将首先从拥有它的对象存储区转移到需要他的对象存储区</p><blockquote><p>tips: function先后顺序，影响ray，例如b函数调用a函数，那么a不加修饰器，就必须放置b前面</p></blockquote><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://blog.csdn.net/weixin_43255962/article/details/88689665">Ray 入门指南(1) — Ray 分布式框架的介绍</a></li><li><a href="https://towardsdatascience.com/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8">Modern Parallel and Distributed Python: A Quick Tutorial on Ray</a></li></ul><h1 id="RAY-CORE"><a href="#RAY-CORE" class="headerlink" title="RAY CORE"></a>RAY CORE</h1><h2 id="Ray-Core-Walkthrough"><a href="#Ray-Core-Walkthrough" class="headerlink" title="Ray Core Walkthrough"></a>Ray Core Walkthrough</h2><h2 id="Using-Ray"><a href="#Using-Ray" class="headerlink" title="Using Ray"></a>Using Ray</h2><p>见</p><h2 id="Configuring-Ray"><a href="#Configuring-Ray" class="headerlink" title="Configuring Ray"></a>Configuring Ray</h2><h2 id="Ray-Dashboard"><a href="#Ray-Dashboard" class="headerlink" title="Ray Dashboard"></a>Ray Dashboard</h2><h1 id="Ray-Cluster"><a href="#Ray-Cluster" class="headerlink" title="Ray Cluster"></a>Ray Cluster</h1><p>Ray 可以在单个机器上运行, 但是 Ray 真正的强大之处在于它可以在一个机器集群上运行。</p><h2 id="Distributed-Ray-Overview"><a href="#Distributed-Ray-Overview" class="headerlink" title="Distributed Ray Overview"></a>Distributed Ray Overview</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul><li><strong>Ray Nodes</strong>: 一个 Ray 集群包含一个 <code>head node</code> 和 一些 <code>worker nodes</code>. 首先运行的是 <code>head node</code>, 然后 <code>worker node</code> 会得到 <code>head node</code> 在集群中的地址. Ray 的集群可以自动扩容, 这意味着它可以根据当前的负载创建或者销毁实例.</li><li><strong>Ports</strong>: Ray 的进程通过 TCP 端口进行交流.</li><li><strong>Ray Cluster Launcher</strong>: 这是一个可以自动提供机器并且发布一个多节点的 Ray 集群的工具.</li></ul><p>一个Ray集群包含了一个<strong>head node</strong>和一堆<strong>worker node</strong>还有一个中心的全局控制储存实例（Global Control Store, <strong>GCS</strong>）。<strong>head node</strong>需要先启动，所有的<strong>worker node</strong>都会有<strong>head node</strong>的地址。</p><p>系统的一些元数据由GCS管理，例如actor的地址。</p><p>我们可以使用<strong>Ray Cluster Launcher</strong>配置计算机并启动多节点Ray群集。可以在AWS、GCP、Azure、Kubernetes、内部部署和Staroid上使用集群启动器，甚至可以在您的自定义节点提供程序上使用。</p><h3 id="所有权关系"><a href="#所有权关系" class="headerlink" title="所有权关系"></a>所有权关系</h3><p>每个worker进程管理并拥有它提交的task以及task的返回（ObjectRef）。这个所有者对task是否执行以及ObjectRef对应的值是否能够被解析负责。worker拥有过它通过<code>ray.put</code>创造的object</p><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><h4 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h4><p>一个Ray实例包含了多个<strong>worker nodes</strong>。每个节点包含以下物理进程：</p><ul><li>一个或者多个work processes，负责task的提交和执行。</li><li>一个所有权的对应表。记录 objects 和对应 worker 的引用计数(ref counts)</li><li>一个进程内的存储。用于存储小的 object</li><li>Raylet ，Raylet 在同一个集群共享所有的 jobs 。raylet 有两个主要的线程：<ul><li>调度线程。负责资源管理和在分布式对象存储里写入任务参数。集群里面的独立的调度都包含 Ray 的分布式调度</li><li>共享内存对象（plasma 对象存储）。负责存储和转换大的对象。集群里面每个对象存储都包含 Ray 分布式对象存储</li></ul></li></ul><h4 id="head"><a href="#head" class="headerlink" title="head"></a>head</h4><p>区别于其他进程，head承担以下任务：</p><ul><li>Global Control Store(GCS)。GCS是一个 key-value 的服务器，包含了系统级别的元数据，例如 objects 和 actors 的位置。有一个进行中的对 GCS 的优化，以便 GCS 可以运行在任意或者多个节点，而不是设定的 head 节点。</li><li>Driver进程。dirver 是一个特殊的 worker 进程（运行<code>ray.init()</code>的进程），它执行上层应用（例如，python 里的<code>__main__</code>）。它能够提交 tasks，但是自己本身不能执行。Driver 进程能够运行在任何 node 熵，但是默认是在 head node里。</li></ul><h3 id="具体如何工作的"><a href="#具体如何工作的" class="headerlink" title="具体如何工作的"></a>具体如何工作的</h3><p>Ray集群将自动启动一个基于负载的autoscaler。autoscaler资源要求scheduler查看集群中的挂起任务、参与者和放置组资源需求，并尝试添加能够满足这些需求的最小节点列表。当工作节点空闲超过一定时间时，它们将被删除（头节点永远不会被删除，除非集群被拆除）。</p><p>Autoscaler使用一个简单的装箱算法将用户需求装箱到可用的集群资源中。剩余的未满足需求被放置在满足需求的最小节点列表上，同时最大化利用率（从最小节点开始）。</p><h2 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/344736949">Ray 1.0架构解读</a></li></ul><h1 id="Ray-Serve"><a href="#Ray-Serve" class="headerlink" title="Ray Serve"></a>Ray Serve</h1><p>Ray Serve 是基于 Ray 构建的可伸缩模型服务库</p><h2 id="Ray-Serve-Scalable-and-Programmable-Serving"><a href="#Ray-Serve-Scalable-and-Programmable-Serving" class="headerlink" title="Ray Serve: Scalable and Programmable Serving"></a>Ray Serve: Scalable and Programmable Serving</h2><ul><li>框架不可知 (Framework Agnostic): 使用相同的工具包即可提供服务, 从使用 PyTorch 或 TensorFlow &amp; Keras 等框架构建的深度学习模型到 Scikit-Learn 模型或任意业务逻辑.</li><li>Python 优先 (Python First): 使用纯 Python 代码配置服务的模型 - 不再需要 YAML 或 JSON 配置.</li><li>面向性能 (Performance Oriented): 启用批处理, 流水线处理和 GPU 加速, 以提高模型的吞吐量.</li><li>本机组合 (Composition Native): 允许你将多个模型组合在一起以创建单个预测, 从而创建”模型管道”.</li><li>水平可扩展 (Horizontally Scalable): 服务可以随着你添加更多计算机而线性扩展.</li></ul><h2 id="Key-Concepts"><a href="#Key-Concepts" class="headerlink" title="Key Concepts"></a>Key Concepts</h2><h3 id="Backends"><a href="#Backends" class="headerlink" title="Backends"></a>Backends</h3><h3 id="Endpoints"><a href="#Endpoints" class="headerlink" title="Endpoints"></a>Endpoints</h3><h1 id="参考文献-2"><a href="#参考文献-2" class="headerlink" title="参考文献"></a>参考文献</h1><ul><li><a href="https://docs.ray.io/en/latest/index.html">官方文档</a></li><li><a href="https://zhuanlan.zhihu.com/p/111340572">Ray 分布式计算框架介绍</a></li><li><a href="https://www.jiqizhixin.com/articles/2020-09-11-11">取代Python多进程！高性能分布式执行框架 - Berkeley Ray</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Ray</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Ray</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数仓：缓慢渐变维度</title>
    <link href="/2020/10/28/%E6%95%B0%E4%BB%93%EF%BC%9A%E7%BC%93%E6%85%A2%E6%B8%90%E5%8F%98%E7%BB%B4%E5%BA%A6/"/>
    <url>/2020/10/28/%E6%95%B0%E4%BB%93%EF%BC%9A%E7%BC%93%E6%85%A2%E6%B8%90%E5%8F%98%E7%BB%B4%E5%BA%A6/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>当业务数据库中的一些数据发生了更改，到底要不要将这些变化也反映到数据仓库中？在数据仓库中，那些数据应该随之变化，哪些可以不用变化？考虑到这些变化，在数据仓库中的维度表又应该如何设计以满足这些需要。</p><h1 id="Type-1-SCD"><a href="#Type-1-SCD" class="headerlink" title="Type 1 SCD"></a>Type 1 SCD</h1><blockquote><p>替换原始记录</p></blockquote><p>我们可以保持业务数据和数据仓库中的数据始终处于一致。</p><ul><li>优点：简单方便</li><li>缺点：无法追溯历史数据</li></ul><h1 id="Type-2-SCD"><a href="#Type-2-SCD" class="headerlink" title="Type 2 SCD"></a>Type 2 SCD</h1><blockquote><p>插入一条新的记录</p></blockquote><ul><li>优点：保留全部历史记录</li><li>缺点：使数据表记录飞涨，可能导致影响查询效率</li></ul><p>尽可能维护来自业务系统中的历史数据，能够真正捕获</p><h1 id="Type-3-SCD"><a href="#Type-3-SCD" class="headerlink" title="Type 3 SCD"></a>Type 3 SCD</h1><blockquote><p>更新原始表结构</p></blockquote><ul><li>优点：既可以反映历史记录，也可以避免成倍的数据增长</li><li>缺点：适用场景非常少，仅能反映部分历史记录。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>MapReduce: 在大型集群上简化数据处理</title>
    <link href="/2020/10/26/MapReduce-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E9%9B%86%E7%BE%A4%E4%B8%8A%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    <url>/2020/10/26/MapReduce-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E9%9B%86%E7%BE%A4%E4%B8%8A%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><blockquote><p>MapReduce 是一种编程模型，用于处理和生成大型数据集的实现。</p></blockquote><p>用户通过指定一个用来处理键值对 (key/value) 的 map 函数来生成一个中间键值对集合。然后，再指定一个 reduce 函数，它用来合并所有的具有相同中间 key 的中间 value.</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>虽然数据处理的逻辑简单，但是由于数据量巨大又需要在有限的时间内完成。计算任务也不得不分配给成百上千台机器去执行。如何并行化计算，分配数据以及处理故障的问题，所有的问题都纠缠在一起，这就需要大量的代码来对它们进行处理。</p><p>为了应对这种复杂性，我们设计了一种抽象。大多数计算计算都涉及到对输入中的每个逻辑记录进行 map 的操作，以便于计算出一个中间键值对的集合。然后，为了恰当的整合衍生数据，我们对共用相同键的所有值进行 reduce 操作。通过使用具备用户所指定的 map 和 reduce 操作的函数式模型，这使得我们能够轻松并行化大型计算。</p><h1 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h1><p>该计算任务将<strong>一个键值对集合</strong>作为输入，并生成一个键值对集合作为输出。<strong>MapReduce</strong> 这个库的用户将这种计算任务以两个函数进行表达，即 <strong>Map</strong> 和 <strong>Reduce</strong> 。</p><p>由用户所编写的 <strong>Map</strong> 函数接收输入，并生成一个中间键值对集合。<strong>MapReduce</strong> 这个库会将所有共用一个键的值组合在一起，并将它们传递给 <strong>Reduce</strong> 函数。</p><p><strong>Reduce</strong> 函数也是由用户编写。它接受一个中间键以及该键的值的集合作为输入。它会将这些值合并在一起，以此来生成一组更小的值的集合。</p><blockquote><p>key / value 集合 —<strong>Map</strong>—&gt; 中间 key / value 集合 —<strong>MapReduce</strong>—&gt; key / value1 / value2 /… —<strong>Reduce</strong>—&gt; key / value.zip</p></blockquote><p>通常每次调用 <strong>Reduce</strong> 函数所产生的值的结果只有0个或者1个。中间值通过一个迭代器来传递给用户所编写的 <strong>Reduce</strong> 函数。这使得我们可以处理这些因为数据量太大而无法存放在内存中的存储值的list列表了。</p><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h3 id="例1"><a href="#例1" class="headerlink" title="例1"></a>例1</h3><p>背景：我们要从大量文档中计算出每个单词的出现次数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * key: document name</span><br><span class="hljs-comment"> * value: document contents</span><br><span class="hljs-comment"> * 返回一个单词加上它出现的次数的键值对</span><br><span class="hljs-comment">**/</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">map</span><span class="hljs-params">(string key, string value)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (word w: value) &#123;<br>        EmitIntermediate(w, <span class="hljs-string">&quot;1&quot;</span>);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * key: a word</span><br><span class="hljs-comment"> * values: a list of counts</span><br><span class="hljs-comment"> * 将该单词的出现次数统计出来</span><br><span class="hljs-comment">**/</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(string key, Iterator values)</span> </span>&#123;<br>    <span class="hljs-keyword">int</span> result = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span> (v: values) &#123;<br>        result += ParseInt(v);<br>        Emit(AsString(result));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="分布式过滤器"><a href="#分布式过滤器" class="headerlink" title="分布式过滤器"></a>分布式过滤器</h3><p><strong>Map</strong> 函数会发出（emit）匹配某个规则的一行。<strong>Reduce</strong> 函数是一个恒等函数，即把中间数据复制到输出。</p><h3 id="计算URL的访问频率"><a href="#计算URL的访问频率" class="headerlink" title="计算URL的访问频率"></a>计算URL的访问频率</h3><p><strong>Map</strong> 函数用来处理网页请求的日志，并输出(URL,1)。<strong>Reduce</strong> 函数则用于将相同URL的值全部加起来，并输出(URL, 访问总次数)这样的键值对结果。</p><h3 id="倒转网络链接图"><a href="#倒转网络链接图" class="headerlink" title="倒转网络链接图"></a>倒转网络链接图</h3><p><strong>Map</strong>函数会在源页面中找到所有的目标URL，并输出&lt;target, source&gt;这样的键值对。<strong>Reduce</strong>函数会将给定的目标URL的所有链接组合成一个列表，输出&lt;target, list(source)&gt;这样的键值对。</p><h3 id="每台主机上的检索词频率"><a href="#每台主机上的检索词频率" class="headerlink" title="每台主机上的检索词频率"></a>每台主机上的检索词频率</h3><p>term（这里是指搜索系统里的某一项东西，这里指检索词）vector（这里指数组）将一个文档或者是一组文档中出现的最重要的单词概括为&lt;单词，频率&gt; 这样的键值对列表，对于每个输入文档，<strong>Map</strong> 函数会输出这样一对键值对&lt;hostname, term vector&gt;（其中hostname是从文档中的URL里提取出来的）。<strong>Reduce</strong> 函数接收给定主机的所有每一个文档的term vector。它会将这些term vector加在一起，并去除频率较低的term，然后输出一个最终键值对&lt;hostname, term vector&gt;。</p><h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><p><strong>Map</strong> 函数会对每个文档进行解析，并输出&lt;word, 文档ID&gt;这样的键值对序列。<strong>Reduce</strong> 函数所接受的输入是一个给定词的所有键值对，接着它会对所有文档ID进行排序，然后输出&lt;word, list(文档ID)&gt;。所有输出键值对的集合可以形成一个简单的倒排索引。我们能简单的计算出每个单词在文档中的位置。</p><h3 id="分布式排序"><a href="#分布式排序" class="headerlink" title="分布式排序"></a>分布式排序</h3><p><strong>Map</strong> 函数会从每条记录中提取出一个key，然后输出&lt;key, record&gt;这样的键值对。<strong>Reduce</strong> 函数对这些键值对不做任何修改，直接输出。这种计算任务依赖分区机制以及排序属性。</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="执行概述"><a href="#执行概述" class="headerlink" title="执行概述"></a>执行概述</h2><p>将传入 <strong>Map</strong> 函数的输入数据自动切分为 <strong>M</strong> 个数据片段的集合，这样就能将 <strong>Map</strong> 操作分布到多台机器上运行。使用分区函数将 <strong>Map</strong> 函数所生成的中间 <strong>key</strong> 值分成 <strong>R</strong> 个不同的分区，这样就可以将 <strong>Reduce</strong> 操作也分布到多台机器上并行处理。</p><img src="/2020/10/26/MapReduce-%E5%9C%A8%E5%A4%A7%E5%9E%8B%E9%9B%86%E7%BE%A4%E4%B8%8A%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/MapReduce%E6%A1%86%E6%9E%B6.png" class="" title="MapReduce框架"><ul><li>用户程序中的 <code>MapReduce</code> 库会先将输入文件切分为 <code>M</code> 个片段，通常每个片段的大小在16MB到64MB之间（具体大小可以由用户通过可选参数来进行指定）。接着，它会在集群中启动许多个程序副本。</li><li>有一个程序副本是比较特殊的，那就是 <code>master</code> 。剩下的副本都是 <code>worker</code>，<code>master</code> 会对这些 <code>worker</code> 进行任务分配。这里有 <code>M</code> 个 <strong>Map</strong> 任务以及 <code>R</code> 个 <strong>Reduce</strong> 任务要进行分配。<code>master</code> 会给每个空闲的 <code>worker</code> 分配一个 <strong>map</strong> 任务或者一个 <strong>reduce</strong> 任务。</li><li>被分配了 <strong>map</strong> 任务的 <code>worker</code> 会读取相关的输入数据片段。它会从输入数据中解析出键值对，并将它们传入用户定义的 <code>Map</code> 函数中。Map函数所生成的中间键值对会被缓存在内存中。</li><li>每隔一段时间，被缓存的键值对会被写入到本地硬盘，并通过分区函数分到 <code>R</code> 个区域内。这些被缓存的键值对在本地磁盘的位置会被传回 <code>master</code>。<code>master</code> 负责将这些位置转发给执行 <code>reduce</code> 操作的 <code>worker</code>。</li><li>当 <code>master</code> 将这些位置告诉了某个执行 <code>reduce</code> 的 <code>worker</code> ，该 <code>worker</code> 就会使用 <code>RPC</code> 的方式去从保存了这些缓存数据的 <code>map worker</code> 的本地磁盘中读取数据。当一个 <code>reduce worker</code> 读取完了所有的中间数据后，它就会根据中间键进行排序，这样使得具有相同键值的数据可以聚合在一起。之所以需要排序是因为通常许多不同的key会映射到同一个 <code>reduce</code> 任务中。如果中间数据的数量太过庞大而无法放在内存中，那就需要使用外部排序。</li><li><code>reduce worker</code> 会对排序后的中间数据进行遍历。然后，对于遇到的每个唯一的中间键，<code>reduce worker</code> 会将该key和对应的中间value的集合传入用户所提供的 <code>Reduce</code> 函数中。<code>Reduce</code> 函数生成的输出会被追加到这个 <code>reduce</code> 分区的输出文件中。</li><li>当所有的 <code>map</code> 任务和 <code>reduce</code> 任务完成后，<code>master</code> 会唤醒用户程序。此时，用户程序会结束对 <code>MapReduce</code> 的调用。</li></ul><p>在成功完成任务后，<code>MapReduce</code> 的输出结果会存放在 <code>R</code> 个输出文件中（每个 <code>reduce</code> 任务都会生成对应的文件，文件名由用户指定）。一般情况下，用户无需将这些文件合并为一个文件。他们通常会将这些文件作为输入传入另一个 <code>MapReduce</code> 调用中。或者在另一个可以处理这些多个分割文件的分布式应用中使用。</p><h2 id="Master-的数据结构"><a href="#Master-的数据结构" class="headerlink" title="Master 的数据结构"></a>Master 的数据结构</h2><ul><li>保存了每个 <code>Map</code> 任务和每个 <code>Reduce</code> 任务的状态 (闲置，正在运行，以及完成)</li><li>非空闲任务 <code>worker</code> 机器的 <code>ID</code></li><li>保存由 <code>map</code> 任务所生成的中间文件区域的位置传播给 <code>reduce</code> 任务。对于每个完成的 <code>map</code> 任务，<code>master</code> 会保存由 <code>map</code> 任务所生成的 <code>R</code> 个中间文件区域的位置和大小。当 <code>map</code> 任务完成后，会对该位置和数据大小信息进行更新。这些信息会被逐渐递增地推送给那些正在运行的<code>Reduce</code>工作。</li></ul><h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><p>因为 <code>MapReduce</code> 库的设计旨在使用成百上千台机器来处理海量的数据，所以该库必须能很好地处理机器故障。</p><h3 id="Worker-故障"><a href="#Worker-故障" class="headerlink" title="Worker 故障"></a>Worker 故障</h3><p><code>master</code> 会周期 <code>ping</code> 下每个 <code>worker</code>. 如果在一定时间内无法收到来自某个 <code>worker</code> 的响应，那么 <code>master</code> 就会将该 <code>worker</code> 标记为 <code>failed</code>. 所有由该 <code>worker</code> 完成的 <code>Map</code> 任务都会被重设为初始的空闲 <code>idle</code> 状态。</p><h3 id="Master-故障"><a href="#Master-故障" class="headerlink" title="Master 故障"></a>Master 故障</h3><h2 id="地区性"><a href="#地区性" class="headerlink" title="地区性"></a>地区性</h2><h2 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h2><h2 id="备用任务"><a href="#备用任务" class="headerlink" title="备用任务"></a>备用任务</h2><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://mp.weixin.qq.com/s/sChCf07SxhTudxFIKd8pgA">https://mp.weixin.qq.com/s/sChCf07SxhTudxFIKd8pgA</a></p><p><a href="https://mp.weixin.qq.com/s/h43tPiycGrKf9089pML2tw">https://mp.weixin.qq.com/s/h43tPiycGrKf9089pML2tw</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Raft分布式一致性</title>
    <link href="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <url>/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<p>这篇文章就是简单描述一下Raft的原理</p><h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><p>首先假设我们有一个单节点的系统，我们可以认为这个节点是一个存储了一个值的数据库服务器</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft1.png" class="" title="raft1"><p>我们同时还有一个客户端可以发送值给这个节点</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft2.png" class="" title="raft2"><p>在单节点的情况下，非常容易达成一致，也就是共识（consensus）</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft3.gif" class="" title="raft3"><p>但是我们如何在多节点的情况下达成共识？这就是<strong>distributed consensus</strong>问题。<strong>Raft</strong>就是一个用来实现<strong>distributed consensus</strong>的协议。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft4.png" class="" title="raft4"><h1 id="Raft-原理"><a href="#Raft-原理" class="headerlink" title="Raft 原理"></a>Raft 原理</h1><p>一个节点有三种状态：<em>Follower</em>, <em>Leader</em>, <em>Candidate</em>。</p><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><h3 id="Leader-Election"><a href="#Leader-Election" class="headerlink" title="Leader Election"></a>Leader Election</h3><ol><li><p>刚开始所有的节点都处于<em>Follower</em>状态。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft5.png" class="" title="raft5"></li><li><p>当这些<em>followers</em>没有感知到<em>leader</em>，它们就会变成<em>candidate</em>。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft6.png" class="" title="raft6"></li><li><p>然后，<em>candidate</em>向其他节点拉票</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft7.gif" class="" title="raft7"></li><li><p>其他节点发起投票回复。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft8.gif" class="" title="raft8"></li><li><p><em>candidate</em>如果收到了半数节点以上的票，就会成为<em>leader</em>。</p></li></ol><h3 id="Log-Replication"><a href="#Log-Replication" class="headerlink" title="Log Replication"></a>Log Replication</h3><ol><li><p>接下来所有对系统的更改都要经过<em>leader</em>。每一个改动都被作为一条entry添加到节点的日志(log)中，现在这条log entry还是未提交的，所以不会更新节点里的值。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft10.gif" class="" title="raft10"></li><li><p>为了提交这个entry，<em>leader</em>把自己的log entry复制了一份给其他的<em>follower</em>。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft11.gif" class="" title="raft11"></li><li><p>然后<em>leader</em>等待直到超过半数的节点已经写入了entry。(每个<em>follower</em>写入entry就会通知<em>leader</em>)</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft12.gif" class="" title="raft12"></li><li><p>现在<em>leader</em>的log entry可以提交了，并把节点的值修改为“5”</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft13.png" class="" title="raft13"></li><li><p><em>leader</em>然后通知所有的<em>followers</em> log entry已经提交了。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft14.gif" class="" title="raft14"></li><li><p>现在这个集群对系统的状态达成了共识。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft15.png" class="" title="raft15"></li></ol><h2 id="具体细节"><a href="#具体细节" class="headerlink" title="具体细节"></a>具体细节</h2><h3 id="Leader-Election-1"><a href="#Leader-Election-1" class="headerlink" title="Leader Election"></a>Leader Election</h3><p>Raft中有控制选举的两个超时机制: election timeout</p><h4 id="Election-Timeout"><a href="#Election-Timeout" class="headerlink" title="Election Timeout"></a>Election Timeout</h4><blockquote><p>指一个<em>follower</em>等待直到成为<em>candidate</em>的时间。</p></blockquote><p>一般是150mm~300mm之间的一个随机数。</p><p>选举超时后，一个<em>follower</em>成为<em>candidate</em>开始一个新的选举周期并投票给自己</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft16.gif" class="" title="raft16"><p>同时向其他的节点发起拉票请求</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft17.png" class="" title="raft17"><p>如果收到拉票请求的节点在这个周期还没有投过票，那么他就会把票投给当前的<em>candidate</em>并重置自己的election timeout</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft18.gif" class="" title="raft18"><p>一旦一个<em>candidate</em>获得超过了半数的选票就会成为<em>leader</em>。<em>leader</em>开始发送<em>Append Entries</em>消息给<em>followers</em>。这些消息以<em>heartbreak timeout</em>为间隔发送，<em>followers</em> 然后回复这些消息。这个选举周期一直到一个<em>follower</em>停止接收心跳并且成为一个<em>candidate</em>。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft19.gif" class="" title="raft19"><h4 id="Leader-Stop"><a href="#Leader-Stop" class="headerlink" title="Leader Stop"></a>Leader Stop</h4><p>当一个<em>leader</em>停止后，会重新选举出<em>leader</em>。节点B现在是第二周期的<em>leader</em>。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft20.gif" class="" title="raft20"><h4 id="Split-Vote"><a href="#Split-Vote" class="headerlink" title="Split Vote"></a>Split Vote</h4><p>如果两个节点同时成为<em>candidate</em>，那么会发生split vote。两个节点在同一个周期同时发起选举。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft21.gif" class="" title="raft21"><p>并且每个<em>candidate</em>都先于另一个接触到其中一个<em>follower</em></p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft22.gif" class="" title="raft22"><p>现在每个<em>candidate</em>有两票并且在这个周期收不到更多的票了</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft23.gif" class="" title="raft23"><p>那么节点就等待直到一个新的选举。节点C在第五周期收获了绝大多数的投票成为了<em>leader</em>。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft24.gif" class="" title="raft24"><h3 id="Log-Replication-1"><a href="#Log-Replication-1" class="headerlink" title="Log Replication"></a>Log Replication</h3><p>一旦我们确定了<em>leader</em>，下一步就是给所有的结点复制所有的改动。运用用于心跳的相同的Append Entry消息来完成。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft25.gif" class="" title="raft25"><ol><li><p>首先一个客户端向<em>leader</em>发送一个改动，这个改动被追加到<em>leader</em>的日志中。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft26.gif" class="" title="raft26"></li><li><p>然后这次改动会在下一次心跳的时候通知所有的<em>followers</em></p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft27.gif" class="" title="raft27"></li><li><p>一旦超过半数的<em>follower</em>确认了，那么这次改动就被提交上去了并且给客户端发送一个回应。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft28.gif" class="" title="raft28"></li></ol><p>例：客户端现在发送一个”ADD 2”请求</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft29.gif" class="" title="raft29"><h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><p>Raft可以同样在网络分区中保持特性。假设现在把A, B和C, D, E区分开来。由于网络分区，我们现在有在不同周期有两个<em>leader</em>。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft30.gif" class="" title="raft30"><p>现在我们额外增加一个客户端并尝试同时去分别更新两个<em>leader</em>。节点B不能收到超过半数的回复，所以无法提交log entry。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft31.gif" class="" title="raft31"><p>另一个客户端尝试去把节点C更新为8。因为可以复制给超过半数的节点，所以成功了。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft32.gif" class="" title="raft32"><p>现在我们修复网络分区。节点B看到了更高的周期所以进行下一步，</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft33.gif" class="" title="raft33"><p>节点A, B会回滚他们未提交的log entry并且匹配新<em>leader</em>的日志。</p><img src="/2020/10/25/Raft%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/raft34.gif" class="" title="raft34"><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="http://thesecretlivesofdata.com/raft/">图解Raft流程</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式系统</title>
    <link href="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    <url>/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<p>这篇学习笔记是针对 MIT 6.824 Distributed System. B站链接 <a href="https://www.bilibili.com/video/av91748150/">https://www.bilibili.com/video/av91748150/</a></p><h1 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h1><ul><li>核心是通过网络是一群计算机相互通信来完成一些连贯的任务</li><li>使用分布式系统的原因<ul><li>实现并行</li><li>容错</li><li>物理上的原因（两台计算机处于不同的地理位置）</li><li>考虑到安全性</li></ul></li><li>分布式系统的挑战<ul><li>部分故障</li><li>提升性能</li></ul></li></ul><h2 id="基础架构"><a href="#基础架构" class="headerlink" title="基础架构"></a>基础架构</h2><ul><li>存储 (最为关注)</li><li>通信</li><li>计算</li></ul><p>目标：能够从分布式存储和计算(computation)基础结构中发现一些可抽象的东西并设计为接口以简化使用</p><h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><h2 id="threads"><a href="#threads" class="headerlink" title="threads"></a>threads</h2><h2 id="concurrency"><a href="#concurrency" class="headerlink" title="concurrency"></a>concurrency</h2><h1 id="性能-Performance"><a href="#性能-Performance" class="headerlink" title="性能 Performance"></a>性能 Performance</h1><h2 id="可扩展性-scalability"><a href="#可扩展性-scalability" class="headerlink" title="可扩展性 scalability"></a>可扩展性 scalability</h2><p>使用两倍的计算机或资源就能使我获得两倍的性能或吞吐量</p><h1 id="容错-Fault-Tolerance"><a href="#容错-Fault-Tolerance" class="headerlink" title="容错 Fault Tolerance"></a>容错 Fault Tolerance</h1><h2 id="可用性-Availability"><a href="#可用性-Availability" class="headerlink" title="可用性 Availability"></a>可用性 Availability</h2><h2 id="可恢复性-Recoverability"><a href="#可恢复性-Recoverability" class="headerlink" title="可恢复性 Recoverability"></a>可恢复性 Recoverability</h2><h2 id="非易失性存储-Non-volatile-memory"><a href="#非易失性存储-Non-volatile-memory" class="headerlink" title="非易失性存储 Non-volatile memory"></a>非易失性存储 Non-volatile memory</h2><h2 id="复制-Replication"><a href="#复制-Replication" class="headerlink" title="复制 Replication"></a>复制 Replication</h2><p>目前流行的三种变更复制的算法: <code>单领导者</code>, <code>多领导者</code>, <code>无领导者</code></p><h3 id="领导者与追随者"><a href="#领导者与追随者" class="headerlink" title="领导者与追随者"></a>领导者与追随者</h3><p>存储数据库副本的每一个节点称为<strong>副本(replica)</strong>.</p><ul><li>基于领导者的复制 (leader-based replication)<ul><li>其中一个副本被指定为 leader. 当客户端要向数据库写入时, 他必须将请求发送给 leader, leader 会将新数据写入器本地存储.</li><li>其他副本被称为 followers. 每当 leader 将新数据写入本地存储时, 他也会将数据变更发送给所有的 followers, 这称为<strong>复制日志(replication log)</strong>. 每个 follower 从 leader 拉取日志, 并相应更新其本地数据库副本, 按照 leader 处理的相同顺序应用所有写入.</li><li>leader 是有读写操作的, 而 follower 只有读操作.</li></ul></li></ul><h4 id="同步复制与异步复制"><a href="#同步复制与异步复制" class="headerlink" title="同步复制与异步复制"></a>同步复制与异步复制</h4><p>复制的一个重要细节就是: 同步还是异步的.</p><blockquote><p><strong>半同步</strong>: 由于从库可能存在(崩溃, 网络故障)等一系列原因, 将所有从库都设置成同步是不切实际的. 实际上, 如果在数据库上启用同步复制, 这意味着通常只有一个 follower 是同步的, 而其他的都是异步的. 如果发现同步的 follower 变得不可用或是缓慢, 使一个异步的 follower 同步. 这样就可以保证至少有在两个节点上拥有最新的数据副本.</p></blockquote><h4 id="设置新从库"><a href="#设置新从库" class="headerlink" title="设置新从库"></a>设置新从库</h4><ol><li>在某个时刻获取主库的一致性快照, 而不必锁定整个数据库.</li><li>将快照复制到新的从库节点</li><li>从库连接到主库, 并拉取快照之后发生的所有数据变更. 这要求快照与主库复制日志中的位置精确关联.</li><li>当从库处理完快照之后积压的数据变更. 现在可以继续处理主库上的数据变化了.</li></ol><h4 id="处理节点宕机"><a href="#处理节点宕机" class="headerlink" title="处理节点宕机"></a>处理节点宕机</h4><ul><li>从库失效: 追赶恢复</li><li>主库失效: 故障切换<ul><li>其中一个从库需要被提升为新的主库, 需要重新配置客户端, 以将他们的写操作发送给新的主库, 其他从库需要开始拉取来自新主库的数据变更.</li></ul></li></ul><h4 id="复制日志的实现"><a href="#复制日志的实现" class="headerlink" title="复制日志的实现"></a>复制日志的实现</h4><ul><li>基于语句的复制<ul><li>任何调用非确定性函数的语句都会在每个副本上生成不同的值.例如 <code>NOW()</code>, <code>RAND()</code></li><li>如果语句使用了自增列, 则必须在每个副本上按照完全相同的顺序执行.</li><li>有副作用的语句可能会在每个副本上产生不同的副作用.</li></ul></li><li>传输预写式日志<ul><li>日志都是包含所有数据库写入的仅追加字节序列.</li></ul></li><li>逻辑日志复制<ul><li>以行的粒度描述对数据库表的写入<ul><li>对于插入的行，日志包含所有列的新值。</li><li>对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，但是如果表上没有主键，则需要记录所有列的旧值。</li><li>对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少所有已更改的列的新值）。</li></ul></li></ul></li></ul><h3 id="复制延迟的问题"><a href="#复制延迟的问题" class="headerlink" title="复制延迟的问题"></a>复制延迟的问题</h3><p>当应用程序从异步从库中读取数据的时候, 如果从库落后, 它可能会看到过时的消息. 但这种不一致只是一个暂时的状态 —— 如果停止写入数据库并等待一段时间, 从库最终会赶上主库并保持一致. 这种效应被称为 <strong>最终一致性 (eventually consistency)</strong></p><ul><li><p>读写一致性</p><ul><li>如果用户重新加载页面, 他们总会看到他们自己提交的任何更新。</li><li>读用户<strong>可能已经修改过</strong>的内容时, 强制都从主库读. (例如: 社交网络上的用户个人资料信息通常只能由用户本人编辑，而不能由其他人编辑. 因此一个简单的规则就是: 从主库读取用户自己的档案，在从库读取其他用户的档案)</li><li>如果应用中的大部分内容都被用户编辑了<ul><li>可以跟踪上次更新时间, 在上次更新后的一分钟内, 从主库读. </li><li>也可以监控从库的复制延迟, 防止向任意滞后超过一分钟的从库发起查询.</li></ul></li></ul></li><li><p>单调读</p><ul><li>用户首先从新副本读取, 然后从旧副本读取. 可能会发现前后读取不一致的情况</li><li>确保每个用户总是从同一个副本进行读取 (不同的用户可以从不同的副本读取)</li></ul></li><li><p>一致前缀读</p><ul><li>如果一系列写入按某个顺序发生, 那么任何人读取这些写入时, 也会看见它们以同样的顺序出现.</li><li>确保任何因果相关的写入都写入相同的分区.</li></ul></li></ul><h3 id="多主复制"><a href="#多主复制" class="headerlink" title="多主复制"></a>多主复制</h3><p>基于领导者的复制有一个主要的缺点：只有一个主库，而所有的写入都必须通过它。如果出于任何原因（例如和主库之间的网络连接中断）无法连接到主库, 就无法向数据库写入。</p><p>多领导者配置可以在每个数据中心都有主库, 每个数据中心内部使用常规的主从复制; 在数据中心之间, 每个数据中心的主库都会将其更改复制到其他数据中心的主库中.</p><h4 id="处理写入冲突"><a href="#处理写入冲突" class="headerlink" title="处理写入冲突"></a>处理写入冲突</h4><p>多领导者复制最大问题是可能发生写冲突, 这意味着需要解决冲突.</p><ul><li>避免冲突<ul><li>如果应用程序可以确保特定记录的所有写入都通过同一个 leader , 那么这个冲突就不会发生.</li></ul></li><li>收敛至一直的状态<ul><li>给每个写入一个唯一的 ID, 挑选最高 ID 的写入作为胜利者, 并丢弃其他写入. (LWW, last write wins)</li><li>以某种方式将这些值合并在一起.</li><li>在保留所有信息的显式数据结构中记录冲突, 并编写解决冲突的应用程序代码</li></ul></li></ul><h4 id="多主复制拓扑"><a href="#多主复制拓扑" class="headerlink" title="多主复制拓扑"></a>多主复制拓扑</h4><p>有两个以上的 leader, 各种不同的拓扑时可能的.</p><img src="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E9%A2%86%E5%AF%BC%E6%8B%93%E6%89%91.png" class="" title="多领导拓扑"><ul><li>循环和星型拓扑的问题是, 如果只有一个结点发生故障, 则可能会中断其他节点之间的复制消息流, 导致无法通信, 直到节点修复.</li><li>全能拓扑也可能有问题. 一些网络连接可能比其他网络连接更快, 一些消息可能先于它所依赖的消息.<ul><li>可以使用版本向量(version vector)来解决.</li></ul></li></ul><h3 id="无主复制"><a href="#无主复制" class="headerlink" title="无主复制"></a>无主复制</h3><p>客户端直接将写入发送到几个副本中. 在无领导配置中, 故障切换不存在, 为了解决这个问题, 当一个客户端从数据库中读取数据的时候, 它不仅仅发送他的请求到一个副本; 读请求也被并行的发送到多个节点. 客户可能会从不同的节点获得不同的响应。即来自一个节点的最新值和来自另一个节点的陈旧值。版本号用于确定哪个值更新.</p><ul><li>法定人数<ul><li>如果有 n 个副本, 每个写入必须由 w 个节点确认才能被认为是成功的, 并且我们必须至少为每一个读取查询 r 个节点. (w + r &gt; n) 即可以保证在读取的节点中一定能够读取到最新的值.</li></ul></li></ul><p>如果两个操作都互相感觉不到对方的存在, 就称这两个操作<strong>并发</strong>.</p><p>服务器可以通过查看版本号来确定两个操作是否并发的</p><ol><li>服务器为每个键保留一个版本号，每次写入键时都增加版本号，并将新版本号与写入的值一起存储.</li><li>当客户端读取键时，服务器将返回所有未覆盖的值以及最新的版本号。客户端在写入前必须读取.</li><li>客户端写入键时，必须包含之前读取的版本号，并且必须将之前读取的所有值合并在一起.</li><li>当服务器接收到具有特定版本号的写入时，它可以覆盖该版本号或更低版本的所有值, 但是它必须保持所有值更高版本号.</li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul><li><a href="https://vonng.gitbooks.io/ddia-cn/content/ch5.html">设计数据密集型应用-第五章</a></li></ul><h2 id="分区-Partition"><a href="#分区-Partition" class="headerlink" title="分区 Partition"></a>分区 Partition</h2><p>分区是一种有意将大型数据库分解成小型数据库的方式.</p><blockquote><p>tips: 上文中的<strong>分区(partition)</strong>,在MongoDB,Elasticsearch和Solr Cloud中被称为<strong>分片(shard)</strong>,在HBase中称之为<strong>区域(Region)**，Bigtable中则是</strong>表块(tablet)<strong>，Cassandra和Riak中是</strong>虚节点(vnode)<strong>, Couchbase中叫做</strong>虚桶(vBucket)**.但是分区(partition) 是约定俗成的叫法。</p></blockquote><h3 id="分区与复制"><a href="#分区与复制" class="headerlink" title="分区与复制"></a>分区与复制</h3><p>不均衡导致的高负载的分区被称为热点(hot spot). 解决这个问题可以采用一些的办法</p><ul><li>根据键的范围分区<ul><li>为每个分区指定一块连续的键范围 (分区边界可以由管理员手动选择, 也可以由数据库自动选择)</li><li>缺点<ul><li>某些特定的访问模式会导致热点. (e.g., 主键是时间戳的话)</li></ul></li></ul></li><li>根据键的散列分区<ul><li>一个好的 hash function 可以将偏斜的数据均匀分布.</li><li>Java 中的 Object.hashCode() 和 Ruby 的 Object#hash, 同一个键可能在不同的进程中有不同的哈希值.</li><li>一致性哈希 <strong>(Consistent Hashing)</strong> <ul><li><a href="http://www.zsythink.net/archives/1182">一致性哈希算法 consistent hashing</a></li></ul></li></ul></li><li>负载倾斜与消除热点<ul><li>如果一个主键被认为是非常火爆的, 可以在这个主键的开始或结尾添加一个随机数.</li><li>需要一些方法来跟踪哪些键需要被分割(否则对于吞吐量低的绝大多数主键来是不必要的开销)</li></ul></li></ul><h3 id="分片与次级索引"><a href="#分片与次级索引" class="headerlink" title="分片与次级索引"></a>分片与次级索引</h3><h4 id="按文档的次级索引"><a href="#按文档的次级索引" class="headerlink" title="按文档的次级索引"></a>按文档的次级索引</h4><img src="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E6%8C%89%E6%96%87%E6%A1%A3%E7%9A%84%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95.png" class="" title="按文档的二级索引"><p>每个分区完全独立: 每个分区维护自己的二级索引, 仅覆盖该分区中的文档. 所以也被称为<strong>本地索引(local index)</strong>.</p><p>缺点: 可能会使二级索引上的读取查询相当昂贵.</p><h4 id="基于关键词的次级索引"><a href="#基于关键词的次级索引" class="headerlink" title="基于关键词的次级索引"></a>基于关键词的次级索引</h4><img src="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E6%8C%89%E5%85%B3%E9%94%AE%E8%AF%8D%E7%9A%84%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95.png" class="" title="按关键词的二级索引"><p>构建一个覆盖所有分区的全局索引, 而不是给每个自己分区创建自己的本地索引.</p><p>缺点: 写入速度较慢且较为复杂, 因为写入单个文档现在可能会影响索引的多个分区</p><h3 id="分区再平衡"><a href="#分区再平衡" class="headerlink" title="分区再平衡"></a>分区再平衡</h3><p>再平衡一般需要满足:</p><ul><li>再平衡之后, 负载(数据存储, 读取和写入请求)应该在集群中的节点之间公平地共享.</li><li>再平衡发生时, 数据库应该继续接受读取和写入</li><li>节点之间只移动必须的数据, 以便快速再平衡, 并减少网络和磁盘 I/O 负载.</li></ul><h4 id="固定数量的分区"><a href="#固定数量的分区" class="headerlink" title="固定数量的分区"></a>固定数量的分区</h4><p>创建比节点更多的分区, 并为每个节点分配多个分区. 如果一个节点被添加到集群中, 新节点可以从当前每个节点中拿走一些分区, 直到分区再次公平分配. 如果从集群中删除一个节点, 就会把节点中的分区再分配回去.</p><img src="/2020/10/22/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%9B%BA%E5%AE%9A%E6%95%B0%E9%87%8F%E7%9A%84%E5%88%86%E5%8C%BA.png" class="" title="固定数量的分区"><p>缺点: 数据集的总大小难以估计, 难以选择正确的分区数.</p><h4 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h4><p>按键的范围进行分区的数据库会动态创建分区. 当分区增长到超过配置的大小时, 会被分成两个分区, 每个分区约占一般的数据. 相反的, 如果大量数据被删除并且分区缩小到某个阈值以下, 则可以将其与相邻分区合并.</p><h4 id="按节点比例分区"><a href="#按节点比例分区" class="headerlink" title="按节点比例分区"></a>按节点比例分区</h4><p>以上两种分区方式, 分区的数量都与节点的数量无关.</p><p>每个分区的大小与数据集大小成比例地增长, 而节点数量保持不变, 但是当增加节点数时, 分区将再次变小. 由于较大的数据量通常需要较大数量的节点进行存储, 因此这种方法也使每个分区的大小较为稳定.</p><h1 id="分布式系统的麻烦"><a href="#分布式系统的麻烦" class="headerlink" title="分布式系统的麻烦"></a>分布式系统的麻烦</h1><ul><li>无法访问的网络</li><li>时钟和时序问题</li></ul><h2 id="故障与部分失效"><a href="#故障与部分失效" class="headerlink" title="故障与部分失效"></a>故障与部分失效</h2><p>在分布式系统中, 尽管系统的其他部分工作正常, 单系统的某些部分可能会以某种不可预知的方式被破坏. <strong>(partial failure 部分失效)</strong></p><h3 id="不可靠的网络"><a href="#不可靠的网络" class="headerlink" title="不可靠的网络"></a>不可靠的网络</h3><h4 id="检测故障"><a href="#检测故障" class="headerlink" title="检测故障"></a>检测故障</h4><ul><li>负载平衡器需要停止向已死亡的节点转发请求</li><li>在单主复制功能的分布式数据库中, 如果主库失效, 则需要将从库之一升级为新主库.</li></ul><h1 id="一致性与共识-Consistency-and-Consensus"><a href="#一致性与共识-Consistency-and-Consensus" class="headerlink" title="一致性与共识 Consistency and Consensus"></a>一致性与共识 Consistency and Consensus</h1><p><strong>共识(consensus)</strong> : 就是让所有的节点对某件事达成共识.</p><h2 id="一致性保证"><a href="#一致性保证" class="headerlink" title="一致性保证"></a>一致性保证</h2><h3 id="线性一致性-强一致性"><a href="#线性一致性-强一致性" class="headerlink" title="线性一致性 = 强一致性"></a>线性一致性 = 强一致性</h3><p>让系统看起来好像只有一个数据副本, 而且所有的操作都是原子性的.</p><h4 id="区别-线性一致性-Linearizability-vs-可序列化-Serializability"><a href="#区别-线性一致性-Linearizability-vs-可序列化-Serializability" class="headerlink" title="区别 线性一致性(Linearizability) vs. 可序列化(Serializability)"></a>区别 线性一致性(Linearizability) vs. 可序列化(Serializability)</h4><ul><li>可序列化<ul><li>Serializability 是事务的隔离属性.</li><li>它确保事务的行为, 与它们按照<strong>某种</strong>顺序依次执行的结果相同. 这种执行顺序可以与事务实际执行的顺序不同.</li><li>保证即使事务可以并行执行, 最终的结果也是一样的, 就好像它们没有任何并发性, 连续挨个执行一样.</li></ul></li><li>线性一致性<ul><li>不会将操作组合成事务. 是在单个对象上面的单个操作保证</li></ul></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Linux中的IO</title>
    <link href="/2020/08/30/Linux%E4%B8%AD%E7%9A%84IO/"/>
    <url>/2020/08/30/Linux%E4%B8%AD%E7%9A%84IO/</url>
    
    <content type="html"><![CDATA[<p>基于面试的时候，碰到了很多与 Linux 有关的话题，对这方面一直了解不够深。本文讨论的背景是network IO。</p><h1 id="概念说明"><a href="#概念说明" class="headerlink" title="概念说明"></a>概念说明</h1><p>在讨论之前，我们先需要明确几个基本的概念</p><h2 id="用户空间和内核空间"><a href="#用户空间和内核空间" class="headerlink" title="用户空间和内核空间"></a>用户空间和内核空间</h2><p>对 32 位操作系统而言，它的寻址空间（虚拟地址空间，或叫线性地址空间）为 4G（2的32次方）。也就是说一个进程的最大地址空间为 4G。操作系统的核心是内核(kernel)，它独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证内核的安全，现在的操作系统一般都强制用户进程不能直接操作内核。具体的实现方式基本都是由操作系统将虚拟地址空间划分为两部分，一部分为内核空间，另一部分为用户空间。针对 Linux 操作系统而言，最高的 1G 字节(从虚拟地址 0xC0000000 到 0xFFFFFFFF)由内核使用，称为内核空间。而较低的 3G 字节(从虚拟地址 0x00000000 到 0xBFFFFFFF)由各个进程使用，称为用户空间。</p><p>每个进程的4G地址空间中，最高1G都是一样的，即内核空间，剩下3G归进程使用。最高1G的内核空间是被所有<b>进程</b>共享的。</p><img src="/2020/08/30/Linux%E4%B8%AD%E7%9A%84IO/%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E5%92%8C%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4.png" class="" title="用户空间和内核空间"><h3 id="为什么区分内核空间和用户空间"><a href="#为什么区分内核空间和用户空间" class="headerlink" title="为什么区分内核空间和用户空间"></a>为什么区分内核空间和用户空间</h3><ul><li>CPU将指令分为特权指令和非特权指令，因为有的指令是非常危险的，如果错用，将导致系统崩溃。</li><li>对于危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令</li></ul><h3 id="内核态和用户态"><a href="#内核态和用户态" class="headerlink" title="内核态和用户态"></a>内核态和用户态</h3><p>当进程运行在内核空间时就处于内核状态，而进程运行在用户空间时则处于用户态。</p><ul><li>在内核态下，进程运行在内核地址空间，此时CPU可以执行任何指令。运行的代码也不受限制，可以自由访问任何有效地址，也可以直接进行端口访问。</li><li>在用户态下，进程运行在用户地址空间中，被执行的代码要受到 CPU 的诸多检查，它们只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址，且只能对任务状态段(TSS)中 I/O 许可位图(I/O Permission Bitmap)中规定的可访问端口进行直接访问。</li></ul><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://www.cnblogs.com/sparkdev/p/8410350.html">https://www.cnblogs.com/sparkdev/p/8410350.html</a></p><h2 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h2><p>为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这就被称为进程切换。</p><p>从一个进程的运行转到另一个进程上进行，整个过程经历了以下的变化</p><ol><li>保存处理机上下文</li><li>更新PCB信息</li><li>把进程的PCB移入相应的队列，如就绪、在某事件阻塞队列。</li><li>选择另一个进程执行，并更新其PCB</li><li>更新内存管理的数据结构</li><li>恢复处理机上下文</li></ol><p>tips: PCB (Process Control Block) 为了描述控制进程的运行，系统中存放进程的管理和控制信息的数据结构。是进程实体的一部分，是操作系统中最重要的记录性数据结构。</p><h2 id="进程的阻塞"><a href="#进程的阻塞" class="headerlink" title="进程的阻塞"></a>进程的阻塞</h2><p>正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种<b>主动</b>行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。</p><h2 id="文件的描述符"><a href="#文件的描述符" class="headerlink" title="文件的描述符"></a>文件的描述符</h2><p>文件描述符(File Descriptor)是一个用于表述指向文件的引用的抽象化概念。实际上，他是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。</p><h2 id="缓存-I-O"><a href="#缓存-I-O" class="headerlink" title="缓存 I/O"></a>缓存 I/O</h2><p>缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。</p><h1 id="IO-模式"><a href="#IO-模式" class="headerlink" title="IO 模式"></a>IO 模式</h1><p>接下来我们详细介绍一下IO的几种模式，对于一次IO的访问，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p><ol><li>用户进程空间 &lt;–&gt; 内核空间</li><li>内核空间 &lt;–&gt; 设备空间</li></ol><ul><li>Linux 中进程无法直接操作I/O设备，其必须通过系统调用请求kernel来协助完成I/O动作</li><li>内核会为每个I/O设备维护一个缓冲区</li><li>对于一个输入操作来说，进程IO系统调用后，内核会先看缓冲区中有没有相应的缓存数据，没有的话再到设备中读取，因为设备IO一般速度较慢，需要等待；内核缓冲区有数据则直接复制到进程空间。<ul><li>等待网络数据到达网卡 -&gt; 读取到内核缓冲区，准备好数据</li><li>从内核缓冲区复制数据到进程空间</li></ul></li></ul><p>由于这两个阶段的存在，Linux系统产生下面五种网络模式的方案</p><h2 id="阻塞-I-O"><a href="#阻塞-I-O" class="headerlink" title="阻塞 I/O"></a>阻塞 I/O</h2><p>在 Linux 中，默认情况下所有的socket都使用的阻塞，一个典型的读流程是这样的：</p><p>进程发起IO系统调用后，进程被阻塞，转到内核空间处理，整个IO处理完毕后返回进程。操作成功则进程获取数据。</p><blockquote><p>blocking IO 的特点就是在 IO 执行的两个阶段都被 block 了</p></blockquote><ol><li><p>应用: 阻塞socket, Java BIO</p></li><li><p>特点</p><ul><li>进程阻塞不消耗CPU资源，及时响应每个操作</li><li>实现难度低，开发比较容易</li><li>适用并发量小的网络应用开发</li><li>不适用并发量大的应用: 因为一个请求IO会阻塞线程，得为每请求分配一个处理进程(线程)以及时响应，系统开销大。</li></ul></li></ol><h2 id="非阻塞-I-O"><a href="#非阻塞-I-O" class="headerlink" title="非阻塞 I/O"></a>非阻塞 I/O</h2><p>在Linux 中，可以通过设置 socket 使其变为 non-blocking. 当对一个 non-blocking socket执行读操作时，流程是这样的：</p><p>进程发起IO系统调用后，如果内核缓冲区没有数据，需要到IO设备中读取，进程返回一个错误而不会被阻塞。进程发起IO系统调用后，如果内核缓冲区有数据，内核就会把数据返回进程。</p><ol><li><p>应用: socket的非阻塞方式</p></li><li><p>特点</p><ul><li>进程轮询调用消耗CPU资源</li><li>实现难度低，开发应用相对阻塞IO模式较难</li></ul></li></ol><h2 id="I-O-多路复用"><a href="#I-O-多路复用" class="headerlink" title="I/O 多路复用"></a>I/O 多路复用</h2><p>这里就涉及到我们说的 <code>select</code>, <code>poll</code>, <code>epoll</code>. 他们都是IO多路复用机制，I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪(一般是读就绪或者写就绪)，能够通知程序进行相应的读写操作。但<code>select</code>, <code>poll</code>, <code>epoll</code>本质上都是同步IO, 因为它们都需要在读写时间就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间</p><p><strong>select</strong>/<strong>poll</strong>的好处在于单个process就可以同时处理多个网络连接的I/O. 它的原理</p><p>上面的图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (<code>select</code> 和 <code>recvfrom</code>)，而blocking IO只调用了一个system call (<code>recvfrom</code>)。但是，用select的优势在于它可以同时处理多个connection。</p><h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><ul><li>select 调用是内核级别的，<code>select</code>轮询相对非阻塞区别在于：<code>select</code> 可以等待多个socket, 能实现同时对多个 IO 端口进行监听，当其中任何一个socket的数据准备好了，就能返回进行可读，然后进程再进行<code>recvform</code>系统调用，将数据由内核拷贝到用户进程，这个过程是阻塞的。</li><li><code>select</code>或者<code>poll</code> 调用之后，会阻塞进程。与blocking IO阻塞的区别在于，此时的select不是等到socket数据全部到达再处理，而是有了一部分数据就会调用用户进程来处理。<code>select</code>的优势在于它可以同时处理多个connection</li></ul><h4 id="具体流程"><a href="#具体流程" class="headerlink" title="具体流程"></a>具体流程</h4><ol><li>当用户进程调用 select, 那么整个进程会被 block. </li><li>同时, kernel会监视所有select负责的socket, 当任何一个socket中的数据准备好了, select就会返回。</li><li>这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。</li></ol><p>在 I/O 编程中，当需要同时处理多个客户端接入请求时，可以利用多线程或者 I/O 多路复用技术进行处理。I/O 多路复用技术通过把多个 I/O 的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。</p><h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul><li>I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源。</li></ul><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">select</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout)</span></span>;<br></code></pre></td></tr></table></figure><p>一共 <code>select</code> 函数监视的文件描述符分3类，分别是<code>writefds</code>、<code>readfds</code>、和<code>exceptfds</code>。调用后<code>select</code>函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当<code>select</code>函数返回后，可以 通过遍历<code>fdset</code>，来找到就绪的描述符。</p><p>注册IO、阻塞扫描，监听的IO最大连接数不能多于FD_SIZE</p><h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><p>原理和select相似，没有数量限制，但IO数量大 扫描线性性能下降</p><h4 id="具体实现-1"><a href="#具体实现-1" class="headerlink" title="具体实现"></a>具体实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">poll</span> <span class="hljs-params">(struct pollfd *fds, <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span> nfds, <span class="hljs-keyword">int</span> timeout)</span></span>;<br></code></pre></td></tr></table></figure><p>不同于<code>select</code>使用三个位置来表示三个fdset的方式，<code>poll</code>使用一个pollfd的指针来实现。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">pollfd</span> &#123;</span><br>    <span class="hljs-keyword">int</span> fd;        <span class="hljs-comment">// file description</span><br>    <span class="hljs-keyword">short</span> events;  <span class="hljs-comment">// requested events to watch</span><br>    <span class="hljs-keyword">short</span> revents; <span class="hljs-comment">// returned events witnessed </span><br>&#125;<br></code></pre></td></tr></table></figure><p>pollfd结构包含了要监视的event和发生的event，不再使用<code>select</code> “参数-值” 传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和<code>select</code>函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。</p><h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>事件驱动不阻塞，mmap实现内核与用户空间的消息传递，数量很大</p><p>// TODO</p><h3 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://www.jianshu.com/p/486b0965c296">https://www.jianshu.com/p/486b0965c296</a></p><h2 id="信号驱动-I-O"><a href="#信号驱动-I-O" class="headerlink" title="信号驱动 I/O"></a>信号驱动 I/O</h2><p>这个目前并不常见</p><h2 id="异步-I-O"><a href="#异步-I-O" class="headerlink" title="异步 I/O"></a>异步 I/O</h2><p>相比于同步IO，异步IO 不是顺序执行。用户进程进行<code>aio_read</code>系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户进程就可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。</p><h1 id="参考文献-2"><a href="#参考文献-2" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://segmentfault.com/a/1190000003063859">https://segmentfault.com/a/1190000003063859</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>nginx那些事</title>
    <link href="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h1><p>在介绍什么是 nginx 之前，我们先了解两个概念</p><h2 id="web服务器"><a href="#web服务器" class="headerlink" title="web服务器"></a>web服务器</h2><blockquote><p>负责处理和响应用户请求，一般也称为http服务器，如 Apache, IIS, Nginx</p></blockquote><h2 id="应用服务器"><a href="#应用服务器" class="headerlink" title="应用服务器"></a>应用服务器</h2><blockquote><p>存放和运行系统程序的服务器，负责处理程序中的业务逻辑，如 Tomcat, Weblogic, Jboss</p></blockquote><p>总结一下, nginx 就是</p><ul><li>一种轻量级的 web 服务器</li><li>采用事件驱动的异步非阻塞处理方式框架</li><li>占用内存少，启动速度快，并发能力强</li></ul><h2 id="Nginx的四大应用"><a href="#Nginx的四大应用" class="headerlink" title="Nginx的四大应用"></a>Nginx的四大应用</h2><h3 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h3><img src="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB.png" class="" title="动静分离"><p>通过示意图，我们可以得出，<strong>动静分离</strong>其实就是 nginx 服务器将收到的请求分为<strong>动态请求</strong>和<strong>静态请求</strong></p><ul><li>静态请求直接从 nginx 服务器所设定的根目录路径去取对应的资源，动态请求转发给真实的后台去处理，即是应用服务器(Tomcat)</li><li>这样做不仅能给应用服务器减轻压力，将后台 api 接口服务化，还能将前后端代码分开并行开发和部署。</li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;  <br>        <span class="hljs-attribute">listen</span>       <span class="hljs-number">8080</span>;        <br>        <span class="hljs-attribute">server_name</span>  localhost;<br><br>        <span class="hljs-attribute">location</span> / &#123;<br>            <span class="hljs-attribute">root</span>   html; <span class="hljs-comment"># Nginx默认值</span><br>            <span class="hljs-attribute">index</span>  index.html index.htm;<br>        &#125;<br>        <br>        <span class="hljs-comment"># 静态化配置，所有静态请求都转发给 nginx 处理，存放目录为 my-project</span><br>        <span class="hljs-attribute">location</span> <span class="hljs-regexp">~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|ico|js|css)$</span> &#123;<br>            <span class="hljs-attribute">root</span> /usr/local/var/www/my-project; <span class="hljs-comment"># 静态请求所代理到的根目录</span><br>        &#125;<br>        <br>        <span class="hljs-comment"># 动态请求匹配到path为&#x27;node&#x27;的就转发到8002端口处理</span><br>        <span class="hljs-attribute">location</span> /node/ &#123;  <br>            <span class="hljs-attribute">proxy_pass</span> http://localhost:8002; <span class="hljs-comment"># 充当服务代理</span><br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>访问静态资源 nginx 服务器会返回 <code>my-project</code> 里面的文件</li><li>访问动态请求 nginx 服务器会将它从8002端口请求到的内容，原封不动的返回回去</li></ul><h3 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h3><h4 id="什么是反向代理"><a href="#什么是反向代理" class="headerlink" title="什么是反向代理"></a>什么是反向代理</h4><p>反向代理其实就类似你去找代购帮你买东西（浏览器或其他终端向nginx请求），你不用管他去哪里买，只要他帮你买到你想要的东西就行（浏览器或其他终端最终拿到了他想要的内容，但是具体从哪儿拿到的这个过程它并不知道）。</p><h4 id="反向代理的作用"><a href="#反向代理的作用" class="headerlink" title="反向代理的作用"></a>反向代理的作用</h4><ol><li>保障应用服务器的安全 (增加一层代理，可以屏蔽危险攻击，更方便的控制权限)</li><li>实现负载均衡</li><li>实现跨域</li></ol><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;  <br>        <span class="hljs-attribute">listen</span>       <span class="hljs-number">8080</span>;        <br>        <span class="hljs-attribute">server_name</span>  localhost;<br><br>        <span class="hljs-attribute">location</span> / &#123;<br>            <span class="hljs-attribute">root</span>   html; <span class="hljs-comment"># Nginx默认值</span><br>            <span class="hljs-attribute">index</span>  index.html index.htm;<br>        &#125;<br>        <br>        <span class="hljs-attribute">proxy_pass</span> http://localhost:8000; <span class="hljs-comment"># 反向代理配置，请求会被转发到8000端口</span><br>&#125;<br></code></pre></td></tr></table></figure><p>上面这个例子意思是向 nginx 请求 <code>localhost:8080</code> 跟请求 <code>http://localhost:8000</code> 是一样的效果</p><img src="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86.png" class="" title="反向代理"><p>nginx 就充当图中的 proxy. 当左边三个client在请求向 nginx 获取内容，是感受不到三个server的存在的</p><blockquote><p>proxy 就充当了三个server的反向代理</p></blockquote><ul><li>CDN 服务就是经典的反向代理</li><li>反向代理也是实现负载均衡的基础</li></ul><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>随着业务的不断增长和用户的增多，一台服务器已经无法满足系统的需求。这个时候就出现了服务器<strong>集群</strong>。</p><p>在服务器集群中, nginx 可以将接收到的客户端请求“均匀地”（严格讲并不一定均匀，可以通过设置权重）分配到这个集群中所有的服务器上。这个就叫做负载均衡。</p><img src="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.png" class="" title="负载均衡"><h4 id="负载均衡的作用"><a href="#负载均衡的作用" class="headerlink" title="负载均衡的作用"></a>负载均衡的作用</h4><ul><li>分摊服务器集群压力</li><li>保证客户端访问的稳定性</li></ul><p>nginx 自带<strong>健康检查</strong>功能，会定期轮询向集群里的所有服务器发送健康检查请求，来检查集群中是否有服务器处于异常状态。一旦发现某台服务器出现异常，那么在这以后代理进来的客户端请求都不会被发送到该服务器上，从而保证客户端访问的稳定性。</p><p>配置一个负载均衡</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-comment"># 负载均衡：设置domain</span><br><span class="hljs-attribute">upstream</span> domain &#123;<br>    <span class="hljs-attribute">server</span> localhost:<span class="hljs-number">8000</span>;<br>    <span class="hljs-attribute">server</span> localhost:<span class="hljs-number">8001</span>;<br>&#125;<br><span class="hljs-section">server</span> &#123;  <br>        <span class="hljs-attribute">listen</span>       <span class="hljs-number">8080</span>;        <br>        <span class="hljs-attribute">server_name</span>  localhost;<br><br>        <span class="hljs-attribute">location</span> / &#123;<br>            <span class="hljs-comment"># root   html; # Nginx默认值</span><br>            <span class="hljs-comment"># index  index.html index.htm;</span><br>            <br>            <span class="hljs-attribute">proxy_pass</span> http://domain; <span class="hljs-comment"># 负载均衡配置，请求会被平均分配到8000和8001端口</span><br>            <span class="hljs-attribute">proxy_set_header</span> Host $host:$server_port;<br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>8000和80001是我本地用 Node.js 起的两个服务，负载均衡成功后可以看到访问 <code>localhost:8080</code> 有时会访问到8000端口的页面，有时会访问到8001端口的页面。</p><h3 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h3><img src="/2020/08/25/nginx%E9%82%A3%E4%BA%9B%E4%BA%8B/%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86.png" class="" title="正向代理"><p>正向代理跟反向道理正好相反。</p><blockquote><p>此时，proxy就充当了三个client的正向代理</p></blockquote><p>正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理。</p><p>科学上网vpn（俗称翻墙）其实就是一个正向代理工具。</p><p>该 vpn 会将想访问墙外服务器 server 的网页请求，代理到一个可以访问该网站的代理服务器 proxy 上。这个 proxy 把墙外服务器 server 上获取的网页内容，再转发给客户。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://juejin.im/entry/6844903464816869383">https://juejin.im/entry/6844903464816869383</a></p><p><a href="https://juejin.im/post/6844904129987526663">https://juejin.im/post/6844904129987526663</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Git的原理</title>
    <link href="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/"/>
    <url>/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>这篇文章主要是讲一讲git的底层实现原理，之前有了解过一点，现在作一个完整的梳理。</p><h1 id="Git-的信息是怎样被储存的"><a href="#Git-的信息是怎样被储存的" class="headerlink" title="Git 的信息是怎样被储存的"></a>Git 的信息是怎样被储存的</h1><p>首先我们初始化git, 可以发现新建了一个.git/目录，Git会将整个数据库储存在.git/目录下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git init<br>$ tree .git/objects<br>.git/objects<br>├── info<br>└── pack<br></code></pre></td></tr></table></figure><p>然后我们先创建两个文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ tree .git/objects<br>.git/objects<br>├── 58<br>│   └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c<br>├── c2<br>│   └── 00906efd24ec5e783bee7f23b5d7c941b0c12c<br>├── info<br>└── pack<br>$ <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;111&#x27;</span> &gt; a.txt<br>$ <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;222&#x27;</span> &gt; b.txt<br>$ git add *.txt<br></code></pre></td></tr></table></figure><p>可以看一个这个objects里面具体是什么</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ cat .git/objects/58/c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c<br>xKOR0a044K%<br></code></pre></td></tr></table></figure><p>这个乱码的出现其实是git把信息压缩成了二进制文件。但是不用担心，因为Git也提供了一个能够帮助你探索它的api <code>git cat-file [-t] [-p]</code>， -t可以查看object的类型，-p可以查看object储存的具体内容。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git cat-file -t 58c9<br>blob<br><br>$ git cat-file -p 58c9<br>111<br></code></pre></td></tr></table></figure><p>可以发现这个object是一个blob类型的节点，他的内容是111，也就是说这个object储存着a.txt文件的内容。这就引出了我们所说的第一个在git中数据存储的类型<strong>blob</strong></p><h2 id="Blob"><a href="#Blob" class="headerlink" title="Blob"></a>Blob</h2><p>它只储存的是一个文件的内容，不包括文件名等其他信息。然后将这些信息经过SHA1哈希算法得到对应的哈希值，这个哈希值就是这个文件在这个Git仓库中的唯一标识。即目前我们的Git 仓库是这样滴</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%861.png" class="" title="示意图"><p>我们继续探索, 我们新建了一个commit</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git commit -m <span class="hljs-string">&quot;[+] init&quot;</span><br>$ tree .git/objects<br>.git/objects<br>├── 4c<br>│   └── aaa1a9ae0b274fba9e3675f9ef071616e5b209<br>├── 58<br>│   └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c<br>├── ae<br>│   └── 202f2a6e3588115a05581d4dc12e082e3e97e4<br>├── c2<br>│   └── 00906efd24ec5e783bee7f23b5d7c941b0c12c<br>├── info<br>└── pack<br></code></pre></td></tr></table></figure><p>我们可以看到当我们commit了之后，又多了两个objects。使用cat-file看看具体的内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git cat-file -t 4caaa1<br>tree<br><br>$ git cat-file -p 4caaa1<br>100644 blob 58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6ca.txt<br>100644 blob c200906efd24ec5e783bee7f23b5d7c941b0c12cb.txt<br></code></pre></td></tr></table></figure><p>现在我们碰到了第二个数据类型<strong>tree</strong></p><h2 id="Tree"><a href="#Tree" class="headerlink" title="Tree"></a>Tree</h2><p>它将当前的目录结构打了一个快照。从它储存的内容来看可以发现它储存了一个目录结构（类似于文件夹），以及每一个文件（或者子文件夹）的权限、类型、对应的身份证（SHA1值）、以及文件名。现在我们的git仓库是这样的</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%862.png" class="" title="示意图"><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git cat-file -t ae20<br>commit<br><br>$ git cat-file -p ae20<br>tree 4caaa1a9ae0b274fba9e3675f9ef071616e5b209<br>author zhengchicheng.bob &lt;zhengchicheng.bob@bytedance.com&gt; 1598099521 +0800<br>committer zhengchicheng.bob &lt;zhengchicheng.bob@bytedance.com&gt; 1598099521 +0800<br><br>[+] init<br></code></pre></td></tr></table></figure><p>现在我们发现了第三种数据类型<strong>commit</strong></p><h2 id="Commit"><a href="#Commit" class="headerlink" title="Commit"></a>Commit</h2><p>它储存的是一个提交的信息，包括对应目录结构的快照tree的哈希值，上一个提交的哈希值（这里由于是第一个提交，所以没有父节点。在一个merge提交中还会出现多个父节点），提交的作者以及提交的具体时间，最后是该提交的信息。现在我们的数据库是这样的</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%863.png" class="" title="示意图"><p>那么目前为止，我们就已经知道了Git是如何去储存一个提交信息的了, 我们已经了解了Blob, Tree, Commit三个基本的数据类型。那么我们平时接触到的分支信息又存储在哪里呢</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ cat .git/HEAD<br>ref: refs/heads/master<br><br>$ cat .git/refs/heads/master<br>0c96bfc59d0f02317d002ebbf8318f46c7e47ab2<br></code></pre></td></tr></table></figure><p>在Git仓库中, HEAD、分支、普通的tag可以简单的理解成一个指针，指向对应commit的SHA1值。</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%864.png" class="" title="示意图"><blockquote><p>本质上Git是一个key-value的数据库加上默克尔树形成的无环图(DAG)</p></blockquote><p>tips: 默克尔树又叫哈希树，主要特点是:</p><ol><li>最下面的叶结点包含存储数据或其哈希值</li><li>非叶子结点都是他的两个孩子节点内容的哈希值<br>作用：</li><li>可以快速比较大量数据</li><li>快速定位修改</li></ol><h1 id="Git-的三个分区"><a href="#Git-的三个分区" class="headerlink" title="Git 的三个分区"></a>Git 的三个分区</h1><p>继续上面的例子，当前我们的仓库状态是这样的</p><img src="/2020/08/22/Git%E7%9A%84%E5%8E%9F%E7%90%86/Git%E5%8E%9F%E7%90%864.png" class="" title="示意图"><h2 id="工作目录"><a href="#工作目录" class="headerlink" title="工作目录"></a>工作目录</h2><p>操作系统上的文件，所有代码开发编辑都在这上面完成。</p><h2 id="Index-索引区"><a href="#Index-索引区" class="headerlink" title="Index 索引区"></a>Index 索引区</h2><p>可以理解成一个暂存区域，这里面的代码会在下一次commit被提交到Git仓库</p><h2 id="Git-仓库"><a href="#Git-仓库" class="headerlink" title="Git 仓库"></a>Git 仓库</h2><p>由Git object记录着每一次提交的快照，以及链式结构记录的提交变更历史</p><p>图解Git<br><a href="https://marklodato.github.io/visual-git-guide/index-zh-cn.html">https://marklodato.github.io/visual-git-guide/index-zh-cn.html</a></p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.jiqizhixin.com/articles/2019-12-20">https://www.jiqizhixin.com/articles/2019-12-20</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Docker那些事</title>
    <link href="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="容器生态系统"><a href="#容器生态系统" class="headerlink" title="容器生态系统"></a>容器生态系统</h1><h2 id="容器核心技术"><a href="#容器核心技术" class="headerlink" title="容器核心技术"></a>容器核心技术</h2><p>容器核心技术指的是能够让 Container 在 host 上运行起来的技术</p><h3 id="容器规范"><a href="#容器规范" class="headerlink" title="容器规范"></a>容器规范</h3><blockquote><p>我们熟知的Docker只是容器的一种</p></blockquote><p>OCI 发布了以下两个规范</p><ul><li>runtime spec</li><li>image format spec<br>有了这两个规范，不同组织和厂商开发的容器能够在不同的runtime上运行</li></ul><h3 id="容器runtime"><a href="#容器runtime" class="headerlink" title="容器runtime"></a>容器runtime</h3><p>Java 程序 -&gt; 容器</p><p>JVM -&gt; runtime</p><p>JVM 为 Java 程序提供运行环境，同样的容器只有在runtime中才能运行</p><p>目前主流的三种容器runtime</p><ul><li>lxc<ul><li>Linux 上老牌的容器 runtime</li><li>Docker 最初也使用的 lxc</li></ul></li><li>runc<ul><li>是 Docker 开发的容器，也是 Docker 默认的runtime</li></ul></li><li>rkt<ul><li>是 CoreOS 开发的容器</li></ul></li></ul><h3 id="容器管理工具"><a href="#容器管理工具" class="headerlink" title="容器管理工具"></a>容器管理工具</h3><p>有了 runtime 之后，用户得有工具来管理容器，每种不同的runtime有自己不同的管理工具</p><ul><li>lxc<ul><li>lxd</li></ul></li><li>runc <ul><li>docker engine<ul><li>cli</li><li>deamon</li></ul></li><li>我们提到的 Docker 一般指的就是 docker engine</li></ul></li><li>rkt<ul><li>rkt cli</li></ul></li></ul><h3 id="容器定义工具"><a href="#容器定义工具" class="headerlink" title="容器定义工具"></a>容器定义工具</h3><p>允许用户自己定义容器的内容和属性，这样容器可以被保存、共享、重建。</p><ul><li>docker image<ul><li>runtime 依据 docker image 创建容器</li></ul></li><li>dockerfile<ul><li>包含若干命令的文本文件，可以通过这个创建出docker image</li></ul></li><li>ACI (App Container Image) </li></ul><h3 id="Registries"><a href="#Registries" class="headerlink" title="Registries"></a>Registries</h3><p>因为容器是通过模板 image 来创建的，需要有一个仓库来统一存放 image, 这个仓库就叫做 Registry</p><ul><li>Docker Registry<ul><li>企业通过 Docker Registry 来构建私有的 Registry</li></ul></li><li>Docker Hub</li><li>Quay.io</li></ul><h3 id="容器OS"><a href="#容器OS" class="headerlink" title="容器OS"></a>容器OS</h3><p>容器 OS 是专门运行容器的操作系统。与常规 OS 相比，容器 OS 通常体积更小，启动更快</p><h2 id="容器平台技术"><a href="#容器平台技术" class="headerlink" title="容器平台技术"></a>容器平台技术</h2><p>容器核心技术使得容器能够在单个 host 上运行，而容器平台技术能够让容器作为集群在分布式环境中运行。</p><p>部署在容器中的应用一般采用微服务架构，在这种架构下，应用被划分为不同的组件，并以服务的形式运行在<strong>各自</strong>的容器中。为了保证应用的高可用，每个组件都可能会运行多个相同的容器。这些容器会组成集群，集群中的容器会根据业务需要被动的创建、迁移和销毁。</p><h3 id="容器编排引擎"><a href="#容器编排引擎" class="headerlink" title="容器编排引擎"></a>容器编排引擎</h3><p>编排 (orchestration) 包括容器管理、调度、集群定义和服务发现。通过容器编排引擎，容器被有机组合成微服务应用。</p><p>以下三个是当前主流的容器编排引擎</p><ul><li>docker swarm<ul><li>Docker 开发的容器编排阵容</li></ul></li><li>kubernetes<ul><li>Google 开发的容器编排阵容</li></ul></li><li>mesos + marathon</li></ul><h3 id="容器管理平台"><a href="#容器管理平台" class="headerlink" title="容器管理平台"></a>容器管理平台</h3><p>容器管理平台是架构在容器编排引擎之上的一个更为通用的平台。</p><ul><li>Rancher</li><li>ContainerShip</li></ul><h3 id="基于容器的PaaS"><a href="#基于容器的PaaS" class="headerlink" title="基于容器的PaaS"></a>基于容器的PaaS</h3><p>基于容器的 PaaS 为微服务应用开发人员与公司提供了开发、部署和管理应用的平台</p><ul><li>Deis</li><li>Flynn</li><li>Dokku</li></ul><h2 id="容器支持技术"><a href="#容器支持技术" class="headerlink" title="容器支持技术"></a>容器支持技术</h2><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AE%B9%E5%99%A8%E6%94%AF%E6%8C%81%E6%8A%80%E6%9C%AF.png" class="" title="容器支持技术"><h3 id="容器网络"><a href="#容器网络" class="headerlink" title="容器网络"></a>容器网络</h3><p>容器的出现使网络拓扑变得更加动态和复杂。用户需要专门的解决方案来管理容器与容器，容器与其他实体之间的连通性和隔离性。</p><ul><li>docker network</li><li>flannel</li><li>weave</li><li>calico</li></ul><h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p>动态变化是微服务应用的一大特点。当负载增加时，集群会自动创建新的容器; 负载减小，多余的容器会被销毁。容器也会根据 host 的资源使用情况在不同的 host 中迁移，容器的 IP 和端口也会随之发生变化。那么就必须有一种机制可以让 client 能够知道如何访问容器提供的服务</p><ul><li>etcd</li><li>consul</li><li>zookeeper</li></ul><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul><li>docker ps/top/stats</li><li>docker stats API</li><li>sysdig</li><li>cAdvisor/Heapster</li><li>Weave Scope</li></ul><h3 id="数据管理"><a href="#数据管理" class="headerlink" title="数据管理"></a>数据管理</h3><ul><li>Rex-Ray</li></ul><h3 id="日志管理"><a href="#日志管理" class="headerlink" title="日志管理"></a>日志管理</h3><ul><li>docker logs<ul><li>是 Docker 原生的日志工具</li></ul></li><li>logsput</li></ul><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><ul><li>OpenSCAP</li></ul><h1 id="容器核心知识概述"><a href="#容器核心知识概述" class="headerlink" title="容器核心知识概述"></a>容器核心知识概述</h1><h2 id="什么是容器-Container"><a href="#什么是容器-Container" class="headerlink" title="什么是容器(Container)"></a>什么是容器(Container)</h2><p>容器是一种轻量级、可移植、自包含的软件打包<strong>技术</strong>, 使应用程序可以在几乎任何地方以相同的方式运行。</p><h3 id="容器与虚拟机"><a href="#容器与虚拟机" class="headerlink" title="容器与虚拟机"></a>容器与虚拟机</h3><ul><li>容器<ul><li>不会虚拟硬件层</li><li>用 namespace 和 cgroups 进行隔离<ul><li>namespace 使每个进程只看到它自己的系统视图 (文件, 进程, 网络接口, 主机名). 进程只能看到同一个命名空间下的资源。<ul><li>存在多种类型的多个命名空间. 所以一个进程属于每个类型的一个命名空间<ul><li>Mount (mnt)</li><li>ProcessID (pid)</li><li>Network (net)</li><li>Inter-process communication (ipd)</li><li>UTS</li><li>UserID (user)</li></ul></li><li>通过分派两个不同的 UTS 命名空间给一对进程, 能使他们看见不同的本地主机名</li><li>一个进程属于什么 Network 命名空间决定了运行在进程里的应用程序能看见什么网络接口.</li></ul></li><li>cgroups 限制了进程能使用的资源量(CPU, 内存, 网络带宽)<ul><li>cgroups 是一个 Linux 内核功能, 它被用来限制一个进程或者一组进程的资源使用</li></ul></li></ul></li><li>应用程序本身</li><li><strong>依赖</strong><ul><li>应用程序需要的库或其他软件容器在 Host 操作系统的用户空间中运行，与<strong>操作系统的其他进程隔离</strong></li><li>这一点显著区别于虚拟机</li></ul></li></ul></li><li>虚拟机<ul><li>在一个宿主的平台上又搭建出一个完全隔离的环境<ul><li>把 CPU, 内存, 硬盘, 网卡, 显卡, 声卡都虚拟化了</li><li>在一整套虚拟硬件的基础上，再搭建一个虚拟系统</li></ul></li><li>VMWare, KVM, Xen</li><li>为了运行应用，除了部署应用本身及其依赖，还得安装整个操作系统</li></ul></li></ul><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AE%B9%E5%99%A8%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA.png" class="" title="容器与虚拟机"><ol><li>每个虚拟机需要运行自己的一组系统进程, 这就产生了除组件进程消耗以外的额外计算资源损耗</li><li>一个容器仅仅是运行在宿主机上被隔离的单个进程, 仅消耗应用容器消耗的资源, 不会有其他进程的开销</li></ol><h2 id="为什么需要容器"><a href="#为什么需要容器" class="headerlink" title="为什么需要容器"></a>为什么需要容器</h2><blockquote><p>容器使软件具备了超强的可移植能力</p></blockquote><ul><li>一个应用包含多种服务，这些服务有自己所依赖的库和软件包</li><li>存在多种部署环境，服务在运行时可能需要动态迁移到不同的环境中</li></ul><p>Docker 将集装箱思想运用到软件打包上，为代码提供了一个基于容器的标准化运输系统。Docker 可以将任何应用极其依赖打包成一个轻量级、可移植、自包含的容器。容器可以运行在几乎所有的操作系统上。</p><p>只需要配置好标准的 runtime 环境，服务器就可以运行任何容器。容器消除了开发、测试、生产环境的不一致性。</p><h2 id="容器是怎么工作的"><a href="#容器是怎么工作的" class="headerlink" title="容器是怎么工作的"></a>容器是怎么工作的</h2><h3 id="Docker-架构"><a href="#Docker-架构" class="headerlink" title="Docker 架构"></a>Docker 架构</h3><p>Docker 的核心组件</p><ul><li>Docker 客户端: Client</li><li>Docker 服务端: Docker daemon</li><li>Docker 镜像: Image</li><li>Registry</li><li>Docker 容器: Container</li></ul><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/Docker%E6%9E%B6%E6%9E%84.png" class="" title="Docker架构"><ul><li>Docker 采用 Client/Server 架构。</li><li>客户端向服务端发送请求，服务端负责构建、运行和分发容器</li><li>客户端和服务端可以运行在同一个 Host 上，客户端也可以通过 socket 或 REST API 与远程的服务器通信</li></ul><h3 id="Docker-客户端"><a href="#Docker-客户端" class="headerlink" title="Docker 客户端"></a>Docker 客户端</h3><h3 id="Docker-服务端"><a href="#Docker-服务端" class="headerlink" title="Docker 服务端"></a>Docker 服务端</h3><h3 id="Docker-镜像"><a href="#Docker-镜像" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h3><p>可将 Docker 镜像看成只读模板，通过它可以创建 Docker 容器。</p><ul><li>从无到有创建镜像</li><li>下载并使用别人创建好的现成镜像</li><li>在现有镜像上创建新的镜像</li></ul><h3 id="Docker-容器"><a href="#Docker-容器" class="headerlink" title="Docker 容器"></a>Docker 容器</h3><p>Docker 容器就是 Docker 镜像运行的实例</p><h3 id="Registry"><a href="#Registry" class="headerlink" title="Registry"></a>Registry</h3><p>Registry 是存放 Docker 镜像的仓库，Registry 分私有和公有两种。</p><h1 id="Docker-镜像-1"><a href="#Docker-镜像-1" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h1><h2 id="镜像的内部结构"><a href="#镜像的内部结构" class="headerlink" title="镜像的内部结构"></a>镜像的内部结构</h2><h3 id="base-镜像"><a href="#base-镜像" class="headerlink" title="base 镜像"></a>base 镜像</h3><ul><li>不依赖其他镜像，从 scratch 构建</li><li>其他镜像可以以之为基础进行扩展</li><li>能称作 base 镜像的通常都是各种 Linux 发行版的 Docker 镜像<ul><li>Ubuntu</li><li>Debian</li><li>CentOS</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ docker pull centos<br>$ docker images centos<br>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE<br>centos              latest              0d120b6ccaa8        6 weeks ago         215MB<br></code></pre></td></tr></table></figure><h4 id="为什么-SIZE-这么小"><a href="#为什么-SIZE-这么小" class="headerlink" title="为什么 SIZE 这么小"></a>为什么 SIZE 这么小</h4><p>Linux 操作系统是由内核空间和用户空间构成的</p><ol><li>rootfs</li></ol><ul><li>rootfs (用户空间 文件系统)<ul><li>/dev</li><li>/proc</li><li>/bin</li><li>/etc</li><li>/usr</li><li>/tmp</li><li>…</li></ul></li><li>bootfs<ul><li>kernel (内核空间)</li></ul></li></ul><p>对于 base 镜像来说，底层直接用 host 的 kernel, 自己只需要提供 rootfs 就好了</p><ol start="2"><li><p>base 镜像提供的是最小安装的 Linux 发行版</p></li><li><p>支持多种 Linux OS</p></li></ol><h3 id="镜像的分层结构"><a href="#镜像的分层结构" class="headerlink" title="镜像的分层结构"></a>镜像的分层结构</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">FROM</span> debian<br><span class="hljs-keyword">RUN</span><span class="bash"> apt-get install emacs</span><br><span class="hljs-keyword">RUN</span><span class="bash"> apt-get install apache2</span><br><span class="hljs-keyword">CMD</span><span class="bash"> [<span class="hljs-string">&quot;/bin/bash&quot;</span>]</span><br></code></pre></td></tr></table></figure><ol><li>从 debian base 镜像上构建</li><li>安装 emacs 编辑器</li><li>安装 apache2</li><li>容器启动时运行 bash</li></ol><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/%E9%95%9C%E5%83%8F%E7%9A%84%E5%88%86%E5%B1%82%E7%BB%93%E6%9E%84.png" class="" title="镜像的分层结构"><h4 id="可写的容器层"><a href="#可写的容器层" class="headerlink" title="可写的容器层"></a>可写的容器层</h4><ul><li>当容器启动的时候，一个新的可写层被加载到镜像的顶端</li><li>通常被称为<strong>容器层</strong>，<strong>容器层</strong>下面的叫做<strong>镜像层</strong></li></ul><img src="/2020/08/20/Docker%E9%82%A3%E4%BA%9B%E4%BA%8B/%E9%95%9C%E5%83%8F%E5%B1%82.png" class="" title="镜像层"><p>所有对容器的改动，无论添加、删除还是修改文件都只会发生在容器层中。只有容器层是可写的，容器层下面的镜像层是只读的。只有当需要修改时才复制出一份数据，这种特性被称之为 Copy-on-Write. 可见容器保存的是镜像变化的部分，不会对镜像本身进行修改。</p><h2 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h2><h3 id="docker-commit"><a href="#docker-commit" class="headerlink" title="docker commit"></a>docker commit</h3><ul><li>运行容器</li><li>修改容器</li><li>将容器保存为新的镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ docker run -it ubuntu<br>root@d4729bbdc9fb:/<span class="hljs-comment">#</span><br><span class="hljs-comment"># -it 参数的作用是已交互模式进入容器，并打开终端。d4729bbdc9fb 是容器内部 ID</span><br></code></pre></td></tr></table></figure><p>// todo 跳过</p><h2 id="分发镜像"><a href="#分发镜像" class="headerlink" title="分发镜像"></a>分发镜像</h2><ul><li>用相同的 Dockerfile 在其他 host 构建镜像</li><li>将镜像上传到公共 Registry (比如 Docker Hub) Host 直接下载使用</li><li>搭建私有的 Registry 供本地 Host 使用</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>《每天5分钟玩转Docker容器技术》</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>理解GoLang中的Context</title>
    <link href="/2020/08/05/%E7%90%86%E8%A7%A3GoLang%E4%B8%AD%E7%9A%84Context/"/>
    <url>/2020/08/05/%E7%90%86%E8%A7%A3GoLang%E4%B8%AD%E7%9A%84Context/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在实际的业务开发中，经常会有碰到一个在父协程中启动一个子协程的情况。一直没有弄明白这个子协程的关闭到底是否依赖与父协程，并且应该如何与父协程进行通信。今天在此补作一笔。</p><h1 id="子协程的退出问题"><a href="#子协程的退出问题" class="headerlink" title="子协程的退出问题"></a>子协程的退出问题</h1><p>先说结论，子协程是不会随着父协程的结束而结束，可以通过GoLang的MPG模型来理解，在此不做赘述。具体可以通过代码来发现</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    fmt.Println(<span class="hljs-string">&quot;main 函数 开始...&quot;</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;父 协程 开始...&quot;</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;子 协程 执行中...&quot;</span>)<br>timer := time.NewTimer(time.Second * <span class="hljs-number">2</span>)<br>&lt;-timer.C<br>&#125;<br>&#125;()<br>time.Sleep(time.Second*<span class="hljs-number">5</span>)<br>fmt.Println(<span class="hljs-string">&quot;父 协程 退出...&quot;</span>)<br>&#125;()<br>time.Sleep(time.Second*<span class="hljs-number">10</span>)<br>fmt.Println(<span class="hljs-string">&quot;main 函数 退出&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs erlang">main 函数 开始...<br>父 协程 开始...<br>子 协程 执行中...<br>子 协程 执行中...<br>子 协程 执行中...<br>父 协程 退出...<br>子 协程 执行中...<br>子 协程 执行中...<br></code></pre></td></tr></table></figure><p>可以得到结论</p><ul><li><code>main</code>函数退出，所有协程退出</li><li>协程无父子关系，在父协程开启新的协程，若父协程退出，不会影响子协程</li></ul><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>那么如何实现父协程与子协程的通信问题呢</p><h2 id="Context-上下文"><a href="#Context-上下文" class="headerlink" title="Context 上下文"></a>Context 上下文</h2><p>先看方式</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    fmt.Println(<span class="hljs-string">&quot;main 函数 开始...&quot;</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>ctx, cancel := context.WithCancel(context.Background())<br><span class="hljs-keyword">defer</span> cancel()<br>fmt.Println(<span class="hljs-string">&quot;父 协程 开始...&quot;</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-ctx.Done():<br>fmt.Println(<span class="hljs-string">&quot;子 协程 接受停止信号...&quot;</span>)<br><span class="hljs-keyword">return</span><br><span class="hljs-keyword">default</span>:<br>fmt.Println(<span class="hljs-string">&quot;子 协程 执行中...&quot;</span>)<br>timer := time.NewTimer(time.Second * <span class="hljs-number">2</span>)<br>&lt;-timer.C<br>&#125;<br>&#125;<br>&#125;<br>&#125;(ctx)<br>time.Sleep(time.Second*<span class="hljs-number">5</span>)<br>fmt.Println(<span class="hljs-string">&quot;父 协程 退出...&quot;</span>)<br>&#125;()<br>time.Sleep(time.Second*<span class="hljs-number">10</span>)<br>fmt.Println(<span class="hljs-string">&quot;main 函数 退出&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs erlang">main 函数 开始...<br>父 协程 开始...<br>子 协程 执行中...<br>子 协程 执行中...<br>子 协程 执行中...<br>父 协程 退出...<br>子 协程 接受停止信号...<br>main 函数 退出<br></code></pre></td></tr></table></figure><p>总算了我心头一事🐶，原来<code>context</code>是这么使用的。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Context <span class="hljs-keyword">interface</span> &#123;<br>Deadline() (deadline time.Time, ok <span class="hljs-keyword">bool</span>)<br>Done() &lt;-<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;<br>Err() error<br>Value(key <span class="hljs-keyword">interface</span>&#123;&#125;) <span class="hljs-keyword">interface</span>&#123;&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中，</p><ol><li><code>Deadline</code>: 返回<code>context.Context</code>被取消的时间</li><li><code>Done</code>: 返回一个Channel,这个Channel会在当前工作完成或者上下文被取消之后关闭, 多次调用<code>Done</code>会返回同一个Channel</li><li><code>Err</code>: 返回 <code>context.Context</code> 结束的原因，它只会在 <code>Done</code> 返回的 Channel 被关闭时才会返回非空的值</li><li><code>Value</code>: 从 <code>context.Context</code> 中获取键对应的值，对于同一个上下文来说，多次调用 <code>Value</code> 并传入相同的<code>Key</code> 会返回相同的结果，该方法可以用来传递请求特定的数据</li></ol><h3 id="Context-设计原理"><a href="#Context-设计原理" class="headerlink" title="Context 设计原理"></a>Context 设计原理</h3><p>见参考文献</p><h2 id="Channel-管道"><a href="#Channel-管道" class="headerlink" title="Channel 管道"></a>Channel 管道</h2><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/">https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/</a></p><p><a href="https://blog.csdn.net/cdq1358016946/article/details/106380790?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param">https://blog.csdn.net/cdq1358016946/article/details/106380790?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>RPC框架</title>
    <link href="/2020/07/23/RPC%E6%A1%86%E6%9E%B6/"/>
    <url>/2020/07/23/RPC%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="RPC-定义"><a href="#RPC-定义" class="headerlink" title="RPC 定义"></a>RPC 定义</h1><p>RPC是一种技术思想而非一种规范或协议，常见的RPC技术和框架有</p><ul><li>应用级的服务框架：阿里的Dubbo/Dubbox, Google的gRPC, Spring Boot/Spring Cloud</li><li>远程通信协议：RMI, Socket, SOAP(HTTP XML), REST(HTTP JSON)</li><li>通信框架：MINA和Netty</li></ul><p>RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。</p><h1 id="RPC-流程"><a href="#RPC-流程" class="headerlink" title="RPC 流程"></a>RPC 流程</h1><img src="/2020/07/23/RPC%E6%A1%86%E6%9E%B6/RPC%E6%A1%86%E6%9E%B6%E5%9B%BE.png" class="" title="RPC框架图"><ol><li>本地调用某个函数方法</li><li>本地机器的RPC框架把这个调用信息封装起来（调用的函数、入参等），序列化(json、xml等)后，通过网络传输发送给远程服务器。</li><li>远程服务器收到调用请求后，远程机器的RPC框架反序列化获得调用信息，并根据调用信息定位到实际要执行的方法，执行完这个方法后，序列化执行结果，通过网络传输把执行结果发送回本地机器。</li><li>本地机器的RPC框架反序列化出执行结果，函数return这个结果</li></ol><h1 id="GO-RPC-源码分析"><a href="#GO-RPC-源码分析" class="headerlink" title="GO RPC 源码分析"></a>GO RPC 源码分析</h1><h2 id="server端"><a href="#server端" class="headerlink" title="server端"></a>server端</h2><ul><li><p>server端首先进行方法注册，通过反射处理将方法取出后存到map中。</p></li><li><p>然后进行网络调用，主要是监听端口，读取数据包，解码请求，调用反射处理后的方法，将返回值编码，返回给客户端。</p><h3 id="方法注册"><a href="#方法注册" class="headerlink" title="方法注册"></a>方法注册</h3></li><li><p>Register</p></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Register publishes the receiver&#x27;s methods in the DefaultServer.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Register</span><span class="hljs-params">(rcvr <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">error</span></span> &#123; <span class="hljs-keyword">return</span> DefaultServer.Register(rcvr) &#125;<br><br><span class="hljs-comment">// RegisterName is like Register but uses the provided name for the type</span><br><span class="hljs-comment">// instead of the receiver&#x27;s concrete type.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">RegisterName</span><span class="hljs-params">(name <span class="hljs-keyword">string</span>, rcvr <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">error</span></span> &#123;<br><span class="hljs-keyword">return</span> DefaultServer.RegisterName(name, rcvr)<br>&#125;<br></code></pre></td></tr></table></figure><p>方法注册的入口函数有两个,分别为Register以及RegisterName,这里interface{}通常是带方法的对象.如果想要自定义方法的接收对象,则可以使用RegisterName.</p><ul><li>反射处理过程<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> methodType <span class="hljs-keyword">struct</span> &#123;<br>    sync.Mutex <span class="hljs-comment">// protects counters</span><br>    method     reflect.Method    <span class="hljs-comment">//反射后的函数</span><br>    ArgType    reflect.Type      <span class="hljs-comment">//请求参数的反射值</span><br>    ReplyType  reflect.Type      <span class="hljs-comment">//返回参数的反射值</span><br>    numCalls   <span class="hljs-keyword">uint</span>              <span class="hljs-comment">//调用次数</span><br>&#125;<br><br><br><span class="hljs-keyword">type</span> service <span class="hljs-keyword">struct</span> &#123;<br>    name   <span class="hljs-keyword">string</span>                 <span class="hljs-comment">// 服务名,这里通常为register时的对象名或自定义对象名</span><br>    rcvr   reflect.Value          <span class="hljs-comment">// 服务的接收者的反射值</span><br>    typ    reflect.Type           <span class="hljs-comment">// 接收者的类型</span><br>    method <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]*methodType <span class="hljs-comment">// 对象的所有方法的反射结果.</span><br>&#125;<br></code></pre></td></tr></table></figure>反射处理过程,其实就是将对象以及对象的方法,通过反射生成上面的结构,如注册<code>Arith.Multiply(xx,xx) error </code>这样的对象时,生成的结构为<code> map[&quot;Arith&quot;]service, service 中ethod为 map[&quot;Multiply&quot;]methodType</code>.</li></ul><h3 id="网络调用"><a href="#网络调用" class="headerlink" title="网络调用"></a>网络调用</h3><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://segmentfault.com/a/1190000013532622">https://segmentfault.com/a/1190000013532622</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>http和https的那些事</title>
    <link href="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><h2 id="HTTP-基本概念"><a href="#HTTP-基本概念" class="headerlink" title="HTTP 基本概念"></a>HTTP 基本概念</h2><p><b>HTTP（超文本传输协议，HyperText Transfer Protocol)</b>是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。是用于从WWW服务器传输超文本到本地浏览器的传输协议。默认使用80端口，HTTP客户端发起一个请求，建立一个到服务器指定端口（默认是80端口）的TCP连接，但是具体的通信不是在80端口。</p><p>我们可以把它拆成三个部分去理解</p><ul><li>超文本</li><li>传输</li><li>协议</li></ul><blockquote><p>协议</p></blockquote><p>HTTP 是一个用在计算机世界里的<strong>协议</strong>。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。</p><blockquote><p>传输 </p></blockquote><p>HTTP 协议是一个<strong>双向协议</strong></p><p>HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。</p><blockquote><p>超文本</p></blockquote><p>我们先来理解「文本」，在互联网早期的时候只是简单的字符文字，但现在「文本」的涵义已经可以扩展为图片、视频、压缩包等，在 HTTP 眼里这些都算作「文本」。</p><p>再来理解「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。</p><p>HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。</p><p>那么经过上面一系列分析，就可以给出比「超文本传输协议」这七个字更准确更有技术含量的答案：</p><blockquote><p>HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。</p></blockquote><p>HTTP协议和TCP协议是不冲突的，HTTP定义在七层协议中的应用层，TCP解决的是传输层的逻辑。HTTP使用TCP而不是UDP的原因在于（打开）一个网页必须传送很多数据，而TCP协议提供传输控制，按顺序组织数据，和错误纠正。所以<b>HTTP是一个基于TCP/IP通信协议来传递数据</b>。也要经过三次握手和四次挥手。</p><p><b>HTTP协议的瓶颈及其优化技巧都是基于TCP协议本身的特性。</b>如TCP建立连接时三次握手有1.5个RTT（round-trip time）的延迟，为了避免每次请求的都经历握手带来的延迟，应用层会选择不同策略的http长链接方案。(长连接和短连接会在下文中补充)又如TCP在建立连接的初期有慢启动（slow start）的特性，所以连接的重用总是比新建连接性能要好。</p><p>HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。HTTP/1.0是第一个在通讯中指定版本号的HTTP 协议版本，至今仍被广泛采用，特别是在代理服务器中。</p><p>HTTP/1.1是当前版本，持久连接被默认采用，并能很好地配合代理服务器工作，还支持以管道方式同时发送多个请求，以便降低线路负载，提高传输速度。HTTP／2.0在HTTP 1.x的基础上，大幅度的提高了web性能，减少了网络延迟。HTTP1.0和1.1在之后很长的一段时间内会一直并存，这是由于网络基础设施更新缓慢所决定的。</p><h3 id="常见的状态码"><a href="#常见的状态码" class="headerlink" title="常见的状态码"></a>常见的状态码</h3><h2 id="GET与POST"><a href="#GET与POST" class="headerlink" title="GET与POST"></a>GET与POST</h2><h2 id="HTTP-是无状态的"><a href="#HTTP-是无状态的" class="headerlink" title="HTTP 是无状态的"></a>HTTP 是无状态的</h2><p><a href="https://www.zhihu.com/question/23202402">https://www.zhihu.com/question/23202402</a></p><h2 id="HTTP-1-0"><a href="#HTTP-1-0" class="headerlink" title="HTTP 1.0"></a>HTTP 1.0</h2><p>HTTP 协议老的标准是HTTP/1.0，为了提高系统的效率，HTTP 1.0规定浏览器与服务器只保持<b>短暂的连接</b>，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。</p><p>但是，这也造成了一些性能上的缺陷，例如，一个包含有许多图像的网页文件中并没有包含真正的图像数据内容，而只是指明了这些图像的URL地址，当WEB浏览器访问这个网页文件时，浏览器首先要发出针对该网页文件的请求，当浏览器解析WEB服务器返回的该网页文档中的HTML内容时，发现其中的图像标签后，浏览器将根据标签中的src属性所指定的URL地址再次向服务器发出下载图像数据的请求。显然，访问一个包含有许多图像的网页文件的整个过程包含了多次请求和响应，每次请求和响应都需要建立一个单独的连接，每次连接只是传输一个文档和图像，上一次和下一次请求完全分离。即使图像文件都很小，但是客户端和服务器端每次建立和关闭连接却是一个相对比较费时的过程，并且会严重影响客户机和服务器的性能。当一个网页文件中包含JavaScript文件，CSS文件等内容时，也会出现类似上述的情况。</p><p>同时，带宽和延迟也是影响一个网络请求的重要因素。在网络基础建设已经使得带宽得到极大的提升的当下，大部分时候都是延迟在于响应速度。基于此会发现，http1.0被抱怨最多的就是<b>连接无法复用</b>，和<b>head of line blocking</b>这两个问题。理解这两个问题有一个十分重要的前提：客户端是依据域名来向服务器建立连接，一般PC端浏览器会针对单个域名的server同时建立6～8个连接，手机端的连接数则一般控制在4～6个。显然连接数并不是越多越好，资源开销和整体延迟都会随之增大。连接无法复用会导致每次请求都经历三次握手和慢启动。（多个连接的请求每次都要重新来）三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。head of line blocking会导致带宽无法被充分利用，以及后续健康请求被阻塞。</p><p>head of line blocking(holb)会导致健康的请求会被不健康的请求影响，而且这种体验的损耗受网络环境影响，出现随机且难以监控。为了解决holb带来的延迟，协议设计者设计了一种新的pipelining机制。pipelining只能适用于http1.1,而且由于使用苛刻，很多浏览器厂商并不支持。</p><p>tips: head of line blocking是队头阻塞，是指一列的第一个数据包（队头）受阻而导致整列数据报受阻。</p><h2 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP 1.1"></a>HTTP 1.1</h2><p>相较于HTTP1.0，HTTP1.1主要做了如下改动：</p><h3 id="长连接"><a href="#长连接" class="headerlink" title="长连接"></a>长连接</h3><ul><li>为了克服HTTP 1.0的这个缺陷，HTTP 1.1支持持久连接（HTTP/1.1的默认模式使用<strong>带流水线的持久连接</strong>），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。<ul><li>HTTP/1.1协议的持续连接有两种方式，即<strong>非流水线方式和流水线</strong>方式。非流水线方式的特点是，客户在收到前一个响应后才能发出下一个请求；流水线方式的特点是，客户在收到HTTP的响应报文之前就能接着发送新的请求报文。</li></ul></li><li>一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。</li><li>在 HTTP1.1 中默认开启 Connection： keep-alive，一定程度上弥补了 HTTP1.0 每次请求都要创建连接的缺点。</li></ul><h3 id="缓存处理"><a href="#缓存处理" class="headerlink" title="缓存处理"></a>缓存处理</h3><ul><li>在 HTTP1.0 中主要使用 header 里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。<h3 id="带宽优化及网络连接的使用"><a href="#带宽优化及网络连接的使用" class="headerlink" title="带宽优化及网络连接的使用"></a>带宽优化及网络连接的使用</h3></li><li>HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了range 头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</li></ul><h3 id="错误通知的管理"><a href="#错误通知的管理" class="headerlink" title="错误通知的管理"></a>错误通知的管理</h3><ul><li>在 HTTP1.1 中新增了24 个错误状态响应码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。</li></ul><h3 id="Host头处理"><a href="#Host头处理" class="headerlink" title="Host头处理"></a>Host头处理</h3><ul><li>在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个 IP 地址。HTTP1.1 的请求消息和响应消息都应支持 Host 头域，且请求消息中如果没有 Host 头域会报告一个错误（400 Bad Request）。</li><li>HTTP/1.0不支持文件断点续传，<code>RANGE:bytes</code>是HTTP/1.1新增内容，HTTP/1.0每次传送文件都是从文件头开始，即0字节处开始。<code>RANGE:bytes=XXXX</code>表示要求服务器从文件XXXX字节处开始传送，这就是我们平时所说的断点续传！</li><li>HTTP 1.1的持续连接，也需要增加新的请求头来帮助实现，例如，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。</li></ul><p>在http1.1，request和reponse头中都有可能出现一个connection的头，此header的含义是当client和server通信时对于长链接如何进行处理。<br>在http1.1中，client和server都是默认对方支持长链接的， 如果client使用http1.1协议，但又不希望使用长链接，则需要在header中指明connection的值为close；如果server方也不想支持长链接，则在response中也需要明确说明connection的值为close。不论request还是response的header中包含了值为close的connection，都表明当前正在使用的tcp链接在当天请求处理完毕后会被断掉。以后client再进行新的请求时就必须创建新的tcp链接了。</p><p>缺点：</p><ul><li>虽然HTTP1.1允许复用TCP连接，但是仍然没有解决队头阻塞的问题</li><li>HTTP1.x使用的都是<strong>明文</strong>传输，无法保证传输的安全性(后面会介绍使用HTTPS来增加传输的安全性)</li><li>HTTP1.x使用时，header里携带的内容过大，在一定程度上增加了传输的成本，并且每次请求 header 基本不怎么变化，尤其在移动端增加用户流量。</li><li><code>keep-alive</code>会给服务端带来巨大的性能压力，因为它在文件被请求后还保持了不必要的连接</li></ul><h2 id="SPDY-协议"><a href="#SPDY-协议" class="headerlink" title="SPDY 协议"></a>SPDY 协议</h2><p>SPDY 协议综合了HTTPS和HTTP两者于一体的传输协议</p><h3 id="降低延迟"><a href="#降低延迟" class="headerlink" title="降低延迟"></a>降低延迟</h3><ul><li><p>采用**多路复用(multiplexing)**。多路复用通过多个请求stream共享一个TCP连接的方式，解决了holb(head of line blocking)的问题，降低了延时同时提高了带宽的利用率。</p><h3 id="请求优先级"><a href="#请求优先级" class="headerlink" title="请求优先级"></a>请求优先级</h3></li><li><p>多路复用带来一个新的问题是，在连接共享的基础之上有可能会导致关键请求被阻塞。SPDY 允许给每个 request 设置优先级，这样重要的请求就会优先得到响应。比如浏览器加载首页，首页的 html 内容应该优先展示，之后才是各种静态资源文件，脚本文件等加载，这样可以保证用户能第一时间看到网页内容。</p><h3 id="header压缩"><a href="#header压缩" class="headerlink" title="header压缩"></a>header压缩</h3></li><li><p>前面提到 HTTP1.x 的 header 很多时候都是重复多余的。选择合适的压缩算法可以减小包的大小和数量。</p><h3 id="基于HTTPS的加密传输，大大提高了传输数据的可靠性"><a href="#基于HTTPS的加密传输，大大提高了传输数据的可靠性" class="headerlink" title="基于HTTPS的加密传输，大大提高了传输数据的可靠性"></a>基于HTTPS的加密传输，大大提高了传输数据的可靠性</h3><h3 id="服务端推送-server-push"><a href="#服务端推送-server-push" class="headerlink" title="服务端推送(server push)"></a>服务端推送(server push)</h3></li><li><p>采用了SPDY的网页</p><h3 id="SPDY构成图"><a href="#SPDY构成图" class="headerlink" title="SPDY构成图:"></a>SPDY构成图:</h3>  <img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/SPDY.png" class="" title="SPDY"></li></ul><h2 id="HTTP-2-0"><a href="#HTTP-2-0" class="headerlink" title="HTTP 2.0"></a>HTTP 2.0</h2><p>HTTP 2.0是SPDY的升级版，主要有以下两点区别：</p><ul><li>HTTP2.0 支持明文 HTTP 传输，而 SPDY 强制使用 HTTPS</li><li>HTTP2.0 消息头的压缩算法采用 HPACK，而非 SPDY 采用的 DEFLATE</li></ul><h3 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a>二进制分帧</h3><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><ul><li>连接(Connection)<ul><li>一个TCP连接包含多个stream</li></ul></li><li>流(Stream)<ul><li>流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）</li><li>在建立连接后，一次的请求与被响应，可以看作流</li><li>一个双向通讯数据流，包含一条或多条message</li></ul></li><li>消息(Message)<ul><li>是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧(frame)组成。</li></ul></li><li>帧(Frame)<ul><li>客户端与服务器通过交换帧来通信，帧是基于这个新协议通信的最小单位，以二进制压缩格式存放 HTTP1.x 中的内容。</li><li>每一帧都包含几个字段,<code>length</code>, <code>type</code>, <code>flags</code>等。</li></ul></li></ul><p>HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。 HTTP / 1 的请求和响应报文，都是由起始行，首部和实体正文（可选）组成，各部分之间以文本换行符分隔。HTTP 2.0将请求和响应数据分割为更小的帧，并且它们采用二进制编码。</p><ul><li><p>帧、流、消息的关系</p>  <img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E6%B5%81-%E6%B6%88%E6%81%AF-%E5%B8%A7.png" class="" title="流-消息-帧"></li></ul><h3 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h3><p>多路复用代替原来的序列和阻塞机制，所有的请求都是通过一个TCP连接并发的完成。同时也很好的解决了浏览器限制同一个域名下的请求数量的问题。</p><ul><li>同域名下所有的通信都是在单个连接上完成，同个域名只需要占用一个TCP连接，使用一个连接并行发送多个请求和响应。</li><li>单个连接可以承载任意数量的双向数据流，单个连接上可以并行交错的请求和响应，之间互不干扰。</li><li>数据流以消息的形式发送，而消息又有一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。每个请求都可以带一个31bits的优先值，0表示最高优先级，数值越大优先级越低。</li></ul><p><a href="https://juejin.im/post/5d70848df265da03d871de9c">https://juejin.im/post/5d70848df265da03d871de9c</a></p><p>HTTP 2.0 的多路复用其实是 HTTP 1.1 中长连接的升级版本。</p><p>在 HTTP 1.1 中，一次链接成功后，只要该链接还没断开，那么 client 端可以在这么一个链接中有序地发起多个请求，并以此获得每个请求对应的响应数据。它的缺点是，一次请求与响应的交互必须要等待前面的请求交互完成，否则后面的只能等待，这个就是<b>线头阻塞.</b> 下面举个例子：</p><blockquote><p>请求A 和 请求B。A 先被发起，此时 server 端接收到了 A 请求，正在处理。同时 B 请求也发过来了。但是 A 请求还没被返回，此时 B 请求只能等待。</p></blockquote><p>在 HTTP 2.0 中，一次链接成功后，只要链接还没断开，那么 client 端就可以在一个链接中并发地发起多个请求，每个请求及该请求的响应不需要等待其他的请求，某个请求任务耗时严重，不会影响到其它连接的正常执行。</p> <img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" class="" title="多路复用"><h3 id="首部压缩"><a href="#首部压缩" class="headerlink" title="首部压缩"></a>首部压缩</h3><p>HTTP1.x 的 header 带有大量信息，而且每次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的header大小，通讯双方各自cache一份header fields表，既<b>避免了重复 header 的传输</b>，<b>又减小了需要传输的大小</b>。</p><ul><li>HTTP 2.0 在客户端和服务端使用”首部表”来跟踪和存储之前发送的键 - 值对，不再重复发送header</li><li>首部表在HTTP 2.0 的连接存续期内始终存在，由客户端和服务器共同渐进地更新</li><li>每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值</li></ul><blockquote><p>示例：</p></blockquote> <img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E9%A6%96%E9%83%A8%E5%8E%8B%E7%BC%A9.png" class="" title="首部压缩"><h3 id="服务端推送"><a href="#服务端推送" class="headerlink" title="服务端推送"></a>服务端推送</h3><p>Server Push 即服务端能通过 push 的方式将客户端需要的内容预先推送过去，也叫 “cache push”. 服务器可以对一个客户端请求发送多个响应。服务器向客户端推送资源无需客户端明确地请求，服务端可以提前给客户端推送必要的资源，这样可以减少请求延迟时间，例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不是等到 HTML 解析到资源时发送请求。</p><p>tips: 所有推送的资源都遵守同源策略。 服务器必须遵循请求- 响应的循环，只能借着对请求的响应推送资源。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.jianshu.com/p/52d86558ca57">https://www.jianshu.com/p/52d86558ca57</a></p><p><a href="https://juejin.im/post/5d7082bcf265da03f233ed9b">https://juejin.im/post/5d7082bcf265da03f233ed9b</a></p><h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><h2 id="HTTPS-的加密方式"><a href="#HTTPS-的加密方式" class="headerlink" title="HTTPS 的加密方式"></a>HTTPS 的加密方式</h2><h3 id="加密方式"><a href="#加密方式" class="headerlink" title="加密方式"></a>加密方式</h3><ul><li>对称加密</li><li>非对称加密<h4 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h4></li></ul><img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png" class="" title="对称加密"><ul><li>定义<ul><li>需要对加密和解密使用相同密钥的加密算法。所谓对称，就是采用这种加密方法的双方使用方式用同样的密钥进行加密和解密。密钥是控制加密及解密过程的指令。算法是一组规则，规定如何进行加密和解密。</li></ul></li><li>算法实现<ul><li>可以参见<a href="https://juejin.im/post/5b48b0d7e51d4519962ea383">https://juejin.im/post/5b48b0d7e51d4519962ea383</a> 再次不作过多的叙述。</li></ul></li></ul><h4 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h4><p>由于使用对称加密的话，密钥是使用明文传输的，任然存在被截取的风险，这就是非对称加密的由来。</p><img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png" class="" title="非对称加密"><ul><li>定义<ul><li>非对称加密算法需要两个密钥：公开密钥（publickey:简称公钥）和私有密钥（privatekey:简称私钥）。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密。如果用公钥对数据进行加密，只有用对应的私钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。</li></ul></li></ul><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>由于非对称加密在加密的时候速度特别慢，比对称加密慢了上百倍。所以我们选用对称加密+非对称加密的形式。</p><h3 id="对称加密-非对称加密："><a href="#对称加密-非对称加密：" class="headerlink" title="对称加密+非对称加密："></a>对称加密+非对称加密：</h3><p>服务器用明文的方式给客户端发送自己的公钥，客户端收到公钥之后，会生成一把密钥(对称加密用的)，然后用服务器的公钥对这把密钥进行加密，之后再把密钥传输给服务器，服务器收到之后进行解密，最后服务器就可以安全着得到这把密钥了，而客户端也有同样一把密钥，他们就可以进行对称加密了。</p><h3 id="风险"><a href="#风险" class="headerlink" title="风险"></a>风险</h3><p>服务器以明文的方式给客户端传输公钥的时候，中间人截取了这把属于服务器的公钥，并且把中间人自己的公钥冒充服务器的公钥传输给了客户端。之后客户端就会用中间人的公钥来加密自己生成的密钥。然后把被加密的密钥传输给服务器，这个时候中间人又把密钥给截取了，中间人用自己的私钥对这把被加密的密钥进行解密，解密后中间人就可以获得这把密钥了。最后中间人再对这把密钥用刚才服务器的公钥进行加密，再发给服务器。</p><p>非对称加密之所以不安全，是因为客户端不知道这把公钥是不是属于服务器的。如何解决这个问题呢，就需要引入<strong>数字证书</strong>。</p><h2 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h2><ul><li>我们需要找到一个拥有公信力、大家都认可的认证中心(CA)。</li><li>服务器在给客户端传输公钥的过程中，会把公钥以及服务器的个人信息通过Hash算法生成<strong>信息摘要</strong>。</li><li>为了防止信息摘要被人调换，客户端还会用CA提供的私钥对信息摘要进行加密来形成<strong>数字签名</strong>。</li><li>把原来没Hash算法之前的个人信息以及公钥 和 数字签名合并在一起，形成<strong>数字证书</strong>。</li></ul><img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6_%E6%9C%8D%E5%8A%A1%E7%AB%AF.png" class="" title="数字证书_服务端"><ul><li>当数字证书拿到这份数字证书的时候，就会用CA提供的公钥来对数字证书里面的数字签名进行解密来得到信息摘要，然后对数字证书里服务器的公钥以及个人信息进行Hash得到另外一份信息摘要。最后把两份信息摘要进行对比，如果一样，则证明这个人是服务器。</li></ul><img src="/2020/07/14/http%E5%92%8Chttps%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6_%E5%AE%A2%E6%88%B7%E7%AB%AF.png" class="" title="数字证书_客户端"><blockquote><p>客户端如何获得CA的公钥, 服务器又怎么会有CA的私钥</p></blockquote><p>其实，(有些)服务器一开始就向认证中心申请了这些证书了(有没有看过没有证书的网站在地址栏会被标出警告？)，而客户端是，也会内置这些证书。当客户端收到服务器传输过来的数据数字证书时，就会在内置的证书列表里，查看是否有解开该数字证书的公钥。</p><h3 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://segmentfault.com/a/1190000019687184">https://segmentfault.com/a/1190000019687184</a></p><p><a href="https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/30-zhang-tu-jie-http-chang-jian-mian-shi-ti">https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/30-zhang-tu-jie-http-chang-jian-mian-shi-ti</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>kite框架和gin框架</title>
    <link href="/2020/07/13/kite%E6%A1%86%E6%9E%B6%E5%92%8Cgin%E6%A1%86%E6%9E%B6/"/>
    <url>/2020/07/13/kite%E6%A1%86%E6%9E%B6%E5%92%8Cgin%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>字符编码</title>
    <link href="/2020/07/11/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/"/>
    <url>/2020/07/11/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>IO那些事</title>
    <link href="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<p>本来计划七月OKR了解一下经常面经中看到但是不很了解的“I/O多路复用”，发现自己在整理序列化，反序列化的时候连基本的I/O也没有整明白，于是搜集资料准备好好梳理一下</p><h1 id="为什么使用I-O"><a href="#为什么使用I-O" class="headerlink" title="为什么使用I/O"></a>为什么使用I/O</h1><ul><li>当我们的程序需要从硬盘，网络，或其他应用程序中读取或写入数据时候，数据传输量可能很大，而我们的内存或带宽有限，<strong>无法一次性读取获取写入大量数据</strong>。</li><li>而流（Stream）可以实现一点一点的逐步传输数据。</li><li>想想我们是怎样下载一个大文件的, 下载软件(例如x雷)并不会占用你内存很大的空间, 而只是在内存划分一个缓冲区, 一点一点地下载到自己的内存(缓冲区满了再写到硬盘)。</li></ul><h1 id="I-O在Java中的架构"><a href="#I-O在Java中的架构" class="headerlink" title="I/O在Java中的架构"></a>I/O在Java中的架构</h1><h2 id="I-O-的分类"><a href="#I-O-的分类" class="headerlink" title="I/O 的分类"></a>I/O 的分类</h2><h3 id="从流的方向划分"><a href="#从流的方向划分" class="headerlink" title="从流的方向划分"></a>从流的方向划分</h3><ul><li><p>输入流 (I)</p><ul><li>  <img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/Input.jpg" class="" title="Input"></li></ul></li><li><p>输出流 (O)</p><ul><li>  <img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/Output.jpg" class="" title="Output"><h3 id="从流的传输单位来分"><a href="#从流的传输单位来分" class="headerlink" title="从流的传输单位来分"></a>从流的传输单位来分</h3></li></ul></li><li><p>字节流 (8位字节)</p><ul><li>每次读取（写出）一个字节，当传输资源有中文时，就会出现乱码。</li><li>具体参见 为什么会乱码 // TODO</li></ul></li><li><p>字符流 (16位字节)</p><ul><li>每次读取（写出）两个字节，有中文时，使用流程就可以正确传输显示中文。<h2 id="Java中的分类"><a href="#Java中的分类" class="headerlink" title="Java中的分类"></a>Java中的分类</h2></li></ul></li><li><p>四大基本类型</p><table><thead><tr><th></th><th>输入流</th><th>输出流</th></tr></thead><tbody><tr><td>字节流</td><td>InputStream 字节输入流</td><td>OutputStream 字符输出流</td></tr><tr><td>字符流</td><td>Reader 字符输入流</td><td>Writer 字符输出流</td></tr></tbody></table></li><li><p>各自的子类都以父类作为自己的后缀，比如文件的字节输出流：FileOutputStream</p><h2 id="Java中的架构"><a href="#Java中的架构" class="headerlink" title="Java中的架构"></a>Java中的架构</h2></li><li><img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/JavaIO%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class="" title="JavaIO体系架构图"></li><li><p>流的选择</p><ul><li>选用输入流还是输出流，根据具体的使用场景判断，如果是写程序到别的地方，那么就使用输出流。反之就是输入流。</li><li>如果传输的数据有中文，那么选择字符流。</li><li>再根据额外需要的功能具体选择。<h2 id="Java底层实现"><a href="#Java底层实现" class="headerlink" title="Java底层实现"></a>Java底层实现</h2><h3 id="字节输入流-InputStream"><a href="#字节输入流-InputStream" class="headerlink" title="字节输入流 InputStream"></a>字节输入流 InputStream</h3></li></ul></li><li>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">InputStream</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Closeable</span> </span>&#123;<br><br>    <span class="hljs-comment">// Reads the next byte of data from the input stream.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-keyword">int</span> <span class="hljs-title">read</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException</span>;<br><br><br>    <span class="hljs-comment">// Closes this stream and releases any system resources associated with it.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;&#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">    Skips over and discards n bytes of data from this inputstream.</span><br><span class="hljs-comment">    <span class="hljs-doctag">@return</span>     the actual number of bytes skipped.</span><br><span class="hljs-comment">    */</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">skip</span><span class="hljs-params">(<span class="hljs-keyword">long</span> n)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-comment">// ...</span><br>    &#125;<br><br><br>    <span class="hljs-comment">// Returns an estimate of the number of bytes that can be read (or skipped over) from this input stream without blocking by the next invocation of a method for this input stream.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">available</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;###<br><br>    <span class="hljs-comment">// Marks the current position in this input stream</span><br>    <span class="hljs-comment">// 如果从标记处开始往后，已经获取或者跳过了readLimit个字节，那么这个标记失效，不允许再重新通过reset回到这个位置。</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-keyword">void</span> <span class="hljs-title">mark</span><span class="hljs-params">(<span class="hljs-keyword">int</span> readlimit)</span> </span>&#123;&#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reset</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> IOException(<span class="hljs-string">&quot;mark/reset not supported&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="ByteArrayInputStream"><a href="#ByteArrayInputStream" class="headerlink" title="ByteArrayInputStream"></a>ByteArrayInputStream</h4><p>字节数组输入流，该类的功能就是从字节数组 byte[] 中进行以字节为单位的读取，也就是将资源文件都以字节形式存入到该类中的字节数组中去，我们拿数据也是从这个字节数组中拿。</p><h4 id="PipedInputStream"><a href="#PipedInputStream" class="headerlink" title="PipedInputStream"></a>PipedInputStream</h4><p>管道字节输入流，它和 PipedOutputStream 一起使用，能实现多线程间的管道通信。</p><h4 id="FilterInputStream"><a href="#FilterInputStream" class="headerlink" title="FilterInputStream"></a>FilterInputStream</h4><p>装饰者模式中充当装饰者的角色，具体的装饰者都要继承它，所以在该类的子类下都是用来装饰别的流的，也就是处理类。</p><h4 id="BufferedInputStream"><a href="#BufferedInputStream" class="headerlink" title="BufferedInputStream"></a>BufferedInputStream</h4><p>缓冲流，对处理流进行装饰、增强，内部会有一个缓冲区，用来存放字节，每次都是将缓冲区存满然后发送，而不是一个字节或两个字节这样发送，效率更高。</p><h4 id="DataInputStream"><a href="#DataInputStream" class="headerlink" title="DataInputStream"></a>DataInputStream</h4><p>数据输入流，用来装饰其他输入流，它允许通过数据流来读写Java基本类型。</p><h4 id="FileInputStream"><a href="#FileInputStream" class="headerlink" title="FileInputStream"></a>FileInputStream</h4><p>文件输入流，通常用于对文件进行读取操作。</p><h4 id="File"><a href="#File" class="headerlink" title="File"></a>File</h4><p>对指定目录的文件进行操作。</p><h4 id="ObjectInputStream"><a href="#ObjectInputStream" class="headerlink" title="ObjectInputStream"></a>ObjectInputStream</h4><p>对象输入流，用来提供对“基本数据或对象”的持久存储。通俗点讲，就是能直接传输Java对象（序列化、反序列化用。</p><h3 id="字节输出流-OutputStream"><a href="#字节输出流-OutputStream" class="headerlink" title="字节输出流 OutputStream"></a>字节输出流 OutputStream</h3></li><li>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">OutputStream</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Closeable</span>, <span class="hljs-title">Flushable</span> </span>&#123;<br><br>    <span class="hljs-comment">// Writes the specified byte to this output stream.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-keyword">void</span> <span class="hljs-title">write</span><span class="hljs-params">(<span class="hljs-keyword">byte</span> b[])</span> <span class="hljs-keyword">throws</span> IOException</span>;<br><br>    <span class="hljs-comment">// Flushes this stream by writing any buffered output to the underlying stream.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">flush</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;&#125;<br><br>    <span class="hljs-comment">// Closes this stream and releases any system resources associated with it.</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="缓冲区的作用"><a href="#缓冲区的作用" class="headerlink" title="缓冲区的作用"></a>缓冲区的作用</h4><p>为了<strong>加快数据传输速度</strong>，<strong>提高数据输出效率</strong>，又是输出数据流会在提交数据之前把所要输出的数据先暂时保存在内存缓冲区中，然后成批进行输出，每次传输过程都以某特定数据长度为单位进行传输，在这种方式下，数据的末尾一般都会有一部分数据由于数量不够一个批次，而存留在缓冲区里，调用 flush() 方法可以将这部分数据强制提交。</p></li></ul><h3 id="字符输入流-Reader"><a href="#字符输入流-Reader" class="headerlink" title="字符输入流 Reader"></a>字符输入流 Reader</h3><img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AD%97%E7%AC%A6%E8%BE%93%E5%85%A5%E6%B5%81.png" class="" title="字符输入流"><p>Reader 中各个类的用途和使用方法基本和InputStream 中的类使用一致。</p><h3 id="字符输出流-Writer"><a href="#字符输出流-Writer" class="headerlink" title="字符输出流 Writer"></a>字符输出流 Writer</h3><img src="/2020/07/10/IO%E9%82%A3%E4%BA%9B%E4%BA%8B/%E5%AD%97%E7%AC%A6%E8%BE%93%E5%87%BA%E6%B5%81.png" class="" title="字符输出流"><h2 id="字节流与字符流的区别"><a href="#字节流与字符流的区别" class="headerlink" title="字节流与字符流的区别"></a>字节流与字符流的区别</h2><ul><li>字节流操作的基本单元为字节；字符流操作的基本单元为Unicode码元。</li><li>字节流默认不使用缓冲区；字符流使用缓冲区。</li><li>字节流通常用于处理二进制数据，实际上它可以处理任意类型的数据，但它不支持直接写入或读取Unicode码元；字符流通常处理文本数据，它支持写入及读取Unicode码元。</li></ul><h2 id="字节流与字符流使用场景"><a href="#字节流与字符流使用场景" class="headerlink" title="字节流与字符流使用场景"></a>字节流与字符流使用场景</h2><ul><li>字节流：图像，视频，PPT, Word, 纯文本</li><li>字符流：纯文本类型（TXT), 不能处理图像视频等非文本类型的文件</li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://juejin.im/post/5d4ee73ae51d4561c94b0f9d">https://juejin.im/post/5d4ee73ae51d4561c94b0f9d</a><br><a href="https://zhuanlan.zhihu.com/p/109941007">https://zhuanlan.zhihu.com/p/109941007</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>序列化和反序列化</title>
    <link href="/2020/07/10/%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <url>/2020/07/10/%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<p>鉴于面试的时候被这个问题虐的实在太惨了，每次都只能说自己只是使用过，遂今天深挖一下这个底层的实现原理。</p><p>序列化与反序列化是一个标准，它是编程语言的一种共性，只是有些编程语言是内置的（如Java，PHP等），有些语言是通过第三方库来实现的（如C/C++）。</p><h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><ul><li>对象的持久化（将对象内容保存到数据库或文件中）</li><li>远程数据传输（将对象发送给其他计算机系统）</li></ul><h1 id="序列化协议的选择"><a href="#序列化协议的选择" class="headerlink" title="序列化协议的选择"></a>序列化协议的选择</h1><ul><li>通用性<ul><li>是否只能用于Java间序列化/反序列化，是否跨语言，跨平台</li></ul></li><li>性能<ul><li>空间开销：序列化后的数据一般用于存储或网络传输，其大小是很重要的一个参数</li><li>时间开销：解析的时间也影响了序列化协议的选择</li></ul></li><li>可扩展性<ul><li>系统升级不可避免，某一实体的属性变更，会不会导致反序列化异常</li></ul></li><li>易用性<ul><li>API使用是否复杂</li></ul></li></ul><h1 id="Java中的序列化与反序列化-（JDK-序列化）"><a href="#Java中的序列化与反序列化-（JDK-序列化）" class="headerlink" title="Java中的序列化与反序列化 （JDK 序列化）"></a>Java中的序列化与反序列化 （JDK 序列化）</h1><h2 id="实现Serializable接口的类"><a href="#实现Serializable接口的类" class="headerlink" title="实现Serializable接口的类"></a>实现Serializable接口的类</h2><p>jdk会自动帮我们序列化该类所有的信息，但如果用户定义了writeObject和readObject方法，那么在序列化和反序列化的时候会通过反射优先调用自定义的方法。默认情况会跳过transient修饰的对象。</p><h2 id="实现Externalizable接口的类"><a href="#实现Externalizable接口的类" class="headerlink" title="实现Externalizable接口的类"></a>实现Externalizable接口的类</h2><p>需要用户自定义序列化和反序列化的逻辑，分别重写writeExternal和readExternal方法。</p><h2 id="序列化具体步骤"><a href="#序列化具体步骤" class="headerlink" title="序列化具体步骤"></a>序列化具体步骤</h2><ol><li>创建一个对象输出流，它可以包装一个其它类型的目标输出流，如文件输出流：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Java">ObjectOutputStream oos = <span class="hljs-keyword">new</span> ObjectOutputStream(<span class="hljs-keyword">new</span> FileOutputStream(<span class="hljs-string">&quot;D:\object.out&quot;</span>));<br></code></pre></td></tr></table></figure><ol start="2"><li>通过对象输出流的writeObject()方法写对象：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Java">oos.writeObject(<span class="hljs-keyword">new</span> User(<span class="hljs-string">&quot;xuliugen&quot;</span>, <span class="hljs-string">&quot;123456&quot;</span>, <span class="hljs-string">&quot;male&quot;</span>));<br></code></pre></td></tr></table></figure><h2 id="反序列化的具体步骤"><a href="#反序列化的具体步骤" class="headerlink" title="反序列化的具体步骤"></a>反序列化的具体步骤</h2><ol><li>创建一个对象输入流，它可以包装一个其它类型输入流，如文件输入流：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Java">ObjectInputStream ois= <span class="hljs-keyword">new</span> ObjectInputStream(<span class="hljs-keyword">new</span> FileInputStream(<span class="hljs-string">&quot;object.out&quot;</span>));<br></code></pre></td></tr></table></figure><ol start="2"><li>通过对象输出流的readObject()方法读取对象：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Java">User user = (User) ois.readObject();<br></code></pre></td></tr></table></figure><h2 id="底层分析"><a href="#底层分析" class="headerlink" title="底层分析"></a>底层分析</h2><p>一般来说，在网上搜索序列化就是这些api的使用方法，但是我想去深挖一下这个<code>readObject</code>和<code>writeObject</code>的背后原理。隐隐感觉和反射有关。</p><h3 id="ObjectOutputStream的构造器"><a href="#ObjectOutputStream的构造器" class="headerlink" title="ObjectOutputStream的构造器"></a>ObjectOutputStream的构造器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/** if true, invoke writeObjectOverride() instead of writeObject() */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">boolean</span> enableOverride;<br><br><span class="hljs-comment">/** filter stream for handling block data conversion */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> BlockDataOutputStream bout;<br><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ObjectOutputStream</span><span class="hljs-params">(OutputStream out)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    verifySubclass();<br><br><br>    <span class="hljs-comment">// bout 是底层的字节数据容器</span><br>    bout = <span class="hljs-keyword">new</span> BlockDataOutputStream(out);<br>    handles = <span class="hljs-keyword">new</span> HandleTable(<span class="hljs-number">10</span>, (<span class="hljs-keyword">float</span>) <span class="hljs-number">3.00</span>);<br>    subs = <span class="hljs-keyword">new</span> ReplaceTable(<span class="hljs-number">10</span>, (<span class="hljs-keyword">float</span>) <span class="hljs-number">3.00</span>);<br><br>    enableOverride = <span class="hljs-keyword">false</span>;<br><br>    writeStreamHeader(); <span class="hljs-comment">// 写入文件头</span><br>    bout.setBlockDataMode(<span class="hljs-keyword">true</span>); <span class="hljs-comment">// flush数据</span><br>    <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>        debugInfoStack = <span class="hljs-keyword">new</span> DebugTraceInfoStack();<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        debugInfoStack = <span class="hljs-keyword">null</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>构造函数中首先会把bout绑定到底层的字节数据容器，然后调用<code>writeStreamHeader</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeStreamHeader</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    bout.writeShort(STREAM_MAGIC);<br>    bout.writeShort(STREAM_VERSION);<br>&#125;<br></code></pre></td></tr></table></figure><p>在writeStreamHeader()方法中首先会往底层字节容器中写入表示序列化的Magic Number以及版本号</p><h3 id="writeObject"><a href="#writeObject" class="headerlink" title="writeObject"></a>writeObject</h3><p>先贴上一段具体的实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">    Write the specified object to the ObjectOutputStream.   </span><br><span class="hljs-comment">*/</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeObject</span><span class="hljs-params">(Object obj)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    <span class="hljs-keyword">if</span> (enableOverride) &#123;<br>        writeObjectOverride(obj);<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-keyword">try</span> &#123;<br>        writeObject0(obj, <span class="hljs-keyword">false</span>);<br>    &#125; <span class="hljs-keyword">catch</span> (IOException ex) &#123;<br>        <span class="hljs-keyword">if</span> (depth == <span class="hljs-number">0</span>) &#123;<br>            writeFatalException(ex);<br>        &#125;<br>        <span class="hljs-keyword">throw</span> ex;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们可以发现这里直接走到了<code>writeObject0</code>函数，继续跟踪</p><h4 id="writeObject0"><a href="#writeObject0" class="headerlink" title="writeObject0"></a>writeObject0</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Underlying writeObject/writeUnshared implementation.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeObject0</span><span class="hljs-params">(Object obj, <span class="hljs-keyword">boolean</span> unshared)</span></span><br><span class="hljs-function">    <span class="hljs-keyword">throws</span> IOException</span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">boolean</span> oldMode = bout.setBlockDataMode(<span class="hljs-keyword">false</span>);<br>    depth++;<br>    <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-comment">// handle previously written and non-replaceable objects</span><br>        <span class="hljs-keyword">int</span> h;<br>        <span class="hljs-keyword">if</span> ((obj = subs.lookup(obj)) == <span class="hljs-keyword">null</span>) &#123;<br>            writeNull();<br>            <span class="hljs-keyword">return</span>;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!unshared &amp;&amp; (h = handles.lookup(obj)) != -<span class="hljs-number">1</span>) &#123;<br>            writeHandle(h);<br>            <span class="hljs-keyword">return</span>;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Class) &#123;<br>            writeClass((Class) obj, unshared);<br>            <span class="hljs-keyword">return</span>;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> ObjectStreamClass) &#123;<br>            writeClassDesc((ObjectStreamClass) obj, unshared);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br><br>        <span class="hljs-comment">// check for replacement object</span><br>        Object orig = obj;<br>        <span class="hljs-comment">// 获取对象的类型</span><br>        Class&lt;?&gt; cl = obj.getClass();<br>        ObjectStreamClass desc;<br>        <span class="hljs-keyword">for</span> (;;) &#123;<br>            <span class="hljs-comment">// REMIND: skip this check for strings/arrays?</span><br>            Class&lt;?&gt; repCl;<br>            desc = ObjectStreamClass.lookup(cl, <span class="hljs-keyword">true</span>);<br>            <span class="hljs-keyword">if</span> (!desc.hasWriteReplaceMethod() ||<br>                (obj = desc.invokeWriteReplace(obj)) == <span class="hljs-keyword">null</span> ||<br>                (repCl = obj.getClass()) == cl)<br>            &#123;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            cl = repCl;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (enableReplace) &#123;<br>            Object rep = replaceObject(obj);<br>            <span class="hljs-keyword">if</span> (rep != obj &amp;&amp; rep != <span class="hljs-keyword">null</span>) &#123;<br>                cl = rep.getClass();<br>                desc = ObjectStreamClass.lookup(cl, <span class="hljs-keyword">true</span>);<br>            &#125;<br>            obj = rep;<br>        &#125;<br><br>        <span class="hljs-comment">// if object replaced, run through original checks a second time</span><br>        <span class="hljs-keyword">if</span> (obj != orig) &#123;<br>            subs.assign(orig, obj);<br>            <span class="hljs-keyword">if</span> (obj == <span class="hljs-keyword">null</span>) &#123;<br>                writeNull();<br>                <span class="hljs-keyword">return</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!unshared &amp;&amp; (h = handles.lookup(obj)) != -<span class="hljs-number">1</span>) &#123;<br>                writeHandle(h);<br>                <span class="hljs-keyword">return</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Class) &#123;<br>                writeClass((Class) obj, unshared);<br>                <span class="hljs-keyword">return</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> ObjectStreamClass) &#123;<br>                writeClassDesc((ObjectStreamClass) obj, unshared);<br>                <span class="hljs-keyword">return</span>;<br>            &#125;<br>        &#125;<br><br><br>        <span class="hljs-comment">// remaining cases</span><br>        <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> String) &#123;<br>            writeString((String) obj, unshared);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cl.isArray()) &#123;<br>            writeArray(obj, desc, unshared);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Enum) &#123;<br>            writeEnum((Enum&lt;?&gt;) obj, desc, unshared);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Serializable) &#123;<br>            writeOrdinaryObject(obj, desc, unshared);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>                <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NotSerializableException(<br>                    cl.getName() + <span class="hljs-string">&quot;\n&quot;</span> + debugInfoStack.toString());<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NotSerializableException(cl.getName());<br>            &#125;<br>        &#125;<br>    &#125; <span class="hljs-keyword">finally</span> &#123;<br>        depth--;<br>        bout.setBlockDataMode(oldMode);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>看到了熟悉的反射，来分析一下这个<code>writeObject0</code>具体是怎么实现的</p><p>具体看到最后的部分</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Java"><br><span class="hljs-comment">// remaining cases</span><br><span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> String) &#123;<br>    writeString((String) obj, unshared);<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cl.isArray()) &#123;<br>    writeArray(obj, desc, unshared);<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Enum) &#123;<br>    writeEnum((Enum&lt;?&gt;) obj, desc, unshared);<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (obj <span class="hljs-keyword">instanceof</span> Serializable) &#123;<br>    writeOrdinaryObject(obj, desc, unshared);<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NotSerializableException(<br>            cl.getName() + <span class="hljs-string">&quot;\n&quot;</span> + debugInfoStack.toString());<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> NotSerializableException(cl.getName());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这就告诉我们如果是简单的String, Array, Enum类型可以直接序列化，如果是通过实现<code>Serializable</code>接口的话，那么会继续往下调用<code>writeOrdinaryObject</code>, 这里具体的参数obj是我们要序列化的对象，desc是我们要序列化对象的class description</p><p>tips: 如果我们进到<code>Serializable</code>接口内部的时候会发现这是一个空的接口，实际上，它的作用只是在这里为我们做一个标识。</p><p>继续往下</p><h4 id="writeOrdinaryObject"><a href="#writeOrdinaryObject" class="headerlink" title="writeOrdinaryObject"></a>writeOrdinaryObject</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs Java"><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Writes representation of a &quot;ordinary&quot; (i.e., not a String, Class,</span><br><span class="hljs-comment"> * ObjectStreamClass, array, or enum constant) serializable object to the</span><br><span class="hljs-comment"> * stream.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeOrdinaryObject</span><span class="hljs-params">(Object obj, ObjectStreamClass desc, <span class="hljs-keyword">boolean</span> unshared)</span> <span class="hljs-keyword">throws</span> IOException</span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>        debugInfoStack.push(<br>            (depth == <span class="hljs-number">1</span> ? <span class="hljs-string">&quot;root &quot;</span> : <span class="hljs-string">&quot;&quot;</span>) + <span class="hljs-string">&quot;object (class \&quot;&quot;</span> +<br>            obj.getClass().getName() + <span class="hljs-string">&quot;\&quot;, &quot;</span> + obj.toString() + <span class="hljs-string">&quot;)&quot;</span>);<br>    &#125;<br>    <span class="hljs-keyword">try</span> &#123;<br>        desc.checkSerialize();<br><br>        <span class="hljs-comment">// 写入Object标志位</span><br>        bout.writeByte(TC_OBJECT);<br>        <span class="hljs-comment">// 写入类元数据</span><br>        writeClassDesc(desc, <span class="hljs-keyword">false</span>);<br>        handles.assign(unshared ? <span class="hljs-keyword">null</span> : obj);<br>        <span class="hljs-keyword">if</span> (desc.isExternalizable() &amp;&amp; !desc.isProxy()) &#123;<br>            writeExternalData((Externalizable) obj);  <span class="hljs-comment">// 写入被序列化的对象的实例数据</span><br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            writeSerialData(obj, desc);<br>        &#125;<br>    &#125; <span class="hljs-keyword">finally</span> &#123;<br>        <span class="hljs-keyword">if</span> (extendedDebugInfo) &#123;<br>            debugInfoStack.pop();<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>在这个方法中首先会往底层字节容器中写入TC_OBJECT，表示这是一个新的Object</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">* new Object.</span><br><span class="hljs-comment">*/</span><br><span class="hljs-keyword">final</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">byte</span> TC_OBJECT =       (<span class="hljs-keyword">byte</span>)<span class="hljs-number">0x73</span>;<br></code></pre></td></tr></table></figure><p>接下来会调用writeClassDesc()方法写入被序列化对象的类的类元数据</p><h4 id="writeClassDesc"><a href="#writeClassDesc" class="headerlink" title="writeClassDesc"></a>writeClassDesc</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">// 写入被序列化对象的类的类元数据</span><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeClassDesc</span><span class="hljs-params">(ObjectStreamClass desc, <span class="hljs-keyword">boolean</span> unshared)</span> <span class="hljs-keyword">throws</span> IOException</span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">int</span> handle;<br>    <span class="hljs-keyword">if</span> (desc == <span class="hljs-keyword">null</span>) &#123;<br>        <span class="hljs-comment">// 如果desc为null</span><br>        writeNull();<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!unshared &amp;&amp; (handle = handles.lookup(desc)) != -<span class="hljs-number">1</span>) &#123;<br>        writeHandle(handle);<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (desc.isProxy()) &#123;<br>        writeProxyDesc(desc, unshared);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        writeNonProxyDesc(desc, unshared);<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h5 id="writeNull"><a href="#writeNull" class="headerlink" title="writeNull()"></a>writeNull()</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeNull</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    <span class="hljs-comment">// TC_NULL =         (byte)0x70;</span><br>    <span class="hljs-comment">// 表示对一个Object引用的描述的结束</span><br>    bout.writeByte(TC_NULL);<br>&#125;<br></code></pre></td></tr></table></figure><h5 id="writeProxyDesc"><a href="#writeProxyDesc" class="headerlink" title="writeProxyDesc"></a>writeProxyDesc</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs Java">    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">writeNonProxyDesc</span><span class="hljs-params">(ObjectStreamClass desc, <span class="hljs-keyword">boolean</span> unshared)</span> <span class="hljs-keyword">throws</span> IOException</span><br><span class="hljs-function">    </span>&#123;<br>        <span class="hljs-comment">// TC_CLASSDESC =    (byte)0x72;</span><br>        <span class="hljs-comment">// 表示一个新的Class描述符</span><br>        bout.writeByte(TC_CLASSDESC);<br>        handles.assign(unshared ? <span class="hljs-keyword">null</span> : desc);<br> <br>        <span class="hljs-keyword">if</span> (protocol == PROTOCOL_VERSION_1) &#123;<br>            <span class="hljs-comment">// do not invoke class descriptor write hook with old protocol</span><br>            desc.writeNonProxy(<span class="hljs-keyword">this</span>);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            writeClassDescriptor(desc);<br>        &#125;<br> <br>        Class cl = desc.forClass();<br>        bout.setBlockDataMode(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">if</span> (cl != <span class="hljs-keyword">null</span> &amp;&amp; isCustomSubclass()) &#123;<br>            ReflectUtil.checkPackageAccess(cl);<br>        &#125;<br>        annotateClass(cl);<br>        bout.setBlockDataMode(<span class="hljs-keyword">false</span>);<br>        bout.writeByte(TC_ENDBLOCKDATA);<br> <br>        writeClassDesc(desc.getSuperDesc(), <span class="hljs-keyword">false</span>);<br>&#125;<br><br></code></pre></td></tr></table></figure><p>在这个方法中首先会写入一个字节的TC_CLASSDESC，这个字节表示接下来的数据是一个新的Class描述符，接着会调用writeNonProxy()方法写入实际的类元信息，writeNonProxy()实现如下:</p><h5 id="writeNonProxy"><a href="#writeNonProxy" class="headerlink" title="writeNonProxy"></a>writeNonProxy</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">writeNonProxy</span><span class="hljs-params">(ObjectOutputStream out)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    out.writeUTF(name); <span class="hljs-comment">// 写入类的名字</span><br>    out.writeLong(getSerialVersionUID()); <span class="hljs-comment">// 写入类的序列号</span><br> <br>    <span class="hljs-keyword">byte</span> flags = <span class="hljs-number">0</span>;<br>    <span class="hljs-comment">// 获取类的标识</span><br>    <span class="hljs-keyword">if</span> (externalizable) &#123;<br>        flags |= ObjectStreamConstants.SC_EXTERNALIZABLE;<br>        <span class="hljs-keyword">int</span> protocol = out.getProtocolVersion();<br>        <span class="hljs-keyword">if</span> (protocol != ObjectStreamConstants.PROTOCOL_VERSION_1) &#123;<br>            flags |= ObjectStreamConstants.SC_BLOCK_DATA;<br>        &#125;<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (serializable) &#123;<br>        flags |= ObjectStreamConstants.SC_SERIALIZABLE;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (hasWriteObjectData) &#123;<br>        flags |= ObjectStreamConstants.SC_WRITE_METHOD;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (isEnum) &#123;<br>        flags |= ObjectStreamConstants.SC_ENUM;<br>    &#125;<br>    out.writeByte(flags); <span class="hljs-comment">// 写入类的flag</span><br> <br>    out.writeShort(fields.length); <span class="hljs-comment">// 写入对象的字段的个数</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; fields.length; i++) &#123;<br>        ObjectStreamField f = fields[i];<br>        out.writeByte(f.getTypeCode());<br>        out.writeUTF(f.getName());<br>        <span class="hljs-keyword">if</span> (!f.isPrimitive()) &#123;<br>            <span class="hljs-comment">// 如果不是原始类型，即是对象或者Interface</span><br>            <span class="hljs-comment">// 则会写入表示对象或者类的类型字符串</span><br>            out.writeTypeString(f.getTypeString());<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>jdk的缺点十分明显</p><ul><li>无法跨语言<ul><li>这一缺点几乎是致命伤害，对于跨进程的服务调用，通常都需要考虑到不同语言的相互调用时候的兼容性，而这一点对于jdk序列化操作来说却无法做到。这是因为jdk序列化操作时是使用了java语言内部的私有协议，在对其他语言进行反序列化的时候会有严重的阻碍。</li></ul></li><li>序列化之后的码流过大<ul><li>jdk进行序列化编码之后产生的字节数组过大，占用的存储内存空间也较高，这就导致了相应的流在网络传输的时候带宽占用较高，性能相比较为低下的情况。</li></ul></li></ul><h1 id="Kryo"><a href="#Kryo" class="headerlink" title="Kryo"></a>Kryo</h1><h1 id="Hessian"><a href="#Hessian" class="headerlink" title="Hessian"></a>Hessian</h1><p>Hessian的源码里面，核心主要还是com.caucho.hessian.io里面的代码，AbstractSerializer是Hessian里面的核心序列化类，当我们仔细查看源码的时候就会发现hessian提供了许多种序列化和反序列化的类进行不同类型数据的处理。（我使用的是hessian4.0，因此相应的类会多很多）</p><p>在SerializerFactory里面有getSerializer和getDefaultSerializer的函数，专门用于提取这些序列化和反序列化的工具类，这样可以避免在使用该工具类的时候又要重新实例化，这些工具类都会被存储到不同的ConcurrentHashMap里面去。</p><h1 id="Protobuf"><a href="#Protobuf" class="headerlink" title="Protobuf"></a>Protobuf</h1><h1 id="不同序列化框架的对比"><a href="#不同序列化框架的对比" class="headerlink" title="不同序列化框架的对比"></a>不同序列化框架的对比</h1><table><thead><tr><th></th><th>JDK</th><th>Hessian</th><th>Kryo</th><th>Xstream</th><th>Protobuf</th></tr></thead><tbody><tr><td>优点</td><td>使用方便<br>序列化包含的信息较多较全<br>安全性高</td><td>产生的码流小<br>支持跨语言</td><td>产生的码流小<br>速度快</td><td>对于被序列化对象的要求比较低<br>支持跨语言</td><td>产生的码流小<br>支持跨语言<br>速度快<br>灵活性高</td></tr><tr><td>缺点</td><td>产生的码流过大<br>网络传输占用带宽<br>消耗性能<br>不支持跨语言的序列化处理</td><td>性能比JDK序列化方式好<br>但是效率依旧不好</td><td>对于循环引用的情况需要将reference开启<br>开启之后性能会有所下降</td><td>序列化的耗时久<br>性能不高</td><td>需要进行环境安装和搭建</td></tr></tbody></table><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://juejin.im/post/6844903918879637518">https://juejin.im/post/6844903918879637518</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>进程间的通信</title>
    <link href="/2020/07/05/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1/"/>
    <url>/2020/07/05/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h1><p>管道，英文为pipe。这是一个我们在学习Linux命令行的时候就会引入的一个很重要的概念。它的发明人是道格拉斯.麦克罗伊，这位也是UNIX上早期shell的发明人。他在发明了shell之后，发现系统操作执行命令的时候，经常有需求要将一个程序的输出交给另一个程序进行处理，也因此，管道应运而生了。Golang中的Channel也是管道的思想。 </p><p>管道可以分为两类：匿名管道和命名管道。</p><p>常见的Linux命令 “|” 其实就是匿名管道，表示把一个进程的输出传输到另外一个进程，如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Happyjava&quot;</span> | awk -F <span class="hljs-string">&#x27;j&#x27;</span> <span class="hljs-string">&#x27;&#123;print $2&#125;&#x27;</span><br><span class="hljs-comment"># 输出 ava</span><br></code></pre></td></tr></table></figure><p>一个进程往管道输入数据，则会阻塞等待别的进程从管道读取数据。</p><h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><p>注意，此消息队列不是我们常用的MQ，如kafka，rabbitmq，rocketmq等。<br>消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。  每个数据块都被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。我们可以通过发送消息来避免命名管道的同步和阻塞问题。但是消息队列与命名管道一样，每个数据块都有一个最大长度的限制。<br>使用消息队列进行进程间通信，可能会收到数据块最大长度的限制约束等，这也是这种通信方式的缺点。如果频繁的发生进程间的通信行为，那么进程需要频繁地读取队列中的数据到内存，相当于间接地从一个进程拷贝到另一个进程，这需要花费时间。</p><h1 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h1><p>共享内存这个通信方式就可以很好着解决拷贝所消耗的时间了。系统加载一个进程的时候，分配给进程的内存并不是实际物理内存，而是虚拟内存空间。那么我们可以让两个进程各自拿出一块虚拟地址空间来，然后映射到相同的物理内存中，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了。</p><p>Golang中经典：不要通过共享内存来通信，而应该通过通信来共享内存。使用复制来减少锁的使用。</p><h1 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h1><p>共享内存最大的问题是什么？没错，就是多进程竞争内存的问题，就像类似于我们平时说的线程安全问题。如何解决这个问题？这个时候我们的信号量就上场了。<br>信号量的本质就是一个计数器，用来实现进程之间的互斥与同步。例如信号量的初始值是 1，然后 a 进程来访问内存1的时候，我们就把信号量的值设为 0，然后进程b 也要来访问内存1的时候，看到信号量的值为 0 就知道已经有进程在访问内存1了，这个时候进程 b 就会访问不了内存1。所以说，信号量也是进程之间的一种通信方式。</p><h1 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h1><p>这个就是我们一直在用的进程间的通信方式了，如我们的微信APP跟微信服务器通信，其实就是使用的Socket套接字进行通信的。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>面试那些事</title>
    <link href="/2020/07/03/%E9%9D%A2%E8%AF%95%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/07/03/%E9%9D%A2%E8%AF%95%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="字节跳动"><a href="#字节跳动" class="headerlink" title="字节跳动"></a>字节跳动</h1><h2 id="岗位：后端开发工程师-地点：杭州"><a href="#岗位：后端开发工程师-地点：杭州" class="headerlink" title="岗位：后端开发工程师 地点：杭州"></a>岗位：后端开发工程师 地点：杭州</h2><h3 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h3><ol><li>go里面线程，进程，协程的区别</li><li>完全二叉树与搜索二叉树的概念</li><li>Java中JVM 内存，垃圾回收机制。（面试官抠的比较细，要求讲到复制算法适用新生代，标记清楚算法适用年老代）</li><li>MySQL的索引原理</li><li>b树与b+树的区别</li><li>InnoDB 和 MyISAM的区别  (聚簇索引和非聚簇索引)</li><li>Redis的基本数据结构(string, hash, set, list zset)</li><li>讲一下跳表的原理（因为我前面提到了zset底层实现原理是skip list）</li><li>TCP/UDP 网络模型一共有几层</li><li>TCP和UDP的区别</li><li>从应用层到网络层各层的header都有什么不同的功能。（绝了，不知道咋讲。。说了存放地址和端口）</li><li>算法题<ul><li>通过给定的tree，判断是不是搜索二叉树和完全二叉树</li><li>tips:用中序遍历和广度优先法 </li></ul></li></ol><h3 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h3><ol><li>算法题<ul><li>给定一个随意的正整数数组，求最长的连续数字长度</li><li>eg. [3, 8, 9, 4, 6, 7] =&gt; 4 (6789)</li><li>刚开始用了桶排序，后面在面试官的提示下用map优化了一下</li></ul></li><li>Redis删除key的机制 （还问了一个很神奇的，为什么要删除 从来没想过这个问题）</li><li>Redis和MySQL存储数据的区别</li><li>Java中String为什么要声明成不可变的</li><li>如果自己设计一个不可变的类，有哪些步骤</li><li>说一个设计模式 （说了观察者模式）</li><li>为什么需要回调 （大概讲了因为一直监控耗费性能，但好像不是面试官特别想要的答案:-&lt;）</li><li>聊了一下之前在腾讯做过的项目</li></ol><h3 id="三面"><a href="#三面" class="headerlink" title="三面"></a>三面</h3><ol><li>算法题<ul><li>给定一个数组和一个数s，找到最短的子数组加起来的和超过s</li><li>用两个指针去遍历 讲了一遍思路 面试官让我开始写 写了十分钟还有bug 面试官让我先跳过了（真是想吐槽一下牛客的IDE）</li></ul></li><li>聊了一下暑假在字节做的项目<ul><li>总结了一篇新人文档</li><li>一个权限管理的平台 （封装了一些后端的接口）</li><li>一个对齐员工进度的表 （全栈）</li></ul></li></ol><p>主要还是在聊项目，没有考别的基础知识了</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总的来说，面试的时候还是有很多的不足，每次面试都是一次学习的过程。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis</title>
    <link href="/2020/07/03/Redis/"/>
    <url>/2020/07/03/Redis/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h1><ul><li>Redis 是 C 语言开发的一个开源的（遵从 BSD 协议）高性能键值对（key-value）的内存数据库，可以用作数据库、缓存、消息中间件等。</li><li>它是一种 NoSQL（not-only sql，泛指非关系型数据库）的数据库。（MySQL是一种关系型数据库）</li><li>性能优秀，数据在内存中，读写速度非常快，支持并发 10W QPS。</li><li>单进程单线程，是线程安全的，采用 IO 多路复用机制。</li><li>丰富的数据类型，支持字符串（strings）、散列（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等。</li><li>支持数据持久化。可以将内存中数据保存在磁盘中，重启时加载。</li><li>主从复制，哨兵，高可用。</li><li>可以用作分布式锁。</li><li>可以作为消息中间件使用，支持发布订阅。</li></ul><h1 id="Redis的五种数据类型"><a href="#Redis的五种数据类型" class="headerlink" title="Redis的五种数据类型"></a>Redis的五种数据类型</h1><h2 id="Redis-核心对象-redisObject"><a href="#Redis-核心对象-redisObject" class="headerlink" title="Redis 核心对象 (redisObject)"></a>Redis 核心对象 (redisObject)</h2><ul><li>数据类型 type<ul><li>string<ul><li>可以理解成与 Memcached一模一样的类型，一个 Key 对应一个 Value。Value 不仅是 String，也可以是数字。</li><li>String 类型是二进制安全的，意思是 Redis 的 String 类型可以包含任何数据，比如 jpg 图片或者序列化的对象。String 类型的值最大能存储 512M。</li></ul></li><li>hash<ul><li>Hash是一个键值（key-value）的集合。Redis 的 Hash 是一个 String 的 Key 和 Value 的映射表，Hash 特别适合存储对象。常用命令：hget，hset，hgetall 等。</li></ul></li><li>list<ul><li>List 列表是简单的字符串列表，按照插入顺序排序。可以添加一个元素到列表的头部（左边）或者尾部（右边） 常用命令：lpush、rpush、lpop、rpop、lrange（获取列表片段）等。</li><li>双向列表</li></ul></li><li>set<ul><li>集合是通过 hashtable 实现的。Set 中的元素是没有顺序的，而且是没有重复的。常用命令：sdd、spop、smembers、sunion 等。</li></ul></li><li>sorted list<ul><li>和 Set 相比，Sorted Set关联了一个 Double 类型权重的参数 Score，使得集合中的元素能够按照 Score 进行有序排列，Redis 正是通过分数来为集合中的成员进行从小到大的排序。</li><li>Redis Sorted Set 的内部使用 HashMap 和跳跃表（skipList）来保证数据的存储和有序，HashMap 里放的是成员到 Score 的映射。</li></ul></li></ul></li><li>编码方式 encoding<ul><li>raw </li><li>int</li><li>ht</li><li>zipmap</li><li>linkedlist</li><li>ziplist</li><li>intest</li></ul></li><li>数据指针</li><li>虚拟内存</li><li>其他</li></ul><p>使用<strong>一个</strong> redisObject 对象来表示<strong>所有</strong>的 key 和 value</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>type 表示一个 value 对象具体是何种数据类型，encoding 是不同数据类型在 Redis 内部的存储方式。</p><h1 id="Redis缓存"><a href="#Redis缓存" class="headerlink" title="Redis缓存"></a>Redis缓存</h1><p>//todo</p><h2 id="Redis雪崩"><a href="#Redis雪崩" class="headerlink" title="Redis雪崩"></a>Redis雪崩</h2><p><strong>举个栗子</strong>：如果首页所有 Key 的失效时间都是 12 小时，中午 12 点刷新的，我零点有个大促活动大量用户涌入，假设每秒 6000 个请求，本来缓存可以抗住每秒 5000 个请求，但是缓存中所有 Key 都失效了。</p><p><strong>解决方案</strong>：在批量往 Redis 存数据的时候，把每个 Key 的失效时间都加个随机值就好了，这样可以保证数据不会再同一时间大面积失效。</p><h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透是指缓存和数据库中都没有的数据，而用户（黑客）不断发起请求。</p><p><strong>举个栗子</strong>：我们数据库的 id 都是从 1 自增的，如果发起 id=-1 的数据或者 id 特别大不存在的数据，这样的不断攻击导致数据库压力很大，严重会击垮数据库。</p><p><strong>解决方案</strong></p><ul><li>缓存穿透我会在接口层增加校验，比如用户鉴权，参数做校验，不合法的校验直接 return，比如 id 做基础校验，id&lt;=0 直接拦截。</li><li><strong>布隆过滤器</strong><ul><li>快速剔除一些不在数据库的值</li><li>布隆过滤器是一个 bit 向量或者说 bit 数组，如果我们要映射一个值到布隆过滤器中，我们需要使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1。</li><li>如果查询的时候对应bit是 0，那么可以确定一定不在。但如果都是1，只能说明可能存在。</li><li><a href="https://zhuanlan.zhihu.com/p/43263751">https://zhuanlan.zhihu.com/p/43263751</a></li></ul></li></ul><h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>缓存击穿是指一个 Key 非常热点，在不停地扛着大量的请求，大并发集中对这一个点进行访问，当这个 Key 在失效的瞬间，持续的大并发直接落到了数据库上，就在这个 Key 的点上击穿了缓存。</p><p><strong>解决方案</strong>：设置热点数据永不过期，或者加上互斥锁就搞定了。</p><h1 id="Redis性能分析"><a href="#Redis性能分析" class="headerlink" title="Redis性能分析"></a>Redis性能分析</h1><p>Redis 是单进程单线程的模型，因为 Redis 完全是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。</p><h2 id="Redis速度快的原因分析"><a href="#Redis速度快的原因分析" class="headerlink" title="Redis速度快的原因分析"></a>Redis速度快的原因分析</h2><ul><li><p>Redis 完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度是 O(1)。</p></li><li><p>数据结构简单，对数据操作也简单。</p></li><li><p>采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的 CPU 切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗。</p></li><li><p>使用多路复用 IO 模型，非阻塞 IO。//todo</p></li></ul><h2 id="Redis-vs-Memcached"><a href="#Redis-vs-Memcached" class="headerlink" title="Redis vs. Memcached"></a>Redis vs. Memcached</h2><ul><li><p>存储方式上：Memcache 会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis 有部分数据存在硬盘上，这样能保证数据的持久性。</p></li><li><p>数据支持类型上：Memcache 对数据类型的支持简单，只支持简单的 key-value，，而 Redis 支持五种数据类型。</p></li><li><p>使用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。Redis 直接自己构建了 VM 机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</p></li><li><p>Value 的大小：Redis 可以达到 1GB，而 Memcache 只有 1MB。</p></li></ul><h2 id="Redis-淘汰策略"><a href="#Redis-淘汰策略" class="headerlink" title="Redis 淘汰策略"></a>Redis 淘汰策略</h2><table><thead><tr><th>策略</th><th>描述</th></tr></thead><tbody><tr><td>volatile-lru</td><td>从已设置过期时间的KV集中优先对最近最少使用的数据 (less recently usesd) 淘汰</td></tr><tr><td>volatile-ttl</td><td>从已设置过期时间的KV集中优先对剩余时间短的数据 (time to live) 淘汰</td></tr><tr><td>volatile-random</td><td>从已设置过期时间的KV集中随机淘汰</td></tr><tr><td>allKeys-lru</td><td>从所有KV集中优先对最近最少使用的数据 (less recently usesd) 淘汰</td></tr><tr><td>allKeys-random</td><td>从所有KV集中随机淘汰</td></tr><tr><td>noeviction</td><td>不淘汰，若超过最大内存，返回错误信息</td></tr></tbody></table><h1 id="Redis持久化机制"><a href="#Redis持久化机制" class="headerlink" title="Redis持久化机制"></a>Redis持久化机制</h1><p>Redis 为了保证效率，数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。当 Redis 重启的时候，它会优先使用 AOF 文件来还原数据集，因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。</p><h2 id="AOF-Append-Only-File"><a href="#AOF-Append-Only-File" class="headerlink" title="AOF (Append Only File)"></a>AOF (Append Only File)</h2><p>把所有的对 Redis 的服务器进行修改的<strong>命令</strong>都存到一个文件里，命令的集合。Redis 默认是快照 RDB 的持久化方式。</p><ul><li>工作方式<ul><li>使用 AOF 做持久化，每一个写命令都通过 write 函数追加到 appendonly.aof 中</li></ul></li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">appendfsync</span> <span class="hljs-literal">yes</span><br>appendfsync always     <span class="hljs-comment">#每次有数据修改发生时都会写入AOF文件。</span><br>appendfsync everysec   <span class="hljs-comment">#每秒钟同步一次，该策略为AOF的缺省策略。</span><br></code></pre></td></tr></table></figure><p>AOF 可以做到全程持久化，只需要在配置中开启 appendonly yes。这样 Redis 每执行一个修改数据的命令，都会把它添加到 AOF 文件中，当 Redis 重启时，将会读取 AOF 文件进行重放，恢复到 Redis 关闭前的最后时刻。</p><ul><li><p>优点</p><ul><li>让 Redis 变得非常耐久。可以设置不同的 Fsync 策略，AOF的默认策略是每秒钟 Fsync 一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。</li></ul></li><li><p>缺点</p><ul><li>对于相同的数据集来说，AOF 的文件体积通常要大于 RDB 文件的体积。根据所使用的 Fsync 策略，AOF 的速度可能会慢于 RDB。</li></ul></li></ul><h2 id="RDB-Redis-Database"><a href="#RDB-Redis-Database" class="headerlink" title="RDB (Redis Database)"></a>RDB (Redis Database)</h2><p>快照形式是直接把内存中的数据保存到一个 dump 的文件中，定时保存，保存策略。</p><ul><li>工作方式<ul><li> 当 Redis 需要做持久化时，Redis 会 fork 一个子进程，子进程将数据写到磁盘上一个临时 RDB 文件中。</li><li> 当子进程完成写临时文件后，将原来的 RDB 替换掉，这样的好处是可以 copy-on-write。</li></ul></li><li>优点<ul><li>这种文件非常适合用于备份：比如，你可以在最近的 24 小时内，每小时备份一次，并且在每个月的每一天也备份一个 RDB 文件。RDB 非常适合灾难恢复。</li></ul></li><li>缺点<ul><li>如果你需要尽量避免在服务器故障时丢失数据，那么RDB不合适你。 </li></ul></li></ul><p>如果你非常关心你的数据，但仍然可以承受数分钟内的数据丢失，那么可以额只使用 RDB 持久。AOF 将 Redis 执行的每一条命令追加到磁盘中，处理巨大的写入会降低Redis的性能，不知道你是否可以接受。数据库备份和灾难恢复：定时生成 RDB 快照非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度快。当然了，Redis 支持同时开启 RDB 和 AOF，系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。</p><h1 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h1><h2 id="整体步骤"><a href="#整体步骤" class="headerlink" title="整体步骤"></a>整体步骤</h2><ul><li>从节点执行 slaveof[masterIP][masterPort]，保存主节点信息。</li><li>从节点中的定时任务发现主节点信息，建立和主节点的 Socket 连接。</li><li>从节点发送 Ping 信号，主节点返回 Pong，两边能互相通信。</li><li>连接建立后，主节点将所有数据发送给从节点（数据同步）。</li><li>主节点把当前的数据同步给从节点后，便完成了复制的建立过程。接下来，主节点就会持续的把写命令发送给从节点，保证主从数据一致性。</li></ul><h2 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul><li>runId：每个 Redis 节点启动都会生成唯一的 uuid，每次 Redis 重启后，runId 都会发生变化。</li><li>offset：主节点和从节点都各自维护自己的主从复制偏移量 offset，当主节点有写入命令时，offset=offset+命令的字节长度。<br>从节点在收到主节点发送的命令后，也会增加自己的 offset，并把自己的 offset 发送给主节点。<br>这样，主节点同时保存自己的 offset 和从节点的 offset，<strong>通过对比 offset 来判断主从节点数据是否一致</strong>。</li><li>repl_backlog_size：保存在主节点上的一个固定长度的先进先出队列，默认大小是 1MB。</li></ul><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><ul><li>Redis 2.8 之前使用 sync[runId][offset] 同步命令，Redis 2.8 之后使用 psync[runId][offset] 命令。</li><li>两者不同在于，Sync 命令仅支持全量复制过程，Psync 支持全量和部分复制。</li></ul><h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><h3 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h3><pre><code class=" mermaid">graph RL;  从Redis-- 发送sync命令 --&gt;主Redis  主Redis-- 发送RDB文件 --&gt;从Redis  主Redis-- 发送缓冲获得所有写命令 --&gt;从Redis</code></pre><ul><li>复制过程：<ul><li>slave 服务启动，slave 会建立和 master 的连接，发送 sync 命令。</li><li>master 启动一个后台进程将数据库快照保存到 RDB 文件中<ul><li>注意：此时如果生成 RDB 文件过程中存在写数据操作会导致 RDB 文件和当前主 redis 数据不一致，所以此时 master 主进程会开始收集写命令并缓存起来。</li></ul></li><li>master 就发送 RDB 文件给 slave</li><li>slave 将文件保存到磁盘上，然后加载到内存恢复</li><li>master 把缓存的命令转发给 slave<ul><li>注意：后续 master 收到的写命令都会通过开始建立的连接发送给 slave。</li></ul></li><li>当 master 和 slave 的连接断开时 slave 可以自动重新建立连接。如果 master 同时收到多个 slave 发来的同步连接命令，只会启动一个进程来写数据库镜像，然后发送给所有 slave。</li></ul></li><li>问题</li></ul><h3 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h3><p>首次同步</p><pre><code class=" mermaid">graph RL;  从Redis-- 发送psync命令 --&gt;主Redis  主Redis-- 发送RDB文件 --&gt;从Redis  主Redis-- 发送缓冲获得所有写命令 --&gt;从Redis</code></pre><p>非首次同步</p><pre><code class=" mermaid">graph RL;  从Redis-- 发送psync命令 --&gt;主Redis  主Redis-- 发送部分非同步数据文件 --&gt;从Redis</code></pre><ul><li>复制过程<ul><li>从机连接主机后，会主动发起 PSYNC 命令，从机会提供 master 的 runid(机器标识，随机生成的一个串) 和 offset（数据偏移量，如果offset主从不一致则说明数据不同步）</li><li>主机验证 runid 和 offset 是否有效，runid 相当于主机身份验证码，用来验证从机上一次连接的主机<ul><li>如果 runid 验证未通过则，则进行全同步，如果验证通过则说明曾经同步过，根据 offset 同步部分数据。</li></ul></li></ul></li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.kancloud.cn/mayan0718/php/515287">https://www.kancloud.cn/mayan0718/php/515287</a></p><h1 id="Sentinel-哨兵机制"><a href="#Sentinel-哨兵机制" class="headerlink" title="Sentinel 哨兵机制"></a>Sentinel 哨兵机制</h1><h2 id="哨兵机制简介"><a href="#哨兵机制简介" class="headerlink" title="哨兵机制简介"></a>哨兵机制简介</h2><ul><li>Sentinel(哨兵) 进程是用于监控 Redis 集群中 Master 主服务器工作的状态</li><li>在 Master 主服务器发生故障的时候，可以实现 Master 和 Slave 服务器的切换，保证系统的高可用（High Availability）</li><li>Sentinel 本身没有主从之分，只有 Redis 服务节点有主从之分。</li></ul><h2 id="哨兵进程的作用"><a href="#哨兵进程的作用" class="headerlink" title="哨兵进程的作用"></a>哨兵进程的作用</h2><ul><li>监控(Monitoring)：哨兵(sentinel) 会不断地检查你的 Master 和 Slave 是否运作正常。</li><li>提醒(Notification)：当被监控的某个Redis节点出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知。（使用较少）</li><li>自动故障迁移(Automatic failover)：当一个 Master 不能正常工作时，哨兵(sentinel) 会开始一次自动故障迁移操作。具体操作如下：<ul><li>它会将失效 Master 的其中一个 Slave 升级为新的 Master, 并让失效 Master 的其他Slave 改为复制新的 Master。</li><li>当客户端试图连接失效的 Master 时，集群也会向客户端返回新 Master 的地址，使得集群可以使用现在的 Master 替换失效 Master。</li><li>Master 和 Slave 服务器切换后，Master 的 redis.conf、Slave 的 redis.conf 和sentinel.conf 的配置文件的内容都会发生相应的改变，即 Master 主服务器的 redis.conf 配置文件中会多一行 slaveof 的配置，sentinel.conf 的监控目标会随之调换。</li></ul></li></ul><h2 id="哨兵的工作方式"><a href="#哨兵的工作方式" class="headerlink" title="哨兵的工作方式"></a>哨兵的工作方式</h2><ul><li><p><strong>每个</strong> Sentinel（哨兵）进程以<strong>每秒钟一次</strong>的频率向整个集群中的<strong>Master主服务器，Slave 从服务器以及其他 Sentinel（哨兵）进程</strong>发送一个 PING 命令。</p></li><li><p>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为<strong>主观下线（SDOWN）</strong>。</p></li><li><p>如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态。</p></li><li><p>当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为<strong>客观下线（ODOWN）</strong>。</p></li><li><p>在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master 主服务器、Slave 从服务器发送 INFO 命令。</p></li><li><p>当 Master 主服务器被 Sentinel（哨兵）进程标记为<strong>客观下线（ODOWN）</strong>时，Sentinel（哨兵）进程向下线的 Master 主服务器的所有 Slave 从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。</p></li><li><p>若没有足够数量的 Sentinel（哨兵）进程同意 Master 主服务器下线， Master 主服务器的<strong>客观下线</strong>状态就会被移除。若 Master 主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master 主服务器的主观下线状态就会被移除。</p></li><li><img src="/2020/07/03/Redis/sentinel.jpg" class="" title="sentinel"></li></ul><h2 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/44474652">https://zhuanlan.zhihu.com/p/44474652</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>LeetCode那些事</title>
    <link href="/2020/06/29/LeetCode%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <url>/2020/06/29/LeetCode%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="Q146-LRU-Cache"><a href="#Q146-LRU-Cache" class="headerlink" title="Q146 LRU Cache"></a>Q146 LRU Cache</h1><p>Design and implement a data structure for Least Recently Used (LRU) cache. It should support the following operations: get and put.</p><p>get(key) - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.<br>put(key, value) - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.</p><p>The cache is initialized with a positive capacity.</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><h3 id="LinkedHashMap"><a href="#LinkedHashMap" class="headerlink" title="LinkedHashMap"></a>LinkedHashMap</h3><h4 id="LinkedHashMap-vs-HashMap"><a href="#LinkedHashMap-vs-HashMap" class="headerlink" title="LinkedHashMap vs. HashMap"></a>LinkedHashMap vs. HashMap</h4><p>大多数情况下，只要不涉及线程安全问题，Map基本都可以使用HashMap，不过HashMap有一个问题，就是迭代HashMap的顺序并不是HashMap放置的顺序，也就是无序。HashMap的这一缺点往往会带来困扰，因为有些场景，我们期待一个<strong>有序</strong>的Map.</p><ul><li><p>LinkedHashMap = LinkedList + HashMap</p></li><li><p>accessOrder   </p><ul><li>false： 基于插入顺序    </li><li>true：  基于访问顺序 </li></ul></li></ul><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://juejin.im/post/5a4b433b6fb9a0451705916f">https://juejin.im/post/5a4b433b6fb9a0451705916f</a></p><h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LRUCache</span> </span>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> capacity;<br>    <span class="hljs-keyword">private</span> LinkedHashMap&lt;Integer, Integer&gt; map;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">LRUCache</span><span class="hljs-params">(<span class="hljs-keyword">int</span> capacity)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.capacity = capacity;<br>        map = <span class="hljs-keyword">new</span> LinkedHashMap&lt;&gt;(capacity, <span class="hljs-number">1</span>, <span class="hljs-keyword">true</span>);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">get</span><span class="hljs-params">(<span class="hljs-keyword">int</span> key)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (!map.containsKey(key)) &#123;<br>            <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> map.get(key);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">put</span><span class="hljs-params">(<span class="hljs-keyword">int</span> key, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (!map.containsKey(key)) &#123;<br>            <span class="hljs-keyword">if</span> (map.size() &gt;= capacity) &#123;<br>                <span class="hljs-keyword">for</span> (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123;<br>                    map.remove(entry.getKey());<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>        map.put(key, value);<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL笔记</title>
    <link href="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="数据库三大范式"><a href="#数据库三大范式" class="headerlink" title="数据库三大范式"></a>数据库三大范式</h1><h2 id="第一范式"><a href="#第一范式" class="headerlink" title="第一范式"></a>第一范式</h2><p>每个列都不可以再拆分</p><h2 id="第二范式"><a href="#第二范式" class="headerlink" title="第二范式"></a>第二范式</h2><p>第一范式 + 非主键完全依赖于主键，而不能是依赖于主键的一部分</p><h2 id="第三范式"><a href="#第三范式" class="headerlink" title="第三范式"></a>第三范式</h2><p>第二范式 + 非主键列只依赖于主键，不依赖于其他非主键</p><p><a href="https://www.cnblogs.com/linjiqin/archive/2012/04/01/2428695.html">https://www.cnblogs.com/linjiqin/archive/2012/04/01/2428695.html</a></p><hr><h1 id="B树和B-树"><a href="#B树和B-树" class="headerlink" title="B树和B+树"></a>B树和B+树</h1><h2 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h2><p>我们知道，二叉树的查找的时间复杂度是O(logN)，其查找效率与深度有关，而普通的二叉树可能由于内部节点排列问题退化成链表，这样查找效率就会很低。因此平衡二叉树是更好的选择，因为它保持平衡，即通过旋转调整结构保持最小的深度。其查找的时间复杂度也是O(logN)。但实际上，数据库中索引的结构也并非AVL树或更优秀的红黑树，尽管它的查询的时间复杂度很低。</p><blockquote><p>为什么平衡二叉树不适合作为索引<br>不选择平衡二叉树的原因并不是因为O(logN)的时间复杂度不够好。</p></blockquote><p>索引是存在于索引文件中，是存在于磁盘中的。因为索引通常是很大的，因此无法一次将全部索引加载到内存当中，因此每次只能从磁盘中读取一个磁盘页的数据到内存中。而这个磁盘的读取的速度较内存中的读取速度而言是差了好几个级别。</p><p>注意，我们说的平衡二叉树结构，指的是逻辑结构上的平衡二叉树，其物理实现是数组。然后由于在逻辑结构上相近的节点在物理结构上可能会差很远。因此，每次读取的磁盘页的数据中有许多是用不上的。因此，查找过程中要进行许多次的磁盘读取操作。而适合作为索引的结构应该是尽可能少的执行磁盘IO操作，因为执行磁盘IO操作非常的耗时。因此，平衡二叉树并不适合作为索引结构。</p><h2 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h2><p>平衡二叉树没能充分利用磁盘预读功能，而B树是为了充分利用磁盘预读功能来而创建的一种数据结构，也就是说B树就是为了作为索引才被发明出来的的。</p><blockquote><p>局部性原理与磁盘预读：由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。</p></blockquote><blockquote><p>这样做的理论依据是计算机科学中著名的局部性原理：<br>当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。</p></blockquote><h2 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h2><blockquote><p>为什么B+树会比B树更加优秀</p></blockquote><p>B树：有序数组 + 平衡多叉树</p><p>B+树：有序数组链表 + 平衡多叉树</p><ul><li>B+树的关键字全部存放在叶子节点中，非叶子节点用来做索引，而叶子节点中有一个指针指向一下个叶子节点。做这个优化的目的是为了提高区间访问的性能。而正是这个特性决定了B+树更适合用来存储外部数据。</li><li>MySQL底层对B+Tree进行了进一步优化：在叶子节点中是双向链表，且在链表的头结点和尾节点也是循环指向的。</li><li>出于对IO性能的考虑，B-Tree的高度更高，IO更频繁。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存，只能逐一加载每一个磁盘页。</li></ul><blockquote><p>B+树还有一个最大的好处，方便扫库，B树必须用中序遍历的方法按序扫库，而B+树直接从叶子结点挨个扫一遍就完了，B+树支持range-query非常方便，而B树不支持。这是数据库选用B+树的最主要原因。比如要查 5-10之间的，B+树一把到5这个标记，再一把到10，然后串起来就行了，B树就非常麻烦。B树的好处，就是成功查询特别有利，因为树的高度总体要比B+树矮。不成功的情况下，B树也比B+树稍稍占一点点便宜。<br>B树比如你的例子中查，17的话，一把就得到结果了，有很多基于频率的搜索是选用B树，越频繁query的结点越往根上走，前提是需要对query做统计，而且要对key做一些变化。<br>另外B树也好B+树也好，根或者上面几层因为被反复query，所以这几块基本都在内存中，不会出现读磁盘IO，一般已启动的时候，就会主动换入内存。”</p></blockquote><img src="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/B+Tree.png" class="" title="B+Tree"><h3 id="B-Tree-的查找过程"><a href="#B-Tree-的查找过程" class="headerlink" title="B+Tree 的查找过程"></a>B+Tree 的查找过程</h3><p>如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。</p><h3 id="B-树的性质"><a href="#B-树的性质" class="headerlink" title="B+树的性质"></a>B+树的性质</h3><ul><li><p>索引字段要尽量的小<br>我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。</p></li><li><p>索引的最左匹配特性(即从左往右匹配)<br>当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。</p></li></ul><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p><a href="">MySQL-索引</a></p><h1 id="MySQL优化"><a href="#MySQL优化" class="headerlink" title="MySQL优化"></a>MySQL优化</h1><h2 id="MySQL逻辑架构"><a href="#MySQL逻辑架构" class="headerlink" title="MySQL逻辑架构"></a>MySQL逻辑架构</h2><img src="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/MySQL%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84.png" class="" title="MySQL逻辑架构"><p>MySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。</p><p>MySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。</p><p>最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。</p><h2 id="MySQL查询过程"><a href="#MySQL查询过程" class="headerlink" title="MySQL查询过程"></a>MySQL查询过程</h2><p>当我们向MySQL发送一个请求，MySQL内部具体流程</p><img src="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B.png" class="" title="MySQL查询过程"><h3 id="客户端-服务端通信协议"><a href="#客户端-服务端通信协议" class="headerlink" title="客户端/服务端通信协议"></a>客户端/服务端通信协议</h3><p>MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。</p><p>客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。</p><p>与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。</p><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。</p><p>MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。</p><p>如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。</p><p>既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：</p><ul><li>任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存</li><li>如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗</li></ul><p>基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：</p><ul><li>用多个小表代替一个大表，注意不要过度设计</li><li>批量插入代替循环单条插入</li><li>合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适</li><li>可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存</li></ul><p>最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。</p><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><ul><li>缓存是如何让使用内存的</li><li>如何控制内存的碎片化</li><li>事务对查询缓存有何影响</li></ul><h3 id="语法解析和预处理"><a href="#语法解析和预处理" class="headerlink" title="语法解析和预处理"></a>语法解析和预处理</h3><p>MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等。</p><h3 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h3><p>经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。</p><p>MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。</p><p>有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样（我们希望执行时间尽可能短，但MySQL值选择它认为成本小的，但成本小并不意味着执行时间短）等等。</p><p>MySQL的查询优化器是一个非常复杂的部件，它使用了非常多的优化策略来生成一个最优的执行计划：</p><ul><li>重新定义表的关联顺序（多张表关联查询时，并不一定按照SQL中指定的顺序进行，但有一些技巧可以指定关联顺序）</li><li>优化MIN()和MAX()函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值，具体原理见下文）</li><li>提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询）</li><li>优化排序（在老版本MySQL会使用两次传输排序，即先读取行指针和需要排序的字段在内存中对其排序，然后再根据排序结果去读取数据行，而新版本采用的是单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序。对于I/O密集型应用，效率会高很多）</li></ul><h3 id="查询执行引擎"><a href="#查询执行引擎" class="headerlink" title="查询执行引擎"></a>查询执行引擎</h3><p>在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为handler API。查询过程中的每一张表由一个handler实例表示。实际上，MySQL在查询优化阶段就为每一张表创建了一个handler实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。存储引擎接口提供了非常丰富的功能，但其底层仅有几十个接口，这些接口像搭积木一样完成了一次查询的大部分操作。</p><h3 id="返回结果给客户端"><a href="#返回结果给客户端" class="headerlink" title="返回结果给客户端"></a>返回结果给客户端</h3><p>查询执行的最后一个阶段就是将结果返回给客户端。即使查询不到数据，MySQL仍然会返回这个查询的相关信息，比如该查询影响到的行数以及执行时间等。</p><p>如果查询缓存被打开且这个查询可以被缓存，MySQL也会将结果存放到缓存中。</p><p>结果集返回客户端是一个增量且逐步返回的过程。有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>客户端向MySQL服务器发送一条查询请求</li><li>服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段</li><li>服务器进行SQL解析、预处理、再由优化器生成对应的执行计划</li><li>MySQL根据执行计划，调用存储引擎的API来执行查询</li><li>将结果返回给客户端，同时缓存查询结果</li></ol><h2 id="性能优化建议"><a href="#性能优化建议" class="headerlink" title="性能优化建议"></a>性能优化建议</h2><h3 id="Schema设计与数据类型优化"><a href="#Schema设计与数据类型优化" class="headerlink" title="Schema设计与数据类型优化"></a>Schema设计与数据类型优化</h3><p>选择数据类型只要遵循小而简单的原则就好，越小的数据类型通常会更快，占用更少的磁盘、内存，处理时需要的CPU周期也更少。越简单的数据类型在计算时需要更少的CPU周期，比如，整型就比字符操作代价低，因而会使用整型来存储ip地址，使用DATETIME来存储时间，而不是使用字符串。</p><ul><li>通常来说把可为NULL的列改为NOT NULL不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为NOT NULL。</li><li>对整数类型指定宽度，比如INT(11)，没有任何卵用。INT使用32位（4个字节）存储空间，那么它的表示范围已经确定，所以INT(1)和INT(20)对于存储和计算是相同的。</li><li>UNSIGNED表示不允许负值，大致可以使正数的上限提高一倍。比如TINYINT存储范围是-128 ~ 127，而UNSIGNED TINYINT存储的范围却是0 - 255。</li><li>通常来讲，没有太大的必要使用DECIMAL数据类型。即使是在需要存储财务数据时，仍然可以使用BIGINT。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用BIGINT存储。这样可以避免浮点数计算不准确和DECIMAL精确计算代价高的问题。</li><li>TIMESTAMP使用4个字节存储空间，DATETIME使用8个字节存储空间。因而，TIMESTAMP只能表示1970 - 2038年，比DATETIME表示的范围小得多，而且TIMESTAMP的值因时区不同而不同。</li><li>大多数情况下没有使用枚举类型的必要，其中一个缺点是枚举的字符串列表是固定的，添加和删除字符串（枚举选项）必须使用ALTER TABLE（如果只只是在列表末尾追加元素，不需要重建表）。</li><li>schema的列不要太多。原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高。</li><li>大表ALTER TABLE非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇技淫巧可以解决这个问题，有兴趣可自行查阅。</li></ul><h3 id="创建高性能索引"><a href="#创建高性能索引" class="headerlink" title="创建高性能索引"></a>创建高性能索引</h3><p>索引是提高MySQL查询性能的一个重要途径，但过多的索引可能会导致过高的磁盘使用率以及过高的内存占用，从而影响应用程序的整体性能。应当尽量避免事后才想起添加索引，因为事后可能需要监控大量的SQL才能定位到问题所在，而且添加索引的时间肯定是远大于初始添加索引所需要的时间，可见索引的添加也是非常有技术含量的。</p><h1 id="MySQL-事务"><a href="#MySQL-事务" class="headerlink" title="MySQL 事务"></a>MySQL 事务</h1><p><a href="https://zhuangzhuang131419.github.io/2021/01/04/MySQL-%E4%BA%8B%E5%8A%A1/">MySQL 事务</a></p><h1 id="MySQL-锁🔐"><a href="#MySQL-锁🔐" class="headerlink" title="MySQL 锁🔐"></a>MySQL 锁🔐</h1><img src="/2020/06/28/MySQL%E7%AC%94%E8%AE%B0/%E9%94%81.png" class="" title="锁"><h2 id="从对数据操作分类"><a href="#从对数据操作分类" class="headerlink" title="从对数据操作分类"></a>从对数据操作分类</h2><h3 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h3><ul><li>读锁 = 共享锁: 针对同一份数据，多个读操作可以同时进行，不会互相影响。<h3 id="写锁"><a href="#写锁" class="headerlink" title="写锁"></a>写锁</h3></li><li>写锁 = 排他锁: 当前写操作没有完成前，会阻断其他写锁和读锁。</li></ul><h2 id="从对数据操作的粒度分类"><a href="#从对数据操作的粒度分类" class="headerlink" title="从对数据操作的粒度分类"></a>从对数据操作的粒度分类</h2><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><ul><li>开销小，加锁快</li><li>锁定粒度大，发生锁冲突的概率较高，并发度较低</li><li>不会出现死锁</li><li>MyISAM和Memory存储引擎采用的是表级锁</li></ul><h3 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h3><ul><li>开销大，加锁慢</li><li>锁定粒度小，发生锁冲突的概率最低，并发度较高</li><li>会出现死锁</li><li>InnoDB存储引擎既支持行级锁也支持表级锁，但默认情况是采用行级锁</li></ul><h3 id="页面锁"><a href="#页面锁" class="headerlink" title="页面锁"></a>页面锁</h3><ul><li>开销和加锁时间介于表锁和行锁之间</li><li>会出现死锁</li><li>锁定粒度界于表锁和行锁之间，并发度一般</li></ul><h2 id="MyISAM-表锁"><a href="#MyISAM-表锁" class="headerlink" title="MyISAM 表锁"></a>MyISAM 表锁</h2><p>MyISAM的表锁有两种模式</p><ul><li>表共享读锁(Table Read Lock): 不会阻塞其他用户对同一表的读请求，不会阻塞对同一表的写请求</li><li>表独占写锁(Table Write Lock): 会阻塞其他用户读同一表的读和写操作</li></ul><h2 id="InnoDB-行锁"><a href="#InnoDB-行锁" class="headerlink" title="InnoDB 行锁"></a>InnoDB 行锁</h2><ul><li>共享锁(S): 允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。</li><li>排他锁(X): 允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。</li><li>意向共享锁(IS): 事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。</li><li>意向排他锁(IX): 事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。</li></ul><h3 id="记录锁"><a href="#记录锁" class="headerlink" title="记录锁"></a>记录锁</h3><p>单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">WHERE</span> id <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br></code></pre></td></tr></table></figure><p>它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行</p><h3 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h3><p>当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”。</p><p>InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。</p><p>对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。</p><p><b>使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据</b></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">WHERE</span> id BETWEN <span class="hljs-number">1</span> <span class="hljs-keyword">AND</span> <span class="hljs-number">10</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span><br></code></pre></td></tr></table></figure><p>即所有在（1，10）区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。</p><h3 id="临键锁"><a href="#临键锁" class="headerlink" title="临键锁"></a>临键锁</h3><p>等于<b>记录锁</b>+<b>间隙锁</b> 它的封锁范围，既包含索引记录，又包含索引区间。(临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。</p><h3 id="特点分析"><a href="#特点分析" class="headerlink" title="特点分析"></a>特点分析</h3><p>InnoDB 这种行锁意味着: 只有通过索引条件检索数据，InnoDB才会使用行级锁，否则，InnoDB将使用表级锁</p><blockquote><p>假设有个表单products 里面有 id 和 name 两个栏位, id 是主键</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sql"># 明确指明主键，并且有这条记录 <span class="hljs-operator">=</span>》行锁<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id<span class="hljs-operator">=</span><span class="hljs-string">&#x27;3&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id<span class="hljs-operator">=</span><span class="hljs-string">&#x27;3&#x27;</span> <span class="hljs-keyword">and</span> type<span class="hljs-operator">=</span><span class="hljs-number">1</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><br># 明确指明主键，但是没有这条记录 <span class="hljs-operator">=</span>》不加锁<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id<span class="hljs-operator">=</span><span class="hljs-string">&#x27;-1&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><br># 无主键 <span class="hljs-operator">=</span>》表锁<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> name<span class="hljs-operator">=</span><span class="hljs-string">&#x27;Mouse&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><br># 主键不明确 <span class="hljs-operator">=</span>》表锁<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id<span class="hljs-operator">&lt;&gt;</span><span class="hljs-string">&#x27;3&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> products <span class="hljs-keyword">WHERE</span> id <span class="hljs-keyword">LIKE</span> <span class="hljs-string">&#x27;3&#x27;</span> <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">UPDATE</span>;<br><br></code></pre></td></tr></table></figure><h2 id="加锁机制"><a href="#加锁机制" class="headerlink" title="加锁机制"></a>加锁机制</h2><h3 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h3><p>乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。</p><h3 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h3><p>悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。</p><h3 id="两种锁机制的适用场景"><a href="#两种锁机制的适用场景" class="headerlink" title="两种锁机制的适用场景"></a>两种锁机制的适用场景</h3><ul><li>悲观锁比较适合写入操作比较频繁的场景，如果出现大量读取的操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。</li><li>乐观锁比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低系统的吞吐量。</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://dbaplus.cn/news-155-1531-1.html">https://dbaplus.cn/news-155-1531-1.html</a></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sftp服务器搭建</title>
    <link href="/2020/06/27/sftp%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"/>
    <url>/2020/06/27/sftp%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><h2 id="1-Linux管理员-root-修改和查看普通用户的密码"><a href="#1-Linux管理员-root-修改和查看普通用户的密码" class="headerlink" title="1. Linux管理员(root)修改和查看普通用户的密码"></a>1. Linux管理员(root)修改和查看普通用户的密码</h2><h3 id="root修改普通用户密码"><a href="#root修改普通用户密码" class="headerlink" title="root修改普通用户密码"></a>root修改普通用户密码</h3><p><code>-&gt; sudo passwd user_name</code></p><h3 id="root查看普通用户密码"><a href="#root查看普通用户密码" class="headerlink" title="root查看普通用户密码"></a>root查看普通用户密码</h3><p>密码是无法被查看的，即使是root也不行，因此普通用户要是遗忘了密码，可以参照上一步，让管理员使用root权限修改密码，然后再将新密码告知普通用户</p><h3 id="普通用户修改自己的密码"><a href="#普通用户修改自己的密码" class="headerlink" title="普通用户修改自己的密码"></a>普通用户修改自己的密码</h3><p><code>-&gt; passwd</code></p><h2 id="2-查看当前用户及用户组"><a href="#2-查看当前用户及用户组" class="headerlink" title="2. 查看当前用户及用户组"></a>2. 查看当前用户及用户组</h2><h3 id="可以查看所有用户的列表"><a href="#可以查看所有用户的列表" class="headerlink" title="可以查看所有用户的列表"></a>可以查看所有用户的列表</h3><p><code>-&gt; cat /etc/passwd</code></p><h3 id="可以查看当前活跃的用户列表"><a href="#可以查看当前活跃的用户列表" class="headerlink" title="可以查看当前活跃的用户列表"></a>可以查看当前活跃的用户列表</h3><p><code>-&gt; w</code></p><h3 id="查看用户组"><a href="#查看用户组" class="headerlink" title="查看用户组"></a>查看用户组</h3><p><code>-&gt; cat /etc/group</code></p><h3 id="查看当前登录用户名"><a href="#查看当前登录用户名" class="headerlink" title="查看当前登录用户名"></a>查看当前登录用户名</h3><p><code>-&gt; who am i</code></p><h3 id="查看用户属于哪一个用户组"><a href="#查看用户属于哪一个用户组" class="headerlink" title="查看用户属于哪一个用户组"></a>查看用户属于哪一个用户组</h3><p><code>-&gt; groups username</code></p><h1 id="开始搭建"><a href="#开始搭建" class="headerlink" title="开始搭建"></a>开始搭建</h1><p>需求：创建三个用户，其中一个为sftp管理员，其余两个分别为指定目录的访问用户。sftp管理员对其他用户的sftp根目录下的内容具有读写权限，限制其他用户只能访问其自己的根目录且仅有读权限；相关的sftp用户不能登录到Linux系统中。</p><h2 id="1-确认openssh的版本"><a href="#1-确认openssh的版本" class="headerlink" title="1. 确认openssh的版本"></a>1. 确认openssh的版本</h2><p><code>-&gt; ssh -V</code><br><img src="/Users/zhuangzhuang/Blog/source/images/sftp-ssh.png"></p><h2 id="2-切换到管理员-root"><a href="#2-切换到管理员-root" class="headerlink" title="2. 切换到管理员(root)"></a>2. 切换到管理员(root)</h2><blockquote><p>也可以不切换在下面的命令行前加<code>sudo</code></p></blockquote><p><code>-&gt; sudo -i</code></p><h2 id="3-创建sftp管理组及用户组"><a href="#3-创建sftp管理组及用户组" class="headerlink" title="3. 创建sftp管理组及用户组"></a>3. 创建sftp管理组及用户组</h2><blockquote><p>添加管理组 bytedance_admin</p></blockquote><p><code>-&gt; groupadd bytedance_admin </code></p><blockquote><p>添加用户组 bytedance</p></blockquote><p><code>-&gt; groupadd bytedance </code></p><h2 id="4-创建sftp管理用户及普通用户"><a href="#4-创建sftp管理用户及普通用户" class="headerlink" title="4. 创建sftp管理用户及普通用户"></a>4. 创建sftp管理用户及普通用户</h2><blockquote><p><code>/bin/false</code> 目的是不让用户登录 也可以使用<code>/bin/nologin</code></p></blockquote><p><code>-&gt; useradd -g bytedance -s /bin/false bob</code></p><p><code>-&gt; useradd -g bytedance -s /bin/false john</code></p><p><code>-&gt; useradd -g bytedance_admin -s /bin/false king</code></p><blockquote><p>为每一位用户设置密码</p></blockquote><p><code>-&gt; passwd king</code></p><p><code>-&gt; passwd bob</code></p><p><code>-&gt; passwd john</code></p><h2 id="5-分别创建对应用户的bytedance根目录并指定为其家目录"><a href="#5-分别创建对应用户的bytedance根目录并指定为其家目录" class="headerlink" title="5. 分别创建对应用户的bytedance根目录并指定为其家目录"></a>5. 分别创建对应用户的bytedance根目录并指定为其家目录</h2><p><code>-&gt; mkdir -pv /usr/bytedance/&#123;bob,john&#125;/share</code></p><h2 id="6-配置sshd-config文件"><a href="#6-配置sshd-config文件" class="headerlink" title="6. 配置sshd_config文件"></a>6. 配置sshd_config文件</h2><p><code>-&gt; vi /etc/ssh/sshd_config</code></p><p>找到如下这行，用#符号注释掉，大致在文件末尾处。 </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Subsystem sftp /usr/libexec/openssh/sftp-server</span><br><br><span class="hljs-string">Subsystem</span> <span class="hljs-string">sftp</span> <span class="hljs-string">internal-sftp</span>     <span class="hljs-comment">#这行指定使用sftp服务使用系统自带的internal-sftp</span><br><br><span class="hljs-string">Match</span> <span class="hljs-string">Group</span> <span class="hljs-string">bytedance</span>     <span class="hljs-comment">#这行用来匹配bytedance组的用户，如果要匹配多个组，多个组之间用逗号分割；</span><br><br><span class="hljs-string">ChrootDirectory</span> <span class="hljs-string">/usr/bytedance/%u</span>        <span class="hljs-comment">#用chroot将用户的根目录指定到%h，%h代表用户home目录，这样用户就只能在用户目录下活动。也可用%u，%u代表用户名。</span><br><br><span class="hljs-string">ForceCommand</span> <span class="hljs-string">internal-sftp</span>    <span class="hljs-comment">#指定sftp命令 </span><br><br><span class="hljs-string">AllowTcpForwarding</span> <span class="hljs-literal">no</span><br><br><span class="hljs-string">X11Forwarding</span> <span class="hljs-literal">no</span><br><br><span class="hljs-string">Match</span> <span class="hljs-string">User</span> <span class="hljs-string">bytedance_admin</span>        <span class="hljs-comment">#匹配用户了，多个用户名之间也是用逗号分割</span><br><br><span class="hljs-string">ChrootDirectory</span> <span class="hljs-string">/usr/bytedance</span><br><br><span class="hljs-string">ForceCommand</span> <span class="hljs-string">internal-sftp</span><br><br><span class="hljs-string">AllowTcpForwarding</span> <span class="hljs-literal">no</span><br><br><span class="hljs-string">X11Forwarding</span> <span class="hljs-literal">no</span><br><br></code></pre></td></tr></table></figure><h2 id="7-设置Chroot目录的权限"><a href="#7-设置Chroot目录的权限" class="headerlink" title="7. 设置Chroot目录的权限"></a>7. 设置Chroot目录的权限</h2><h3 id="chown和chmod-命令"><a href="#chown和chmod-命令" class="headerlink" title="chown和chmod 命令"></a>chown和chmod 命令</h3><blockquote><p>chmod修改的是文件的读、写、执行。</p><p>chown修改的是文件的用户或者组的权限。</p></blockquote><h3 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#修改普通用户的根目录属组</span><br><br>chown root:bytedance <span class="hljs-regexp">/usr/</span>bytedance/&#123;bob,john&#125;<br></code></pre></td></tr></table></figure><p><img src="/Users/zhuangzhuang/Blog/source/images/sftp-chown.png"></p><p>第一个root表示文件所有者 第二个bytedance表示文件所在的群组</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#修改普通用户的根目录权限</span><br>-&gt; chmod <span class="hljs-number">755</span> <span class="hljs-regexp">/usr/</span>bytedance/&#123;bob,john&#125;  <br><br><span class="hljs-comment">#修改管理员的根目录属组</span><br>-&gt; chown root:bytedance_admin <span class="hljs-regexp">/usr/</span>bytedance/<br><br><span class="hljs-comment">#修改管理员根目录的权限</span><br>-&gt; chmod <span class="hljs-number">755</span> <span class="hljs-regexp">/usr/</span>bytedance/<br><br><span class="hljs-comment">#修改各普通用户下的share目录的属主为管理员，属组为普通用户组</span><br>-&gt; chown king:bytedance <span class="hljs-regexp">/usr/</span>bytedance<span class="hljs-regexp">/&#123;bob,john&#125;/</span>share/ <br><br><span class="hljs-comment">#各share目录管理员的权限为读写，普通bytedance组仅有读权限，其他用户没有权限访问</span><br>-&gt; chmod <span class="hljs-number">750</span> <span class="hljs-regexp">/usr/</span>bytedance<span class="hljs-regexp">/&#123;bob,john&#125;/</span>share/<br><br></code></pre></td></tr></table></figure><p>chmod 后面的数字含义参考</p><p><a href="https://chmodcommand.com/">https://chmodcommand.com/</a></p><h2 id="8-关闭selinux"><a href="#8-关闭selinux" class="headerlink" title="8. 关闭selinux"></a>8. 关闭selinux</h2><p><code>-&gt; vim /etc/selinux/config</code></p><p><code>SELINUX=permissive</code></p><p><code>-&gt; setenforce 0</code></p><p>如果提示 <code>setenforce: command not found</code></p><p>解决方案:</p><ul><li><p><code>apt-get install selinux-utils</code></p></li><li><p>添加环境变量<br><code>/usr/sbin/setenforce</code></p></li></ul><h2 id="9-重启sshd服务"><a href="#9-重启sshd服务" class="headerlink" title="9. 重启sshd服务"></a>9. 重启sshd服务</h2><p><code>-&gt; service sshd restart</code></p><p>如果提示<br><code>Job for ssh.service failed because the control process exited with error codesee systemctl status ssh.service and journalctl -xe for details.</code><br>解决方案：</p><ul><li>按照提示<code>systemctl status ssh.service</code><ul><li><img src="/Users/zhuangzhuang/Blog/source/images/sftp-sshd.png"></li></ul></li><li><code>/usr/sbin/sshd -T</code><ul><li>根据具体情况分析</li><li><img src="/Users/zhuangzhuang/Blog/source/images/sftp-sshd02.png"></li><li>这里我的情况是把Match User写到了前面，导致后面的参数读取失败</li></ul></li></ul><p><strong>Tips:</strong><br>请务必解决上述问题，不然sshd重启出错将会导致之后本地无法通过ssh连接开发机</p><h2 id="10-验证sftp登录"><a href="#10-验证sftp登录" class="headerlink" title="10. 验证sftp登录"></a>10. 验证sftp登录</h2><figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs capnproto"><span class="hljs-comment">#管理员登录，能对share目录下的文件进行读写操作</span><br><br>-&gt; sftp king<span class="hljs-symbol">@127</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span><br><br>Connecting to <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>...<br>king<span class="hljs-symbol">@127</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span>&#x27;s password: <br><span class="hljs-comment">#输入之前的密码</span><br><br>sftp&gt; <br><br><span class="hljs-comment">#普通用户登录，对share目录下的文件只能进行读操作</span><br><br>-&gt; sftp bob<span class="hljs-symbol">@127</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span><br><br>bob<span class="hljs-symbol">@127</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span>&#x27;s password: <br><br>sftp&gt; ls<br>share<br><br></code></pre></td></tr></table></figure><p>验证登录出现<code>sftp&gt;</code> 基本就说明了sftp服务器搭建成功了，剩下需要注意的就是权限问题了。此时也可以通过相关的ftp client 如：FileZilla FTP Client 和xftp 来连接到对应的sftp服务器了。</p><h1 id="设置记录sftp服务器的登录及操作日志"><a href="#设置记录sftp服务器的登录及操作日志" class="headerlink" title="设置记录sftp服务器的登录及操作日志"></a>设置记录sftp服务器的登录及操作日志</h1><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.jianshu.com/p/6b588a712513">https://www.jianshu.com/p/6b588a712513</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
